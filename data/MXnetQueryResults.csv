Id,Body,Tags,CreationDate,DeletionDate,Score,OwnerUserId,LastActivityDate,AnswerCount,CommentCount,FavoriteCount,ClosedDate,UserId,Reputation,UpVotes,DownVotes
"34525112","<p>I am trying to compile <code>mxnet</code> (<a href=""http://mxnet.readthedocs.org/en/latest/index.html"" rel=""nofollow"">http://mxnet.readthedocs.org/en/latest/index.html</a>) on OSX Capitan from <code>https://github.com/dmlc/mxnet</code>. After following the installation instructions and verifying that all dependencies are in place I am encountering the following error during the build step:</p>

<pre><code>In file included from src/c_api/./c_api_error.h:9:0,
             from src/c_api/c_api_error.cc:6:
./dmlc-core/include/dmlc/base.h:104:23: fatal error: sys/types.h: No such file or directory
 #include &lt;sys/types.h&gt;
</code></pre>

<p>Tracking down the offending script, <code>../mxnet/dmlc-core/include/dmlc/base.h</code>, I locate what see to be the offending lines: </p>

<pre><code>extern ""C"" {
#include &lt;sys/types.h&gt;
}
</code></pre>

<p>I try out the following patch: </p>

<pre><code>extern ""C"" {
#include &lt;/usr/local/include/c++/4.9.2/parallel/types.h&gt;
}
</code></pre>

<p>which produces the following error: </p>

<pre><code>In file included from /usr/local/include/c++/4.9.2/parallel/types.h:35:0,
             from ./dmlc-core/include/dmlc/base.h:105,
             from src/c_api/c_predict_api.cc:6:
/usr/local/include/c++/4.9.2/cstdlib:72:20: fatal error: stdlib.h: No such file or directory
 #include &lt;stdlib.h&gt;
</code></pre>

<p>Any thoughts? <code>types.h</code> definitely exists on my machine, but the script as I get it from the repo isn't finding that file which is killing the build. </p>
","<c++><unix><deep-learning><mxnet>","2015-12-30 07:40:55","","0","375267","2016-11-07 20:51:31","0","4","","2015-12-30 10:04:51","375267","2427","769","1"
"55362660","<p>I am trying to build and deploy a simple neural network in MXNet and deploy it on a server using mxnet-model-server.</p>

<p>The biggest issue is to deploy the model - model server crashes after uploading the .mar file but I have no idea what the problem could be.</p>

<p>I used the following code to create a custom (but very simple) neural network for testing:</p>

<pre><code>from __future__ import print_function
import numpy as np
import mxnet as mx
from mxnet import nd, autograd, gluon

data_ctx = mx.cpu()
model_ctx = mx.cpu()

# fix the seed
np.random.seed(42)
mx.random.seed(42)

num_examples = 1000

X = mx.random.uniform(shape=(num_examples, 49))
y = mx.random.uniform(shape=(num_examples, 1))
dataset_train = mx.gluon.data.dataset.ArrayDataset(X, y)

dataset_test = dataset_train

data_loader_train = mx.gluon.data.DataLoader(dataset_train, batch_size=25)
data_loader_test = mx.gluon.data.DataLoader(dataset_test, batch_size=25)

num_outputs = 2
net = gluon.nn.HybridSequential()
net.hybridize()
with net.name_scope():
    net.add(gluon.nn.Dense(49, activation=""relu""))
    net.add(gluon.nn.Dense(64, activation=""relu""))
    net.add(gluon.nn.Dense(num_outputs))

net.collect_params().initialize(mx.init.Normal(sigma=.1), ctx=model_ctx)
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .01})

epochs = 1
smoothing_constant = .01

for e in range(epochs):
    cumulative_loss = 0
    for i, (data, label) in enumerate(data_loader_train):
        data = data.as_in_context(model_ctx).reshape((-1, 49))
        label = label.as_in_context(model_ctx)
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)
        loss.backward()
        trainer.step(data.shape[0])
        cumulative_loss += nd.sum(loss).asscalar()
</code></pre>

<p>Following, exported the model using:</p>

<pre><code>net.export(""model_files/my_project"")
</code></pre>

<p>The result are a .json and .params file.</p>

<p>I created a signature.json</p>

<pre><code>{
  ""inputs"": [
    {
      ""data_name"": ""data"",
      ""data_shape"": [
        1,
        49
      ]
    }
  ]
}
</code></pre>

<p>The model handler is the same from the mxnet tutorial:</p>

<pre><code># Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (the ""License"").
# You may not use this file except in compliance with the License.
# A copy of the License is located at
#     http://www.apache.org/licenses/LICENSE-2.0
# or in the ""license"" file accompanying this file. This file is distributed
# on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
# express or implied. See the License for the specific language governing
# permissions and limitations under the License.

""""""
ModelHandler defines a base model handler.
""""""
import logging
import time


class ModelHandler(object):
    """"""
    A base Model handler implementation.
    """"""

    def __init__(self):
        self.error = None
        self._context = None
        self._batch_size = 0
        self.initialized = False

    def initialize(self, context):
        """"""
        Initialize model. This will be called during model loading time

        :param context: Initial context contains model server system properties.
        :return:
        """"""
        self._context = context
        self._batch_size = context.system_properties[""batch_size""]
        self.initialized = True

    def preprocess(self, batch):
        """"""
        Transform raw input into model input data.

        :param batch: list of raw requests, should match batch size
        :return: list of preprocessed model input data
        """"""
        assert self._batch_size == len(batch), ""Invalid input batch size: {}"".format(len(batch))
        return None

    def inference(self, model_input):
        """"""
        Internal inference methods

        :param model_input: transformed model input data
        :return: list of inference output in NDArray
        """"""
        return None

    def postprocess(self, inference_output):
        """"""
        Return predict result in batch.

        :param inference_output: list of inference output
        :return: list of predict results
        """"""
        return [""OK""] * self._batch_size

    def handle(self, data, context):
        """"""
        Custom service entry point function.

        :param data: list of objects, raw input from request
        :param context: model server context
        :return: list of outputs to be send back to client
        """"""
        self.error = None  # reset earlier errors

        try:
            preprocess_start = time.time()
            data = self.preprocess(data)
            inference_start = time.time()
            data = self.inference(data)
            postprocess_start = time.time()
            data = self.postprocess(data)
            end_time = time.time()

            metrics = context.metrics
            metrics.add_time(""PreprocessTime"", round((inference_start - preprocess_start) * 1000, 2))
            metrics.add_time(""InferenceTime"", round((postprocess_start - inference_start) * 1000, 2))
            metrics.add_time(""PostprocessTime"", round((end_time - postprocess_start) * 1000, 2))

            return data
        except Exception as e:
            logging.error(e, exc_info=True)
            request_processor = context.request_processor
            request_processor.report_status(500, ""Unknown inference error"")
            return [str(e)] * self._batch_size

</code></pre>

<p>Following, I created the .mar file using:</p>

<pre><code>model-archiver --model-name my_project --model-path my_project --handler ssd_service:handle
</code></pre>

<p>Starting the model on the server:</p>

<pre><code>mxnet-model-server --start --model_store my_project --models ssd=my_project.mar

</code></pre>

<p>I literally followed every tutorial on:
<a href=""https://github.com/awslabs/mxnet-model-server"" rel=""nofollow noreferrer"">https://github.com/awslabs/mxnet-model-server</a></p>

<p>However, the server is crashing. The worker die, backend worker die, workers are disconnected, Load model failed: ssd, error: worker died</p>

<p>I have absolutely no clue what to do so I would be very glad if you helped me out!</p>

<p>Best</p>
","<python><mxnet>","2019-03-26 17:06:56","","0","10851981","2019-03-26 20:49:48","1","0","","","10851981","15","0","0"
"39216640","<p>I'm trying to recreate the char-level CNN in <a href=""https://arxiv.org/pdf/1606.01781v1.pdf"" rel=""nofollow"">this paper</a> and am a bit stuck at the final step where I need to create a k-max pooling layer, because I am using MXNet and it does not have this.</p>

<blockquote>
  <p>An important difference is also the introduction of multiple temporal
  k-max pooling layers. This allows to detect the k most important
  features in a sentence, independent of their specific position,
  preserving their relative order.</p>
</blockquote>

<p>However, MXNet does have the ability to <a href=""http://mxnet.readthedocs.io/en/latest/how_to/new_op.html"" rel=""nofollow"">add a new-op</a> which I have been trying to do like so (although getting a bit confused with the shape of the data, given filters and batch-size). </p>

<p>The shape of the data coming in:</p>

<pre><code>128 (min-batch) x 512 (number of filters) x 1 (height) x 125 (width)
</code></pre>

<p>The shape of the data coming out (k-max pooling, k = 7):</p>

<pre><code>128 (min-batch) x 512 (number of filters) x 1 (height)  x 7 (width)
</code></pre>

<p>My idea so far ... :</p>

<pre><code>class KMaxPooling(mx.operator.CustomOp):
    def forward(self, is_train, req, in_data, out_data, aux):
        # Desired (k=3):
        # in_data = np.array([1, 2, 4, 10, 5, 3])
        # out_data = [4, 10, 5]
        x = in_data[0].asnumpy()
        idx = x.argsort()[-k:]
        idx.sort(axis=0)
        y = x[idx]
</code></pre>

<p>However, I'm not sure about several things:</p>

<ol>
<li>How to test whether this works (once I have some complete code)</li>
<li>What the dimensions should be? I'm sorting on the last dimension (axis=0)</li>
<li>What to do for the backward() function i.e. the gradient propogation</li>
<li>Whether this will work with GPU - I'm guessing I will have to rewrite it in C/cuda?</li>
</ol>

<p>I found this example by someone else for keras (but don't have the rep to link):</p>

<pre><code>import numpy as np
import theano.tensor as T
from keras.layers.core import MaskedLayer

class KMaxPooling(MaskedLayer):
    def __init__(self, pooling_size):
        super(MaskedLayer, self).__init__()
        self.pooling_size = pooling_size
        self.input = T.tensor3()

    def get_output_mask(self, train=False):
        return None

    def get_output(self, train=False):
        data = self.get_input(train)
        mask = self.get_input_mask(train)

        if mask is None:
            mask = T.sum(T.ones_like(data), axis=-1)
        mask = mask.dimshuffle(0, 1, ""x"")

        masked_data = T.switch(T.eq(mask, 0), -np.inf, data)

        result = masked_data[T.arange(masked_data.shape[0]).dimshuffle(0, ""x"", ""x""),
                             T.sort(T.argsort(masked_data, axis=1)[:, -self.pooling_size:, :], axis=1),
                             T.arange(masked_data.shape[2]).dimshuffle(""x"", ""x"", 0)]
</code></pre>
","<python><neural-network><deep-learning><conv-neural-network><mxnet>","2016-08-29 23:25:43","","3","6772173","2018-01-19 23:13:12","1","0","","","6772173","29","2","0"
"48044595","<p>I am training a neural network in mxnet that does classification, and I would like to put more weight on some of the classes. So besically, I would like to use a weighted version of <a href=""https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.SoftmaxOutput"" rel=""nofollow noreferrer"">mxnet.symbol.SoftmaxOutput</a>. As a toy example, I used a simplified version of <a href=""https://mxnet.incubator.apache.org/tutorials/python/mnist.html"" rel=""nofollow noreferrer"">this mnist code</a>.</p>

<p>Here is the code that defines the network</p>

<pre><code>import mxnet as mx
mnist = mx.test_utils.get_mnist()

batch_size = 100
train_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)

data = mx.sym.var('data')
data = mx.sym.flatten(data=data)


fc1  = mx.sym.FullyConnected(data=data, num_hidden=15)
act1 = mx.sym.Activation(data=fc1, act_type=""relu"")

# MNIST has 10 classes
fc2  = mx.sym.FullyConnected(data=act1, num_hidden=10)
# Softmax with cross entropy loss
mlp  = mx.sym.SoftmaxOutput(data=fc2, name='softmax')
</code></pre>

<p>And here is the code that trains the network:</p>

<pre><code>import logging
logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout
# create a trainable module on CPU
mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())
mlp_model.fit(train_iter,  # train data
              eval_data=val_iter,  # validation data
              optimizer='sgd',  # use SGD to train
              optimizer_params={'learning_rate':0.1},  # use fixed learning rate
              eval_metric='acc',  # report accuracy during training
              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches
              num_epoch=1)  # train for at most 10 dataset passes
</code></pre>

<p>Now let's say that I want to put more weight on the digit 0. I added the following lines right below the definition of <code>mlp</code>:</p>

<pre><code>weight=[[5,1,1,1,1,1,1,1,1,1]]
weight_sym  = mx.symbol.Variable(name=""weight"",
     init=mx.init.Constant(weight), attr={}, shape=(1,10))

mlp=mx.sym.broadcast_mul(mlp,weight_sym)
</code></pre>

<p>Then when I tried to train, I got the error:</p>

<blockquote>
  <p>TypeError: NDArray does not support assignment with [[5, 1, 1, 1, 1,
  1, 1, 1, 1, 1]] of type </p>
</blockquote>

<p>What would be the proper way to do that?</p>
","<python><machine-learning><neural-network><deep-learning><mxnet>","2017-12-31 17:40:56","","0","7214344","2018-02-19 21:34:42","1","1","","","7214344","11864","433","40"
"51713425","<p>We are playing mxnet for a while. still couldnt get full cpu utilization as we have in tensorflow in default.</p>

<p>we have:
python 3.6
mxnet     1.2.1 pos1
mxnet-mkl 1.2.1 pos1</p>

<p>installed via pip (in Pycharm).
mac os x Sierra 10.12.6</p>

<p>we have only 2 core of the cpu used out of the 8 cores.</p>

<p>Thanks</p>
","<multithreading><mxnet>","2018-08-06 18:12:58","","1","9188950","2018-08-06 22:41:07","1","0","1","","9188950","137","10","0"
"46637219","<p>I have a system that generates training data, and I want add loss functions together to get a batch size. I am trying to do (<a href=""https://github.com/aidan-plenert-macdonald/mxnet-the-straight-dope/blob/fef0ac0d3ffebb2f0bb60bdfd90daf78915f97c6/cheatsheets/tensorflow-to-mxnet.ipynb"" rel=""nofollow noreferrer"">full code at commit in question</a>),</p>

<pre><code>for epoch in range(100):
    with mx.autograd.record():
        loss = 0.0
        for k in range(40):
            (i, x), (j, y) = random.choice(data), random.choice(data)
            # Just compute loss on last output
            if i == j:
                loss = loss - l2loss(net(mx.nd.array(x)), net(mx.nd.array(y)))
            else:
                loss = loss + l2loss(net(mx.nd.array(x)), net(mx.nd.array(y)))
        loss.backward()
    trainer.step(BATCH_SIZE)
</code></pre>

<p>But I get an error like,</p>

<pre><code>---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
&lt;ipython-input-39-14981406278a&gt; in &lt;module&gt;()
     21             else:
     22                 loss = loss + l2loss(net(mx.nd.array(x)), net(mx.nd.array(y)))
---&gt; 23         loss.backward()
     24     trainer.step(BATCH_SIZE)
     25     avg_loss += mx.nd.mean(loss).asscalar()

... More trace ...

MXNetError: [16:52:49] src/pass/gradient.cc:187: Operator _copyto is non-differentiable because it didn't register FGradient attribute.
</code></pre>

<p>How do I incrementally add loss functions like I am trying to?</p>
","<mxnet>","2017-10-08 23:59:45","","0","3002273","2017-10-18 22:11:40","1","0","","","3002273","2301","192","12"
"42405537","<p>When I run the example/image-classification/train_mnist.py, I was told that <code>TypeError: fit() got an unexpected keyword argument 'monitor'</code>. I have change nothing in this file. And I have just download the latest version from the github. </p>

<pre><code>example\image-classification&gt;python train_mnist.py
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=N
one, kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs=
'10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_
epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_
k=0, wd=0.0001)
Traceback (most recent call last):
  File ""train_mnist.py"", line 76, in &lt;module&gt;
    fit.fit(args, sym, get_mnist_iter)
  File ""D:\Zhenxingjian\MxNet\mxnet-0.9.3\mxnet-0.9.3\example\image-classificati
on\common\fit.py"", line 183, in fit
    monitor            = monitor)
TypeError: fit() got an unexpected keyword argument 'monitor'
</code></pre>
","<mxnet>","2017-02-23 01:40:16","","0","7608181","2017-06-08 19:14:20","1","0","","","7608181","31","0","0"
"55346475","<p>I am trying to learn how to visualize layer activations in a convolutional neural network using MXNet and Tensorboard. When following the tutorial, however, I run into an error that seems to be related to numpy.</p>

<p>I followed this tutorial:
<a href=""https://medium.com/apache-mxnet/mxboard-mxnet-data-visualization-2eed6ae31d2c"" rel=""nofollow noreferrer"">https://medium.com/apache-mxnet/mxboard-mxnet-data-visualization-2eed6ae31d2c</a></p>

<p>When I am in the conda prompt and enter the code:</p>

<pre><code>tensorboard --logdir=./logs --host=127.0.0.1 --port=8888
</code></pre>

<p>The following error occurs:</p>

<pre><code>ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
ImportError: numpy.core.multiarray failed to import
</code></pre>

<p>I thought I found a solution on the web that claimed that I have installed an older version of numpy (1.14). Which is kind of ironic because MXNet runs witht this older version only. So I am kind of confused...</p>

<p>In general, however, I am totally lost how to visualize the layer activation as others do. So if you know a different way how to do it, I am glad for some help!</p>

<p>Thanks a lot!</p>
","<numpy><tensorboard><mxnet>","2019-03-25 21:12:42","","0","10851981","2019-04-04 23:44:29","1","0","","","10851981","15","0","0"
"38981212","<p>I'm looking for something like this:</p>

<ul>
<li><a href=""https://github.com/rksltnl/Deep-Metric-Learning-CVPR16"" rel=""nofollow"">https://github.com/rksltnl/Deep-Metric-Learning-CVPR16</a></li>
</ul>

<p>but with MXnet or Keras.</p>
","<keras><mxnet>","2016-08-16 17:39:27","","2","2039597","2016-08-16 20:16:48","1","0","2","","2039597","254","179","1"
"46907393","<p>eg: in tensorflow we can do it as followed,how can we do the same thing to control kernel in mxnet,(weights = weights * mask),thank you very much.</p>

<pre><code>if mask_type is not None:
      #C
      mask[:center_h, :, :, :] = 1
      if mask_type == 'A':
        mask[center_h, :center_w, :, :] = 1

      if mask_type == 'B':
        mask[center_h, :center_w+1, :, :] = 1

    else:
      mask[:, :, :, :] = 1

    weights_shape = [kernel_h, kernel_w, in_channel, num_outputs]
    weights = tf.get_variable(""weights"", weights_shape,
      tf.float32, tf.truncated_normal_initializer(stddev=0.1))
    weights = weights * mask
    biases = tf.get_variable(""biases"", [num_outputs],
          tf.float32, tf.constant_initializer(0.0))

    outputs = tf.nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1], padding=""SAME"")
    outputs = tf.nn.bias_add(outputs, biases)
</code></pre>

#

#########this is the full code by tensorflow

<pre><code>def conv2d(inputs, num_outputs, kernel_shape, strides=[1, 1], mask_type=None, scope=""conv2d""):
  with tf.variable_scope(scope) as scope:
    kernel_h, kernel_w = kernel_shape
    stride_h, stride_w = strides
    batch_size, height, width, in_channel = inputs.get_shape().as_list()

    center_h = kernel_h // 2
    center_w = kernel_w // 2

    assert kernel_h % 2 == 1 and kernel_w % 2 == 1, ""kernel height and width must be odd number""
    mask = np.zeros((kernel_h, kernel_w, in_channel, num_outputs), dtype=np.float32)
    if mask_type is not None:
      #C
      mask[:center_h, :, :, :] = 1
      if mask_type == 'A':
        mask[center_h, :center_w, :, :] = 1

      if mask_type == 'B':
        mask[center_h, :center_w+1, :, :] = 1

    else:
      mask[:, :, :, :] = 1

    weights_shape = [kernel_h, kernel_w, in_channel, num_outputs]
    weights = tf.get_variable(""weights"", weights_shape,
      tf.float32, tf.truncated_normal_initializer(stddev=0.1))
    weights = weights * mask
    biases = tf.get_variable(""biases"", [num_outputs],
          tf.float32, tf.constant_initializer(0.0))

    outputs = tf.nn.conv2d(inputs, weights, [1, stride_h, stride_w, 1], padding=""SAME"")
    outputs = tf.nn.bias_add(outputs, biases)

    return outputs
</code></pre>
","<tensorflow><kernel><convolution><mxnet>","2017-10-24 09:53:38","","0","8030005","2018-03-14 08:34:34","1","0","","","8030005","1","0","0"
"51710241","<p>I am trying to write a numpy.ndarray as the labels for Amazon Sagemaker's conversion tool: write_numpy_to_dense_tensor(). It converts a numpy array of  features and labels to a RecordIO for better use of Sagemaker algorithms.</p>

<p>However, if I try to pass a multilabel output for the labels, I get an error stating it can only be a vector (i.e. a scalar for every feature row).</p>

<p>Is there any way of having multiple values in the label? This is useful for multidimensional regressions which can be achieved with XGBoost, Random Forests, Neural Networks, etc.</p>

<p><strong>Code</strong></p>

<pre><code>import sagemaker.amazon.common as smac
print(""Types: {}, {}"".format(type(X_train), type(y_train)))
print(""X_train shape: {}"".format(X_train.shape))
print(""y_train shape: {}"".format(y_train.shape))
f = io.BytesIO()
smac.write_numpy_to_dense_tensor(f, X_train.astype('float32'), y_train.astype('float32'))
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Types: &lt;class 'numpy.ndarray'&gt;, &lt;class 'numpy.ndarray'&gt;
X_train shape: (9919, 2684)
y_train shape: (9919, 20)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-14-fc1033b7e309&gt; in &lt;module&gt;()
      3 print(""y_train shape: {}"".format(y_train.shape))
      4 f = io.BytesIO()
----&gt; 5 smac.write_numpy_to_dense_tensor(f, X_train.astype('float32'), y_train.astype('float32'))

~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/amazon/common.py in write_numpy_to_dense_tensor(file, array, labels)
     94     if labels is not None:
     95         if not len(labels.shape) == 1:
---&gt; 96             raise ValueError(""Labels must be a Vector"")
     97         if labels.shape[0] not in array.shape:
     98             raise ValueError(""Label shape {} not compatible with array shape {}"".format(

ValueError: Labels must be a Vector
</code></pre>
","<python><mxnet><amazon-sagemaker>","2018-08-06 14:43:44","","0","5615492","2018-08-13 18:50:28","1","0","","","5615492","89","43","0"
"51710506","<p>I wrote a program which contains an algorithm called distributed randomized gradient descent (DRGD). There are some internal variables in the algorithm which are used to calculate the step lengths. The training algorithms should be much complex than DRGD, so there should be more internal variables. If we preserve these variables, we can pause training and test the model; then, we will resume the training again. </p>
","<machine-learning><mxnet>","2018-08-06 14:57:56","","-1","9033700","2019-04-12 19:09:12","2","1","","","9033700","156","2","0"
"48957333","<p><a href=""https://mxnet.incubator.apache.org/how_to/s3_integration.html"" rel=""nofollow noreferrer"">This</a> page talks about reading training data from S3 bucket directly. Does anybody know if the data is read in a streaming fashion or if the entire training data is copied to a local cache before training begins?</p>
","<mxnet>","2018-02-23 22:50:38","","0","124091","2018-02-23 22:50:38","1","0","","","124091","1107","99","1"
"47029809","<p>The simple examples in the Guon tutorial for mxnet are very helpful to those of us who are just getting started with mxnet. As yet, there is not a simple example for model parallelism. I see the model parallelism example code for <a href=""https://github.com/eric-haibin-lin/mxnet/tree/master/example/model-parallel-lstm"" rel=""nofollow noreferrer"">LSTM</a>, but I am new to mxnet and it would help me (and perhaps others) to have a more streamlined example. So, I have created a model parallelism example by working off the regression example in the gluon tutorial, and by mixing in some code from <a href=""https://mxnet.incubator.apache.org/api/python/gluon.html#mxnet.gluon.Trainer"" rel=""nofollow noreferrer"">mxnet.gluon.Trainer</a>.</p>

<p>However, I am clearly getting something wrong. The gradients do not seem to be updated. Can anyone assist by identifying the problem(s)? The goal here is to create a linear regression model that has three layers, each held on a different gpu. The model itself is not useful, except as an example to show how initialization and training can occur for model parallelism, when using a custom block and imperative programming.</p>

<p>As I understand it, Trainer() is written for data parallelism. It will not work for model parallelism in that it requires all parameters to be initialized on all GPUs.</p>

<pre><code>import os
import numpy as np
import mxnet as mx
from mxnet import nd, autograd, gluon
from mxnet.gluon import Block

# make some data
num_inputs = 2
num_outputs = 1
num_examples = 10000

def real_fn(X):
    return 2 * X[:, 0] - 3.4 * X[:, 1] + 4.2

X = np.random.normal(0,1, (num_examples, num_inputs))
noise = 0.001 * np.random.normal(0,1, (num_examples))
y = real_fn(X) + noise
y = y.reshape(-1,1)

# configuration
hidden_layers = 2
num_gpus = hidden_layers + 1
ctxList = [mx.gpu(i) for i in range(num_gpus)]
#ctxList = [mx.gpu() for i in range(num_gpus)]

#os.environ[""MXNET_ENGINE_TYPE""] = ""NaiveEngine""
print(""\n"")

# ======================================================================
class myDenseBlock(Block):
    """"""
    A custom layer
    """"""
    def __init__(self, layer_number, size_input, size_output, **kwargs):
        super(myDenseBlock, self).__init__(**kwargs)

        self.layer_number = layer_number
        self.size_input = size_input
        self.size_output = size_output

        with self.name_scope():
            # add parameters to the Block's ParameterDict.
            self.w = self.params.get(
                'weight',
                init= mx.init.Xavier(magnitude=2.24),
                shape=(size_input, size_output),
                grad_req = 'write')

            self.b = self.params.get(
                'bias',
                init= mx.init.Constant(0.5),
                shape=(size_output,),
                grad_req = 'write')

    def forward(self, x):
        x = x.as_in_context(ctxList[self.layer_number])
        with x.context:
            linear = nd.dot(x, self.w.data()) + self.b.data()
            return linear

# ======================================================================

# create net
net = gluon.nn.Sequential()
with net.name_scope():
    # initial layer, with X as input
    net.add(myDenseBlock(0,
        size_input = 2,
        size_output = 2))

    for ii in range(hidden_layers-1):
        net.add(myDenseBlock(ii+1,
            size_input = 2,
            size_output = 2))

    # final block, Y is nx1
    net.add(myDenseBlock(ii+2,
        size_input = 2,
        size_output = 1))


# ititialize paramerters for different blocks (layers) on different gpus.
params = net.collect_params()

""""""
The parameters are:
sequential0_mydenseblock0_weight
sequential0_mydenseblock0_bias
sequential0_mydenseblock1_weight
sequential0_mydenseblock1_bias
sequential0_mydenseblock2_weight
sequential0_mydenseblock2_bias
""""""

print(""\ninitializing:"")
for i, param in enumerate(params):
    if 'mydenseblock0' in param:
        params[param].initialize(ctx=ctxList[0])
    elif 'mydenseblock1' in param:
        params[param].initialize(ctx=ctxList[1])
    elif 'mydenseblock2' in param:
        params[param].initialize(ctx=ctxList[2])
    print(""  "", i, param, ""  "", params[param].list_data()[0].context)
print(""\n"")

def square_loss(yhat, y):
    return nd.mean((yhat - y) ** 2)

def mytrainer(updaters, params, ignore_stale_grad=False):
    #print(""\n"")
    for i, param in enumerate(params):
        #print(i, param, ""  "", len(params[param].list_data()), params[param].list_data()[0].context)
        if params[param].grad_req == 'null':
            continue
        if not ignore_stale_grad:
            for data in params[param].list_data():
                if not data._fresh_grad:
                    print(
                        ""`%s` on context %s has not been updated""%(params[param].name, str(data.context)))
                    assert False

        for upd, arr, grad in zip(updaters, params[param].list_data(), params[param].list_grad()):

            if not ignore_stale_grad or arr._fresh_grad:
                upd(i, grad, arr)
                arr._fresh_grad = False
                #print (""grad= "", grad)


batch_size = 100
epochs = 100000
iteration = -1

opt = mx.optimizer.create('adam', learning_rate=0.001, rescale_grad = 1 / batch_size)
updaters = [mx.optimizer.get_updater(opt)]

# the following definition for updaters does not work either
#updaters = [mx.optimizer.get_updater(opt) for _ in ctxList]

results = []
for e in range(epochs):
    train_groups = np.array_split(np.arange(X.shape[0]), X.shape[0]/batch_size)
    for ii, idx in enumerate(train_groups):
        iteration += 1
        xtrain, ytrain = X[idx,:], y[idx]

        xtrain = nd.array(xtrain)
        xtrain = xtrain.as_in_context(ctxList[0])

        ytrain = nd.array(ytrain).reshape((-1, 1))
        ytrain = ytrain.as_in_context(ctxList[0])

        with autograd.record():
            yhat = net(xtrain)
            error = square_loss(yhat, ytrain.as_in_context(ctxList[-1]))


            # Question: does the call to error.backward() go under the indent 
            # for autograd.record() or outside the indent? The gluon examples have 
            # it both ways

        error.backward()

        mytrainer(updaters, net.collect_params())

        if iteration%10 == 0:

            results.append([iteration, error.asnumpy().item()])
            print((""epoch= {:5,d}, iter= {:6,d},  error= {:6.3E}"").format(
                e, iteration, error.asnumpy().item()))
</code></pre>

<p>The code fails at the ""if not data._fresh_grad"" test in mytrainer(). The output is:</p>

<pre><code>initializing:
   0 sequential0_mydenseblock0_weight    gpu(0)
   1 sequential0_mydenseblock0_bias    gpu(0)
   2 sequential0_mydenseblock1_weight    gpu(1)
   3 sequential0_mydenseblock1_bias    gpu(1)
   4 sequential0_mydenseblock2_weight    gpu(2)
   5 sequential0_mydenseblock2_bias    gpu(2)

`sequential0_mydenseblock0_weight` on context gpu(0) has not been updated
</code></pre>

<p>I can verify using <code>mx.autograd.get_symbol(error).tojson()</code> that the computational graph only extends to the parameters on gpu(2), and does not reach other gpus. </p>
","<python><mxnet>","2017-10-31 07:16:50","","1","3730571","2018-02-28 21:38:20","1","2","1","","3730571","11","0","0"
"47672253","<p>I can create a model using the pre-build high-level functions like <code>FullyConnected</code>. For example:</p>

<pre><code>X = mx.sym.Variable('data')
P  = mx.sym.FullyConnected(data = X, name = 'fc1', num_hidden = 2)
</code></pre>

<p>In this way I get a symbolic variable <code>P</code> that is dependent on the symbolic variable <code>X</code>. In other words, I have computational graph that can be used to define a model and execute such operations as <code>fit</code> and <code>predict</code>.</p>

<p>Now, I would like to express <code>P</code> through <code>X</code> in a different way. In more detail, instead of using the high-level functionality (like <code>FullyConnected</code>), I would like to specify relations between <code>P</code> and <code>X</code> ""explicitly"", using low-level tensor operations (like matrix multiplication) and symbolic variables representing model parameters (lake weight matrix).</p>

<p>For example to achieve the same as above, I have tried the followig:</p>

<pre><code>W = mx.sym.Variable('W')
B = mx.sym.Variable('B')
P = mx.sym.broadcast_plus(mx.sym.dot(X, W), B)
</code></pre>

<p>However, <code>P</code> obtained this way is not equivalent to <code>P</code> obtained earlier. I cannot use it the same way. In particular, as far as I understand, MXNet is complaining that <code>W</code> and <code>B</code> do not have values (which makes sense).</p>

<p>I have also tried to declare <code>W</code> and <code>B</code> in another way (so that they do have values):</p>

<pre><code>w = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
b = np.array([7.0, 8.0])

W = mx.nd.array(w)
B = mx.nd.array(b)
</code></pre>

<p>It does not work as well. I guess that MXNet complains because it expects a symbolic variable but it gets nd-arrays instead.</p>

<p>So, my question is how to build a model using low-level tensor operations (like matrix multiplication) and explicit objects representing model parameters (like weight matrices).</p>
","<mxnet>","2017-12-06 10:40:03","","11","245549","2017-12-29 14:56:15","1","0","1","","245549","29447","811","37"
"53570356","<p>I am trying to use a custom function with an mxnet neural network model. This custom function is supposed to create a fuzzy representation of the final layer activation vector. </p>

<p>I am confused how to make this work as regular python functions are working in an imperative manner, while mxnet is working in a declarative manner (i.e. Symbols). When I try to use my function with the defined model it raises an exception as the parameter is a Symbol not a real array during model declaration.</p>

<p>Any ideas regarding how to make my custom function works in a declarative manner (i.e. like mxnet.sym.concat for example)? </p>

<p>Here is my custom function definition:</p>

<pre><code>def getFuzzyRep(arr):
    fuzzRep = """"
    x_qual = np.arange(0, 11, 0.1)
    qual_lo = fuzz.trimf(x_qual, [0, 0, 0.5])
    qual_md = fuzz.trimf(x_qual, [0, 0.5, 1.0])
    qual_hi = fuzz.trimf(x_qual, [0.5, 1.0, 1.0])
    FuzzVals=[""Low"",""Medium"",""High""]
    i =0
    for val in arr:
        if i == 0:
            fuzzRep = FuzzVals[np.argmax([fuzz.interp_membership(x_qual, qual_lo, val),fuzz.interp_membership(x_qual, qual_md, val),fuzz.interp_membership(x_qual, qual_hi, val)])]
        else:
            fuzzRep = fuzzRep +"",""+FuzzVals[np.argmax([fuzz.interp_membership(x_qual, qual_lo, val),fuzz.interp_membership(x_qual, qual_md, val),fuzz.interp_membership(x_qual, qual_hi, val)])]
        i+=1
    return fuzzRep 
</code></pre>
","<python><neural-network><deep-learning><mxnet><skfuzzy>","2018-12-01 11:31:13","","0","896327","2018-12-27 20:52:52","1","0","","","896327","1383","3","2"
"51704607","<p>I am new of mxnet, in the official doc, the generation of a convolution layer could be </p>

<pre><code>conv = nd.Convolution(data=data, weight=W, bias=b, kernel=(3,3), num_filter=10)
</code></pre>

<p>But it is required that the <code>weight</code> parameter needs to take a 4-D tensor</p>

<pre><code>W = [weight_num, stride, kernel_height, kernel_width]
</code></pre>

<p>So why we still need to set a <code>kernel</code> parameter in <code>Convolution</code> function?</p>
","<python><mxnet>","2018-08-06 09:36:46","","0","6761900","2018-08-07 19:24:41","1","0","","","6761900","160","22","0"
"49169217","<p>I encountered a problem when try to convert the MXNet model to Caffe model.
I find a nodes operation in MXNet that defined as ""op""=""mean"", which seems not been perfectly supported in Caffe.</p>

<pre><code>MXNet Node:

{
  ""op"": ""mean"", 
  ""name"": ""mean0"", 
  ""attr"": {
    ""axis"": ""(2, 3)"", 
    ""keepdims"": ""True""
  }, 
  ""inputs"": [[781, 0, 0]]
}, 
</code></pre>

<p>According to <a href=""https://mxnet.incubator.apache.org/api/python/symbol/symbol.html?highlight=mean#mxnet.symbol.mean"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/api/python/symbol/symbol.html?highlight=mean#mxnet.symbol.mean</a></p>

<p>This node calculates the mean value separately on the axes<a href=""http://caffe.berkeleyvision.org/tutorial/layers/reduction.html"" rel=""nofollow noreferrer"">2</a> and axes[3], and retain the same dimension size of input.</p>

<p>I find a layer in Caffe named ""Reduction Layer"" as <a href=""http://caffe.berkeleyvision.org/tutorial/layers/reduction.html"" rel=""nofollow noreferrer"">http://caffe.berkeleyvision.org/tutorial/layers/reduction.html</a>
which seems doesn't support the mean operation.</p>

<p>Since my target is pretty simple, calculate the mean value on axe<a href=""http://caffe.berkeleyvision.org/tutorial/layers/reduction.html"" rel=""nofollow noreferrer"">2</a> and [3] and return a full dimension sized tensor, I'm not sure whether there is a way to realize this based on the existing Caffe layers.</p>

<p>For example, I considered to use Convolution Layer in Caffe by setting kernel size=1, output=1, weight=1 to realize the average calculation, but how to define the calculation only happened on specific axes?</p>

<p>Any idea is welcome.</p>

<p>Thanks,
Colin </p>
","<tensorflow><protocol-buffers><caffe><mxnet>","2018-03-08 09:05:06","","0","7644655","2018-03-14 08:52:06","1","0","1","","7644655","11","0","0"
"47984969","<p>Given a series of numbers produced by X unique functions, let’s say 12 for this example, is there a way to build a neural network to determine the 12 unique functions which generate the numbers, as well as which of the functions was used to generate the numbers?</p>

<p>Example, if <code>f(x) = a</code> ghen <code>f(x’) = b</code> through l</p>

<p>Example sequence would be:</p>

<p>a, c, g, f, a, k, d, e, j, j, c, k, l… etc Could you identify that function which generates a, b, c…l?</p>

<p>Simpler example with 3 functions:</p>

<pre><code>a = f(x) = x + 1
b = f(x) = x * 2
c = f(x) = x / 2
</code></pre>

<p>a, b, c given 2 as the input would be
3, 4, 1
The sequence could be:</p>

<p>3, 3, 1, 3, 1, 4, 4, 1, 3, 4</p>

<p>Of course, the functions would never be as simple as the examples.</p>

<p>Could you determine that <code>a = x + 1</code>, <code>b = x * 2</code> and <code>c = x/2</code>?</p>
","<python><tensorflow><neural-network><mxnet>","2017-12-27 00:11:23","","2","9143213","2018-03-02 01:58:49","1","1","","","9143213","11","0","0"
"48070604","<p>I am trying to build a custom pooling layer (both for ndarray and Symbol) and <strong>I need to know the input shape at runtime</strong>. According to the documentation, HybridBlock has the function ""infer_shape"", but I can't make it work. Any pointers into what I am doing wrong?</p>

<h2>mxnet version</h2>

<p>1.0.0 , build from conda, python3. </p>

<h2>Minimum reproducible example</h2>

<p>For example: </p>

<pre class=""lang-py prettyprint-override""><code>import mxnet as mx
import mxnet.ndarray as nd
from mxnet.gluon import HybridBlock

class runtime_shape(HybridBlock):


    def __init__(self,  **kwards):
        HybridBlock.__init__(self,**kwards)


    def hybrid_forward(self,F,_input):

        print (self.infer_shape(_input))

        return _input

xx = nd.random_uniform(shape=[5,5,16,16])

mynet = runtime_shape()
mynet.hybrid_forward(nd,xx)
</code></pre>

<h2>Error Message:</h2>

<pre class=""lang-py prettyprint-override""><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-41-3f539a940958&gt; in &lt;module&gt;()
----&gt; 1 mynet.hybrid_forward(nd,xx)

&lt;ipython-input-38-afc9785b716d&gt; in hybrid_forward(self, F, _input)
     17     def hybrid_forward(self,F,_input):
     18 
---&gt; 19         print (self.infer_shape(_input))
     20 
     21         return _input

 /home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.pyc in infer_shape(self, *args)
    460     def infer_shape(self, *args):
    461         """"""Infers shape of Parameters from inputs.""""""
--&gt; 462         self._infer_attrs('infer_shape', 'shape', *args)
    463 
    464     def infer_type(self, *args):

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.pyc in _infer_attrs(self, infer_fn, attr, *args)
    448     def _infer_attrs(self, infer_fn, attr, *args):
    449         """"""Generic infer attributes.""""""
--&gt; 450         inputs, out = self._get_graph(*args)
    451         args, _ = _flatten(args)
    452         arg_attrs, _, aux_attrs = getattr(out, infer_fn)(

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.pyc in _get_graph(self, *args)
    369             params = {i: j.var() for i, j in self._reg_params.items()}
    370             with self.name_scope():
--&gt; 371                 out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter
    372             out, self._out_format = _flatten(out)
    373 

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.pyc in __exit__(self, ptype, value, trace)
     78         if self._block._empty_prefix:
     79             return
---&gt; 80         self._name_scope.__exit__(ptype, value, trace)
     81         self._name_scope = None
     82         _BlockScope._current = self._old_scope

AttributeError: 'NoneType' object has no attribute '__exit__'
</code></pre>
","<python><python-3.x><mxnet>","2018-01-03 03:01:19","","1","3830606","2018-03-06 20:04:58","1","0","","","3830606","360","183","0"
"37409728","<p>Now i am reading source code in mxnet. The code about reading data is that 
  train_dataiter = mx.io.MNISTIter().And I found the class MNISTIter: public IIterator {}is implenmented in src/io. How can it jump from python to c++?I have wondered how wrapped.Who can help to explained?</p>
","<mxnet>","2016-05-24 09:37:35","","1","5030342","2017-05-26 17:49:29","1","0","","","5030342","73","0","0"
"47007209","<p>In python interface,we can use a mini-batch examples to make prediction like <code>net([[1,2],[3,4],[5,6]])</code>.</p>

<p>But in C++,I can't find a way to do this.</p>

<p>Suppose calling the net to predict a single example needs 10ms. If there is 10000 examples needs to make prediction, that is 100s</p>

<pre><code>void OneInputOneOutputPredict(PredictorHandle pred_hnd, std::vector&lt;mx_float&gt; vector_data, std::vector&lt;mx_float&gt; &amp;output)
{
    MXPredSetInput(pred_hnd, ""data"", vector_data.data(), vector_data.size());

    // Do Predict Forward
    MXPredForward(pred_hnd);

    mx_uint output_index = 0;
    mx_uint *shape = 0;
    mx_uint shape_len;
    MXPredGetOutputShape(pred_hnd, output_index, &amp;shape, &amp;shape_len);
    size_t size = 1;
    for (mx_uint i = 0; i &lt; shape_len; ++i) size *= shape[i];

    std::vector&lt;float&gt; data(size);
    assert(0 == MXPredGetOutput(pred_hnd, output_index, &amp;(data[0]), size));
    output = data;
}

//very long time
for(int step=0;step&lt;10000;step++)
    OneInputOneOutputPredict(pred_hnd, vector_data, vector_label);
</code></pre>

<p>Could we use vectorize the code or something way in C++ that make it fast in prediction?</p>
","<mxnet>","2017-10-30 02:03:39","","0","3759377","2017-10-31 02:33:10","1","0","","","3759377","272","78","3"
"47607676","<p>I have 4 NVIDIA 1080 GPUs (11GB each), 128GB RAM , and I am using a 1600w EVGA supernova P2 power supply in my lab. I am new to deep learning. I want to get a sense of what is normal behaviour during training in terms of the hardware. </p>

<p>I have 70000 medical images that are 256x256x3. I am doing end to end training with AlexNet. </p>

<p>If I set the batch size to anything more than 18 using 3 of my GPUs the computer powers down and then restarts. GPU burn works fine on all GPUs and if I use batches of 4-8 I can use all 4 GPUs. Despite all this, the temperature of the GPUs sticks at 70-75 with no more than 60% utilisation on each of the 3 GPUs. </p>

<p>Is this normal - I would have thought I could train batches of more generous proportions with this hardware. </p>

<p>Thanks. </p>
","<tensorflow><deep-learning><training-data><mxnet>","2017-12-02 12:00:39","","-1","2576839","2017-12-02 12:55:16","1","0","","","2576839","957","119","4"
"46704238","<p>When training deep CNN, a common way is to use <strong>SGD with momentum with a ""step"" learning rate policy</strong> (e.g. learning rate set to be 0.1,0.01,0.001.. at different stages of training).But I encounter an unexpected phenomenon  when training with this strategy under MXNet.</p>

<p>That is the periodic training loss value
<a href=""https://user-images.githubusercontent.com/26757001/31327825-356401b6-ad04-11e7-9aeb-3f690bc50df2.png"" rel=""nofollow noreferrer"">https://user-images.githubusercontent.com/26757001/31327825-356401b6-ad04-11e7-9aeb-3f690bc50df2.png</a></p>

<p>The above is the training loss at a fixed learning rate 0.01, where the loss is decreasing normally
<a href=""https://user-images.githubusercontent.com/26757001/31327872-8093c3c4-ad04-11e7-8fbd-327b3916b278.png"" rel=""nofollow noreferrer"">https://user-images.githubusercontent.com/26757001/31327872-8093c3c4-ad04-11e7-8fbd-327b3916b278.png</a></p>

<p>However, at the second stage of training (with lr 0.001) , the loss goes up and down periodically, and the period is exactly an epoch</p>

<p>So I thought it might be the problem of data shuffling, but it cannot explain why it doesn't happen in the first stage.  Actually I used <code>ImageRecordIter</code> as the <code>DataIter</code> and reset it after every epoch, is there anything I missed or set mistakenly?</p>

<pre><code>train_iter = mx.io.ImageRecordIter(
    path_imgrec=recPath,
    data_shape=dataShape,
    batch_size=batchSize,
    last_batch_handle='discard',
    shuffle=True,
    rand_crop=True,
    rand_mirror=True)
</code></pre>

<p>The codes for training and loss evaluation:</p>

<pre><code>while True:
    train_iter.reset()
    for i,databatch in enumerate(train_iter):
                globalIter += 1
        mod.forward(databatch,is_train=True)
        mod.update_metric(metric,databatch.label)
        if globalIter % 100 == 0:
                    loss = metric.get()[1]
                    metric.reset()
                mod.backward()
                mod.update()
</code></pre>

<p>Actually the loss can converge, but it takes too long.
I've suffered from this problem for a long period of time, on different network and different datasets.
I didn't have this problem when using Caffe.  Is this due to the implementation difference?</p>
","<mxnet><loss>","2017-10-12 07:51:37","","0","2854015","2018-05-04 17:50:14","1","1","","","2854015","6","0","0"
"48270301","<p>I need to install an older version of MXNet - 0.7.0, which is no longer available through pip. The source code for the older versions is available here <a href=""https://github.com/apache/incubator-mxnet/releases?after=v0.9.3a"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/releases?after=v0.9.3a</a>, however I am unable to compile the code using make:</p>

<pre><code>Makefile:23: mshadow/make/mshadow.mk: No such file or directory
Makefile:24: /home/usr/incubator-mxnet-0.7.0/dmlc-core/make/dmlc.mk: No such file or directory
Makefile:86: /home/usr/incubator-mxnet-0.7.0/ps-lite/make/ps.mk: No such file or directory
make: *** No rule to make target `/home/usr/incubator-mxnet-0.7.0/ps-lite/make/ps.mk'.  Stop.
</code></pre>

<p>How can I install it? Is there any more straightforward way to install an older version of MXNet?</p>
","<ubuntu><mxnet>","2018-01-15 20:34:16","","2","984007","2019-02-12 09:21:10","2","0","","","984007","1109","402","0"
"46698701","<p>I am trying gap fill a half hourly time series of carbon fluxes. I want to use train-test-validate cross validation to identify the most parsimonious LSTM model by training a model with all available inputs and then pruning it until the score stops improving.  For each model, I'm using k-fold CV to split 90% train, 10% validate, and then in the model.fit(), splitting train further into a train and test set.  I'm using early stopping to help minimize run time and using ModelCheckpoint to save the best weights (the epoch with the lowest ""val_loss"").  Then I want to load those model weights and calculate the validation score (MSE) on the 10% of the data set aside for validation outside the model using the weights that performed best on test set.</p>

<p>Here is a working example of my code training an LSTM with 9 factors and 13 timestimes (the 6 hours leading up to each observation)</p>

<pre><code>import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from itertools import combinations
from functools import partial
from multiprocessing import Pool
from sklearn.neural_network import MLPRegressor as MPR
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.model_selection import RepeatedKFold
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.wrappers.scikit_learn import KerasRegressor
from keras.callbacks import EarlyStopping,ModelCheckpoint
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.9
session = tf.Session(config=config)

def TimeShape(rolls,X1):
    X = np.zeros(shape = (X1.shape[0],rolls+1,X1.shape[1]))
    X[:,0,:] = X1
    if rolls &gt; 0:
        for roll in range(0,rolls):
            X2 = np.roll(X1,(roll+1),axis=0)
            X[:,roll+1,:] = X2
    return(X)

def LSTM_Model(time_steps,inputs,load=None):
    model = Sequential()
    model.add(LSTM(12, input_shape=(time_steps+1,inputs),return_sequences=True,init='normal', activation='tanh'))
    model.add(LSTM(6,init='normal', activation='tanh'))
    model.add(Dense(1, init='normal',activation='linear'))
    NUM_GPU = 1 # or the number of GPUs available on your machine
    gpu_list = []
    for i in range(NUM_GPU): gpu_list.append('gpu(%d)' % i)
    model.compile(loss='mean_squared_error', optimizer='adam',context=gpu_list) # - Add if using MXNET
    return(model)

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.train_losses = []
        self.test_losses = []
    def on_epoch_end(self, batch, logs={}):
        self.train_losses.append(logs.get('loss'))
        self.test_losses.append(logs.get('val_loss'))

class LSTM_Optimize:
    def __init__(self,Path,y_var):
#       **Read and prep Data Data**
        self.Master = pd.read_csv(Path,delimiter = ',',header = 0,na_values = -9999)
        self.Master = self.Master.set_index(pd.DatetimeIndex(pd.to_datetime(self.Master['datetime'])))
        self.Master['DOY'] = self.Master.index.dayofyear*1.0
        self.Master['HR'] = self.Master.index.hour*1.0
        self.Data = self.Master[np.isfinite(self.Master[y_var])]
        self.Data = self.Data.interpolate().bfill()
        self.Data = self.Data.interpolate().ffill()
#       ** Nomralize Y variable**
#       ** Pipeline takes care of X, but not Y, I've foun the models work better when normalizing Y **
        self.y = self.Data[y_var].values
        self.YStandard = StandardScaler()
        self.YScaled = self.YStandard.fit(self.y.reshape(-1, 1))
        Yscale = self.YScaled.transform(self.y.reshape(-1, 1))
        self.y = np.ndarray.flatten(Yscale)
        self.Ytru = self.YScaled.inverse_transform(self.y.reshape(-1,1))

    def Run(self,Inputs):
        # Preparing the input data
        time_steps = 12   
        X = self.Data[Inputs]
        input_shape = len(Inputs)
        self.XStandard = StandardScaler()
        self.XScaled= self.XStandard.fit(X)
        Xscale = self.XScaled.transform(X)
        Xscale = TimeShape(time_steps,Xscale)
        Xscale = Xscale[time_steps+1:,:,:]
        self.y = self.y[time_steps+1:]


        ES = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=25, verbose=1, mode='auto')
        CH = ModelCheckpoint(filepath='weights.hdf5',monitor='val_loss', verbose=0, save_best_only=True)
        HS=LossHistory()
        MSE = []
        kf = RepeatedKFold(n_splits=10,n_repeats=2)
        batch_size=25
        Mod = LSTM_Model(time_steps,input_shape)
        plt.figure(figsize = (7,7))
        for train,test in kf.split(Xscale,self.y):
            Mod.fit(Xscale[train],self.y[train],batch_size=batch_size, nb_epoch=1000,validation_split=0.1,
                    shuffle=True,callbacks=[ES,CH,HS],verbose=0)
            Y = Mod.predict(Xscale[test],batch_size = batch_size)
            Mod.load_weights('weights.hdf5')
            Y = Mod.predict(Xscale[test],batch_size = batch_size)
            MSE.append(metrics.mean_squared_error(self.y[test],Y))
            plt.plot(HS.test_losses,linestyle='--')
            plt.plot(HS.train_losses)

        print(Mod.summary())
        print(np.asanyarray(MSE).mean())

Path = 'FluxData.csv'
% matplotlib inline
start_time = time.time()
if __name__ == '__main__':  
    CH4_Model = ['Sedge','Shrubby','Temp','VWC','ustar','wind_speed','air_pressure',
             'PPFD_Avg','NR_Wm2_Avg','AirTC_Avg']
    y_var = 'ch4_flux'
    Model = CH4_Model
    Best = LSTM_Optimize(Path,y_var)
    Best.Run(Model)
    print()
    print(""--- %s seconds ---"" % (time.time() - start_time))
</code></pre>

<p>And here are a few rows of my dataset - the actual series has 1000's of observations</p>

<pre><code>datetime,co2_flux,ch4_flux,ustar,wind_speed,AirTC_Avg,air_pressure,AirTC_Min,RH,PPFD_Avg,NR_Wm2_Avg,VWC,Temp,Sedge,Shrubby
7/11/2016 8:00,-0.337747167,0.011732699,0.404379747,3.887986435,15.07,101118.6513,15.03,92.7,414.2,225.1,0.5895,7.950660426,0.001292044,0.823794007
7/11/2016 8:30,-1.021087283,0.010256442,0.424094541,3.94983083,14.89,101144.0926,14.84,92.8,339.7,177.1,0.5895,8.24119905,0.001058732,0.826866339
7/11/2016 9:00,-0.146511388,0.008503355,0.456274817,4.687202214,14.71,101177.3176,14.63,93.4,354.4,183.7,0.5895,8.146344257,0.000474955,0.84272365
7/11/2016 9:30,0.144368521,0.009458078,0.462915317,4.810986576,14.27,101203.9191,14.2,93.3,370.2,188.4,0.5895,7.995179025,0.00147768,0.854715683
7/11/2016 10:00,1.471425801,0.014895985,0.47095652,5.098075355,13.7,101235.9171,13.62,94.3,462.9,233.9,0.5895,7.521166721,4.64E-05,0.871581919
7/11/2016 10:30,0.889911286,0.01564225,0.487227522,4.969666239,13.13,101277.0195,13.04,96,309.9,155.2,0.5895,7.923818563,8.14E-06,0.880709962
</code></pre>

<p>When I run this with a Tensorflow backed, everything goes smoothly and I get .  Howeverif I try to run it with a MXNet backend, it fails to load the save model weights and I get this traceback:</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-1-14c6597a2feb&gt; in &lt;module&gt;()
    114     Model = CH4_Model
    115     Best = LSTM_Optimize(Path,y_var)
--&gt; 116     Best.Run(Model)
    117     print()
    118     print(""--- %s seconds ---"" % (time.time() - start_time))

&lt;ipython-input-1-14c6597a2feb&gt; in Run(self, Inputs)
     96                     shuffle=True,callbacks=[ES,CH,HS],verbose=0)
     97             Y = Mod.predict(Xscale[test],batch_size = batch_size)
---&gt; 98             Mod.load_weights('weights.hdf5')
     99             Y = Mod.predict(Xscale[test],batch_size = batch_size)
    100             MSE.append(metrics.mean_squared_error(self.y[test],Y))

/usr/local/lib/python3.5/dist-packages/Keras-1.2.2-py3.5.egg/keras/engine/topology.py in load_weights(self, filepath, by_name)
   2718             self.load_weights_from_hdf5_group_by_name(f)
   2719         else:
-&gt; 2720             self.load_weights_from_hdf5_group(f)
   2721 
   2722         if hasattr(f, 'close'):

/usr/local/lib/python3.5/dist-packages/Keras-1.2.2-py3.5.egg/keras/engine/topology.py in load_weights_from_hdf5_group(self, f)
   2804                         weight_values[0] = w
   2805                 weight_value_tuples += zip(symbolic_weights, weight_values)
-&gt; 2806             K.batch_set_value(weight_value_tuples)
   2807 
   2808     def load_weights_from_hdf5_group_by_name(self, f):

/usr/local/lib/python3.5/dist-packages/Keras-1.2.2-py3.5.egg/keras/backend/mxnet_backend.py in batch_set_value(tuples)
   2205     """"""
   2206     for p, w in tuples:
-&gt; 2207         set_value(p, w)
   2208 
   2209 

/usr/local/lib/python3.5/dist-packages/Keras-1.2.2-py3.5.egg/keras/backend/mxnet_backend.py in set_value(x, value)
   2193     if isinstance(value, Number):
   2194         value = [value]
-&gt; 2195     x.bind(mx.nd.array(value))
   2196 
   2197 

/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/ndarray.py in array(source_array, ctx, dtype)
   1295                 raise TypeError('source_array must be array like object')
   1296     arr = empty(source_array.shape, ctx, dtype)
-&gt; 1297     arr[:] = source_array
   1298     return arr
   1299 

/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/ndarray.py in __setitem__(self, key, value)
    384                 _internal._set_value(float(value), out=self)
    385             elif isinstance(value, (np.ndarray, np.generic)):
--&gt; 386                 self._sync_copyfrom(value)
    387             else:
    388                 raise TypeError(

/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/ndarray.py in _sync_copyfrom(self, source_array)
    556             print(self.shape)
    557             raise ValueError('Shape inconsistent: expected %s vs got %s'%(
--&gt; 558                 str(self.shape), str(source_array.shape)))
    559         check_call(_LIB.MXNDArraySyncCopyFromCPU(
    560             self.handle,

ValueError: Shape inconsistent: expected () vs got (1,)
</code></pre>

<p>Why do I want to use MXNet?  It seems to be faster than tensorflow, and I will have to perform train-test-validation on many models with varying inputs and different #s of nodes and hyper-paramters.  I've been able to significantly boost the speed of keras models with a MXNet backend by using multiprocessing to train multiple different models in parallel.  However, using a tensroflow back end I get a thread-lock error when trying to do multiprocessing.</p>

<p>For context, I'm using Deep Learning AMI Ubuntu Linux - 2.3_Sep2017 (ami-d6ee1dae) environment on a p2.xlarge instance.</p>

<p>Any ideas would be greatly appreciated!</p>
","<python><tensorflow><keras><mxnet>","2017-10-11 22:48:57","","0","5683778","2017-12-15 17:50:47","1","2","1","","5683778","351","198","2"
"46937610","<p>I would like to train a neural network whilst utilising all 4 GPU's on my g2.8xarge EC2 instance using MXNet. I am using the following AWS Deep Learning Linux community AMI:</p>

<p>Deep Learning AMI Amazon Linux - 3.3_Oct2017 - ami-999844e0)</p>

<p>As per these <a href=""https://aws.amazon.com/about-aws/whats-new/2017/10/aws-deep-learning-ami-now-supports-pytorch-keras-2-and-latest-deep-learning-frameworks/"" rel=""nofollow noreferrer"">instructions</a>, when I connect to the instance I switch to keras v1 with the MXNet backend by issuing this command:</p>

<pre><code>source ~/src/anaconda3/bin/activate keras1.2_p2
</code></pre>

<p>I have also added the context flag to my python model compile code to utilise the GPU's in MXNet:</p>

<pre><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], context=gpu_list)
</code></pre>

<p>where gpu_list is meant to utilise all 4 GPU's.</p>

<p>However every time I run my code, I get this error message:</p>

<blockquote>
  <p>Epoch 1/300
  [15:09:52] /home/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [15:09:52] src/storage/storage.cc:113: Compile with USE_CUDA=1 to enable GPU usage</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>RuntimeError: simple_bind error. Arguments:
  dense_input_1: (25, 34L)
  [15:09:52] src/storage/storage.cc:113: Compile with USE_CUDA=1 to enable GPU usage</p>
</blockquote>

<p>I have checked the config.mk file in /home/ec2-user/src/mxnet and it contains USE_CUDA=1. I have also issued the 'made' command to try and recompile MXNet with the USE_CUDA=1 flag - no change.</p>

<p>Am I having this issue as I'm using the virtual environment the AWS documentation says to use? Has anyone else had this issue with MXNet on the AWS Deep Learning Ubuntu AMI using this virtual env?</p>

<p>Any suggestions greatly appreciated -</p>
","<amazon-web-services><machine-learning><amazon-ec2><deep-learning><mxnet>","2017-10-25 16:29:10","","0","7582019","2017-10-25 18:50:13","1","0","","","7582019","73","13","0"
"38537567","<p>I have a pre-trained Mxnet model. I need to change last two layers and add new two layers for testing. Basically, I need to create a probability map of the image.
How can i do that ?</p>
","<python><mxnet>","2016-07-23 02:28:55","","5","4891866","2018-03-05 02:17:02","1","0","1","","4891866","80","1","0"
"47160112","<p>Follwoing works fine on windows although throws error on Linux</p>

<pre><code>core &lt;- 5
ctx &lt;- lapply(c(1:core), function(i) {mx.cpu(i)})
</code></pre>

<p>The model function is ""mx.model.FeedForward.create""</p>

<pre><code>The error is ""Error in (function (symbol, ctx, grad.req = ""null"", ...) : Need more shape information to decide the shapes of arguments""
</code></pre>

<p>Although, it works properly when core &lt;- 1</p>
","<r><deep-learning><mxnet>","2017-11-07 14:15:32","","-1","4836299","2018-02-19 17:16:00","1","0","","","4836299","92","0","0"
"49968591","<p>I am trying to use the graph structure of MXNet to speed up some calculations, and I am currently trying to mimic behavior that I have already implemented in PyTorch. However, I am confused on how to properly do this, be it with <a href=""https://mxnet.incubator.apache.org/api/python/gluon/gluon.html#mxnet.gluon.Trainer"" rel=""nofollow noreferrer""><code>gluon.Trainer</code></a> or some other method.</p>

<p>To explain with an example, what I have working in PyTorch is the following (slightly modified to try to give the simplest example), and I want to translate this to MXNet.</p>

<pre><code>import torch.optim


def unconstrained_fit(objective, data, pdf, init_pars, tolerance):
    init_pars.requires_grad = True
    optimizer = torch.optim.Adam([init_pars])
    max_delta = None
    n_epochs = 10000
    for _ in range(n_epochs):
        loss = objective(init_pars, data, pdf)
        optimizer.zero_grad()
        loss.backward()
        init_old = init_pars.data.clone()
        optimizer.step()
        max_delta = (init_pars.data - init_old).abs().max()
        if max_delta &lt; tolerance:
            break
    return init_pars
</code></pre>

<p>As <a href=""https://github.com/zackchase/mxnet-the-straight-dope/blob/master/cheatsheets/pytorch_gluon.md#pytorch-optimizer-vs-gluon-trainer"" rel=""nofollow noreferrer"">The Straight Dope points out in the PyTorch to MXNet cheatsheet</a>, in MXNet one would usually be able to use a Trainer where one would use an <a href=""http://pytorch.org/docs/master/optim.html"" rel=""nofollow noreferrer"">optimizer in PyTorch</a>. However, I don't understand how to properly initialize the Trainer in my case, as where one would usually do something along the lines of</p>

<pre><code>trainer = gluon.Trainer(net.collect_params(), 'adam')
</code></pre>

<p>I assume that I will need to collect the parameters myself as I don't have a neural network that I want to use, but rather <code>objective</code> that I want to minimize. I am confused on how to do this properly, as the below is obviously not correct.</p>

<pre><code>import mxnet as mx
from mxnet import gluon, autograd

def unconstrained_fit(self, objective, data, pdf, init_pars, tolerance):
    ctx = mx.cpu()
    # How to properly do this chunck?
    init_pars = mx.gluon.Parameter('init_pars',
                                   shape=init_pars.shape,
                                   init=init_pars.asnumpy().all)
    init_pars.initialize(ctx=ctx)
    optimizer = mx.optimizer.Adam()
    trainer = gluon.Trainer([init_pars], optimizer)
    ###
    max_delta = None
    n_epochs = 10000
    for _ in range(n_epochs):
        with autograd.record():
            loss = objective(init_pars, data, pdf)
        loss.backward()
        init_old = init_pars.data.clone()
        trainer.step(data.shape[0])
        max_delta = (init_pars.data - init_old).abs().max()
        if max_delta &lt; tolerance:
            break
    return init_pars
</code></pre>

<p>I am clearly misunderstanding something basic, so if anyone can point me to something clarifying that would be helpful. Even more helpful would be if someone understands what I am asking and is able to summarize why what I am doing is wrong.</p>
","<python><mxnet>","2018-04-22 17:10:38","","0","8931942","2018-04-26 21:17:05","1","0","","","8931942","69","124","0"
"47122690","<p>Suppose I have two feature maps F1 and F2 output by a network. I want to compute convolution of F1 and F2. Assume that F1 has shape (1, C, 10, 10) and F2 has shape (1, C, 3, 3) and the wanted result should have shape (1, 1, 8, 8) if pad = 0, stride = 1 and dilate = 1. But, in this way I can only set batchsize to 1 because the kernel of Convolution layer is irrelevant of batchsize, so I cannot set the weights with a batch of output data. </p>

<p>How to implement this using MXNet?</p>

<p>I have come up with one possible way that uses mx.sym.Correlation, but I cannot get the idea how correlation operator computes by reading the doc.
Or, can I set the weight of a mx.sym.Convolution layer to F2, and data to F1? Would this interfere the propagation of grads when training?</p>

<p><strong>[Update]</strong>
What I want to do is like the following example:</p>

<p>By correlation, I mean F2 acts like a correlation kernel (or convolution kernel) that slides on F1. For example,</p>

<pre><code>     1 1 1 2 2
F1 = 2 3 4 1 1
     0 0 0 2 3 

     0 1 0
F2 = 1 0 1
     0 1 0
</code></pre>

<p>Then, the correlation result should be</p>

<pre><code>R = F1 * F2 = 7 5 9 
</code></pre>

<p>where</p>

<pre><code>    1 1 1   0 1 0
7 = 2 3 4 x 1 0 1 = 1 + 2 + 4 + 0
    0 0 0   0 1 0

    1 1 2   0 1 0
5 = 3 4 1 x 1 0 1 = 1 + 3 + 1 + 0
    0 0 2   0 1 0

    1 2 2   0 1 0
9 = 4 1 1 x 1 0 1 = 2 + 4 + 1 + 2
    0 2 3   0 1 0
</code></pre>

<p>In the above example, stride = 1, pad = 0, dilate = 0</p>
","<mxnet>","2017-11-05 14:28:54","","2","4542398","2018-02-06 01:44:29","1","0","1","","4542398","57","15","0"
"47088983","<p>I am wondering if it's possible to provide any <code>r</code> sample code for using word2vec and cnn on text classification in H2O DeepWater R version ? There's very very few documentation on either <code>mexnetR</code> or <code>h2o deep water r</code></p>

<p>I have already used the <code>h2o</code> <code>r</code> version package to train my <code>word2vec</code> <code>word embedding</code> vocabulary lookup table and the document word vector matrix. I am wondering if there's any sample code to combine the lookup table and the original raw text into the  using <code>mxnetR</code> (custom iterator) CNN classification model, or using <code>h2o r</code> to build CNN directly.</p>

<p>I am asking because if I convert all data into the array format at once, then my machine will not have enough memory to support it.</p>
","<r><nlp><word2vec><h2o><mxnet>","2017-11-03 05:23:43","","1","8844226","2017-11-29 06:18:20","1","0","","","8844226","15","1","0"
"37550869","<p>As we know, there is concept about multiplegpu in mxnet,when specify -gpu in command.And if we don't specify gpu,it will run it on cpu.How many cpus do it run ?Can it possible to specify multiple cpu?</p>
","<mxnet>","2016-05-31 16:17:34","","3","5030342","2016-11-07 19:41:15","2","0","","","5030342","73","0","0"
"51754897","<p>I am trying to train a 3D convnet with 3D spatial data using mxnet. When I run the program the loss decreases normally over epochs but the training accuracy and the test accuracy is staying exactly the same. I am very new to neural networks and I have no idea why this is happening. I am not sure if it is because my network parameters are bad or if my data isn't preprocessed properly, or if the code for training the network has problems, or something else entirely.</p>

<p>Here is the code I am currently using for the convnet and the output it produces:</p>

<pre><code>train_data = mx.gluon.data.DataLoader(train_dataset, batch_size= 64,shuffle= True, num_workers = cpucount)
test_data = mx.gluon.data.DataLoader(test_dataset,batch_size= 64,shuffle= True, num_workers = cpucount)

batch_size = 64
num_inputs = 2541
num_outputs = 2
num_fc = 635
net = gluon.nn.Sequential()

with net.name_scope():
    net.add(gluon.nn.Conv3D(channels=1, kernel_size=3, activation='relu'))
    net.add(gluon.nn.MaxPool3D(pool_size=2, strides=2))
    net.add(gluon.nn.Conv3D(channels=1, kernel_size=3, activation='relu'))
    net.add(gluon.nn.MaxPool3D(pool_size=2, strides=2))

    net.add(gluon.nn.Flatten())

    net.add(gluon.nn.Dense(num_fc, activation=""relu""))
    net.add(gluon.nn.Dense(num_outputs))

net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .0001})

def evaluate_accuracy(data_iterator, net):
    acc = mx.metric.Accuracy()
    for i, (data, label) in enumerate(data_iterator):
        data = data.as_in_context(ctx)
        label = label.as_in_context(ctx)
        output = net(data)
        predictions = nd.argmax(output,axis = 1)
        label = label.reshape(len(label))
        acc.update(preds=predictions, labels=label)
    return acc.get()[1]

epochs = 100
smoothing_constant = .01

for e in range(epochs):
    for i, (data, label) in enumerate(train_data):
        data = data.as_in_context(ctx)
        label = label.as_in_context(ctx)
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)
        loss.backward()
        trainer.step(data.shape[0])

        curr_loss = nd.mean(loss).asscalar()
        moving_loss = (curr_loss if ((i == 0) and (e == 0))
                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)

    test_accuracy = evaluate_accuracy(test_data, net)
    train_accuracy = evaluate_accuracy(train_data, net)
</code></pre>

<p>output:
Epoch 0. Loss: 26525280.32107588, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 1. Loss: 17045452.882872812, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 2. Loss: 10953605.785322478, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 3. Loss: 7038914.162310514, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 4. Loss: 4523287.90677917, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 5. Loss: 2906717.2884657932, Train_acc 0.462039045553, Test_acc 0.386554621849
Epoch 6. Loss: 1867890.253548351, Train_acc 0.462039045553, Test_acc 0.386554621849</p>

<p>(I omitted the rest of the epochs but even when loss was around 0.09 the accuracies were still the same)</p>
","<python><conv-neural-network><mxnet>","2018-08-08 20:12:39","","0","10171841","2018-08-08 20:12:39","0","2","","","10171841","6","0","0"
"48272913","<p>Assume  I have a Resnet34 pretained model in MXNet and I want to add to it the premade ROIPooling Layer included in the API:</p>

<p><a href=""https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html#mxnet.ndarray.ROIPooling"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html#mxnet.ndarray.ROIPooling</a></p>

<p>If the code for initializing Resnet is the following, how can I add ROIPooling at the last layer of the Resnet features before the classifier?</p>

<p>Actually, how can I utilize the ROIPooling function in my model in general?</p>

<p>How can I incorporate multiple different ROIs in the ROIpooling layer? How should they be stored? <strong>How should the data iterator be changed in order to give me the Batch index required by the ROIPooling function ?</strong></p>

<p>Let us assume that I use this along with the VOC 2012 Dataset for the task of action recognition</p>

<pre><code>batch_size = 40
num_classes = 11
init_lr = 0.001
step_epochs = [2]

train_iter, val_iter, num_samples = get_iterators(batch_size,num_classes)
resnet34 = vision.resnet34_v2(pretrained=True, ctx=ctx)

net = vision.resnet34_v2(classes=num_classes)

class ROIPOOLING(gluon.HybridBlock):
    def __init__(self):
        super(ROIPOOLING, self).__init__()

    def hybrid_forward(self, F, x):
        #print(x)
        a = mx.nd.array([[0, 0, 0, 7, 7]]).tile((40,1))
        return F.ROIPooling(x, a, (2,2), 1.0)

net_cl = nn.HybridSequential(prefix='resnetv20')
with net_cl.name_scope():
    for l in xrange(4):
        net_cl.add(resnet34.classifier._children[l])
    net_cl.add(nn.Dense(num_classes,  in_units=resnet34.classifier._children[-1]._in_units))

net.classifier = net_cl
net.classifier[-1].collect_params().initialize(mx.init.Xavier(rnd_type='gaussian', factor_type=""in"", magnitude=2), ctx=ctx)

net.features = resnet34.features
net.features._children.append(ROIPOOLING())

net.collect_params().reset_ctx(ctx)
</code></pre>
","<python><deep-learning><mxnet><resnet>","2018-01-16 01:30:19","","9","1351721","2018-03-01 01:58:24","1","0","1","","1351721","270","113","3"
"40671490","<p>I want to config the <code>config.mk</code>file to use the <code>cuda</code>. I modified these options:</p>

<pre><code>USE_CUDA = 1
ADD_LDFLAGS = /usr/local/cuda-8.0/lib64
ADD_CFLAGS = /usr/local/cuda-8.0/lib64
USE_CUDA_PATH = /usr/local/cuda 
USE_CUDNN = 1
USE_NVRTC = 1
</code></pre>

<p>while I run <code>make -j8</code>, I got the errors below:</p>

<pre><code>cd /home/wanger/MXNet/mxnet/dmlc-core; make libdmlc.a USE_SSE=1 config=/home/wanger/MXNet/mxnet/config.mk; cd /home/wanger/MXNet/mxnet
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/ndarray/ndarray_function_gpu.o src/ndarray/ndarray_function.cu &gt;build/src/ndarray/ndarray_function_gpu.d
make[1]: Entering directory '/home/wanger/MXNet/mxnet/dmlc-core'
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/optimizer/sgd_gpu.o src/optimizer/sgd.cu &gt;build/src/optimizer/sgd_gpu.d
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/operator/convolution_gpu.o src/operator/convolution.cu &gt;build/src/operator/convolution_gpu.d
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/operator/svm_output_gpu.o src/operator/svm_output.cu &gt;build/src/operator/svm_output_gpu.d
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/operator/leaky_relu_gpu.o src/operator/leaky_relu.cu &gt;build/src/operator/leaky_relu_gpu.d
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/operator/lrn_gpu.o src/operator/lrn.cu &gt;build/src/operator/lrn_gpu.d
/usr/local/cuda /bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/home/wanger/MXNet/mxnet/mshadow/ -I/home/wanger/MXNet/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -msse3 -I/usr/local/cuda /include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 /usr/local/cuda-8.0/lib64 -DMXNET_USE_NVRTC=1"" -M -MT build/src/operator/fully_connected_gpu.o src/operator/fully_connected.cu &gt;build/src/operator/fully_connected_gpu.d
/bin/sh: 1: /usr/local/cuda: Permission denied
Makefile:184: recipe for target 'build/src/ndarray/ndarray_function_gpu.o' failed
make: *** [build/src/ndarray/ndarray_function_gpu.o] Error 126
make: *** Waiting for unfinished jobs....
/bin/sh: 1: /usr/local/cuda: Permission denied
/bin/sh: 1: /usr/local/cuda: Permission denied
Makefile:184: recipe for target 'build/src/optimizer/sgd_gpu.o' failed
make: *** [build/src/optimizer/sgd_gpu.o] Error 126
Makefile:184: recipe for target 'build/src/operator/convolution_gpu.o' failed
make: *** [build/src/operator/convolution_gpu.o] Error 126
/bin/sh: 1: /usr/local/cuda: Permission denied
/bin/sh: 1: /usr/local/cuda: Permission denied
Makefile:184: recipe for target 'build/src/operator/svm_output_gpu.o' failed
make: *** [build/src/operator/svm_output_gpu.o] Error 126
Makefile:184: recipe for target 'build/src/operator/lrn_gpu.o' failed
make: *** [build/src/operator/lrn_gpu.o] Error 126
/bin/sh: 1: /usr/local/cuda: Permission denied
Makefile:184: recipe for target 'build/src/operator/fully_connected_gpu.o' failed
make: *** [build/src/operator/fully_connected_gpu.o] Error 126
make[1]: 'libdmlc.a' is up to date.
make[1]: Leaving directory '/home/wanger/MXNet/mxnet/dmlc-core'
/bin/sh: 1: /usr/local/cuda: Permission denied
Makefile:184: recipe for target 'build/src/operator/leaky_relu_gpu.o' failed
make: *** [build/src/operator/leaky_relu_gpu.o] Error 126
</code></pre>
","<deep-learning><ubuntu-16.04><mxnet>","2016-11-18 07:21:20","","1","5793660","2016-11-18 21:22:17","1","4","","","5793660","1713","91","1"
"46841490","<p>This is python code to generate a <strong>simple multi-ports MLP model-two inputs,two outputs</strong>.Using <code>HybridBlock</code> and <code>erport</code> functions make it possible to use in C++.</p>

<p>Net Graph:</p>

<p><a href=""https://i.stack.imgur.com/dlT3z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dlT3z.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/Y5ES1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y5ES1.png"" alt=""enter image description here""></a></p>

<pre><code>from mxnet import nd
from mxnet.gluon import nn
import mxnet as mx

class HybridNet(nn.HybridBlock):
    def __init__(self, **kwargs):
        super(HybridNet, self).__init__(**kwargs)
        with self.name_scope():
            self.dense0 = nn.Dense(3)
            self.dense1 = nn.Dense(3)
            self.dense2 = nn.Dense(6)

    def hybrid_forward(self, F,x,y):
        result1 = F.relu(self.dense0(x))+F.relu(self.dense1(y))
        result2 = F.relu(self.dense2(result1))
        return [result1,result2]

net = HybridNet()
net.initialize()
net.hybridize()
x = nd.random.normal(shape=(4,3))
y = nd.random.normal(shape=(4,5))
res=net(x,y)
print ""output1:"",res[0]
print ""output2:"",res[1]
net.export('model')
</code></pre>

<p>We can re-import the model to check weather the exporting is correct.You can see the two result is the same.</p>

<pre><code>from collections import namedtuple
sym = mx.symbol.load('model-symbol.json') 
mod=mx.mod.Module(symbol=sym,data_names=['data0','data1'])
mod.bind(data_shapes=[('data0',(1,3)),('data1',(1,5))])
mod.load_params('model-0000.params')
Batch=namedtuple('Batch',['data'])
mod.forward(Batch(data=[x,y]))
print mod.get_outputs()
</code></pre>

<p><a href=""https://i.stack.imgur.com/OYCFY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OYCFY.png"" alt=""enter image description here""></a></p>

<p>See what outputs look like</p>

<pre><code>sym.list_outputs()
</code></pre>

<blockquote>
  <p>['hybridnet0__plus0_output', 'hybridnet0_relu2_output']</p>
</blockquote>

<p>Here is the first part of the C++ code and it raise error.I make sure the <code>num_input_nodes</code> and <code>num_output_nodes</code> both are two.And using <code>MXPredCreatePartialOut</code> to custom my multi-tasks output.</p>

<p><a href=""https://i.stack.imgur.com/3anwj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3anwj.png"" alt=""enter image description here""></a></p>

<pre><code>#include &lt;mxnet/c_predict_api.h&gt;

#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;assert.h&gt;

// Read file to buffer
class BufferFile {
public:
    std::string file_path_;
    int length_;
    char* buffer_;

    explicit BufferFile(std::string file_path)
        :file_path_(file_path) {

        std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary);
        if (!ifs) {
            std::cerr &lt;&lt; ""Can't open the file. Please check "" &lt;&lt; file_path &lt;&lt; "". \n"";
            length_ = 0;
            buffer_ = NULL;
            return;
        }

        ifs.seekg(0, std::ios::end);
        length_ = ifs.tellg();
        ifs.seekg(0, std::ios::beg);
        std::cout &lt;&lt; file_path.c_str() &lt;&lt; "" ... "" &lt;&lt; length_ &lt;&lt; "" bytes\n"";

        buffer_ = new char[sizeof(char) * length_];
        ifs.read(buffer_, length_);
        ifs.close();
    }

    int GetLength() {
        return length_;
    }
    char* GetBuffer() {
        return buffer_;
    }

    ~BufferFile() {
        if (buffer_) {
            delete[] buffer_;
            buffer_ = NULL;
        }
    }
};

int main(int argc, char* argv[]) {

    // Models path for your model, you have to modify it
    std::string json_file = ""./model-symbol.json"";
    std::string param_file = ""./model-0000.params"";

    BufferFile json_data(json_file);
    BufferFile param_data(param_file);

    // Parameters
    int dev_type = 1;  // 1: cpu, 2: gpu
    int dev_id = 1;  // arbitrary.
    mx_uint num_input_nodes = 2;
    mx_uint num_output_nodes = 2;

    const char* input_key[2] = { ""data0"" , ""data1"" };
    const char** input_keys = input_key;
    const char* output_key[2] = { ""hybridnet0__plus0"" , ""hybridnet0_relu2"" };
    const char** output_keys = output_key;

    // input-dims
    int data0_len = 3;
    int data1_len = 5;
    const mx_uint input_shape_indptr[4] = { 0,2,2,4 };
    const mx_uint input_shape_data[4] = {1,static_cast&lt;mx_uint&gt;(data0_len),1,static_cast&lt;mx_uint&gt;(data1_len) };
    PredictorHandle pred_hnd = 0;

    if (json_data.GetLength() == 0 || param_data.GetLength() == 0)
        return -1;

    // Create Predictor
    assert(0 == MXPredCreatePartialOut(
        (const char*)json_data.GetBuffer(),
        (const char*)param_data.GetBuffer(),
        static_cast&lt;size_t&gt;(param_data.GetLength()),
        dev_type,
        dev_id,
        num_input_nodes,
        input_keys,
        input_shape_indptr,
        input_shape_data,
        num_output_nodes,
        output_keys,
        &amp;pred_hnd));   //ERROR HERE
    assert(pred_hnd);

    return 0;
}
</code></pre>
","<mxnet>","2017-10-20 02:21:51","","0","3759377","2018-10-16 03:17:17","1","0","","","3759377","272","78","3"
"52851829","<p>Fitting convnets such as Resnet and VGG benefits from the ImageRecordIter python class, that allows efficiently loading batches from large collections of RGB images stored in RecordIO .rec files,</p>

<p>Does anybody know about equivalent facilities for large arbitrary input 2D or 3D matrices (for 2D, rows = items and cols = features, + channels in 3D)?</p>

<p>NDArrayIter requires loading the whole dataset in memory, which is to be avoided in my case (>40Gb data file). CSVIter does not allow straightforward shuffling, and works only for 2D matrices.</p>
","<python><python-2.7><mxnet>","2018-10-17 09:44:28","","0","2547462","2018-10-25 00:54:20","1","0","","","2547462","55","7","0"
"46678101","<p>I've spent all day trying to figure out how to work mxnet GPU in R on windows. The package installs fine, but on library(mxnet) I get an error:</p>

<p>Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: unable to load shared object 'C:/Users/Po/Documents/R/win-library/3.4/mxnet/libs/x64/libmxnet.dll':
  LoadLibrary failure:  The specified module could not be found.</p>

<p>Really been taken for a ride with all the 'help' topics. This seems to be a common issue but not widely applicable solution. I've downloaded and updated: CUDA, CUDAnn, NVIDIA drivers, OpenBLAS, cmake, opencv, MS visual studio, git, mlbench,  mingw, MS visual cpp community.... the list goes on. </p>

<p>Some solutions say building and compiling is a work around, but frankly building and compiling is so far out of scope I've had to download half dozen programs just to be left with instructions ""Use CMake to create a Visual Studio solution in ./build."" What does that even mean. </p>

<p>I have checked the directory and am sure libmxnet.dll exists. I feel like I am missing something obvious. </p>
","<r><install><gpu><mxnet>","2017-10-11 00:55:26","","0","8268013","2017-12-10 22:28:45","2","0","1","","8268013","142","18","5"
"47507069","<p>I'm trying to train a list of text datasets at the character level (for example, a cat => ""a"", "" "", ""c"", ""a"", ""t"") so that I can classify them with great accuracy.  I'm using mxnet package (CNN Network) in R and using crepe model.  So to prepare for training, I need to do iterations for both training and test datasets.  So the code is as follow:</p>

<pre><code>train.iter &lt;- CustomCSVIter$new(iter=NULL, data.csv=train.file.output, 
                            batch.size=args$batch_size, alphabet=alphabet,
                            feature.len=feature.len)  
test.iter &lt;- CustomCSVIter$new(iter=NULL, data.csv=test.file.output, 
                           batch.size=args$batch_size, alphabet=alphabet, 
                           feature.len=feature.len)
</code></pre>

<p>data.csv where I have these datasets, batch.size is just an integer, feature.len is also just an integer, and alphabet is a vector of alphanumeric quotations (abcd...?!"""").  When I run the above code, I get a message saying I have a fatal error and Rstudio crashes and reloads.  I don't know what I'm doing wrong.  To run the above code, you need the following function:</p>

<pre><code>CustomCSVIter &lt;- setRefClass(""CustomCSVIter"",
                         fields=c(""iter"", ""data.csv"", ""batch.size"",
                                  ""alphabet"",""feature.len""),
                         contains = ""Rcpp_MXArrayDataIter"",
                         methods=list(
                           initialize=function(iter, data.csv, batch.size,
                                               alphabet, feature.len){
                             csv_iter &lt;- mx.io.CSVIter(data.csv=data.csv, 
                                                       data.shape=feature.len+1, #=features + label
                                                       batch.size=batch.size)
                             .self$iter &lt;- csv_iter 
                             .self$data.csv &lt;- data.csv
                             .self$batch.size &lt;- batch.size
                             .self$alphabet &lt;- alphabet
                             .self$feature.len &lt;- feature.len
                             .self
                           },
                           value=function(){
                             val &lt;- as.array(.self$iter$value()$data)
                             val.y &lt;- val[1,]
                             val.x &lt;- val[-1,]
                             val.x &lt;- dict.decoder(data=val.x, 
                                                   alphabet=.self$alphabet,
                                                   feature.len=.self$feature.len,
                                                   batch.size=.self$batch.size)
                             val.x &lt;- mx.nd.array(val.x)
                             val.y &lt;- mx.nd.array(val.y)
                             list(data=val.x, label=val.y)
                           },
                           iter.next=function(){
                             .self$iter$iter.next()
                           },
                           reset=function(){
                             .self$iter$reset()
                           },
                           num.pad=function(){
                             .self$iter$num.pad()
                           },
                           finalize=function(){
                             .self$iter$finalize()
                           }
                         )
</code></pre>

<p>)</p>
","<r><deep-learning><conv-neural-network><mxnet>","2017-11-27 09:00:20","","0","8197225","2018-02-14 22:31:26","1","0","","","8197225","37","1","0"
"49962411","<p>I trained a cnn in mathematica using the network lenet und exported it as MXnet. How can I use the exported JSON and PARAMS in python to predict? How to load the model? I could not find useful examples or documentation for this. I am using python 3.6 with anaconda.</p>
","<python><conv-neural-network><mxnet>","2018-04-22 04:09:49","","0","3483676","2018-04-25 00:16:58","1","1","","","3483676","42","3","0"
"42105631","<p>if I have a input matrix of 400 rows with 20 features and I have 10 labels then what should be my data_shape and label_shape tuples</p>
","<mxnet>","2017-02-08 05:49:04","","0","7463041","2017-06-06 18:43:49","1","0","","","7463041","81","8","0"
"47081667","<p>So this question is about <a href=""https://arxiv.org/abs/1406.2661"" rel=""nofollow noreferrer"">GANs</a>.</p>

<p>I am trying to do a trivial example for my own proof of concept; namely, generate images of hand written digits (MNIST). While most will approach this via deep convolutional gans (dgGANs), I am just trying to achieve this via the 1D array (i.e. instead of 28x28 gray-scale pixel values, a 28*28 1d array).</p>

<p>This <a href=""https://github.com/greydanus/mnist-gan"" rel=""nofollow noreferrer"">git repo</a> features a ""vanilla"" gans which treats the MNIST dataset as a 1d array of 784 values. Their output values look pretty acceptable so I wanted to do something similar.</p>

<h1>Import statements</h1>

<pre><code>from __future__ import print_function
import matplotlib as mpl
from matplotlib import pyplot as plt
import mxnet as mx
from mxnet import nd, gluon, autograd
from mxnet.gluon import nn, utils
import numpy as np
import os
from math import floor
from random import random
import time
from datetime import datetime
import logging


ctx = mx.gpu()
np.random.seed(3)
</code></pre>

<h1>Hyper parameters</h1>

<pre><code>batch_size = 100
epochs = 100
generator_learning_rate = 0.001
discriminator_learning_rate = 0.001
beta1 = 0.5
latent_z_size = 100
</code></pre>

<h1>Load data</h1>

<pre><code>mnist = mx.test_utils.get_mnist()
# convert imgs to arrays
flattened_training_data = mnist[""test_data""].reshape(10000, 28*28)
</code></pre>

<h1>define models</h1>

<pre><code>G = nn.Sequential()
with G.name_scope():
    G.add(nn.Dense(300, activation=""relu""))
    G.add(nn.Dense(28 * 28, activation=""tanh""))

D = nn.Sequential()
with D.name_scope():
    D.add(nn.Dense(128, activation=""relu""))
    D.add(nn.Dense(64, activation=""relu""))
    D.add(nn.Dense(32, activation=""relu""))
    D.add(nn.Dense(2, activation=""tanh""))


loss = gluon.loss.SoftmaxCrossEntropyLoss()
</code></pre>

<h1>init stuff</h1>

<pre><code>G.initialize(mx.init.Normal(0.02), ctx=ctx)
D.initialize(mx.init.Normal(0.02), ctx=ctx)
trainer_G = gluon.Trainer(G.collect_params(), 'adam', {""learning_rate"": generator_learning_rate, ""beta1"": beta1})
trainer_D = gluon.Trainer(D.collect_params(), 'adam', {""learning_rate"": discriminator_learning_rate, ""beta1"": beta1})

metric = mx.metric.Accuracy()
</code></pre>

<h1>dynamic plot (for juptyer notebook)</h1>

<pre><code>import matplotlib.pyplot as plt
import time

def dynamic_line_plt(ax, y_data, colors=['r', 'b', 'g'], labels=['Line1', 'Line2', 'Line3']):
    x_data = []
    y_max = 0
    y_min = 0
    x_min = 0
    x_max = 0
    for y in y_data:
        x_data.append(list(range(len(y))))
        if max(y) &gt; y_max:
            y_max = max(y)
        if min(y) &lt; y_min:
            y_min = min(y)

        if len(y) &gt; x_max:
            x_max = len(y)

    ax.set_ylim(y_min, y_max)
    ax.set_xlim(x_min, x_max)

    if ax.lines:
        for i, line in enumerate(ax.lines):
            line.set_xdata(x_data[i])
            line.set_ydata(y_data[i])

    else:
        for i in range(len(y_data)):
            l = ax.plot(x_data[i], y_data[i], colors[i], label=labels[i])
        ax.legend()

    fig.canvas.draw()
</code></pre>

<h1>train</h1>

<pre><code>stamp = datetime.now().strftime('%Y_%m_%d-%H_%M')
logging.basicConfig(level=logging.DEBUG)


# arrays to store data for plotting
loss_D = nd.array([0], ctx=ctx)
loss_G = nd.array([0], ctx=ctx)
acc_d = nd.array([0], ctx=ctx)
labels = ['Discriminator Loss', 'Generator Loss', 'Discriminator Acc.']

%matplotlib notebook
fig, ax = plt.subplots(1, 1)
ax.set_xlabel('Time')
ax.set_ylabel('Loss')
dynamic_line_plt(ax, [loss_D.asnumpy(), loss_G.asnumpy(), acc_d.asnumpy()], labels=labels)


for epoch in range(epochs):
    tic = time.time()

    data_iter.reset()

    for i, batch in enumerate(data_iter):
        ####################################
        # Update Disriminator: maximize log(D(x)) + log(1-D(G(z)))
        ####################################

        # extract batch of real data
        data = batch.data[0].as_in_context(ctx)
        # add noise


        # Produce our noisey input to the generator
        latent_z = mx.nd.random_normal(0,1,shape=(batch_size, latent_z_size), ctx=ctx)


        # soft and noisy labels
#         real_label = mx.nd.ones((batch_size, ), ctx=ctx) * nd.random_uniform(.7, 1.2, shape=(1)).asscalar()
#         fake_label = mx.nd.ones((batch_size, ), ctx=ctx) * nd.random_uniform(0, .3, shape=(1)).asscalar()

#         real_label = nd.random_uniform(.7, 1.2, shape=(batch_size), ctx=ctx)
#         fake_label = nd.random_uniform(0, .3, shape=(batch_size), ctx=ctx)

        real_label = mx.nd.ones((batch_size, ), ctx=ctx)
        fake_label = mx.nd.zeros((batch_size, ), ctx=ctx)

        with autograd.record():
            # train with real data
            real_output = D(data)
            errD_real = loss(real_output, real_label)

           # train with fake data
            fake = G(latent_z)
            fake_output = D(fake.detach())
            errD_fake = loss(fake_output, fake_label)

            errD = errD_real + errD_fake
            errD.backward()

        trainer_D.step(batch_size)
        metric.update([real_label, ], [real_output,])        
        metric.update([fake_label, ], [fake_output,])


       ####################################
        # Update Generator: maximize log(D(G(z)))
        ####################################
        with autograd.record():
            output = D(fake)
            errG =  loss(output, real_label)
            errG.backward()

        trainer_G.step(batch_size)



        ####
        # Plot Loss
        ####
        # append new data to arrays
        loss_D = nd.concat(loss_D, nd.mean(errD), dim=0)
        loss_G = nd.concat(loss_G, nd.mean(errG), dim=0)
        name, acc = metric.get()
        acc_d = nd.concat(acc_d, nd.array([acc], ctx=ctx), dim=0)

        # plot array
        dynamic_line_plt(ax, [loss_D.asnumpy(), loss_G.asnumpy(), acc_d.asnumpy()], labels=labels)



    name, acc = metric.get()
    metric.reset()
    logging.info('Binary training acc at epoch %d: %s=%f' % (epoch, name, acc))
    logging.info('time: %f' % (time.time() - tic))
</code></pre>

<h1>output</h1>

<pre><code>img = G(mx.nd.random_normal(0,1,shape=(100, latent_z_size), ctx=ctx))[0].reshape((28, 28))
plt.imshow(img.asnumpy(),cmap='gray')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/w17tn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w17tn.png"" alt=""enter image description here""></a></p>

<p>Now this doesn't get nearly as good as the repo's example from above. Although fairly similar.</p>

<p>Thus I was wondering if you could take a look and figure out why:</p>

<ol>
<li>the colors are inverted</li>
<li>why the results are sub par</li>
</ol>

<p>I have been fiddling around with this trying a lot of various things to improve the results (I will list this in a second), but for the MNIST dataset this really shouldn't be needed.</p>

<p>Things I have tried (and I have also tried a host of combinations):</p>

<ul>
<li>increasing the generator network</li>
<li>increasing the discriminator network</li>
<li>using soft labeling</li>
<li>using noisy labeling</li>
<li>batch norm after every layer in the generator</li>
<li>batch norm of the data</li>
<li>normalizing all values between -1 and 1</li>
<li>leaky relus in the generator</li>
<li>drop out layers in the generator</li>
<li>increased learning rate of discriminator compared to generator</li>
<li>decreased learning rate of i compared to generator</li>
</ul>

<p>Please let me know if you have any ideas.</p>
","<machine-learning><neural-network><mxnet>","2017-11-02 17:51:35","","0","5623899","2018-02-15 19:20:13","1","0","","","5623899","1380","181","12"
"47250630","<p>I have a very simple model that is the data input to a hidden layer with 2 units that then outputs to an activation layer and then to the softmax layer.</p>

<p>mxnet will report the computed bias and weight with something like</p>

<pre><code>fullyconnected0_bias -&gt; [ 1.8431 -1.84309]
fullyconnected0_weight -&gt; 
[
 [-1.22873 -1.22873]
 [ 1.22872  1.22872]
]
</code></pre>

<p>given the geometric intuition that this represents a separating hyperplane, how would one go about plotting this? For some reason I can't find any examples of anyone doing this in my searching? What do the weights and bias represent in terms of plot-able inputs?</p>
","<plot><mxnet>","2017-11-12 15:40:05","","0","4705722","2017-11-17 19:54:13","1","0","","","4705722","118","1397","0"
"41367556","<p>For debugging purpose, I would like to monitor in my fit callback func the learning rate value to make sure my mx.lr_scheduler.MultiFactorScheduler does the job as expected. </p>

<p>Unfortunately the learning rate does not seem the be accessible in the Params. Is there a way do access the actual used lr for the current batch?</p>

<p>Many thanks !</p>
","<mxnet>","2016-12-28 18:16:14","","1","7350566","2016-12-29 20:20:17","1","0","","","7350566","24","2","0"
"50808444","<p>In my experiment, the <strong><em>MxNet</em></strong> may forget saving some parameters of my network. </p>

<p>I am studying mxnet’s <em><strong>gluoncv</strong></em> package (<a href=""https://gluon-cv.mxnet.io/index.html"" rel=""nofollow noreferrer"">https://gluon-cv.mxnet.io/index.html</a>). To learn the programming skills from the engineers, I manually generate an SSD with ‘<strong>gluoncv.model_zoo.ssd.SSD</strong>’. The parameters that I use to initialize this class are the same as the official ‘<strong>ssd_512_resnet50_v1_voc</strong>’ network <em>except</em> ‘<strong>classes=('car', 'pedestrian', 'truck', 'trafficLight', 'biker')</strong>’. </p>

<pre><code>from gluoncv.model_zoo.ssd import SSD
import mxnet as mx
name = 'resnet50_v1'
base_size = 512
features=['stage3_activation5', 'stage4_activation2']
filters=[512, 512, 256, 256]
sizes=[51.2, 102.4, 189.4, 276.4, 363.52, 450.6, 492]
ratios=[[1, 2, 0.5]] + [[1, 2, 0.5, 3, 1.0/3]] * 3 + [[1, 2, 0.5]] * 2
steps=[16, 32, 64, 128, 256, 512]
classes=('car', 'pedestrian', 'truck', 'trafficLight', 'biker')

pretrained=True

net = SSD(network = name, base_size = base_size, features = features, 
          num_filters = filters, sizes = sizes, ratios = ratios, steps = steps,
              pretrained=pretrained, classes=classes)
</code></pre>

<p>I try to feed a manmade <strong>data x</strong> to this network, and it gives following errors.</p>

<pre><code>x = mx.nd.zeros(shape=(batch_size,3,base_size,base_size))
cls_preds, box_preds, anchors = net(x)
</code></pre>

<p><code>RuntimeError: Parameter 'ssd0_expand_trans_conv0_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks</code> </p>

<p>This is reasonable. The SSD uses function ‘<em><strong>gluoncv.nn.feature.FeatureExpander</strong></em>’ to add new layers on the '_<strong>resnet50_v1</strong>_', and I forget to initialize them. So, I use following codes.</p>

<pre><code>net.initialize()
</code></pre>

<p>Oho, it gives me a lot of warnings.</p>

<pre><code>  v.initialize(None, ctx, init, force_reinit=force_reinit)
C:\Users\Bird\AppData\Local\conda\conda\envs\ssd\lib\site-packages\mxnet\gluon\parameter.py:687: UserWarning: Parameter 'ssd0_resnetv10_stage4_batchnorm9_running_mean' is already initialized, ignoring. Set force_reinit=True to re-initialize.
  v.initialize(None, ctx, init, force_reinit=force_reinit)
C:\Users\Bird\AppData\Local\conda\conda\envs\ssd\lib\site-packages\mxnet\gluon\parameter.py:687: UserWarning: Parameter 'ssd0_resnetv10_stage4_batchnorm9_running_var' is already initialized, ignoring. Set force_reinit=True to re-initialize.
  v.initialize(None, ctx, init, force_reinit=force_reinit)
</code></pre>

<p>The '<strong>_resnet50_v1_</strong>' which is the base of SSD are pre-trained, so these parameters cannot be installed. However, these warnings are annoying. </p>

<p><strong>How can I turn them off?</strong> </p>

<p>Here, though, <strong>comes the first problem</strong>. I would like to save the parameters of the network.</p>

<pre><code>net.save_params('F:/Temps/Models_tmp/' +'myssd.params')
</code></pre>

<p>The parameter file of _<strong>'resnet50_v1</strong>_' (‘resnet50_v1-c940b1a0.params’) is <strong>97.7MB</strong>; however, my parameter file is only <strong>9.96MB</strong>. Are there some magical technologies to compress these parameters? </p>

<p>To test this new technology, I open <strong>a new console</strong> and rebuild the same network. Then, I load the saved parameters and feed a data to it.</p>

<pre><code>net.load_params('F:/Temps/Models_tmp/' +'myssd.params')
x = mx.nd.zeros(shape=(batch_size,3,base_size,base_size)) 
</code></pre>

<p><strong>The initialization error comes again</strong>.</p>

<blockquote>
  <p>RuntimeError: Parameter 'ssd0_expand_trans_conv0_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks</p>
</blockquote>

<p>This cannot be right because the saved file 'myssd.params' should contain all the installed parameters of my network.</p>

<p>To find the block ‘_<strong>ssd0_expand_trans_conv0</strong><em>’, I do a deeper research in ‘</em><strong>gluoncv.nn.feature. FeatureExpander</strong>_’. I use ‘<strong><em>mxnet.gluon. nn.Conv2D</em></strong>’ to replace <em><strong>‘mx.sym.Convolution</strong></em>’ in the ‘<strong><em>FeatureExpander</em></strong>’ function.</p>

<blockquote>
<pre><code>'''
        y = mx.sym.Convolution(
            y, num_filter=num_trans, kernel=(1, 1), no_bias=use_bn,
            name='expand_trans_conv{}'.format(i), attr={'__init__': weight_init})
        '''
        Conv1 = nn.Conv2D(channels = num_trans,kernel_size = (1, 1),use_bias = use_bn,weight_initializer = weight_init)
        y = Conv1(y)
        Conv1.initialize(verbose = True)
    '''    
    y = mx.sym.Convolution(
        y, num_filter=f, kernel=(3, 3), pad=(1, 1), stride=(2, 2),
        no_bias=use_bn, name='expand_conv{}'.format(i), attr={'__init__': weight_init})
    '''
    Conv2 = nn.Conv2D(channels = f,kernel_size = (3, 3),padding = (1, 1),strides = (2, 2),use_bias = use_bn, weight_initializer = weight_init)
    y = Conv2(y)
    Conv2.initialize(verbose = True)
</code></pre>
</blockquote>

<p>These new blocks can be initialized manually. However, the MxNet still report <strong><em>the same errors</em></strong>. 
It seems that the manual initialization is of no effect. </p>

<p><strong><em>How can I save all the parameters of my network and restore them?</em></strong></p>
","<machine-learning><deep-learning><computer-vision><mxnet>","2018-06-12 02:26:58","","0","9033700","2018-07-08 14:05:26","1","1","","","9033700","156","2","0"
"42089063","<p>Is the Convolution symbol computed cyclically, i.e., does it assume that the padded input symbol is periodical in all dimensions?</p>

<p>More specifically, if I've got input symbol of dimensions 1x3xHxW, representing an RGB image, and I define a convolution operating on it as below:
conv1 = mxmet.symbol.Convolution(data=input, kernel=(3, 5, 5), pad=(0, 2, 2)...
what the trained filter will look like? I expect it to be composed from linear combinations of 2-D filters operating on each of the color channels R,G,B.</p>

<p>Am I correct?</p>
","<mxnet>","2017-02-07 11:45:28","","0","7518742","2017-02-12 12:21:27","1","1","","","7518742","46","2","0"
"46900388","<p>I am trying to train a LSTM like,</p>

<pre><code>from __future__ import print_function
import mxnet as mx
import numpy as np
from mxnet import nd, autograd, sym
from mxnet import gluon

ctx = mx.cpu()

LIMIT = 20
data = np.array([(s, 1) for s in spanish_sentences[LIMIT]] + [(s, 0) for s in english_sentences[LIMIT]])

layer = mx.gluon.rnn.LSTM(100, 3)
net = mx.gluon.nn.Dense(2)
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()

layer.initialize(ctx=ctx)
net.collect_params().initialize(ctx=ctx)

trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})
for epoch in range(10):
    np.random.shuffle(data)
    losses = []
    for s, l in data:
        if len(s) == 0:
            continue

        x = nd.array([ord(c) for c in s]).reshape(shape=(-1, 1, 1))
        y = nd.array([np.eye(2)[int(l)]])
        with autograd.record():
            output = layer(x)[output.shape[0]-1, :, :]
            pred = net(output)
            loss = softmax_cross_entropy(pred, y)
        losses.append(loss.asscalar())
        trainer.step(1, ignore_stale_grad=True)
    print(""Loss:"", np.mean(losses), ""+-"", np.std(losses))
</code></pre>

<p>But I am getting an error,</p>

<pre><code>---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
&lt;ipython-input-31-12ab8d4ad733&gt; in &lt;module&gt;()
     30             output = layer(x)[output.shape[0]-1, :, :]
     31             pred = net(output)
---&gt; 32             loss = softmax_cross_entropy(pred, y)
     33         losses.append(loss.asscalar())
     34         trainer.step(1, ignore_stale_grad=True)

 ... Stack trace ...

MXNetError: Shape inconsistent, Provided=(1,2), inferred shape=(1,1)
</code></pre>

<p>What is being done wrong? When I test the shape of <code>pred</code> and <code>y</code>, I get that they are both equal to <code>(1, 2)</code>. I don't know why it is expecting <code>(1, 1)</code>.</p>
","<mxnet>","2017-10-24 00:24:57","","1","3002273","2017-10-24 01:53:19","1","0","","","3002273","2301","192","12"
"42150105","<p>I am trying to port some <code>mxnet</code> code from python. I am running into an issue with simple binary operations on symbols. I have a self-contained reproducible example below:</p>

<pre><code>library(mxnet)
data &lt;- mx.symbol.Variable('data')
x &lt;- mx.symbol.FullyConnected(data = data, num.hidden = 10)

&gt; x - 1 # this works
</code></pre>

<blockquote>
  <p>C++ object &lt;0x10229c700> of class 'MXSymbol' &lt;0x10b248c10></p>
</blockquote>

<pre><code>&gt; 1 - x # this doesn't
</code></pre>

<blockquote>
  <p>Error in 1 - x : non-numeric argument to binary operator</p>
</blockquote>

<p>How can I subtract a symbol <em>from</em> a number using mxnet in R?</p>
","<r><mxnet>","2017-02-10 01:39:57","","1","919872","2018-03-03 01:49:21","1","1","","","919872","21472","1023","43"
"47327018","<p>I have created a neural network with mxnet. Now I want to train this model iteratively on new data points. After I simulated a new data point I want to make a new gradient descent update on this model. I do not want to save the model to an external file and load it again.</p>

<p>I have written the following code, but the weights do not change after a new training step. I also get <code>NaN</code> as a training error.</p>

<pre><code>library(mxnet)
data &lt;- mx.symbol.Variable(""data"")
fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden = 2, no.bias = TRUE)
lro &lt;- mx.symbol.LinearRegressionOutput(fc1)

# first data observation
train.x = matrix(0, ncol = 3)
train.y = matrix(0, nrow = 2)

# first training step
model = mx.model.FeedForward.create(lro,
  X = train.x, y = train.y, initializer = mx.init.uniform(0.001),
  num.round = 1, array.batch.size = 1, array.layout = ""rowmajor"",
  learning.rate = 0.1, eval.metric = mx.metric.mae)
print(model$arg.params)

# second data observation
train.x = matrix(0, ncol = 3)
train.x[1] = 1
train.y = matrix(0, nrow = 2)
train.y[1] = -33

# retrain model on new data
# pass on params of old model
model = mx.model.FeedForward.create(symbol = model$symbol,
  arg.params = model$arg.params, aux.params = model$aux.params,
  X = train.x, y = train.y, num.round = 1,
  array.batch.size = 1, array.layout = ""rowmajor"",
  learning.rate = 0.1, eval.metric = mx.metric.mae)
# weights do not change
print(model$arg.params)
</code></pre>
","<r><mxnet>","2017-11-16 10:18:17","","2","5580950","2017-12-01 11:03:59","2","0","","","5580950","1023","83","0"
"55648989","<p>I want to run an <a href=""https://github.com/msracver/Flow-Guided-Feature-Aggregation"" rel=""nofollow noreferrer"">MXNet module</a> in GPU. </p>

<p>I have a system which has Ubuntu 18.04 along Cuda 10.0 installed. Apparently this is not covered yet by MXNet binary files so I was focusing on <a href=""https://medium.com/@zhanwenchen/install-cuda-9-2-and-cudnn-7-1-for-tensorflow-pytorch-gpu-on-ubuntu-16-04-1822ab4b2421"" rel=""nofollow noreferrer"">installing 2 cuda versions</a> in my pc (see also <a href=""https://www.pugetsystems.com/labs/hpc/How-To-Install-CUDA-10-together-with-9-2-on-Ubuntu-18-04-with-support-for-NVIDIA-20XX-Turing-GPUs-1236/"" rel=""nofollow noreferrer"">here</a>).</p>

<p>Anyway I now have 2 cuda toolkits in my pc in different folders. I need a way to direct my system to use Cuda 9.2 when run from PyCharm. The funny thing is that from a typical console I can run it just fine (at least the MXNet loading part that is of course).</p>

<p>In the module I want to run the program is stuck in:</p>

<pre><code>import mxnet as mx
</code></pre>

<p>which leads to <code>base.py</code> in MXNet:</p>

<pre><code>def _load_lib():
    """"""Load library by searching possible path.""""""
    lib_path = libinfo.find_lib_path()
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)  # &lt;- This is where is throws the error.
    # DMatrix functions
    lib.MXGetLastError.restype = ctypes.c_char_p
    return lib
</code></pre>

<p>the strange thing is that <code>lib_path[0]</code> just points to the location of <code>libmxnet.so</code> (which is correct by the way) and suddenly it throws an error:</p>

<blockquote>
  <p>OSError: libcudart.so.9.2: cannot open shared object file: No such
  file or directory</p>
</blockquote>

<p>Even if I follow the error trace the last command is this:</p>

<pre><code>self._handle = _dlopen(self._name, mode)
</code></pre>

<p>with <code>self._name</code> being the same location of <code>libmxnet.so</code>.</p>

<p>I have tried to make it work by changing the system variable with</p>

<pre><code>os.environ[""LD_LIBRARY_PATH""] = ""/usr/local/cuda-9.2/lib64""
</code></pre>

<p>as the second line of the module (the 1st is of course <code>import os</code>!) but this does not seem to work. Apparently it's taken into consideration.</p>

<p>So, how can I bypass this? 
Any solution would be acceptable being on the MXNet side or pyCharm side.</p>
","<python><pycharm><mxnet>","2019-04-12 09:52:19","","0","3584765","2019-04-15 07:01:25","1","0","","","3584765","2406","230","10"
"46507380","<p>Following this great post: <a href=""https://devblogs.nvidia.com/parallelforall/scaling-keras-training-multiple-gpus/"" rel=""nofollow noreferrer"">Scaling Keras Model Training to Multiple GPUs</a> I tried to upgrade my model to run in parallel on my multiple GPUs instance.</p>

<p>At first I ran the MNIST example as proposed here: <a href=""https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py"" rel=""nofollow noreferrer"">MNIST in Keras</a> with the additional syntax in the compile command as follows:</p>

<pre><code># Prepare the list of GPUs to be used in training
NUM_GPU = 8 # or the number of GPUs available on your machine
gpu_list = []
for i in range(NUM_GPU): gpu_list.append('gpu(%d)' % i)

# Compile your model by setting the context to the list of GPUs to be used in training.
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'], 
              context=gpu_list)
</code></pre>

<p>then I trained the model:</p>

<pre><code>model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
</code></pre>

<p>So far so good. It ran for less than 1s per epoch and I was really excited and happy until I tried - <strong>data augmentation</strong>.</p>

<p>To that point, my training images were a numpy array at size (6000,1,28,28) and the labels were at size (10,60000) - one-hot encoded. For data augmentation I used the ImageDataGenerator function:</p>

<pre><code>gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,
                               height_shift_range=0.08, zoom_range=0.08)
batches = gen.flow(x_train, y_train, batch_size=NUM_GPU*64)
test_batches = gen.flow(x_test, y_test, batch_size=NUM_GPU*64)
</code></pre>

<p>and then:</p>

<pre><code>model.fit_generator(batches, batches.N, nb_epoch=1, 
                    validation_data=test_batches, nb_val_samples=test_batches.N)
</code></pre>

<p>And unfortunately, from 1s per epoch I started getting ~11s per epoch... I suppose that the ""impact"" of the ImageDataGenerator is destructive and it probably running all the (reading->augmenting->writing to gpu) process really slow and inefficient.</p>

<p>Scaling keras to multiple GPUs is great, but data-augmentation is essential for my model to be robust enough. </p>

<p>I guess one solution could be: load all images from directory and write your own function that shuffles and augment those images. But I'm sure must be some easier way to optimize this process using keras API.</p>

<p><strong>Thanks!</strong></p>
","<python><deep-learning><keras><mxnet>","2017-09-30 21:55:08","","2","8224316","2017-10-01 21:20:57","1","2","","","8224316","123","13","0"
"51507608","<p>I'm calling keras.backend.conv2d in my loss function, and when I try to compile my model I get the following error:</p>

<blockquote>
  <p>MXNet Backend: Cannot automatically infer shape for convolution operator. Please provide input shape. Given input shape - (None, None, None, None)</p>
</blockquote>

<p>I know the shape of my input tensor so if there's some way to manually specify that I can do it, but I can't find such a thing anywhere in the keras api.</p>
","<keras><mxnet>","2018-07-24 21:12:32","","1","65846","2018-08-08 16:34:09","1","0","","","65846","440","92","9"
"35840176","<p>I'm trying to replicate the following example from the mxnet main docs with mxnet.jl in Julia:</p>

<pre><code>A = Variable('A')
B = Variable('B')
C = B * A
D = C + Constant(1)
# get gradient node.
gA, gB = D.grad(wrt=[A, B])
# compiles the gradient function.
f = compile([gA, gB])
grad_a, grad_b = f(A=np.ones(10), B=np.ones(10)*2)
</code></pre>

<p>The example shows how to autodiff a symoblic expression and obtain its gradients. </p>

<p>What is the equivalent in mxnet.jl (latest version 2016-03-07)?</p>
","<julia><gradient-descent><mxnet><mxnet.jl>","2016-03-07 09:28:19","","5","218681","2016-05-04 09:00:58","1","0","","","218681","3553","216","9"
"46184889","<p>According to <a href=""https://mxnet.incubator.apache.org/how_to/visualize_graph.html"" rel=""nofollow noreferrer"">this</a> page, MXNet computation graph can be visualized using <code>mx.viz.plot_network(net)</code>. </p>

<p>But that only works on Jupyter notebook. How do I do it without Jupyter notebook? Is it possible to save the visualization as a image in a file?</p>
","<mxnet>","2017-09-12 20:33:28","","1","124091","2017-09-12 20:33:28","1","0","1","","124091","1107","99","1"
"41603462","<p>I have models trained on tensorflow. Can I use mxnet in forward only mode to run these ?
<a href=""https://github.com/dmlc/nnvm"" rel=""nofollow noreferrer"">https://github.com/dmlc/nnvm</a> says this should be possible in future, but is the support available today ?</p>
","<tensorflow><mxnet>","2017-01-12 00:59:09","","2","1558203","2017-05-26 17:46:07","1","2","2","","1558203","11","0","0"
"42493045","<p>I am trying to visualize the neural network graph created by using mxnet inn python. The code is shown below</p>

<pre><code>net = mx.sym.Variable('data')    
net = mx.sym.FullyConnected(data=net, name='fc1', num_hidden=128)    
net = mx.sym.Activation(data=net, name='relu1', act_type=""relu"")    
net = mx.sym.FullyConnected(data=net, name='fc2', num_hidden=10)    
net = mx.sym.SoftmaxOutput(data=net, name='out')    
mx.viz.plot_network(net, shape={'data':(100,200)})  
</code></pre>

<p>The last line runs without any error and I see this message - graphviz.dot.Digraph at 0x262f91b8e10>    </p>

<p>But I do not see any graph. Please note that I have installed graphviz.</p>
","<python><graphviz><mxnet>","2017-02-27 18:21:00","","1","7463041","2017-06-19 06:42:20","2","4","","","7463041","81","8","0"
"54894692","<p>Whenever one want to create a custom iterator in the Mxnet framework in C++, it is through the inheritance of <code>IIterator&lt;TBlobBatch&gt;</code>. Then, for the registration, a <code>PrefetcherIter</code> is added to the registry. As far as I understand the <code>PrefetcherIter</code> meaning, that means that another thread would be created and its role would be to load the data from the disk before the GPU would need it.</p>

<p>In my custom iterator implementation, I have an array of ""index orders"", which is used to have a shuffled order that is consistent through the epoch (I can't generate random indexes on the fly, otherwise I would likely pass through the same image several one and miss some others). It needs to be access every time that the <code>bool Next(void)</code> is called. And it is overwritten every time <code>void Shuffle(void)</code> is called.
I also have an integer that is the ""current index location"", to increment at each batch size.</p>

<p>Now, this is obviously not thread safe code, unless I take some extra precautions to make it so. Thus, my question is: does the Mxnet framework guarantee that the iterator calls would not be executed concurrently? Or should I take care of that myself?</p>
","<c++><thread-safety><mxnet>","2019-02-26 21:49:57","","0","7128430","2019-02-26 21:49:57","0","0","","","7128430","100","17","0"
"37020754","<p>I am trying to build a 11 class image classifier with 13000 training images and 3000 validation images. I am using deep neural network which is being trained using mxnet. Training accuracy is increasing and reached above 80% but validation accuracy is coming in range of 54-57% and its not increasing. 
What can be the issue here? Should I increase the no of images?</p>
","<deep-learning><caffe><mxnet>","2016-05-04 07:07:31","","7","3114663","2016-05-04 09:34:43","2","3","13","","3114663","549","69","1"
"51108167","<p>With Mxnet, it is possible to use callback functions. One perfect example is with the R API - <a href=""https://stackoverflow.com/questions/43517960/how-to-save-a-model-when-using-mxnet#44194894"">How to save a model when using MXnet</a>.</p>

<p>But with the C++ API, I don't find any example on how to use them, nor some default callback functions (such as the one to save the weights). Though, by  searching ""callback"", I do have some hits, such as ""MXExecutorSetMonitorCallback"" or ""ExecutorMonitorCallback"".</p>

<p>How to define and use callback functions in C++?</p>
","<c++><callback><mxnet>","2018-06-29 19:20:50","","1","7128430","2018-11-20 21:02:51","0","0","","","7128430","100","17","0"
"54588872","<p>I am trying to understand how the internal flow goes in mxnet when we call forward . Is there any way to get source code of mxnet?</p>
","<mxnet>","2019-02-08 08:58:14","","0","6277964","2019-02-13 15:51:59","1","0","","","6277964","33","5","0"
"46195917","<p>Is this expected behaviour?</p>

<pre><code>library(mxnet)

hidden_u_1 &lt;- 100
activ_hidden_1 &lt;- 'tanh'

hidden_u_2 &lt;- 1

learn_rate &lt;- 0.001

initializer &lt;- mx.init.uniform(1)

optimizer &lt;- 'rmsprop' #sgd

loss &lt;- mx.metric.mse

device.cpu &lt;- mx.cpu()

mini_batch &lt;- 64 #8

rounds &lt;- 1 #2


## data symbols

nn_data &lt;- mx.symbol.Variable('data')
nn_label &lt;- mx.symbol.Variable('label')


## first fully connected layer

flatten &lt;- mx.symbol.Flatten(data = nn_data)

fc1 &lt;- mx.symbol.FullyConnected(data = flatten
                                , num_hidden = hidden_u_1)

activ1 &lt;- mx.symbol.Activation(data = fc1, act.type = activ_hidden_1)

## second fully connected layer

fc2 &lt;- mx.symbol.FullyConnected(data = activ1, num_hidden = hidden_u_2)

q_func &lt;- mx.symbol.LinearRegressionOutput(data = fc2, label = nn_label, name = 'regr')


# initialize NN

train.x &lt;- matrix(rnorm(640, 0, 1), ncol = 10)
train.x &lt;- t(train.x)
dim(train.x) &lt;- c(nrow(train.x), 1, 1, ncol(train.x))
train.y = rnorm(64, 0, 1)

nn_model &lt;- mx.model.FeedForward.create(
     symbol = q_func,
     X = train.x,
     y = train.y,
     ctx = device.cpu,
     num.round = rounds,
     array.batch.size = mini_batch,
     optimizer = optimizer,
     eval.metric = loss,
     learning.rate = learn_rate,
     initializer = initializer
)
</code></pre>

<p>1 round (pass) of calculating loss values on a minibatch of samples with size more than 1 always returns NaN, while 2 and more passes give finite values starting from 2nd pass.</p>

<p>If the number of samples is n times larger than <strong>minibatch</strong> (e.g., 64 / 8), then even after 1 round the loss is calculable.</p>
","<r><mxnet><loss>","2017-09-13 11:07:45","","2","8532487","2018-03-01 02:53:41","1","0","","","8532487","162","20","0"
"46218696","<p>I am trying to use <a href=""https://github.com/dmlc/mxnet.js"" rel=""nofollow noreferrer"">Mxnet-js library</a> to visualize my Mxnet trained model in browser. I am following Mxnet-js git readme file. </p>

<p>They provided a python script. <a href=""https://github.com/dmlc/mxnet.js/tree/master/tools"" rel=""nofollow noreferrer""><strong>./tool/model2json</strong></a>, to convert model to json file.
When i am running this script with my model i am getting error:</p>

<pre><code>TypeError: write() argument must be str, not bytes
</code></pre>

<p>Getting this error make sense because, how can i write byte to a file that is opened in string mode. At line </p>

<p><strong>model = base64.b64encode(bytes(open(sys.argv[3], 'rb').read()))</strong> </p>

<p>they are reading it in bytes but in line </p>

<p><strong>with open(sys.argv<a href=""https://github.com/dmlc/mxnet.js"" rel=""nofollow noreferrer"">1</a>, 'w') as fo:</strong> </p>

<p>they are opening file in string mode and in line </p>

<p><strong>fo.write(model)</strong> </p>

<p>they are writing bytes to string.</p>

<p><strong>Am i missing something here ? Why they are trying to write</strong> <strong>bytes</strong> to <strong>string</strong>? </p>

<pre><code>#!/usr/bin/env python
""""""Simple util to convert mxnet model to json format.""""""
import sys
import json
import base64

if len(sys.argv) &lt; 4:
    print('Usage: &lt;output.json&gt; &lt;symbol.json&gt; &lt;model.param&gt; 
                                [mean_image.nd] [synset]')
    exit(0)

symbol_json = open(sys.argv[2]).read()
model = base64.b64encode(bytes(open(sys.argv[3], 'rb').read()))
mean_image = None
synset = None

if len(sys.argv) &gt; 4:
    mean_image = base64.b64encode(bytes(open(sys.argv[4], 
                                      'rb').read()))

if len(sys.argv) &gt; 5:
    synset = [l.strip() for l in open(sys.argv[5]).readlines()]

with open(sys.argv[1], 'w') as fo:

    fo.write('{\n\""symbol\"":\n')
    fo.write(symbol_json)
    if synset:
        fo.write(',\n\""synset\"": ')
        fo.write(json.dumps(synset))
    fo.write(',\n\""parambase64\"": \""')

    fo.write(model)
    fo.write('\""\n')
    if mean_image is not None:
        fo.write(',\n\""meanimgbase64\"": \""')
        fo.write(mean_image)
        fo.write('\""\n')
fo.write('}\n')
</code></pre>
","<python><mxnet>","2017-09-14 12:06:55","","0","5468983","2017-09-21 08:51:51","1","0","","","5468983","560","69","0"
"55124556","<pre><code>def acc(output, label):
    correct_preds = output.argmax(axis=1) == label.astype('float32')
    return correct_preds.mean().asscalar()

for epoch in range(10):

    train_loss, train_acc, valid_acc = 0., 0., 0.
    tic = time()

    for data, label in train_data:
        data = data.copyto(mx.cpu(0))
        label = label.copyto(mx.cpu(0))
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)

        loss.backward()

        trainer.step(batch_size)

        train_loss += loss.mean().asscalar()
        train_acc += acc(output, label)
</code></pre>

<p>When running this part I get the error and my dataset is in pascol voc format</p>

<pre><code>ValueError                                
Traceback (most recent call last)
&lt;ipython-input-7-9926ba7deb21&gt; in &lt;module&gt;()

         12         label = label.copyto(mx.cpu(0))
         13         with autograd.record():
    ---&gt; 14             output = net(data)
         15             loss = softmax_cross_entropy(output, label)
         16 

/home/manasi/.local/lib/python2.7/site-packages/mxnet/gluon/block.pyc in __call__(self, *args)


      539             hook(self, args)
        540 
    --&gt; 541         out = self.forward(*args)
        542 
        543         for hook in self._forward_hooks.values():

/home/manasi/.local/lib/python2.7/site-packages/mxnet/gluon/nn/basic_layers.pyc in forward(self, x)


        51     def forward(self, x):
         52         for block in self._children.values():
    ---&gt; 53             x = block(x)
         54         return x
         55 

/home/manasi/.local/lib/python2.7/site-packages/mxnet/gluon/block.pyc in __call__(self, *args)


        539             hook(self, args)
        540 
    --&gt; 541         out = self.forward(*args)
        542 
        543         for hook in self._forward_hooks.values():

/home/manasi/.local/lib/python2.7/site-packages/mxnet/gluon/block.pyc in forward(self, x, *args)
    911                     params = {i: j.data(ctx) for i, j in self._reg_params.items()}


     912                 except DeferredInitializationError:
    --&gt; 913                     self._deferred_infer_shape(x, *args)
        914                     for _, i in self.params.items():
        915                         i._finish_deferred_init()

/home/manasi/.local/lib/python2.7/site-packages/mxnet/gluon/block.pyc in _deferred_infer_shape(self, *args)

        792             error_msg = ""Deferred initialization failed 
           because shape""\
        793                         "" cannot be inferred. {}"".format(e)
    --&gt; 794             raise ValueError(error_msg)
        795 
        796     def _call_cached_op(self, *args):

ValueError: Deferred initialization failed because shape cannot be inferred. Error in operator conv2_fwd: [10:56:15] src/operator/nn/convolution.cc:196: Check failed: dilated_ksize_x &lt;= AddPad(dshape[3], param_.pad[1]) (5 vs. 3) kernel size exceed input
</code></pre>
","<mxnet>","2019-03-12 14:58:34","","1","11191937","2019-04-13 00:22:40","1","2","","","11191937","6","0","0"
"46780370","<p>If all the images come from 3 classes, can the set of class ids we put into the second column of the .lst file be {101, 280, 76}? Or it has to be consecutive integers like {5,6,7}, or even more strict, has to be {0,1,2} ?
Thanks.</p>
","<mxnet>","2017-10-16 23:23:12","","0","8310455","2017-10-17 20:41:23","1","0","","","8310455","3","0","0"
"47064136","<p>I am trying to run some machine learning algorithms using Tensorflow, CNTK, and MxNet. Do these frameworks have some specific performance analysis tools especially to profile runtime information ( memory, communication etc.)? </p>
","<tensorflow><cntk><mxnet>","2017-11-01 21:41:47","","0","7608304","2017-11-03 11:23:48","2","0","","","7608304","6","0","0"
"55524839","<p>I am compiling a git version of the MXNet framework, which use CuDNN inside its code. Whenever MXNet is compiled in debug, my example test is running fine and my neural network is training. However, when I switch to release mode, the execution fails a test and I get the following error: <code>Check failed: e == CUDNN_STATUS_SUCCESS (8 vs. 0) cuDNN: CUDNN_STATUS_EXECUTION_FAILED</code>.</p>

<p>Note: I don't see any release/debug code which could explain a different behaviour. And I didn't had any problem at all with both release and debug version until I activated CuDNN, thus I trust it is the culprit.</p>

<p>The symptoms:
- The code doesn't necessarily crash at the same location. But it is always during a <code>CUDNN_CALL</code> (which is a macro that calls a CuDNN function and check the status).
- No memory is allocated on my GPU, which has anyway enough memory for such network, thus it shouldn't be a problem.
- It happens only in release - in debug, it is running just fine.</p>

<p>Here is an example of where I get the error:</p>

<pre><code>CUDNN_CALL(cudnnAddTensor(s-&gt;dnn_handle_,
                                &amp;alpha,
                                bias_desc_,
                                bias.dptr_ + bias_offset_ * g,
                                &amp;beta_add,
                                out_desc_,
                                out_ptr + out_offset_ * g));
</code></pre>

<p>So, what could be the causes of such a problem?</p>
","<release><mxnet><cudnn>","2019-04-04 21:01:57","","0","7128430","2019-04-11 15:47:52","1","6","","","7128430","100","17","0"
"55146816","<p>I have millions of images to infer on. I know how to write my own code  to create batches and forward the batches to a trained network using <a href=""https://mxnet.incubator.apache.org/api/python/index.html"" rel=""nofollow noreferrer"">MxNet Module API</a> in order to get the predictions. However, creating the batches leads to a lot of data manipulation that is not especially optimized. </p>

<p>Before doing any optimisation myself, I would like to know if there are some recommended approaches for batch predictions/inferences. More specifically, since this is a common use case, I was wondering if there is  an interface/api that can do the usual image pre-processing, batch creation, and inference given a trained model (i.e. symbole file &amp; epoch checkpoint)?</p>
","<python><mxnet><gluon>","2019-03-13 16:29:32","","1","1162647","2019-03-24 00:54:10","1","0","","","1162647","5649","160","1"
"55186629","<p>I have the following problem: I have a script in Keras which works like a charm. I would like to convert this script to MXNet now. The CNN in Keras looks like this:</p>

<pre><code>model=Sequential()
model.add(Convolution2D(128, (3, 3), padding='same', activation='relu', name='block1_conv1', input_shape=(80,120,3)))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))
model.add(Convolution2D(256, (3, 3), padding='same', activation='relu', name='block2_conv1'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))
model.add(Flatten())
model.add(Dense(2, activation = 'softmax', name='final_fully_connected'))
</code></pre>

<p>I thought the conversion to MXNet couldn't be that difficult, I looked at the corresponding documentation and transferred the parameters to my best knowledge.</p>

<pre><code>model=gluon.nn.Sequential()
with model.name_scope():
    model.add(gluon.nn.Conv2D(channels=128, kernel_size=(3, 3), activation='relu'))
    model.add(gluon.nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))            
    model.add(gluon.nn.Conv2D(channels=256, kernel_size=(3, 3), activation='relu'))
    model.add(gluon.nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))
    # The Flatten layer collapses all axis, except the first one, into one axis.
    model.add(gluon.nn.Flatten())
    model.add(gluon.nn.Dense(2, activation='relu'))
</code></pre>

<p>But if I try to train the model now, I get the following error:</p>

<p>""MXNetError: [17:01:34] C:\ci\libmxnet_1533399150922\work\src\operator\nn\pooling.cc:145: Check failed: param.kernel[1] &lt;= dshape[3] + 2 * param.pad[1] kernel size (2) exceeds input (1 padded to 1)""</p>

<p>I think it has something to do with the dimensions of the kernel and the MaxPooling2D layer, but I don't understand the error because I thought I was actually building the same network as in Keras.</p>

<p>For completeness: My input variable X has the dimensions (80, 120, 3).</p>

<p>I would really appreciate the help of some Keras/MXNet pros.</p>
","<python><keras><mxnet>","2019-03-15 16:09:39","","1","6280502","2019-04-17 09:00:04","4","0","","","6280502","36","1","0"
"47294512","<p>I'm attempting to setup an Amazon Linux EC2 instance with MXNet and R (and the MXNet r package available as well). Unfortunately this has been a lot harder than I expected.</p>

<p>I've attempted to follow the instructions from MXNet using Amazon's deep learning AMI with CUDA 8.0 on a p2.xlarge (<a href=""https://mxnet.incubator.apache.org/get_started/install.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/get_started/install.html</a>)</p>

<p>However I get the same error when attempting to compile the mxnet r package from this SO post:</p>

<p><a href=""https://stackoverflow.com/questions/46942883/issues-installing-mxnet-gpu-r-package-for-amazon-deep-learning-ami"">Issues installing mxnet GPU R package for Amazon deep learning AMI</a></p>

<p>The solution discussed in that post are somewhat beyond my abilities to fully test/debug. i.e. I'm not particularly familiar with linux environment variables and such to modify. I've also reviewed some issues raised on the apache-incubator github for MXnet and those were pretty unhelpful as well.</p>

<p>So my questions are,</p>

<ol>
<li>Is anyone aware of any available AMI's which come pre-packaged with R and MXNet? The ones I see seem to only include python.</li>
<li>Have a working set of instructions (or a script) to run on an Amazon Linux EC2 instance to install the required dependencies (assuming Im using some type of deep learning AMI that comes with CUDA 8.0 at least) to install the MXnet R package?</li>
</ol>
","<r><amazon-web-services><amazon-ec2><deep-learning><mxnet>","2017-11-14 20:19:55","","1","8941278","2017-11-18 04:56:44","1","0","","","8941278","150","12","0"
"48771529","<p>I am going through some CNN articles. I see that they transform the input image to <code>(channel, width, height)</code>.</p>

<p>A code example taken from <a href=""http://gluon.mxnet.io/chapter04_convolutional-neural-networks/cnn-scratch.html"" rel=""nofollow noreferrer"">MXNET CNN Tutorial</a>.</p>

<pre><code>def transform(data, label):
  # 2,0,1 means channels,width, height
  return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)
</code></pre>

<p>Can any one explain why do we do this transformation?</p>
","<machine-learning><neural-network><conv-neural-network><convolution><mxnet>","2018-02-13 16:38:48","","1","3371460","2018-02-17 19:57:58","1","0","1","","3371460","649","104","1"
"50955846","<p>Recently I have been trying to implement a deep learning method for action recognition in single images.</p>

<p>I thus use a model based on Resnet 50 that has two variations:</p>

<ul>
<li>a vanilla version</li>
<li>a version that incorporates ROI-Pooling as the
first layer of the network For the vanilla resnet50 version of the
model</li>
</ul>

<p>I perform training using:</p>

<ul>
<li>the Training partition of the action recognition task of the PASCAL
VOC 2012 Dataset</li>
<li>from each image, I crop the primary regions that contain persons each
of whom is assigned an action label</li>
</ul>

<p>I test the model by using:</p>

<ul>
<li>the Validation partition of the action recognition task of the PASCAL
VOC 2012 Dataset</li>
<li>from each image, I crop the primary regions that contain persons each
of whom is assigned an action label</li>
</ul>

<p>All images are rescaled to 224x224 from the data iterator</p>

<p>No Data Augmentation takes place</p>

<p>The loss function being used is softmax cross entropy</p>

<p>The batch size was set to 64 images</p>

<p><strong>The performance I get by feeding the primary regions of persons to
   the network using the vanilla Resnet-50 is 71.51% mAP</strong></p>

<hr>

<p><strong>Then I introduce ROI Pooling to the Network</strong></p>

<ul>
<li><p>As I mentioned ROI Pooling is introduced as the first layer of the<br>
network</p></li>
<li><p>The dataset partitions I use to train and test are the same</p></li>
<li><p>Images are provided to the data iterator without cropping taking<br>
place and are rescaled to 224x224</p></li>
<li><p>ROI Pooling outputs image crops for the primary regions (depicting<br>
persons) that have a size of 224x224</p></li>
<li><p>Action Labels are assigned properly for the ROI pooling crops</p></li>
<li><p>The number of ROI crops varies per image</p></li>
<li><p>In every batch, I loaded 10 images and each image had a varying<br>
number of ROIs</p></li>
<li><p>No Data augmentation was performed</p></li>
<li><p>The loss function was again softmax cross entropy</p></li>
<li><p><strong>The performance I get by introducing ROI-Pooling to the network<br>
Resnet-50 is 65.93% mAP</strong></p></li>
</ul>

<p><strong>Why is there a difference of approximately 6% mAP in my results?</strong></p>

<p>p.s </p>

<ol>
<li>the ROI-Pooling network seems to overfit a lot and really quickly…</li>
<li>the framework I use to implement this model is MXNet</li>
</ol>

<p>Here is a subset of my code:</p>

<pre><code>number_of_images_per_batch =10
num_classes = 11
init_lr = 0.0001
step_epochs = [3]
schedule_lr = LR_Schedule(init_lr)

train_iter, val_iter, num_samples = get_image_iterators(number_of_images_per_batch,num_classes)

resnet = vision.resnet50_v2(pretrained=True, ctx=ctx)

net = vision.resnet50_v2(classes=num_classes, ctx=ctx)



net_cl = nn.HybridSequential(prefix='resnetv20')
with net_cl.name_scope():
    for l in xrange(4):
        net_cl.add(resnet.classifier._children[l])
    net_cl.add(nn.Dense(num_classes,  in_units=resnet.classifier._children[-1]._in_units))

net.classifier = net_cl
net.classifier[-1].collect_params().initialize(mx.init.Xavier(rnd_type='gaussian', factor_type=""in"", magnitude=2), ctx=ctx)
net.features = resnet.features
net.collect_params().reset_ctx(ctx)

epoch_size = int(math.ceil(float(num_samples) / batch_size))
steps = [epoch_size * x for x in step_epochs]
lr_scheduler = mx.lr_scheduler.MultiFactorScheduler(steps, factor=0.1)
trainer = gluon.Trainer(net.collect_params(), optimizer='sgd', optimizer_params={'learning_rate': init_lr,
                                                                                 'momentum':0.9,
                                                                                 'lr_scheduler': lr_scheduler,
                                                                                 'wd': 0.0005})
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
epochs = 60000
smoothing_constant, moving_loss_tr, moving_loss_val = .01, 0.0, 0.0
patience, lr_drops = 0, 0

best_mAP = 0

batch_primary_regions=[]

for e in range(epochs):
    train_iter.reset()
    val_iter.reset()
    start_time = timeit.default_timer()

    predicts, labels = [], []

    for i, batch in enumerate(train_iter):
        batch_primary_regions = mx.nd.array(batch.data[2]).as_in_context(ctx)
        batch_primary_labels = mx.nd.array(batch.data[3]).as_in_context(ctx)
        data = mx.nd.ROIPooling(mx.nd.array(batch.data[0]).as_in_context(ctx), batch_primary_regions, pooled_size=(224, 224), spatial_scale=1.0)

        with mx.autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, batch_primary_labels)
        loss.backward()
        trainer.step(data.shape[0])
        prob_predictions = nd.softmax(output)

        curr_loss = nd.mean(loss).asscalar()
        moving_loss_tr = (curr_loss if ((i == 0) and (e == 0))
                       else (1 - smoothing_constant) * moving_loss_tr + smoothing_constant * curr_loss)


        predicts.extend(prob_predictions.asnumpy())

        labels.extend(nd.one_hot(batch_primary_labels, num_classes).asnumpy())

    predicts, labels = np.array(predicts), np.array(labels)
    train_accuracy = accuracy_score(np.argmax(labels, axis=1), np.argmax(predicts, axis=1))
    train_mAP, train_APs = evaluate_mAP(labels, predicts)


    predicts_val, labels_groundtruth_val = [], []
    for i, batch in enumerate(val_iter):

        batch_primary_regions = mx.nd.array(batch.data[2]).as_in_context(ctx)
        batch_primary_labels = mx.nd.array(batch.data[3]).as_in_context(ctx)
        data = mx.nd.ROIPooling(mx.nd.array(batch.data[0]).as_in_context(ctx), batch_primary_regions, pooled_size=(224, 224), spatial_scale=1.0)

        output = net(data)
        prob_predictions = nd.softmax(output)
        loss = softmax_cross_entropy(output, batch_primary_labels)
        curr_loss = nd.mean(loss).asscalar()
        moving_loss_val = (curr_loss if ((i == 0) and (e == 0))
                       else (1 - smoothing_constant) * moving_loss_val + smoothing_constant * curr_loss)

        predicts_val.extend(prob_predictions.asnumpy())
        labels_groundtruth_val.extend(nd.one_hot(batch_primary_labels, num_classes).asnumpy())

    predicts_val, labels_groundtruth_val = np.array(predicts_val), np.array(labels_groundtruth_val)
    test_accuracy = accuracy_score(np.argmax(labels_groundtruth_val, axis=1), np.argmax(predicts_val, axis=1))
    val_mAP, val_APs = evaluate_mAP(labels_groundtruth_val, predicts_val)
</code></pre>
","<python><deep-learning><mxnet>","2018-06-20 19:37:16","","6","1351721","2018-06-26 23:29:19","0","8","2","","1351721","270","113","3"
"51074755","<p>I am explicitly trying to install a version of mxnet <strong>WITHOUT CUDA support.</strong> When installing with cuda support I could run <a href=""https://github.com/dmlc/keras/blob/master/examples/mnist_mlp.py"" rel=""nofollow noreferrer"">this example here.</a> I am following the <a href=""https://github.com/awslabs/keras-apache-mxnet/wiki/Installation#1-install-keras-with-apache-mxnet-backend"" rel=""nofollow noreferrer"">keras &amp; mxnet installation guide here.</a></p>

<h1>Steps to reproduce successful CUDA-enabled keras-mxnet:</h1>

<p>Here are my gpu configs from <code>nvcc --version</code>:</p>

<pre><code>~# nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61
</code></pre>

<p>Make sure you don't have <code>mxnet</code> installed.</p>

<pre><code>pip install mxnet-cu80
pip install keras-mxnet
</code></pre>

<p>Running the code on jupyter gives me:</p>

<pre><code>60000 train samples
10000 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 512)               401920    
_________________________________________________________________
activation_1 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
activation_2 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0         
=================================================================
Total params: 669,706
Trainable params: 669,706
Non-trainable params: 0
_________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
 6400/60000 [==&gt;...........................] - ETA: 39s - loss: 2.1718 - acc: 0.2587 
/usr/local/lib/python3.6/dist-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.0078125). Is this intended?
  force_init=force_init)
60000/60000 [==============================] - 6s 103us/step - loss: 1.2105 - acc: 0.6957 - val_loss: 0.5334 - val_acc: 0.8728
Epoch 2/20
60000/60000 [==============================] - 2s 27us/step - loss: 0.5280 - acc: 0.8515 - val_loss: 0.3749 - val_acc: 0.8996
Epoch 3/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.4239 - acc: 0.8786 - val_loss: 0.3213 - val_acc: 0.9098
Epoch 4/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.3740 - acc: 0.8911 - val_loss: 0.2923 - val_acc: 0.9162
Epoch 5/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.3437 - acc: 0.9008 - val_loss: 0.2704 - val_acc: 0.9218
Epoch 6/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.3195 - acc: 0.9079 - val_loss: 0.2539 - val_acc: 0.9263
Epoch 7/20
60000/60000 [==============================] - 2s 29us/step - loss: 0.2965 - acc: 0.9151 - val_loss: 0.2393 - val_acc: 0.9312
Epoch 8/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2792 - acc: 0.9190 - val_loss: 0.2264 - val_acc: 0.9342
Epoch 9/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2641 - acc: 0.9239 - val_loss: 0.2173 - val_acc: 0.9363
Epoch 10/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2520 - acc: 0.9277 - val_loss: 0.2064 - val_acc: 0.9413
Epoch 11/20
60000/60000 [==============================] - 2s 29us/step - loss: 0.2409 - acc: 0.9306 - val_loss: 0.1983 - val_acc: 0.9425
Epoch 12/20
60000/60000 [==============================] - 2s 30us/step - loss: 0.2307 - acc: 0.9331 - val_loss: 0.1894 - val_acc: 0.9447
Epoch 13/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2209 - acc: 0.9362 - val_loss: 0.1813 - val_acc: 0.9463
Epoch 14/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2106 - acc: 0.9396 - val_loss: 0.1756 - val_acc: 0.9478
Epoch 15/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.2044 - acc: 0.9410 - val_loss: 0.1687 - val_acc: 0.9501
Epoch 16/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.1963 - acc: 0.9424 - val_loss: 0.1625 - val_acc: 0.9528
Epoch 17/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.1912 - acc: 0.9436 - val_loss: 0.1576 - val_acc: 0.9542
Epoch 18/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.1842 - acc: 0.9472 - val_loss: 0.1544 - val_acc: 0.9541
Epoch 19/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.1782 - acc: 0.9482 - val_loss: 0.1490 - val_acc: 0.9553
Epoch 20/20
60000/60000 [==============================] - 2s 28us/step - loss: 0.1729 - acc: 0.9494 - val_loss: 0.1447 - val_acc: 0.9570
Test score: 0.144698123593
Test accuracy: 0.957
</code></pre>

<h1>Steps to reproduce unsuccessful CPU-only keras-mxnet:</h1>

<p>Do the same as before but instead of installing <code>mxnet-cu80</code>, install <code>mxnet</code>:</p>

<pre><code>pip uninstall mxnet-cu80
pip install mxnet
</code></pre>

<p>Running the code on a jupyter notebook now gives me:</p>

<pre><code>60000 train samples
10000 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 512)               401920    
_________________________________________________________________
activation_4 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               262656    
_________________________________________________________________
activation_5 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_6 (Activation)    (None, 10)                0         
=================================================================
Total params: 669,706
Trainable params: 669,706
Non-trainable params: 0
_________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/mxnet/symbol/symbol.py in simple_bind(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)
   1512                                                  shared_exec_handle,
-&gt; 1513                                                  ctypes.byref(exe_handle)))
   1514         except MXNetError as e:

/usr/local/lib/python3.6/dist-packages/mxnet/base.py in check_call(ret)
    148     if ret != 0:
--&gt; 149         raise MXNetError(py_str(_LIB.MXGetLastError()))
    150 

MXNetError: [04:19:54] src/storage/storage.cc:123: Compile with USE_CUDA=1 to enable GPU usage

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x1c05f2) [0x7f737ac845f2]
[bt] (1) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x1c0bd8) [0x7f737ac84bd8]
[bt] (2) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d7d3cd) [0x7f737d8413cd]
[bt] (3) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d8141d) [0x7f737d84541d]
[bt] (4) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d83206) [0x7f737d847206]
[bt] (5) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27a2831) [0x7f737d266831]
[bt] (6) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27a2984) [0x7f737d266984]
[bt] (7) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27aecec) [0x7f737d272cec]
[bt] (8) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27b55f8) [0x7f737d2795f8]
[bt] (9) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27c163a) [0x7f737d28563a]



During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-4-c71d8965f0f3&gt; in &lt;module&gt;()
     49 history = model.fit(X_train, Y_train,
     50                     batch_size=batch_size, epochs=nb_epoch,
---&gt; 51                     verbose=1, validation_data=(X_test, Y_test))
     52 score = model.evaluate(X_test, Y_test, verbose=0)
     53 print('Test score:', score[0])

/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)
   1042                                         initial_epoch=initial_epoch,
   1043                                         steps_per_epoch=steps_per_epoch,
-&gt; 1044                                         validation_steps=validation_steps)
   1045 
   1046     def evaluate(self, x=None, y=None,

/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)
    197                     ins_batch[i] = ins_batch[i].toarray()
    198 
--&gt; 199                 outs = f(ins_batch)
    200                 if not isinstance(outs, list):
    201                     outs = [outs]

/usr/local/lib/python3.6/dist-packages/keras/backend/mxnet_backend.py in train_function(inputs)
   4794             def train_function(inputs):
   4795                 self._check_trainable_weights_consistency()
-&gt; 4796                 data, label, _, data_shapes, label_shapes = self._adjust_module(inputs, 'train')
   4797 
   4798                 batch = mx.io.DataBatch(data=data, label=label, bucket_key='train',

/usr/local/lib/python3.6/dist-packages/keras/backend/mxnet_backend.py in _adjust_module(self, inputs, phase)
   4746                     self._set_weights()
   4747                 else:
-&gt; 4748                     self._module.bind(data_shapes=data_shapes, label_shapes=None, for_training=True)
   4749                     self._set_weights()
   4750                     self._module.init_optimizer(kvstore=self._kvstore, optimizer=self.optimizer)

/usr/local/lib/python3.6/dist-packages/mxnet/module/bucketing_module.py in bind(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)
    341                         compression_params=self._compression_params)
    342         module.bind(data_shapes, label_shapes, for_training, inputs_need_grad,
--&gt; 343                     force_rebind=False, shared_module=None, grad_req=grad_req)
    344         self._curr_module = module
    345         self._curr_bucket_key = self._default_bucket_key

/usr/local/lib/python3.6/dist-packages/mxnet/module/module.py in bind(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)
    428                                                      fixed_param_names=self._fixed_param_names,
    429                                                      grad_req=grad_req, group2ctxs=self._group2ctxs,
--&gt; 430                                                      state_names=self._state_names)
    431         self._total_exec_bytes = self._exec_group._total_exec_bytes
    432         if shared_module is not None:

/usr/local/lib/python3.6/dist-packages/mxnet/module/executor_group.py in __init__(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, logger, fixed_param_names, grad_req, state_names, group2ctxs)
    263         self.num_outputs = len(self.symbol.list_outputs())
    264 
--&gt; 265         self.bind_exec(data_shapes, label_shapes, shared_group)
    266 
    267     def decide_slices(self, data_shapes):

/usr/local/lib/python3.6/dist-packages/mxnet/module/executor_group.py in bind_exec(self, data_shapes, label_shapes, shared_group, reshape)
    359             else:
    360                 self.execs.append(self._bind_ith_exec(i, data_shapes_i, label_shapes_i,
--&gt; 361                                                       shared_group))
    362 
    363         self.data_shapes = data_shapes

/usr/local/lib/python3.6/dist-packages/mxnet/module/executor_group.py in _bind_ith_exec(self, i, data_shapes, label_shapes, shared_group)
    637                                            type_dict=input_types, shared_arg_names=self.param_names,
    638                                            shared_exec=shared_exec, group2ctx=group2ctx,
--&gt; 639                                            shared_buffer=shared_data_arrays, **input_shapes)
    640         self._total_exec_bytes += int(executor.debug_str().split('\n')[-3].split()[1])
    641         return executor

/usr/local/lib/python3.6/dist-packages/mxnet/symbol/symbol.py in simple_bind(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)
   1517                 error_msg += ""%s: %s\n"" % (k, v)
   1518             error_msg += ""%s"" % e
-&gt; 1519             raise RuntimeError(error_msg)
   1520 
   1521         # update shared_buffer

RuntimeError: simple_bind error. Arguments:
/dense_4_input1: (128, 784)
[04:19:54] src/storage/storage.cc:123: Compile with USE_CUDA=1 to enable GPU usage

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x1c05f2) [0x7f737ac845f2]
[bt] (1) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x1c0bd8) [0x7f737ac84bd8]
[bt] (2) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d7d3cd) [0x7f737d8413cd]
[bt] (3) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d8141d) [0x7f737d84541d]
[bt] (4) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2d83206) [0x7f737d847206]
[bt] (5) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27a2831) [0x7f737d266831]
[bt] (6) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27a2984) [0x7f737d266984]
[bt] (7) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27aecec) [0x7f737d272cec]
[bt] (8) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27b55f8) [0x7f737d2795f8]
[bt] (9) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27c163a) [0x7f737d28563a]
</code></pre>

<p>What exactly is this error saying? How can I fix this?</p>
","<python><keras><gpu><mxnet>","2018-06-28 04:31:47","","0","3781180","2018-06-28 20:07:49","1","0","","","3781180","1555","81","21"
"37044600","<p>I am using mxnet to train a 11-class image classifier. I am observing a weird behavior training accuracy was increasing slowly and went upto 39% and in next epoch it went down to 9% and then it stays close to 9% for rest of the training.
I restarted the training with saved model (with 39% training accuracy) keeping all other parameter same . Now training accuracy is increasing again. What can be the reason here ? I am not able to understand it . And its getting difficult to train the model this way as it requires me to see training accuracy values constantly.</p>

<p>learning rate is constant at 0.01</p>
","<neural-network><deep-learning><mxnet>","2016-05-05 07:10:46","","9","3114663","2017-08-30 06:40:25","4","3","1","","3114663","549","69","1"
"55832799","<p>I am trying to do time series prediction using GANs. I am using MXNet/Gluon. Thus, I have a sequential data of size (N, 1), which I have transformed it into (N-stepsize, stepsize). Now I have a hard time understanding the input out shapes of the network. Here, the code for Generator and Discriminator networks.</p>

<pre><code>netG = nn.Sequential()
with netG.name_scope():
    netG.add(nn.Dense(20))
    netG.add(nn.BatchNorm(momentum = 0.8))
    netG.add(nn.Dropout(0.5))
    netG.add(nn.Dense(15))
    netG.add(nn.BatchNorm(momentum = 0.8))
    netG.add(nn.Dropout(0.5))
    netG.add(nn.Dense(20))
    netG.add(nn.BatchNorm(momentum = 0.8))
    netG.add(nn.Dropout(0.5))
    netG.add(nn.Dense(step_size, activation = ""tanh""))


#300, 50, 2
#input shape is inferred
netD = nn.Sequential()
with netD.name_scope():
    netD.add(nn.Dense(20))
    netG.add(nn.BatchNorm(momentum = 0.8))
    netD.add(nn.Dense(15, activation='tanh'))
    netG.add(nn.BatchNorm(momentum = 0.8))
    netD.add(nn.Dense(20, activation='tanh'))
    netD.add(nn.Dense(step_size))
</code></pre>

<p>Thanks in advance.</p>
","<python><time-series><mxnet><generative-adversarial-network>","2019-04-24 14:43:10","","0","6104563","2019-04-29 22:49:49","1","0","","","6104563","100","0","0"
"37110169","<p><code>mxnet</code> package is not installing in r (on windows 10) when I follow the steps given in its documentation.</p>

<pre><code>install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
</code></pre>

<p>It gives the following result</p>

<blockquote>
  <p>Installing package into ‘C:/Users/Ashish/Documents/R/win-library/3.3’
  (as ‘lib’ is unspecified) Warning in install.packages :   cannot open
  URL '<a href=""http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES.gz"" rel=""nofollow"">http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES.gz</a>':
  HTTP status was '404 Not Found' Warning in install.packages :   cannot
  open URL
  '<a href=""http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES"" rel=""nofollow"">http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES</a>': HTTP
  status was '404 Not Found' Warning in install.packages :   unable to
  access index for repository
  <a href=""http://dmlc.github.io/drat/bin/windows/contrib/3.3"" rel=""nofollow"">http://dmlc.github.io/drat/bin/windows/contrib/3.3</a>:   cannot open URL
  '<a href=""http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES"" rel=""nofollow"">http://dmlc.github.io/drat/bin/windows/contrib/3.3/PACKAGES</a>' Package
  which is only available in source form, and may need   compilation of
  C/C++/Fortran: ‘mxnet’ Do you want to attempt to install these from
  sources? y/n: y installing the source package ‘mxnet’</p>
  
  <p>trying URL '<a href=""http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz"" rel=""nofollow"">http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz</a>'
  Warning in install.packages :   cannot open URL
  '<a href=""http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz"" rel=""nofollow"">http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz</a>': HTTP status
  was '404 Not Found' Error in download.file(url, destfile, method, mode
  = ""wb"", ...) :    cannot open URL '<a href=""http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz"" rel=""nofollow"">http://dmlc.github.io/drat/src/contrib/mxnet_0.5.tar.gz</a>' Warning in
  install.packages :   download of package ‘mxnet’ failed</p>
</blockquote>

<p>Kindly help me resolve this issue. I'm using R version 3.3.0. Is there any other way of installing it in R?</p>
","<r><installation><mxnet>","2016-05-09 07:40:42","","2","2702219","2018-08-03 17:00:35","6","1","2","","2702219","396","11","0"
"42328682","<p>I am trying to understand the char lstm example mentioned here - <a href=""https://github.com/dmlc/MXNet.jl/blob/master/examples/char-lstm/lstm.jl"" rel=""nofollow noreferrer"">char-lstm julia example</a></p>

<p>Function lstm_cell accepts the second parameter as previous state -<br>
function lstm_cell(data::mx.SymbolicNode, prev_state::LSTMState, param::LSTMParam;num_hidden::Int=512, dropout::Real=0, name::Symbol=gensym())<br>
However, in the section - #stack LSTM cells</p>

<p>next_state = lstm_cell(hidden, l_state, l_param, num_hidden=dim_hidden, dropout=dp,name=Symbol(name, ""<em>lstm</em>$t""))<br>
hidden = next_state.h<br>
layer_param_states[i] = (l_param, next_state)    </p>

<p>layer_param_states[i] gets updated with the next state-
<strong>layer_param_states[i] = (l_param, next_state)</strong><br>
why is this done here. Why is the previous state being updated with the next state.</p>
","<julia><mxnet>","2017-02-19 14:52:58","","1","7463041","2018-01-11 00:01:09","1","1","","","7463041","81","8","0"
"55253061","<p>I'm trying to install <code>mxnet</code> by cloning a git repository as follows:</p>

<pre><code>git clone --recursive https://github.com/dmlc/mxnet
</code></pre>

<p>However, when I try to build it by dropping into the mxnet directory and running <code>make</code> as follows:</p>

<pre><code>make -j $(nproc) USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1
</code></pre>

<p>I get errors indicating that <code>cblas.h</code> cannot be found - e.g.</p>

<pre><code>/home/me/mxnet/3rdparty/mshadow/mshadow/./base.h:162:14: fatal error: cblas.h: No such file or directory
 #include &lt;cblas.h&gt;
</code></pre>

<p>The output of make is a series of <code>nvcc</code> compilation commands that seem to be as follows:</p>

<pre><code>/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -O3 -ccbin /home/me/anaconda2/envs/deepnets/bin/x86_64-conda_cos6-linux-gnu-c++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=[sm_75,compute_75] --fatbin-options -compress-all -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -DNDEBUG=1 -I/home/me/mxnet/3rdparty/mshadow/ -I/home/me/mxnet/3rdparty/dmlc-core/include -fPIC -I/home/me/mxnet/3rdparty/tvm/nnvm/include -I/home/me/mxnet/3rdparty/dlpack/include -I/home/me/mxnet/3rdparty/tvm/include -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -mf16c -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -I/home/me/mxnet/3rdparty/mkldnn/build/install/include -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_MKLDNN=1 -DUSE_MKL=1 -I/home/me/mxnet/src/operator/nn/mkldnn/ -I/home/me/mxnet/3rdparty/mkldnn/build/install/include -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK -DMSHADOW_USE_CUDNN=1  -I/home/me/mxnet/3rdparty/cub -DMXNET_ENABLE_CUDA_RTC=1 -DMXNET_USE_NCCL=0 -DMXNET_USE_LIBJPEG_TURBO=0"" --generate-dependencies -MT build/src/operator/tensor/elemwise_unary_op_trig_gpu.o src/operator/tensor/elemwise_unary_op_trig.cu &gt;build/src/operator/tensor/elemwise_unary_op_trig_gpu.d
</code></pre>

<p>If I break out (what I believe) to be all the include directories, I can pick out these directories:</p>

<pre><code>-I/home/me/mxnet/3rdparty/mshadow/
-I/home/me/mxnet/3rdparty/dmlc-core/include -fPIC
-I/home/me/mxnet/3rdparty/tvm/nnvm/include
-I/home/me/mxnet/3rdparty/dlpack/include
-I/home/me/mxnet/3rdparty/tvm/include
-Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -mf16c
-I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0
-I/home/me/mxnet/3rdparty/mkldnn/build/install/include -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_MKLDNN=1 -DUSE_MKL=1
-I/home/me/mxnet/src/operator/nn/mkldnn/
-I/home/me/mxnet/3rdparty/mkldnn/build/install/include -DMXNET_USE_OPENCV=1
-I/usr/local/include/opencv
-I/usr/local/include -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK -DMSHADOW_USE_CUDNN=1
-I/home/me/mxnet/3rdparty/cub
</code></pre>

<p>When I look for <code>cblas.h</code>, I get see these copies:</p>

<pre><code>(deepnets) me@Chanticleer:~/mxnet$ sudo find /home -name 'cblas.h'
[sudo] password for me: 
/home/me/anaconda2/pkgs/openblas-0.3.3-h9ac9557_1001/include/cblas.h
/home/me/anaconda2/pkgs/lapack-3.6.1-ha44fe06_2/include/cblas.h
/home/me/anaconda2/pkgs/openblas-0.3.5-h9ac9557_1001/include/cblas.h
/home/me/anaconda2/envs/deepnets/include/cblas.h
/home/me/mxnet/julia/deps/cblas.h
(deepnets) me@Chanticleer:~/mxnet$ sudo find /usr -name 'cblas.h'
/usr/include/atlas/cblas.h
/usr/include/openblas/cblas.h
/usr/include/cblas.h
</code></pre>

<p>Clearly none of these seem to be where the <code>Makefile</code> has been directed to look. Do I need to change the <code>Makefile</code> in some way (how?), or do I need to put a copy of <code>cblas.h</code> in some other directory, or at least a soft link to it. If so, which directory and how?</p>
","<makefile><mxnet><cblas>","2019-03-20 03:17:14","","0","1245262","2019-03-21 20:54:09","1","0","","","1245262","2821","149","3"
"48233780","<p>Recently I decided to learn MXNet, as some code I need to use, is written using this API.</p>

<p>However, I would like to know which are the advantages and disadvantages of MXNet compared to the other Deep Learning Libraries out there.</p>
","<tensorflow><deep-learning><caffe><pytorch><mxnet>","2018-01-12 20:45:45","","2","1351721","2018-01-15 02:27:49","1","1","4","2018-01-16 13:16:33","1351721","270","113","3"
"51126186","<p>I'm learning MXNet at the moment and I'm working on a problem using neural nets. I'm interested in observing the curvature of my loss function with respect to the network weights but as best I can tell higher order gradients are not supported for neural network functions at the moment. Is there any (possibly hacky) way that I could still do this?</p>
","<python><neural-network><gradient><data-science><mxnet>","2018-07-01 19:04:47","","1","3175107","2018-07-09 18:59:18","1","0","","","3175107","21","1","0"
"44398995","<p>I am trying to build a Feed Forward neural network with MXNetR. My input is a data frame with 6380 rows and 180 columns. My training and testing outputs are one-dimensional vectors with 319 elements each.</p>

<p>I run the model with the batch size set to 1 and the number of neurons at the output layer set to 319. So for each batch, I expected to get a vector with 319 elements. I aim to minimize my loss function, which is the correlation between my predicted output vector and actual output vector.</p>

<p>Below is my code:</p>

<pre><code>    # Define the input data
    data &lt;- mx.symbol.Variable(""data"")

    # Define the first fully connected layer
    fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden = 100)
    act.fun &lt;- mx.symbol.Activation(fc1, act_type = ""relu"") # create a hidden layer with Rectified Linear Unit as its activation function.
    output &lt;&lt;- mx.symbol.FullyConnected(act.fun, num_hidden = 319)

    # Customize loss function
    label &lt;- mx.symbol.Variable(""label"")
    lro &lt;-
        mx.symbol.MakeLoss(mx.symbol.Correlation(mx.symbol.reshape(output 
    ,shape = (1,319)),label))

    model &lt;- mx.model.FeedForward.create(symbol=lro, X=train.x, 
                                         y=train.y,
                                         eval.data = list( data = test.x, 
                                                       label = test.y),
                                         num.round=5000, 
                                         array.batch.size=1, 
                                         optimizer = ""adam"",
                                         learning.rate = 0.0003, 
                                         eval.metric = mx.metric.rmse,
                                         epoch.end.callback = 
                                         mx.callback.log.train.metric(20, logger))
</code></pre>

<p>And here is the error when I run the code above:</p>

<pre><code>[15:49:28] /home/cgagnon/src/q5/mxnet/dmlc-core/include/dmlc/./logging.h:304: [15:49:28] src/operator/./correlation-inl.h:176: Check failed: dshape1.ndim() == 4U (2 vs. 4) data should be a 4D tensor

Stack trace returned 10 entries:
[bt] (0) /usr/lib64/R/library/mxnet/libs/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x29) [0x7f725a8528b9]
[bt] (1) /usr/lib64/R/library/mxnet/libs/libmxnet.so(_ZNK5mxnet2op15CorrelationProp10InferShapeEPSt6vectorIN4nnvm6TShapeESaIS4_EES7_S7_+0x2a2) [0x7f725b4a8222]
[bt] (2) /usr/lib64/R/library/mxnet/libs/libmxnet.so(+0xd461f9) [0x7f725b3241f9]
[bt] (3) /usr/lib64/R/library/mxnet/libs/libmxnet.so(+0x116630f) [0x7f725b74430f]
[bt] (4) /usr/lib64/R/library/mxnet/libs/libmxnet.so(+0x1167bb2) [0x7f725b745bb2]
[bt] (5) /usr/lib64/R/library/mxnet/libs/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7f725b761481]
[bt] (6) /usr/lib64/R/library/mxnet/libs/libmxnet.so(_ZN4nnvm9ApplyPassENS_5GraphERKSs+0x8e) [0x7f725b699f2e]
[bt] (7) /usr/lib64/R/library/mxnet/libs/libmxnet.so(_ZN4nnvm4pass10InferShapeENS_5GraphESt6vectorINS_6TShapeESaIS3_EESs+0x240) [0x7f725b69c520]
[bt] (8) /usr/lib64/R/library/mxnet/libs/libmxnet.so(MXSymbolInferShape+0x281) [0x7f725b6959a1]
[bt] (9) /usr/lib64/R/library/mxnet/libs/mxnet.so(_ZNK5mxnet1R6Symbol10InferShapeERKN4Rcpp6VectorILi19ENS2_15PreserveStorageEEE+0x6b9) [0x7f724cef6739]
</code></pre>

<p>At the moment, I am clueless about how I should fix this error. I have been searching for a way to reshape my data sets so that they are 4D tensors but could not find any. I do not look for an explicit solution for my problem, but any suggestions on how I should tackle this error would be greatly appreciated.</p>
","<r><neural-network><deep-learning><mxnet><tensor>","2017-06-06 20:10:52","","0","8121795","2017-06-06 22:36:41","1","0","","","8121795","11","0","0"
"44420877","<p>I am creating a network using mxnetR and want to create a customized operator. I look at the mx.symbol.Custom function in the package and the description says that I should use a front end language like Python to define my operation.</p>

<p>I found a sample code here: <a href=""https://github.com/dmlc/mxnet/issues/4205"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/issues/4205</a> where the programmer use the @mx.operator.register decorator followed by the definition of the operation. I wonder if I can do the same thing in R.</p>
","<python><r><neural-network><deep-learning><mxnet>","2017-06-07 19:06:19","","0","8121795","2018-03-07 01:10:48","1","0","","","8121795","11","0","0"
"44350485","<p>I am reading the mxnet tutorial on <a href=""http://mxnet.io/tutorials/basic/ndarray.html"" rel=""nofollow noreferrer"">NDarray part</a> and I am confused about the use of <code>sum_axis</code> function and the example is :</p>

<pre><code>&gt;&gt;&gt; a = mx.nd.ones((2,3))
&gt;&gt;&gt; c = mx.nd.sum_axis(a, axis=1)
&gt;&gt;&gt; c.asnumpy()
    array([ 3.,  3.], dtype=float32)
&gt;&gt;&gt; c = mx.nd.sum_axis(a, axis=0)
&gt;&gt;&gt; c.asnumpy()
    array([ 2.,  2.,  2.], dtype=float32)
</code></pre>

<p>What I am wondering is when the value of paramter <code>axis</code> is <code>1</code>, I think it should output </p>

<pre><code>array([ 2.,  2.,  2.], dtype=float32)
</code></pre>

<p>but not </p>

<pre><code>array([ 3.,  3.], dtype=float32)
</code></pre>

<p>As when the value of paramter <code>axis</code> is <code>1</code>, I think the <code>sum_axis</code> should compute the sum along the column ,but the result shows it compute the sum along the rows.</p>

<p>And it seems that  <code>numpy</code> also compute like this and I really don't understand why this way.
So anyone could explain this ?</p>

<p>Thanks!!</p>
","<mxnet>","2017-06-04 03:23:40","","0","1347796","2017-06-05 17:06:59","1","0","","","1347796","391","213","1"
"51640057","<p>My data are not timeseries, but it has sequential properties.</p>

<p>Consider one sample: </p>

<pre><code>data1 = matrix(rnorm(10, 0, 1), nrow = 1)
label1 = rnorm(1, 0, 1)
</code></pre>

<p>label1 is a function of the data1, but the data matrix is not a timeseries. I suppose that label is a function of not just one data sample, but more older samples, which are naturally ordered in time (not sampled randomly), in other words, data samples are dependent with one another.</p>

<p>I have a batch of examples, say, 16.</p>

<p>With that I want to understand how I can design an RNN/LSTM model which will memorize all 16 examples from the batch to construct the internal state. I am especially confused with the <code>seq_len</code> parameter, which as I understand is specifically about the length of the timeseries used as an input to a network, which is not case.</p>

<p>Now this piece of code (taken from a timeseries example) only confuses me because I don't see how my task fits in.</p>

<pre><code>rm(symbol)

symbol &lt;- rnn.graph.unroll(seq_len = 5, 
                           num_rnn_layer =  1, 
                           num_hidden = 50,
                           input_size = NULL,
                           num_embed = NULL, 
                           num_decode = 1,
                           masking = F, 
                           loss_output = ""linear"",
                           dropout = 0.2, 
                           ignore_label = -1,
                           cell_type = ""lstm"",
                           output_last_state = F,
                           config = ""seq-to-one"")

graph.viz(symbol, type = ""graph"", direction = ""LR"", 
          graph.height.px = 600, graph.width.px = 800)

train.data &lt;- mx.io.arrayiter(
          data = matrix(rnorm(100, 0, 1), ncol = 20)
          , label = rnorm(20, 0, 1)
          , batch.size = 20
          , shuffle = F
                 )
</code></pre>
","<r><lstm><mxnet>","2018-08-01 18:29:51","","0","8532487","2018-08-08 21:21:39","1","2","","","8532487","162","20","0"
"51657108","<p>I have two separate folders containing 3D arrays (data), each folder contains files of the same classification. I used mxnet.gluon.data.ArrayDataset() create datasets for each label respectively. Is there a way to combine these two datasets into the final training dataset that combines both classifications? The new data sets are different size. </p>

<p>e.g</p>

<pre><code>A_data = mx.gluon.data.ArrayDataset(list2,label_A )
noA_data = mx.gluon.data.ArrayDataset(list,label_noA)
</code></pre>

<p>^ I want to combine A_data and noA_data for a complete dataset. </p>

<p>Additionally, is there an easier way to combine the two folders with its classification into a mxnet dataset from the get-go? That would also solve my problem.</p>
","<python-2.7><neural-network><mxnet>","2018-08-02 15:17:57","","0","10171841","2018-08-02 17:50:47","1","0","","","10171841","6","0","0"
"44452571","<p>Since Adam Optimizer keeps an pair of running averages like mean/variance for the gradients, I wonder how it should properly handle weight decay. I have seen two ways of implementing it.</p>

<ol>
<li><p>Only update mean/variance from the gradients based on the objective loss, decay weight explicitly at each mini-batch.  (the following code is taken from <a href=""https://github.com/dmlc/mxnet/blob/v0.7.0/python/mxnet/optimizer.py"" rel=""noreferrer"">https://github.com/dmlc/mxnet/blob/v0.7.0/python/mxnet/optimizer.py</a>)</p>

<pre><code>weight[:] -= lr*mean/(sqrt(variance) + self.epsilon)

wd = self._get_wd(index)
if wd &gt; 0.:
    weight[:] -= (lr * wd) * weight
</code></pre></li>
<li><p>Update mean/variance from the gradients based on the objective loss + regularization loss, and update weights like usual. (the following code is taken from <a href=""https://github.com/dmlc/mxnet/blob/master/src/operator/optimizer_op-inl.h#L210"" rel=""noreferrer"">https://github.com/dmlc/mxnet/blob/master/src/operator/optimizer_op-inl.h#L210</a>)</p>

<pre><code>grad = scalar&lt;DType&gt;(param.rescale_grad) * grad +
scalar&lt;DType&gt;(param.wd) * weight;
// stuff
Assign(out, req[0],
   weight -
   scalar&lt;DType&gt;(param.lr) * mean /
   (F&lt;square_root&gt;(var) + scalar&lt;DType&gt;(param.epsilon)));
</code></pre></li>
</ol>

<p>These two approaches sometimes show significant difference in training results. And I actually think the first one makes more sense (and find it gives better results time to time).  Caffe and old version of mxnet follow the first approach, while torch, tensorflow and new version of mxnet follow the second one. </p>

<p>Really appreciate your help！</p>
","<tensorflow><deep-learning><caffe><torch><mxnet>","2017-06-09 08:08:41","","7","6238109","2019-02-14 00:02:55","2","2","0","","6238109","36","3","0"
"51663328","<p>I have a working python code in keras wit tensorflow backend. I am utilizing transfer learning from VGG16 . All is good.</p>

<p>I wan to use mxnet backend but had some issues:</p>

<pre><code>from keras.preprocessing.image import ImageDataGenerator
from keras import applications
from helper import target_size, batch_size
from math import ceil
import numpy as np

datagen = ImageDataGenerator(rescale=1./255)
</code></pre>

<blockquote>
  <p>loading vgg16 model, excluding the top fully connected layers</p>
</blockquote>

<pre><code>model = applications.VGG16(include_top=False, weights='imagenet' , input_shape=(224, 224 , 3))
</code></pre>

<p>above code (shape(224,224,3)) gives :</p>

<blockquote>
  <p>ValueError: The input must have 3 channels; got <code>input_shape=(224, 224, 3)</code></p>
</blockquote>

<p>if I use : shape(3,224,24)</p>

<blockquote>
  <p>'Redefinition of variable %s' % self.name
  AssertionError: Redefinition of variable block1_conv1/kernel1</p>
</blockquote>

<p>how can I properly use mxnet instead of tensorflow backend in working code?</p>

<p>thx</p>

<p>Note: keras.json:</p>

<pre><code>{
""epsilon"": 1e-07, 
""floatx"": ""float32"", 
""image_data_format"": ""channels_first"", 
""backend"": ""mxnet""
</code></pre>

<p>}</p>

<h1>EDIT 1:</h1>

<p>when I change the backend to mxnet from tensorflow is keras need to re-download vgg16 model for mxnet ? </p>
","<python><tensorflow><keras><mxnet>","2018-08-02 23:15:29","","1","9188950","2018-09-01 20:33:51","1","2","1","","9188950","137","10","0"
"49567237","<p>Im new to MXNet and I was wondering if any one knows how to fine tune more layers in CNN other than only the FC layers. All the examples that Im looking at, have fine tuning only on the FC layers. In Keras this can be easily done and more blocks of ConvNets other than FC block can be fine tuned: <a href=""https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/10_Fine-Tuning.ipynb"" rel=""nofollow noreferrer"">https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/10_Fine-Tuning.ipynb</a></p>

<p><a href=""https://i.stack.imgur.com/fO687.png"" rel=""nofollow noreferrer"">Pre-trained network</a></p>

<p>If we want to fine-tune only the FC block, we make all the layers trainability to false:
layer.trainable = False</p>

<p><a href=""https://i.stack.imgur.com/qBS8L.png"" rel=""nofollow noreferrer"">finetune the FC layers</a></p>

<p>If we want to fine-tune more blocks of ConnNet other than FC layers, we make the layer.trainable=True for those layers:
<a href=""https://i.stack.imgur.com/ZvnaN.png"" rel=""nofollow noreferrer"">finetune blocks of ConvNet in Keras</a></p>

<p>My question is how to do similarly in MXNet</p>
","<deep-learning><conv-neural-network><mxnet>","2018-03-30 01:25:26","","0","9565715","2018-07-20 03:37:55","1","1","","","9565715","16","1","0"
"53525630","<p><code>mxnet</code> version 1.3.0</p>

<p>I am attempting to [train_mnist.py][1] on 2 nodes of a cluster, one with 3 GPUs (nodeA) and one with 1 GPU (nodeB). Following this [blog post][2], I am doing so using the provided [launch.py][3] script in the <code>mxnet</code> repo.</p>

<p>I have set up a <code>hosts</code> file that consists of the two hostnames:</p>

<pre><code>username@nodeA
username@nodeB
</code></pre>

<p>And then I have attempted to launch distributed training like this:</p>

<pre><code>    python3 launch.py -n 4 -H hosts ""/opt/python/current/bin/python3 train_mnist.py  
           --network mlp --lr-factor .9 --lr .01 --kv-store dist_sync""
</code></pre>

<p>(Note that I did modify fit.py so that the script detects how many gpus are on its local host and sets the <code>context</code> accordingly, and I have verified that this works on each node separately). </p>

<p>I am running into this error:</p>

<pre><code>Traceback (most recent call last):
  File ""train_mnist.py"", line 28, in &lt;module&gt;
    from common import find_mxnet, fit
  File ""/home/username/username/common/find_mxnet.py"", line 20, in &lt;module&gt;
    import mxnet as mx
  File ""/opt/python/current/lib/python3.6/site-packages/mxnet/__init__.py"", line 57, in &lt;module&gt;
    from . import kvstore_server
  File ""/opt/python/current/lib/python3.6/site-packages/mxnet/kvstore_server.py"", line 85, in &lt;module&gt;
    _init_kvstore_server_module()
  File ""/opt/python/current/lib/python3.6/site-packages/mxnet/kvstore_server.py"", line 82, in _init_kvstore_server_module
    server.run()
  File ""/opt/python/current/lib/python3.6/site-packages/mxnet/kvstore_server.py"", line 73, in run
    check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))
  File ""/opt/python/current/lib/python3.6/site-packages/mxnet/base.py"", line 252, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [10:44:47] src/van.cc:291: Check failed: (my_node_.port) != (-1) bind failed
</code></pre>

<p>And this continues with stack trace info:</p>

<pre><code>Stack trace returned 10 entries:
[bt] (0) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3617ba) [0x7f2cb77d37ba]
[bt] (1) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x361dd1) [0x7f2cb77d3dd1]
[bt] (2) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x312b3fa) [0x7f2cba59d3fa]
[bt] (3) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31352fa) [0x7f2cba5a72fa]
[bt] (4) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31265e9) [0x7f2cba5985e9]
[bt] (5) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2be69d3) [0x7f2cba0589d3]
[bt] (6) /opt/python/current/lib/python3.6/site-packages/mxnet/libmxnet.so(MXKVStoreRunServer+0x88) [0x7f2cb9e4b7f8]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f2d12c9ddae]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f2d12c9d71f]
[bt] (9) /opt/python/current/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x29f) [0x7f2d12eb24af]
</code></pre>

<p>What I've tried so far:</p>

<ul>
<li>Reducing my hosts file to include only one host. I tried with both options (so running just <code>nodeA</code> or just <code>nodeB</code>), but I got the same error</li>
<li>Changing the number of workers (but I thought it should reflect the number of gpus available)</li>
<li>Looking for <code>my_node_</code> in either of the last 2 files mention in the traceback, namely <code>/opt/python/current/lib/python3.6/site-packages/mxnet/base.py</code> and <code>/opt/python/current/lib/python3.6/site-packages/mxnet/kvstore_server.py</code>. Neither of these files seems to contain a reference to that variable. </li>
</ul>

<p>I'm not sure where to go from here. I was under the impression distributed training was supposed to be fairly seamless with <code>mxnet</code> so I'm hoping it's an easy fix. Would welcome suggestions of what to check and/or how to debug this code. Thanks.</p>

<pre><code>  [1]: https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/train_mnist.pyn
  [2]: https://tsmatz.wordpress.com/2017/02/22/mxnetr-gpu-acceleration-distributed-training-active-learning/
  [3]: https://github.com/apache/incubator-mxnet/blob/master/tools/launch.py
</code></pre>
","<python><distributed-system><mxnet>","2018-11-28 18:12:18","","0","8762321","2018-11-28 18:12:18","0","1","","","8762321","116","7","0"
"49548422","<p>I've uploaded my own Jupyter notebook to Sagemaker, and am trying to create an iterator for my training / validation data which is in S3, as follow:</p>

<pre><code>train = mx.io.ImageRecordIter(
        path_imgrec         = ‘s3://bucket-name/train.rec’ …… )
</code></pre>

<p>I receive the following exception: </p>

<pre><code>MXNetError: [04:33:32] src/io/s3_filesys.cc:899: Need to set enviroment variable AWS_SECRET_ACCESS_KEY to use S3
</code></pre>

<p>I've checked that the IAM role attached with this notebook instance has S3 access. Any clues on what might be needed to fix this?</p>
","<amazon-web-services><amazon-s3><mxnet><amazon-sagemaker>","2018-03-29 05:07:08","","2","5628686","2018-05-05 20:01:50","1","0","2","","5628686","315","15","1"
"50675708","<p>I'm trying to make transfer learning method on MXNet on Sagemaker instance. Train and serve start locally without any problem and I'm using that python code to predict:</p>

<pre><code>def predict_mx(net, fname):
    with open(fname, 'rb') as f:
      img = image.imdecode(f.read())
      plt.imshow(img.asnumpy())
      plt.show()
    data = transform(img, -1, test_augs)
    plt.imshow(data.transpose((1,2,0)).asnumpy()/255)
    plt.show()
    data = data.expand_dims(axis=0)
    return net.predict(data.asnumpy().tolist())
</code></pre>

<p>I checked <code>data.asnumpy().tolist()</code> that is ok and pyplot draw images (firts is the original image, the second is the resized image). But <code>net.predict</code> raise an error:</p>

<pre><code>---------------------------------------------------------------------------
JSONDecodeError                           Traceback (most recent call last)
&lt;ipython-input-171-ea0f1f5bdc72&gt; in &lt;module&gt;()
----&gt; 1 predict_mx(predictor.predict, './data2/burgers-imgnet/00103785.jpg')

&lt;ipython-input-170-150a72b14997&gt; in predict_mx(net, fname)
     30     plt.show()
     31     data = data.expand_dims(axis=0)
---&gt; 32     return net(data.asnumpy().tolist())
     33 

~/Projects/Lab/ML/AWS/v/lib64/python3.6/site-packages/sagemaker/predictor.py in predict(self, data)
     89         if self.deserializer is not None:
     90             # It's the deserializer's responsibility to close the stream
---&gt; 91             return self.deserializer(response_body, response['ContentType'])
     92         data = response_body.read()
     93         response_body.close()

~/Projects/Lab/ML/AWS/v/lib64/python3.6/site-packages/sagemaker/predictor.py in __call__(self, stream, content_type)
    290         """"""
    291         try:
--&gt; 292             return json.load(codecs.getreader('utf-8')(stream))
    293         finally:
    294             stream.close()

/usr/lib64/python3.6/json/__init__.py in load(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)
    297         cls=cls, object_hook=object_hook,
    298         parse_float=parse_float, parse_int=parse_int,
--&gt; 299         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)
    300 
    301 

/usr/lib64/python3.6/json/__init__.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)
    352             parse_int is None and parse_float is None and
    353             parse_constant is None and object_pairs_hook is None and not kw):
--&gt; 354         return _default_decoder.decode(s)
    355     if cls is None:
    356         cls = JSONDecoder

/usr/lib64/python3.6/json/decoder.py in decode(self, s, _w)
    337 
    338         """"""
--&gt; 339         obj, end = self.raw_decode(s, idx=_w(s, 0).end())
    340         end = _w(s, end).end()
    341         if end != len(s):

/usr/lib64/python3.6/json/decoder.py in raw_decode(self, s, idx)
    355             obj, end = self.scan_once(s, idx)
    356         except StopIteration as err:
--&gt; 357             raise JSONDecodeError(""Expecting value"", s, err.value) from None
    358         return obj, end

JSONDecodeError: Expecting value: line 1 column 1 (char 0)
</code></pre>

<p>I tried to json.dumps my data, and there is no problem with that.</p>

<p>Note that I didn't deployed the service on AWS yet, I want to be able to test the model and prediction locally before to make a larger train and to serve it later.</p>

<p>Thanks for your help</p>
","<python><mxnet><amazon-sagemaker>","2018-06-04 07:48:56","","2","1472048","2018-07-14 16:02:52","2","4","2","","1472048","2072","63","5"
"55785465","<p>I am using the code below to create a Sequential Gluon model. For some reason the property params returns an empty collection.</p>

<pre><code>def build_net():
    net = gluon.nn.Sequential()
    with net.name_scope():
        net.add(gluon.nn.Dense(32, activation='relu'))
        net.add(gluon.nn.Dense(32, activation='relu'))
        net.add(gluon.nn.Dense(1))

    net.collect_params().initialize(mx.init.Normal(sigma=.1))
    return net

net_1 = build_net() 
print(net_1.params)
</code></pre>

<p>Output:</p>

<pre><code>sequential0_ (

)
</code></pre>
","<python><mxnet>","2019-04-21 18:18:30","","0","1576254","2019-04-23 15:58:45","1","0","","","1576254","421","74","2"
"53547317","<p>I am new to <code>mxnet</code> and running a script lightly modified from the documentation on <a href=""https://gluon.mxnet.io/chapter05_recurrent-neural-networks/rnns-gluon.html"" rel=""nofollow noreferrer"">RNN with gluon</a>. I modified the code so that I am working with strictly numerical time series rather than an NLP problem. Everything was running great until I modified this line:</p>

<pre><code>context = mx.gpu()
</code></pre>

<p>to </p>

<pre><code>GPU_COUNT = 3
context = [mx.gpu(i) for i in range(GPU_COUNT)]
</code></pre>

<p>now the variable initialization triggers an error that causes a crash, in particular at this line:</p>

<pre><code>model.collect_params().initialize(mx.init.Xavier(), ctx=context)
</code></pre>

<p>The line causes this error:</p>

<pre><code>mxnet.base.MXNetError: include/mxnet/./base.h:388: Invalid context string[]
</code></pre>

<p>I have only been using <code>mxnet</code> for a few days, so I am not very knowledgeable about what could go wrong. However, I have run another sample script - for an MLP - where I also swapped in multiple gpus for a single one, and that ran fine. </p>

<p>This made me think that it is the RNN, and indeed when I removed the RNN portion of the code (so that it's just essentially a feed forward network) it runs the troublesome line just fine with any valid number of GPUs. Also, I tried both with a 'rnn_relu' option and a 'gru' option, and they both failed with the same error.</p>

<p>So my question is: <strong>do <code>mxnet</code> RNNs work with multuple GPUs (one machine) in <code>mxnet</code> currently via the gluon API?</strong> I don't see this discussed one way or the other in the docs, although I have seen some discussions on <a href=""https://github.com/apache/incubator-mxnet/issues/9344"" rel=""nofollow noreferrer"">github</a> as to certain functions not being implemented for multi device use. How would I confirm this theory? Also are there other explanations I should be checking into?</p>
","<python><gpu><mxnet>","2018-11-29 20:46:20","","0","8762321","2018-11-30 20:18:11","1","0","","","8762321","116","7","0"
"49475134","<p>I am trying to use mxnet ssd object detection provided in <a href=""http://gluon.mxnet.io/chapter08_computer-vision/object-detection.html?highlight=multiboxtarget"" rel=""nofollow noreferrer"">mxnet SSD</a>, while I'm trying with provided data set with two classes, it works fine. But I am trying to use my own data set with 40 different classes, there is a problem.</p>

<p>I noticed that ""MultiBoxTarget"" always returns zero. I am not familiar with the mechanism of MultiBoxTarget and can not figure the problem exactly.</p>

<p>Is there any one who can describe this function for me?
Any helpful hint is appreciated.   </p>
","<machine-learning><deep-learning><mxnet>","2018-03-25 11:09:20","","1","9442808","2018-11-20 23:09:36","1","3","","","9442808","109","10","0"
"39392340","<p>I need to convert an image in a numpy array loaded via cv2 into the correct format for the deep learning library mxnet for its convolutional layers.</p>

<p>My current images are shaped as follows: (256, 256, 3), or (height, width, channels).</p>

<p>From what I've been told, this actually needs to be (3, 256, 256), or (channels, height, width).</p>

<p>Unfortunately, my knowledge of numpy/python opencv isn't good enough to know how to manipulate the arrays correctly.</p>

<p>I've figured out that I could split the arrays into channels by cv2.split, but I'm uncertain of how to combine them again in the right format (I don't know if using cv2.split is optimal, or if there are better ways in numpy).</p>

<p>Thanks for any help.</p>
","<python><opencv><numpy><mxnet>","2016-09-08 13:30:41","","2","791025","2016-09-08 13:48:56","1","0","1","","791025","1201","89","2"
"44457432","<p>I am implementing a neural network in MXNetR. I attempted to customize my loss function to compute the correlation between my output vector and the targeting vector. Below is my code:</p>

<p>Below is my code:</p>

<pre><code># Generate testing data
train.x = matrix(data = rexp(200, rate = 10), nrow = 120, ncol = 6380)
test.x = matrix(data = rexp(200, rate = 10), nrow = 60, ncol = 6380)
train.y = matrix(data = rexp(200, rate = 10), nrow = 120, ncol = 319)
test.y = matrix(data = rexp(200, rate = 10), nrow = 60, ncol = 319)

# Reshape testing data
train.array &lt;-train.x
dim(train.array) &lt;-c(20,319,1,ncol(train.x))
test.array&lt;-test.x
dim(test.array) &lt;-c (20,319,1,ncol(test.x))

# Define the input data
data &lt;- mx.symbol.Variable(""data"")

# Define the first fully connected layer
fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden = 100)
act.fun &lt;- mx.symbol.Activation(fc1, act_type = ""relu"") # create a hidden layer with Rectified Linear Unit as its activation function.
output &lt;&lt;- mx.symbol.FullyConnected(act.fun, num_hidden = 319)

# Customize loss function
label &lt;- mx.symbol.Variable(""label"")

output_mean &lt;- mx.symbol.mean(output)
label_mean &lt;- mx.symbol.mean(label)

output_delta &lt;-mx.symbol.broadcast_sub(output, output_mean)
label_delta &lt;- mx.symbol.broadcast_sub(label, label_mean)

output_sqr &lt;-mx.symbol.square(output_delta)
label_sqr &lt;- mx.symbol.square(label_delta)

output_sd &lt;- mx.symbol.sqrt(mx.symbol.sum(output_delta))
label_sd &lt;- mx.symbol.sqrt(mx.symbol.sum(label_delta))

numerator &lt;- mx.symbol.sum(output_delta * label_delta)
denominator &lt;- output_sd * label_sd

lro &lt;- mx.symbol.MakeLoss(numerator/denominator)

# Generate a new model
model &lt;- mx.model.FeedForward.create(symbol=lro, X=train.array, y=train.y, 
                                 num.round=5000, array.batch.size=1, optimizer = ""adam"",
                                 learning.rate = 0.0003, eval.metric = mx.metric.rmse,
                                 epoch.end.callback = mx.callback.log.train.metric(20, logger))
</code></pre>

<p>And I got this error:</p>

<pre><code>Error in mx.model.init.params(symbol, input.shape, initializer, mx.cpu()) : 
Not enough information to get shapes
</code></pre>

<p>I tried to wrap the whole correlation formula in MXNet:</p>

<pre><code>lro2 &lt;- mx.symbol.MakeLoss(
    mx.symbol.negative((mx.symbol.sum(output * label) -
    (mx.symbol.sum(output) * mx.symbol.sum(label))) /
    mx.symbol.sqrt((mx.symbol.sum(mx.symbol.square(output)) -
    ((mx.symbol.sum(output)) * (mx.symbol.sum(output)))) *
    (mx.symbol.sum(mx.symbol.square(label)) - ((mx.symbol.sum(label)) * (mx.symbol.sum(label))))))
)
</code></pre>

<p>I can compile with this version, but my model runs very slowly and the code is apparently not very readable. I wonder if there is any way to implement get around the error and implement the first version as I described above.</p>
","<r><neural-network><deep-learning><mxnet>","2017-06-09 12:07:27","","1","8121795","2018-05-04 20:10:13","1","1","","","8121795","11","0","0"
"51678419","<p>I have a folder containing files with 11*11*21 3D data and I am trying to do a binary classification with a 3D convolutional neural network. I only found the tutorial for the 2D convolutional NN on the gluon tutorials and I am not sure what things to change to accommodate 3D data. I am following this tutorial but using my own data, I tried to change the layer to 3D but I am stuck on what else I need to change. <a href=""https://gluon.mxnet.io/chapter04_convolutional-neural-networks/cnn-gluon.html"" rel=""nofollow noreferrer"">https://gluon.mxnet.io/chapter04_convolutional-neural-networks/cnn-gluon.html</a></p>

<p>I am very new to convnets and 3D convnets so any help would be greatly appreciated.   </p>
","<python-2.7><deep-learning><conv-neural-network><mxnet>","2018-08-03 18:41:34","","-1","10171841","2018-08-03 23:11:05","1","0","","","10171841","6","0","0"
"48691875","<p>I have onnx 0.2.1 installed on my conda virtual environment</p>

<pre><code>conda list | grep onnx

packages in environment at /Users/aanirud/anaconda2/envs/onnx:
onnx 0.2.1 py27_1 ezyang
onnx-caffe2 0.2.1 py27hbe716ef_1 ezyang
onnx-mxnet 0.4.1
</code></pre>

<p>But I am not able to use the onnx.checker or onnx.helper attributes. When I try to use them I get the following error -</p>

<pre><code>import onnx
onnx.checker.check_model(""toy_model.onnx"")
Traceback (most recent call last):
File """", line 1, in 
AttributeError: 'module' object has no attribute 'checker'
</code></pre>

<p>Get the same error when I try to use onnx.helper. What am I doing wrong here?</p>
","<tensorflow><deep-learning><protocol-buffers><mxnet><caffe2>","2018-02-08 17:55:25","","0","1788146","2018-02-09 00:19:15","1","0","","","1788146","1","0","0"
"50672439","<p>I'm trying to implement my own optimization algorithm for MxNet (Imperative / Gluon) that does not use gradients. My question is pretty simple is there a simple way to create new <code>nn.Dense(...)</code> layer initialized with parameters (i.e. Biases and Weights) represented by two nd.array() instances?</p>

<p>Thank you in advance!</p>
","<mxnet>","2018-06-04 01:27:59","","0","504325","2018-06-09 00:28:44","1","1","","","504325","8875","272","31"
"49658834","<p>I have trained and saved a model using Amazon SageMaker which saves the model in the format of <code>model.tar.gz</code> which when untarred, has a file <code>model_algo-1</code> which is a serialized Apache MXNet object. To load the model in memory I need to deserialize the model. I tried doing so as follows:</p>

<p><code>import mxnet as mx
print(mx.ndarray.load('model_algo-1'))</code></p>

<p>Reference taken from <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html</a></p>

<p>However, doing this yields me the following error:</p>

<pre><code>Traceback (most recent call last):
File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
File ""/usr/local/lib/python3.4/site-packages/mxnet/ndarray/utils.py"", line 
175, in load
ctypes.byref(names)))
File ""/usr/local/lib/python3.4/site-packages/mxnet/base.py"", line 146, in 
check_call
raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [19:06:25] src/ndarray/ndarray.cc:1112: Check failed: 
header == kMXAPINDArrayListMagic Invalid NDArray file format

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.4/site-packages/mxnet/libmxnet.so(+0x192112) 
[0x7fe432bfa112]
[bt] (1) /usr/local/lib/python3.4/site-packages/mxnet/libmxnet.so(+0x192738) 
[0x7fe432bfa738]
[bt] (2) /usr/local/lib/python3.4/site-
packages/mxnet/libmxnet.so(+0x24a5c44) [0x7fe434f0dc44]
[bt] (3) /usr/local/lib/python3.4/site-
packages/mxnet/libmxnet.so(MXNDArrayLoad+0x248) [0x7fe434d19ad8]
[bt] (4) /usr/lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe48c5bbcec]
[bt] (5) /usr/lib64/libffi.so.6(ffi_call+0x1f5) [0x7fe48c5bb615]
[bt] (6) /usr/lib64/python3.4/lib-dynload/_ctypes.cpython-
34m.so(_ctypes_callproc+0x2fb) [0x7fe48c7ce18b]
[bt] (7) /usr/lib64/python3.4/lib-dynload/_ctypes.cpython-34m.so(+0xa4cf) 
[0x7fe48c7c84cf]
[bt] (8) /usr/lib64/libpython3.4m.so.1.0(PyObject_Call+0x8c) 
[0x7fe4942fcb5c]
[bt] (9) /usr/lib64/libpython3.4m.so.1.0(PyEval_EvalFrameEx+0x36c5) 
[0x7fe4943ac915]
</code></pre>

<p>Could someone suggest how this can be resolved?</p>
","<mxnet><amazon-sagemaker>","2018-04-04 19:21:07","","1","6865456","2019-03-15 00:26:26","2","3","1","","6865456","159","0","0"
"40857033","<p>I followed the tutorial of object detection in mxnet,
<a href=""http://mxnet.io/tutorials/computer_vision/detection.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/computer_vision/detection.html</a>
but I don't download the pretrained network and place the extracted file final-0000.params.
Where place I can find the file to download in the Internet?</p>
","<mxnet>","2016-11-29 02:56:17","","0","7194417","2016-12-12 17:35:12","2","0","1","","7194417","13","0","0"
"38561304","<p>I have created <strong>Mxnet</strong> Rec data through <strong>Im2rec</strong>. I would like to feed this into <strong>Tensorflow</strong>. Is it possible ? and How would i do that? Any idea ?</p>
","<python><tensorflow><mxnet>","2016-07-25 06:48:38","","2","4891866","2017-07-17 02:17:02","1","0","","","4891866","80","1","0"
"47841051","<p>I'm having trouble making an MLP in MxNet learn. It tends to output fairly constant values, only occasionally outputting anything different. I'm using the Pima Indians dataset to do binary classification, but no matter what I do (normalisation, scaling, changing activations, objective functions, number of neurons, batch size, epochs) it wouldn't produce anything useful.</p>

<p>The same MLP in Keras works fine.</p>

<p>Here's the MxNet code:</p>

<pre><code>batch_size=10
train_iter=mx.io.NDArrayIter(mx.nd.array(df_train), mx.nd.array(y_train), 
batch_size, shuffle=True)
val_iter=mx.io.NDArrayIter(mx.nd.array(df_test), mx.nd.array(y_test), batch_size)

data=mx.sym.var('data')

fc1 = mx.sym.FullyConnected(data=data, num_hidden=12)
act1 = mx.sym.Activation(data=fc1, act_type='relu')

fc2 = mx.sym.FullyConnected(data=act1, num_hidden=8)
act2 = mx.sym.Activation(data=fc2, act_type='relu')

fcfinal = mx.sym.FullyConnected(data=act2, num_hidden=2)
mlp = mx.sym.SoftmaxOutput(data=fcfinal, name='softmax')

mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())
mlp_model.fit(train_iter,
          eval_data=val_iter,
          optimizer='sgd',
          eval_metric='ce',
          num_epoch=150)
</code></pre>

<p>And the same MLP in Keras:</p>

<pre><code>model = Sequential()
model.add(Dense(12, input_dim=8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(df_train_res, y_train_res)
</code></pre>
","<python><deep-learning><mxnet>","2017-12-15 23:20:14","","0","8687359","2017-12-21 17:44:11","1","0","","","8687359","48","2","0"
"47691395","<p>When we define a deep learning model, we do the following steps:</p>

<ol>
<li>Specify how the output should be calculated based on the input and the model's parameters.</li>
<li>Specify a cost (loss) function.</li>
<li>Search for the model's parameters by minimizing the cost function.</li>
</ol>

<p>It looks to me that in MXNet the first two steps are bound. For example, in the following way I define a linear transformation:</p>

<pre><code># declare a symbolic variable for the model's input
inp = mx.sym.Variable(name = 'inp')
# define how output should be determined by the input
out = mx.sym.FullyConnected(inp, name = 'out', num_hidden = 2)

# specify input and model's parameters
x = mx.nd.array(np.ones(shape = (5,3)))
w = mx.nd.array(np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]))
b = mx.nd.array(np.array([7.0, 8.0]))

# calculate output based on the input and parameters
p = out.bind(ctx = mx.cpu(), args = {'inp':x, 'out_weight':w, 'out_bias':b})
print(p.forward()[0].asnumpy())
</code></pre>

<p>Now, if I want to add a SoftMax transformation on top of it, I need to do the following:</p>

<pre><code># define the cost function
target = mx.sym.Variable(name = 'target')
cost = mx.symbol.SoftmaxOutput(out, target, name='softmax')

y = mx.nd.array(np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0]]))
c = cost.bind(ctx = mx.cpu(), args = {'inp':x, 'out_weight':w, 'out_bias':b, 'target':y})
print(c.forward()[0].asnumpy())
</code></pre>

<p>What I do not understand, is why do we need to create the symbolic variable <code>target</code>. We would need it only if we want to calculate costs, but so far, we just calculate output based on the input (by doing a linear transformation and SoftMax).</p>

<p>Moreover, we need to provide a numerical value for the target to get the output calculated. So, it looks like it is required but it is not used (the provided value of the target does not change the value of the output).</p>

<p>Finally, we can use the <code>cost</code> object to define a model which we can fit as soon as we have data. But what about the cost function? It has to be specified, but it is not. Basically, it looks like I am forced to use a specific cost bunction just because I use SoftMax. But why?</p>

<p><strong>ADDED</strong></p>

<p>For more statistical / mathematical point of view check <a href=""https://stats.stackexchange.com/questions/307025/is-there-a-binding-between-loss-functions-and-models"">here</a>. Although the current question is more pragmatic / programmatic in nature. It is basically: How to decouple the output nonlinearity and the cost function in MXNEt. For example I might want to do a linear transformation and then find the model parameters by minimizing absolute deviation instead of squared one.</p>
","<deep-learning><mxnet>","2017-12-07 09:11:23","","2","245549","2017-12-29 15:41:59","1","0","1","","245549","29447","811","37"
"47927281","<p>I want each epoch information to be stored in a log file to see the accuracy versus epoch, but I am not able to log. Why?</p>

<pre><code>mnist = mx.test_utils.get_mnist()
batch_size = 100

print(os.getcwd())

log_file = '1.log'#''process_fold_' + str(0) + '_trial_' + str(1) + '.log'
logging.basicConfig(format='%(asctime)s %(levelname)s - %(message)s', datefmt='%d/%m/%Y %I:%M:%S %p', filename=log_file, level=logging.INFO)
logging.info('Started training on fold {} at trial {}'.format(0, 0))

train_iter = mx.io.NDArrayIter(mnist['train_data'],mnist['train_label'], batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'],
                             batch_size)  # important as the prediction need not have equal barch size
lenet =get_my_net()
# create a trainable module on GPU 0
lenet_model = mx.mod.Module(symbol=lenet, context=mx.gpu(),logger=logzulu)
# train with the same
lenet_model.fit(train_iter,
                eval_data=val_iter,
                optimizer='sgd',
                optimizer_params={'learning_rate':0.1},
                eval_metric='acc',
                batch_end_callback = mx.callback.Speedometer(batch_size, 100),
                num_epoch=10,
                initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=""in"", magnitude=2))

test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)
</code></pre>
","<logging><deep-learning><conv-neural-network><epoch><mxnet>","2017-12-21 14:42:18","","1","3863980","2018-02-25 10:28:36","2","0","","","3863980","21","13","0"
"55224886","<p>Is it possible to make ""import mxnet"" skip loading CUDA libraries when only inference on CPU is intended? </p>

<p>Context:</p>

<ul>
<li>MXNet is installed with CUDA support and model trainings are usually run on GPU's</li>
<li>however inference can be run in parallel on many nodes without GPU and it would be nice to use the same MXNet build with CPU only but some libraries are not available on non-GPU nodes.</li>
</ul>
","<python><mxnet>","2019-03-18 15:33:49","","0","1288210","2019-03-18 15:33:49","0","3","","","1288210","16","1","0"
"41323159","<p>I am trying to create my own data iterator to use with mxnet. When I run it I get the error :</p>

<pre><code>Traceback (most recent call last):
File ""train.py"", line 24, in &lt;module&gt;
batch_end_callback = mx.callback.Speedometer(batch_size, 1) # output progress for each 200 data batches
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.py"", line 811, in fit
sym_gen=self.sym_gen)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.py"", line 236, in _train_multi_device
executor_manager.load_data_batch(data_batch)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.py"", line 410, in load_data_batch
self.curr_execgrp.load_data_batch(data_batch)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.py"", line 257, in load_data_batch
_load_data(data_batch, self.data_arrays)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.py"", line 93, in _load_data
_load_general(batch.data, targets)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.py"", line 89, in _load_general
d_src[slice_idx].copyto(d_dst)
AttributeError: 'numpy.ndarray' object has no attribute 'copy'
</code></pre>

<p>I assume this has something to do with the way I return the data. See my data iterator code below:</p>

<pre><code>from mxnet.io import DataIter, DataDesc
import csv
from random import shuffle
import numpy as np
from cv2 import imread, resize

class MyData(DataIter):
    def __init__(self, root_dir, flist_name, batch_size, size=(256,256), shuffle=True):
        super(MyData, self).__init__()
        self.batch_size = batch_size
        self.root_dir = root_dir
        self.flist_name = flist_name
        self.size = size
        self.shuffle = shuffle

        self.data = []
        with open(flist_name, 'rb') as csvfile:
            csvreader = csv.reader(csvfile)
            for row in csvreader:
                self.data.append(row)
        self.num_data = len(self.data)
        self.provide_data = [DataDesc('data', (self.batch_size, 6, self.size[0], self.size[1]), np.float32)]
        self.provide_label = [DataDesc('Pa_label', (self.batch_size, 1), np.float32)]
        self.reset()

    def reset(self):
        """"""Reset the iterator. """"""
        self.cursor = 0
        if self.shuffle:
            shuffle(self.data)

    def iter_next(self):
        """"""Iterate to next batch.
        Returns
        -------
        has_next : boolean
            Whether the move is successful.
        """"""
        self.cursor += self.batch_size
        success = self.cursor &lt; self.num_data
        return success

    def getdata(self):
        """"""Get data of current batch.
        Returns
        -------
        data : NDArray
            The data of current batch.
        """"""
        datalist = self.data[self.cursor:self.cursor+self.batch_size]
        ret = np.ndarray(shape=(0,6,self.size[0],self.size[1]), dtype=np.float32)
        for data_row in datalist:
            img1 = resize(imread(data_row[0]), self.size)
            img2 = resize(imread(data_row[1]), self.size)
            img1 = np.rollaxis(img1, 2)
            img2 = np.rollaxis(img2, 2)
            img = np.concatenate((img1, img2), 0)
            imge = np.expand_dims(img,0)
            ret = np.append(ret, imge, 0)

        print ret.shape
        pad = self.batch_size - ret.shape[0]
        if pad &gt; 0:
            ret = np.append(ret, np.zeros((pad, 6, self.size[0], self.size[1])), 0)
        return ret

    def getlabel(self):
        """"""Get label of current batch.
        Returns
        -------
        label : NDArray
            The label of current batch.
        """"""
        datalist = self.data[self.cursor:self.cursor+self.batch_size]
        ret = np.ndarray(shape=(0,1,1,1), dtype=np.float32)
        for data_row in datalist:
            label = np.ndarray(shape=(1,1,1,1), dtype=np.float32)
            label[0,0,0,0] = float(data_row[2]) / float(data_row[5])
            np.append(ret, label, 0)

        pad = self.batch_size - ret.shape[0]
        np.append(ret, np.zeros((pad, 1,1,1)), 0)
        return ret

    def getindex(self):
        """"""Get index of the current batch.
        Returns
        -------
        index : numpy.array
            The index of current batch
        """"""
        return self.cursor

    def getpad(self):
        """"""Get the number of padding examples in current batch.
        Returns
        -------
        pad : int
            Number of padding examples in current batch
        """"""
        if self.cursor + self.batch_size &gt; self.num_data:
            return self.cursor + self.batch_size - self.num_data
        else:
            return 0
</code></pre>
","<python><mxnet>","2016-12-25 17:30:02","","1","987599","2016-12-28 19:09:54","1","0","","","987599","1174","84","12"
"55790217","<p><strong>Let me list down the configuration first:</strong></p>

<ol>
<li>Deep Learning AMI (Ubuntu), version 22.0 <a href=""https://aws.amazon.com/marketplace/pp/B077GCH38C"" rel=""nofollow noreferrer"">https://aws.amazon.com/marketplace/pp/B077GCH38C</a> </li>
<li>The DLAMI is hosted on an AWS C5XLarge type of EC2 instance</li>
<li>Environment: amazonei_mxnet_p27</li>
<li>Model format: ONNX</li>
<li>AWS Elastic Inference Accelerator of type eia1.large, with 2GB of RAM (attached to the EC2 instance)</li>
</ol>

<p><strong>Now let me explain the scenario:</strong></p>

<p>I have a fairly large set of (1639 to be precise) .jpeg images I am running inference on. Currently, I am using a minibatch size of 210, i.e. I am dividing the original set into smaller subsets of 210 (or less for the last minibatch) images and running inference on them.
Also, the inference is of type ""ensemble inference"". i.e. I am running inference using 3 models, one by one, on each minibatch.</p>

<p><strong>The issue I am facing:</strong></p>

<p>I ssh into AWS console and then run the code with a minibatch size larger than 210, I get the error as follows:</p>

<pre><code>Using Amazon Elastic Inference Client Library Version: 1.2.12
Number of Elastic Inference Accelerators Available: 1
Elastic Inference Accelerator ID: eia-cb0a16c893874b43855dc0e0d2aacab7
Elastic Inference Accelerator Type: eia1.large

[Mon Apr 22 06:16:17 2019, 275419us] [Execution Engine][MXNet][6] Failed - Last Error: 
    EI Error Code: [51, 8, 31]
    EI Error Description: Accelerator out of memory. Consider using a larger accelerator.
    EI Request ID: MX-A19B0DE6-7999-4580-8C49-8EA7EBD5EACB  --  EI Accelerator ID: eia-cb0a16c893874b43855dc0e0d2aacab7
    EI Client Version: 1.2.12
Traceback (most recent call last):
  File ""Ensemble_Inferrer_2.py"", line 65, in &lt;module&gt;
    batched_prediction_list = inferrer.batch_infer('', current_image_list_batch, current_image_list_batch_index)
  File ""/home/ubuntu/Ensembled_Inference/Lib/Inferrer.py"", line 78, in batch_infer
    current_predictions = current_output.asnumpy().tolist()
  File ""/home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/ndarray/ndarray.py"", line 1972, in asnumpy
    ctypes.c_size_t(data.size)))
  File ""/home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/base.py"", line 252, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [06:16:17] src/operator/subgraph/eia/eia_subgraph_op.cc:206: Last Error: 
    EI Error Code: [51, 8, 31]
    EI Error Description: Accelerator out of memory. Consider using a larger accelerator.
    EI Request ID: MX-A19B0DE6-7999-4580-8C49-8EA7EBD5EACB  --  EI Accelerator ID: eia-cb0a16c893874b43855dc0e0d2aacab7
    EI Client Version: 1.2.12


Stack trace returned 10 entries:
[bt] (0) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(dmlc::StackTrace()+0x44) [0x7f5658cae394]
[bt] (1) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x21) [0x7f5658cae771]
[bt] (2) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(mxnet::op::EiaSubgraphOperator::Forward(mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)+0x147) [0x7f5658cfe637]
[bt] (3) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x2fc52f2) [0x7f565b6602f2]
[bt] (4) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x564) [0x7f565b641a34]
[bt] (5) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(std::_Function_handler&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#1}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;)+0x92) [0x7f565b645902]
[bt] (6) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/mxnet/libmxnet.so(std::thread::_Impl&lt;std::_Bind_simple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; &gt;::_M_run()+0x44) [0x7f565b642154]
[bt] (7) /home/ubuntu/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/scipy/sparse/../../../../libstdc++.so.6(+0xb86d4) [0x7f56627ce6d4]
[bt] (8) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7f5670b426ba]
[bt] (9) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f567016841d]
</code></pre>

<p>Also when I am keeping the minibatch size fairly smaller, like 120, but spawning multiple instances of the process, the EI also gets out of memory.</p>

<p>I am curious if there is any way to optimize the following code so that I can use larger minibatch size or run multiple instances of the process simultaneously and still don't exhaust the EI's memory.</p>

<p><strong>Below is the code I have written:</strong></p>

<p><strong>Ensemble_Inferrer_2.py</strong></p>

<pre><code>import sys
import traceback
import os
import time
import logging
from logging.handlers import RotatingFileHandler
from scipy.stats import mode
from Lib.Inferrer import Inferrer

logger = logging.getLogger('')
logger.setLevel(logging.ERROR)

handler = RotatingFileHandler('Logs/error_log.log', maxBytes=100*1024*1024, backupCount=10)
formatter = logging.Formatter('%(asctime)-12s [%(levelname)s] %(message)s')
handler.setFormatter(formatter)

logger.addHandler(handler)


def handle_exception(exception_type, exception_value, exception_traceback):
    logger.error(
        'An internal error occurred. Exception message: {}', format(traceback.format_exception(exception_type,
                                                                                               exception_value,
                                                                                               exception_traceback
                                                                                               )
                                                                    )
    )

    sys.exit(1)


output_directory = './Video_Frames'
models = [
    './Models/facenet1154o7.onnx',
    './Models/facenet1302u7.onnx',
    './Models/facenet10387.onnx'
]
emotion_labels = ['Anger', 'Confusion', 'Contempt', 'Disgust', 'Fear', 'Happiness', 'LookAway', 'Neutral', 'NoFace',
                  'Sadness', 'Surprise']
batch_size = 240
channel_count = 3
image_width = 227
image_height = 227
final_prediction_list = list()

inferrer = Inferrer(output_directory, models, emotion_labels, batch_size, channel_count, image_width, image_height,
                    False)

image_list = os.listdir(output_directory)
image_list.sort(key=lambda f: int(
                ''.join(filter(str.isdigit, str(f)))))

step_size = 0
if len(image_list) &lt; batch_size:
    step_size = len(image_list)
else:
    step_size = batch_size

batched_image_list = [image_list[i:i + int(batch_size)] for i in range(0, len(image_list), step_size)]

started_at = time.time()
print('Process started at: ' + str(started_at))

for current_image_list_batch_index, current_image_list_batch in enumerate(batched_image_list):
    batched_prediction_list = inferrer.batch_infer('', current_image_list_batch, current_image_list_batch_index)

    for this_batched_prediction_list in batched_prediction_list:
        final_prediction_list.append(mode(this_batched_prediction_list)[0][0])


print(final_prediction_list)

ended_at = time.time()
print('Process ended at: ' + str(ended_at))

print('Total time taken (in seconds): ' + str(ended_at - started_at))
</code></pre>

<p><strong>Inferrer.py</strong></p>

<pre><code>import mxnet as mx
import mxnet.contrib.onnx as onnx_mxnet
import numpy as np
from collections import namedtuple
from PIL import Image


class Inferrer:
    def __init__(self, output_directory, models, emotion_labels, batch_size, channel_count, image_width,
                 image_height, resize_required):
        self.__output_directory = output_directory
        self.__models = models
        self.__emotion_labels = emotion_labels
        self.__batch_size = batch_size
        self.__channel_count = channel_count
        self.__image_width = image_width
        self.__image_height = image_height
        self.__resize_required = resize_required
        self.__batched_prediction_list = list()

    '''Method to extract and process pixel data from the target image'''

    def __get_image_datum(self, target_image_path):
        image = Image.open(target_image_path)

        if self.__resize_required is True:
            image = image.resize((self.__image_width, self.__image_height))

        image_data = np.asarray(image, dtype=np.float32)
        image_data = np.ascontiguousarray(np.rollaxis(image_data, 2))
        image_data = image_data[np.newaxis, :, :, :].astype(np.float32)

        return image_data

    '''Method to get processed pixel data for a batch of images'''

    def __get_image_data(self, image_sub_directory, image_batch):
        self.__batched_prediction_list = np.empty((len(image_batch), len(self.__models))).astype(np.str)

        batched_image_data = np.zeros(
            (len(image_batch), int(self.__channel_count), int(self.__image_width), int(self.__image_height)))

        for current_image_index, current_image_path in enumerate(image_batch):
            if '' == image_sub_directory:
                batched_image_data[current_image_index, :, :, :] = self.__get_image_datum(
                    self.__output_directory + '/' + current_image_path)
            else:
                batched_image_data[current_image_index, :, :, :] = self.__get_image_datum(self.__output_directory + '/'
                                                                                          + image_sub_directory + '/'
                                                                                          + current_image_path)

        return batched_image_data

    '''Method to infer facial emotions from the target image'''

    def batch_infer(self, image_sub_directory, image_batch, image_batch_index):
        batched_image_data = self.__get_image_data(image_sub_directory, image_batch)

        if 0 == image_batch_index:
            # ctx = mx.cpu()  # For local development
            ctx = mx.eia()

        for this_model_index, this_model in enumerate(self.__models):
            if 0 == image_batch_index:
                model_metadata = onnx_mxnet.get_model_metadata(this_model)
                data_names = [inputs[0] for inputs in model_metadata.get('input_tensor_data')]
                Batch = namedtuple('Batch', 'data')
                sym, arg, aux = onnx_mxnet.import_model(this_model)
                mod = mx.mod.Module(symbol=sym, data_names=data_names, context=ctx, label_names=None)

            mod.bind(data_shapes=[(data_names[0], batched_image_data.shape)], label_shapes=None, for_training=False)
            mod.set_params(arg_params=arg, aux_params=aux, allow_missing=True, allow_extra=True)

            mod.forward(Batch([mx.nd.array(batched_image_data)]))
            outputs = mod.get_outputs()[0]

            for current_output_index, current_output in enumerate(outputs):
                current_predictions = current_output.asnumpy().tolist()
                zipb_object = zip(self.__emotion_labels, current_predictions)
                current_prediction_dictionary = dict(zipb_object)
                most_probable_prediction = max(current_prediction_dictionary, key=current_prediction_dictionary.get)

                self.__batched_prediction_list[current_output_index, this_model_index] = most_probable_prediction

        print(self.__batched_prediction_list)

        return self.__batched_prediction_list
</code></pre>
","<python-2.7><amazon-web-services><mxnet>","2019-04-22 06:43:16","","0","2613614","2019-04-22 06:43:16","0","0","","","2613614","3","0","0"
"50343360","<p>here is approximately what I did：</p>

<pre><code>import mxnet as mx
import cv2
from multiprocessing import Pool
from itertools import repeat

num_worker=4
CNNNet=[]
img = cv2.imread('../datasets/1.jpg')
sym, arg_params, aux_params = mx.model.load_checkpoint('det1', 0)
for i in range(num_worker):
    worker_net = mx.mod.Module(symbol=sym,label_names=None)
    worker_net.bind(data_shapes=[('data', (1, 3, 1000, 1000))],for_training=False)
    worker_net.set_params(arg_params,aux_params)
    CNNNet.append(worker_net)
pool = Pool(num_worker)
threshold = 0.6
res = pool.map(do_work_warpper,zip(repeat(img),CNNNet[:num_worker],repeat(threshold)))
</code></pre>

<p>and the <code>do_work_warpper()</code> function is:</p>

<pre><code>def do_work_warpper(args):
    return do_work(*args)
def do_work(img,net,threshold):
    #do image predict job here
    return res
</code></pre>

<p>I am puzzled by the question that when using <code>multiprocessing.Pool</code> with the <code>mx.mod.Module</code> object, I get the error in python3.6:</p>

<pre><code>TypeError: can't pickle module objects
</code></pre>

<p>or in python2.7:</p>

<pre><code>PicklingError: Can't pickle &lt;type 'module'&gt;: attribute lookup __builtin__.module failed
</code></pre>

<p>any suggestion will be appreciated.</p>
","<python><mxnet>","2018-05-15 06:11:00","","0","9791657","2018-05-15 06:33:04","1","0","","","9791657","3","0","0"
"48512924","<p>I'm creating a simple ensemble of two xgboost and mxnet models. The data frame is A3n.df with the classification variable at A3n.df[,1]. Both the models run fine on their own and get believable accuracy. All data is normalized 0-1, shuffled and the class variable converted to a factor (for caret). I have already run grid search for the best hyperparameters, but need to include a grid for caretEnsemble.</p>

<pre><code>#training grid for xgboost
xgb_grid_A3 = expand.grid(
  nrounds = 1200,   
  eta = 0.01,
  max_depth = 20,
  gamma = 1,
  colsample_bytree = 0.6,
  min_child_weight = 2,
  subsample = 0.8)

#training grid for mxnet
mxnet_grid_A3 = expand.grid(layer1 = 12,
                            layer2 = 2,
                            layer3 = 0,
                            learningrate = 0.001,
                            dropout = 0
                            beta1 = .9,
                            beta2 = 0.999,
                            activation = 'relu')

Ensemble_control_A4 &lt;- trainControl(
  method = ""cv"",
  number = 5,
  verboseIter = TRUE,
  returnData = TRUE,
  returnResamp = ""all"",                                                        
  classProbs = TRUE,                                                           
  summaryFunction = twoClassSummary,
  allowParallel = TRUE,
  sampling = ""up"",
  index=createResample(yEf, 20))

yE = A4n.df[,1]
xE = data.matrix(A4n.df[,-1])
yf &lt;- yE
yEf &lt;- ifelse(yE == 0, ""no"", ""yes"") 
yEf &lt;- factor(yEf)

Ensemble_list_A4 &lt;- caretList(
  x=xE,
  y=yEf,
  trControl=Ensemble_control_A4,
  metric=""ROC"",
  methodList=c(""glm"", ""rpart""),
  tuneList=list(
    xgbA4=caretModelSpec(method=""xgbTree"", tuneGrid=xgb_grid_A4),
    mxA4=caretModelSpec(method=""mxnetAdam"", tuneGrid=mxnet_grid_A4)))
</code></pre>

<p>XGboost seems to train fine: </p>

<pre><code>+ Resample01: eta=0.01, max_depth=20, gamma=1, colsample_bytree=0.6, min_child_weight=2, subsample=0.8, nrounds=1200 
....
+ Resample20: eta=0.01, max_depth=20, gamma=1, colsample_bytree=0.6, min_child_weight=2, subsample=0.8, nrounds=1200 
- Resample20: eta=0.01, max_depth=20, gamma=1, colsample_bytree=0.6, min_child_weight=2, subsample=0.8, nrounds=1200 
Aggregating results
Selecting tuning parameters
Fitting nrounds = 1200, max_depth = 20, eta = 0.01, gamma = 1, colsample_bytree = 0.6, min_child_weight = 2, subsample = 0.8 on full training set
</code></pre>

<p>However, mxnet seems to only run for 10 rounds, when 1 or 2 thousand makes more sense, and there seems to be missing parameters: </p>

<pre><code>+ Resample01: layer1=12, layer2=2, layer3=0, learningrate=0.001, dropout=0, beta1=0.9, beta2=0.999, activation=relu 
Start training with 1 devices
[1] Train-accuracy=0.487651209677419
[2] Train-accuracy=0.624751984126984
[3] Train-accuracy=0.599082341269841
[4] Train-accuracy=0.651909722222222
[5] Train-accuracy=0.662202380952381
[6] Train-accuracy=0.671006944444444
[7] Train-accuracy=0.676463293650794
[8] Train-accuracy=0.683407738095238
[9] Train-accuracy=0.691964285714286
[10] Train-accuracy=0.698660714285714
- Resample01: layer1=12, layer2=2, layer3=0, learningrate=0.001, dropout=0, beta1=0.9, beta2=0.999, activation=relu

+ Resample01: parameter=none 
- Resample01: parameter=none 
+ Resample02: parameter=none 
Aggregating results
Selecting tuning parameters
Fitting cp = 0.0243 on full training set
There were 40 warnings (use warnings() to see them)
</code></pre>

<p>Warnings (1-40):</p>

<pre><code>1: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  ... :
  prediction from a rank-deficient fit may be misleading
</code></pre>

<p>I expect mxnet to train for thousands of rounds, and the training accuracy to end up like the pre-ensemble model, 60-70%
*On second thought, some of the 20 mxnet runs reach 60-70%, but it seems inconsistent. Perhaps it is functioning normally?</p>
","<r><r-caret><xgboost><mxnet><ensemble-learning>","2018-01-30 02:20:05","","0","8268013","2018-03-10 04:10:38","1","0","","","8268013","142","18","5"
"47755934","<p>I try to follow this nice <a href=""https://github.com/zackchase/mxnet-the-straight-dope/blob/master/chapter02_supervised-learning/linear-regression-gluon.ipynb"" rel=""nofollow noreferrer"">MXNet Tutorial</a>. I create an extremely simple neural network (two input unit, no hidden units and one output unit) doing this:</p>

<pre><code>from mxnet import gluon

net = gluon.nn.Dense(1, in_units=2)
</code></pre>

<p>After that I try to take a look at the shape of the weight matrix (the same way as it is described in the tutorial):</p>

<pre><code>print(net.weight)
</code></pre>

<p>As a result I expect to see this:</p>

<pre><code>Parameter dense4_weight (shape=(1, 2), dtype=None)
</code></pre>

<p>However, I see the following error message:</p>

<pre><code>Traceback (most recent call last):
  File ""tmp.py"", line 5, in &lt;module&gt;
    print(net.weight)
  File ""/usr/local/lib/python3.6/site-packages/mxnet/gluon/parameter.py"", line 120, in __repr__
    return s.format(**self.__dict__)
KeyError: 'shape'
</code></pre>

<p>Am I doing something wrong?</p>
","<mxnet>","2017-12-11 15:15:51","","0","245549","2017-12-11 19:31:36","1","3","","","245549","29447","811","37"
"48865895","<p>I am currently working on a machine learning project with Apache MXNet, and I am using the Inception V3 model (imagenet1k-inception-bn model on the MXNet model zoo).</p>

<p>I am currently trying to train a model to distinguish between two object types, but the difference between the objects are subtle. I am finding that the model still confuses one thing for the other since it looks mostly the same.</p>

<p>For example, say you are trying to train a model to distinguish between an alligator and a crocodile. One of the ways humans tell them apart at first glance is by looking at the shape of their snout. When training a machine learning model, would I give it images of entire alligators and crocodiles and hope it figures it out, or would I give it images of just their snouts since that is the difference I am focusing on?</p>

<p>Thanks!</p>
","<machine-learning><image-recognition><mxnet>","2018-02-19 12:07:14","","1","74984","2018-02-21 19:09:51","1","0","2","","74984","1936","5","3"
"48401060","<p>Try to edit the example of <a href=""https://mxnet.incubator.apache.org/tutorials/python/linear-regression.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/python/linear-regression.html</a> to develop a machine learning solution for solving quadratic equations. I am now getting divide by zero error:</p>

<pre><code>INFO:root:Epoch[0] Train-mse=49.961319
INFO:root:Epoch[0] Time cost=0.030
INFO:root:Epoch[0] Validation-mse=58229.367065
INFO:root:Epoch[1] Batch [2]    Speed: 2000.14 samples/sec  mse=361.597036
INFO:root:Epoch[1] Batch [4]    Speed: 2000.14 samples/sec  mse=1903.920013
INFO:root:Epoch[1] Batch [6]    Speed: 2000.14 samples/sec  mse=6117.729675
INFO:root:Epoch[1] Batch [8]    Speed: 1999.67 samples/sec  mse=4203.171875
INFO:root:Epoch[1] Batch [10]   Speed: 2000.14 samples/sec  mse=31765.921204
INFO:root:Epoch[1] Batch [12]   Speed: 2000.14 samples/sec  mse=6946.003112
Traceback (most recent call last):  File ""C:\Users\ibraheem\.vscode\extensions\ms-python.python-0.9.1\pythonFiles\PythonTools\visualstudio_py_launcher_nodebug.py"", line 74, in run
    _vspu.exec_file(file, globals_obj)
  File ""C:\Users\ibraheem\.vscode\extensions\ms-python.python-0.9.1\pythonFiles\PythonTools\visualstudio_py_util.py"", line 119, in exec_file

    exec_code(code, file, global_variables)
  File ""C:\Users\ibraheem\.vscode\extensions\ms-python.python-0.9.1\pythonFiles\PythonTools\visualstudio_py_util.py"", line 95, in exec_code
    exec(code_obj, global_variables)
  File ""c:\Users\ibraheem\Desktop\OtherProjects\python_AI_ML\Untitled-1.py"", line 37, in &lt;module&gt;
    batch_end_callback = mx.callback.Speedometer(batch_size, 2))
  File ""C:\Python27amd64\lib\site-packages\mxnet\module\base_module.py"", line 506, in fit
    callback(batch_end_params)
  File ""C:\Python27amd64\lib\site-packages\mxnet\callback.py"", line 159, in __call__
    speed = self.frequent * self.batch_size / (time.time() - self.tic)
ZeroDivisionError: float division by zero
</code></pre>

<p>Entire source:</p>

<pre><code>import mxnet as mx
import numpy as np
import math
import logging
logging.getLogger().setLevel(logging.DEBUG)

train_size = 50
train_data = np.random.uniform(0.1, 1, [train_size, 3])
for i in range(0, train_size):
    train_data[i, 1] *= 25
train_label = np.array([(-train_data[i][1] + math.sqrt(train_data[i][1] ** 2 - 4 * train_data[i][0] * train_data[i][2])) / (2 * train_data[i][0]) for i in range(train_size)])

#Evaluation Data
eval_data = np.array([[7,3,-34],[6,1,-57],[12,5,-3152]])
eval_label = np.array([2,3,16])

#training
batch_size = 1
train_iter = mx.io.NDArrayIter(train_data,train_label, batch_size, shuffle=True,label_name='lin_reg_label')
eval_iter = mx.io.NDArrayIter(eval_data, eval_label, batch_size, shuffle=False)

X = mx.sym.Variable('data')
Y = mx.symbol.Variable('lin_reg_label')
fully_connected_layer = mx.sym.FullyConnected(data=X, name='fc1', num_hidden = 1)
lro = mx.sym.LinearRegressionOutput(data=fully_connected_layer, label=Y, name=""lro"")

model = mx.mod.Module(
    symbol = lro ,
    data_names=['data'],
    label_names = ['lin_reg_label']# network structure
)
mx.viz.plot_network(symbol=lro)
model.fit(train_iter, eval_iter,
            optimizer_params={'learning_rate':0.005, 'momentum': 0.9},
            num_epoch=50,
            eval_metric='mse',
            batch_end_callback = mx.callback.Speedometer(batch_size, 2))

print model.predict(eval_iter).asnumpy()
</code></pre>

<p>I am multiplying the 2 factor of train data to avoid non-real solutions for equation</p>
","<python><windows><time><python-2.x><mxnet>","2018-01-23 11:51:16","","0","7429464","2018-01-23 12:17:44","1","2","","","7429464","486","2156","45"
"48292162","<p>Got a dataframe with columns 2:37 as variables and column one as a binary response variable. </p>

<pre><code>mx.set.seed(1234)
train.x = data.matrix(A3n.df[,2:37])
train.y = A3n.df[,1]

data &lt;- mx.symbol.Variable(""data"")
fc1 &lt;- mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=12)
act1 &lt;- mx.symbol.Activation(fc1, name=""relu1"", act_type=""relu"")
fc2 &lt;- mx.symbol.FullyConnected(act1, name=""fc2"", num_hidden=1)
logoutput &lt;- mx.symbol.LogisticRegressionOutput(fc2, name=""logoutput"")

A1.MXmodel &lt;- mx.model.FeedForward.create(logoutput, X=train.x, y=train.y,
                                     ctx=mx.gpu(), num.round=1000, array.batch.size=100,
                                     learning.rate=0.01, momentum=0.9,  eval.metric=mx.metric.accuracy,
                                     initializer=mx.init.uniform(0.07),
                                     epoch.end.callback=mx.callback.log.train.metric(100))
</code></pre>

<p>Leads to error: </p>

<pre><code>Error in mx.io.internal.arrayiter(as.array(data), as.array(label), unif.rnds,  : 
  io.cc:50: Seems X, y was passed in a Row major way, MXNetR adopts a column major convention.
Please pass in transpose of X instead
</code></pre>

<p>Just a few days ago I used:</p>

<pre><code>train.x &lt;- t(train.x)
</code></pre>

<p>Which fixed the error and yielded a error rate low enough to be believable, but today, it's nearly .50 with no learning. I also tried switching around array.layout to rowmajor/colmajor to no effect. </p>

<pre><code>[16] Train-accuracy=0.460714285714286
[17] Train-accuracy=0.460714285714286
[18] Train-accuracy=0.460714285714286
[19] Train-accuracy=0.460714285714286
[20] Train-accuracy=0.460714285714286
[993] Train-accuracy=0.460714285714286
[994] Train-accuracy=0.460714285714286
[995] Train-accuracy=0.460714285714286
[996] Train-accuracy=0.460714285714286
[997] Train-accuracy=0.460714285714286
[998] Train-accuracy=0.460714285714286
[999] Train-accuracy=0.460714285714286
[1000] Train-accuracy=0.460714285714286
</code></pre>
","<arrays><r><neural-network><mxnet>","2018-01-17 00:59:56","","0","8268013","2018-01-19 00:56:56","1","0","","","8268013","142","18","5"
"40678514","<p>I want to run a Neural Network on mobile. Currently, I am exploring Mxnet (<a href=""http://mxnet.io"" rel=""nofollow noreferrer"">http://mxnet.io</a>) framework for deploying it (only for Inference). As I am concerned about the execution time performance on mobile, I want to know if it runs on the GPU of mobile phones (Android/iOS). The documentation mentions that it can use multiple CPUs as well as GPUs for training, but it is still not clear if it can GPU of mobile phone for inference on mobile. It mentions about dependency on BLAS, because of which it seems it uses CPU on mobile. Could anyone please tell me if I can use mobile GPU with mxnet for inference? If not, what are my other options? </p>
","<android><ios><deep-learning><gpu><mxnet>","2016-11-18 13:37:28","","2","2531306","2018-09-04 18:52:57","1","0","2","","2531306","482","5","0"
"48498920","<p>i am running a model for my own data set(the project was implemented for training/testing with ImageNet) with 2 classes. I have made all the changes (in config files etc) but after training finishes(successfully), i get the following error when starting testing:</p>

<pre><code>wrote gt roidb to ./data/cache/ImageNetVID_DET_val_gt_roidb.pkl
Traceback (most recent call last):
  File ""experiments/dff_rfcn/dff_rfcn_end2end_train_test.py"", line 20, in &lt;module&gt;
    test.main()
  File ""experiments/dff_rfcn/../../dff_rfcn/test.py"", line 53, in main
    args.vis, args.ignore_cache, args.shuffle, config.TEST.HAS_RPN, config.dataset.proposal, args.thresh, logger=logger, output_path=final_output_path)
  File ""experiments/dff_rfcn/../../dff_rfcn/function/test_rcnn.py"", line 68, in test_rcnn
    roidbs_seg_lens[gpu_id] += x['frame_seg_len']
KeyError: 'frame_seg_len'
</code></pre>

<p>I cleaned the cache file before running. As i have read in previous topics, this might be an issue of previous datasets .pkl files in cache. What may have caused this error? I also want to mention that i changed .txt filenames that feed the neural network(if this is important), and that training finishes well.
This is my first time running a project in Deep Learning so please show some understanding.</p>
","<python><neural-network><deep-learning><training-data><mxnet>","2018-01-29 10:18:41","","0","9268685","2018-05-04 18:29:27","1","2","","","9268685","19","4","0"
"49326470","<p>I am trying to implement tutorials of mxnet <a href=""http://gluon.mxnet.io/chapter02_supervised-learning/regularization-scratch.html"" rel=""nofollow noreferrer"">in this page</a>, in computing gradient decent:</p>

<pre><code>def SGD(params, lr):
for param in params:
    param[:] = param - lr * param.grad
</code></pre>

<p>I noticed that when lr&lt;1,  the scalar to array multiplication </p>

<pre><code>lr * param.grad
</code></pre>

<p>becomes a zero matrix with same size of param.grad</p>

<p>I do not  know why this happens. can any one help me to understand this?</p>

<p>Many thanks</p>
","<machine-learning><mxnet>","2018-03-16 17:30:18","","0","9442808","2018-03-19 05:20:39","1","5","","","9442808","109","10","0"
"47370673","<p>Does mxnet store data/models somewhere outside of R? I keep running into scenarios where the first NN run of the day will produce good results, and every following run (even of the exact same code) will produce NA/NaN for all training steps.</p>

<p>Example: <a href=""https://github.com/xup6fup/MxNetR-examples/blob/master/1.%20Basic%20models/3.%20softmax%20regression/1.%20Standard%20example.R"" rel=""nofollow noreferrer"">https://github.com/xup6fup/MxNetR-examples/blob/master/1.%20Basic%20models/3.%20softmax%20regression/1.%20Standard%20example.R</a></p>

<p>I copied and pasted the code as is, ran it and got about 70% accuracy. I noticed that the device was set to cpu, and I have gpu version compiled. So I changed it to gpu, reran ..... all NaN. Clear R session workspace, rerun original code with cpu, all NA.</p>

<p>Restart Rstudio server, rerun exact code.... all NA. It seems like SOMETHING is being stored outside of rstudio server and it interferes with subsequent FeedForward. I have this issue with multiple mxnet tutorials, where often they will work the first time, but subsequently will fail, even with identical code run.</p>
","<r><neural-network><rstudio-server><mxnet>","2017-11-18 20:24:19","","1","8268013","2017-11-29 06:02:42","1","7","","","8268013","142","18","5"
"47427500","<p>I want to replace mx.symbol.SoftmaxOutput with the weighted version (assign different weight respect to label's frequency in the whole dataset)</p>

<p>The original function works well like below:</p>

<pre><code>cls_prob = mx.symbol.SoftmaxOutput(data=data,
                                   label=label,
                                   multi_output=True,
                                   normalization='valid',
                                   use_ignore=True, 
                                   ignore_label=-1,
                                   name='cls_prob')
</code></pre>

<p>The current code I wrote as below. The code can run without errors, but the loss quickly explode to nan. I am dealing with detection problem, RCNNL1 loss with quickly become nan when I use my code as CustomOp.
Another thing is that I have to ignore label -1 and I am not sure how to do it properly. Any help will be greatly appreciated.</p>

<pre><code>import mxnet as mx
import numpy as np

class WeightedSoftmaxCrossEntropyLoss(mx.operator.CustomOp):
    def __init__(self, num_class):
        self.num_class = int(num_class)

    def forward(self, is_train, req, in_data, out_data, aux):

        data = in_data[0]
        label = in_data[1]
        pred = mx.nd.SoftmaxOutput(data, label, multi_output=True,
                               normalization='valid', use_ignore=True, ignore_label=-1,
                               name='rcnn_cls_prob')

        self.assign(out_data[0], req[0], pred)

    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):
        cls_weight = np.array([
            0.002852781814876101, 
            0.30715984513157385, 
            1.0932468996115976, 
            1.1598757152765971, 
            0.20739109264009636, 
            1.1984256112776808, 
            0.18746186040248036, 
            2.9009928470737023, 
            0.92140970338602113, 
            1.200317380251021
        ])
        label = in_data[1]
        pred = out_data[0]
        label = label.asnumpy().astype('int32').reshape((-1))
        pred = pred.asnumpy().reshape((pred.shape[0], pred.shape[1], -1)).transpose((0, 2, 1))
        pred = pred.reshape((label.shape[0], -1))

        # Need to ignore label (how)
        out_inds = np.where(label == -1)[0]
        #label = label[keep_inds]
        one_hot = np.zeros((label.shape[0], self.num_class))
        one_hot[np.arange(label.shape[0]), label] = 1
        # gradient
        dx = pred - one_hot
        #dx[out_inds] = 0.0
        weighted_dx = cls_weight * dx / 4
        self.assign(in_grad[0], req[0], weighted_dx)

@mx.operator.register(""weighted_softmax_ce_loss"")
class WeightedSoftmaxCrossEntropyLossProp(mx.operator.CustomOpProp):
    def __init__(self, num_class):
        super(WeightedSoftmaxCrossEntropyLossProp, self).__init__(need_top_grad=False)
        self.num_class = num_class

    def list_arguments(self):
        return ['data', 'label']

    def list_outputs(self):
        return ['output']

    def infer_shape(self, in_shapes):
        data_shape = in_shapes[0]
        label_shape = (in_shapes[0][0],)
        output_shape = in_shapes[0]
        return [data_shape, label_shape], [output_shape], []

    def create_operator(self, ctx, in_shapes, in_dtypes):
        #  create and return the CustomOp class.
        `enter code here`return WeightedSoftmaxCrossEntropyLoss(self.num_class)
</code></pre>
","<python><mxnet>","2017-11-22 05:37:13","","4","5379345","2017-12-06 21:50:09","1","0","2","","5379345","103","2","0"
"50719500","<p>I am currently developing an user interface based on R markdown and shiny to make it easy to execute a machine learning training process for other users not proficient in R. This training process is done by a custom built function around the R package <em>mxnet</em> and gives status updates like the training error or what packages are loaded with the <code>message()</code> function directly to the console, when run in a ""normal"" R script. However, when running this app in R markdown nothing is printed to the browser. The following script shows a minimal reproducible example (with the training process replaced with an easy ""dummy"" function):</p>

<pre><code>---
title: ""Training of a Neural Network""
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r start_training, echo=F}
inputPanel(
  actionButton(""button_start_training"", ""Start training"")
)
```

```{r dummy_function, echo=F}
dummy_function &lt;- function(){
  for(i in 1:5){
    message(paste0(""Test: ""),i)
    Sys.sleep(0.5)
  }
}
```

```{r actual_training, echo=F}
event_training = eventReactive(input$button_start_training,{

  dummy_function()

})

renderPrint({
          event_training()

          })
```
</code></pre>

<p>The console output from <code>dummy_function()</code> is not displayed in the browser, but only in the console. If <code>message()</code> is replaced by <code>print()</code> something <em>is</em> displayed in the result, but only <em>after</em> the function is completed and not <em>""live""</em>. Because the actual training process takes a few hours, I would like to give these updates as they would occur in the console. Furthermore, replacing <code>message()</code> by <code>print()</code> could cause some issues since things like the training error are returned inside the mxnet training process as a message and not as a print (if I understood it correctly).</p>

<p>So, this boils down to two questions:</p>

<ol>
<li>Is there a way to make <code>renderPrint()</code> print output as soons as it appears?</li>
<li>Is there a way to make <code>renderPrint()</code> use output generated by <code>message()</code> instead of <code>print()</code>?</li>
</ol>

<p>Thank you for your help.</p>
","<r><machine-learning><shiny><r-markdown><mxnet>","2018-06-06 11:38:46","","0","9608794","2018-07-09 23:52:18","1","0","","","9608794","5","0","0"
"47272597","<p>I have written a custom data iterator using <code>mx.io.DataIter</code> class. What's the easiest way to use this data iterator with <code>Gluon</code> interface? </p>

<p>I went through the documentation and couldn't find an easy way to do so. One of my idea was to use it as iterator and get data adn label from each batch as follows.</p>

<pre><code>for e in range(epochs):
    train_iter.reset()
    for batch_data in train_iter:
        data = nd.concatenate(([d for d in batch_data.data]))
        label = nd.concatenate(([l for l in batch_data.label]))
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)
        loss.backward()
        trainer.step(batch_size)
        print(nd.mean(loss).asscalar())
</code></pre>

<p>But this may not be optimal as I need to concatenate per batch.</p>

<ol>
<li><p>What's the optimal way to achieve this? i.e. is there a systematic<br>
way to write a simple custom iterator for gluon?</p></li>
<li><p>How do I add context information in above cases?</p></li>
</ol>
","<mxnet>","2017-11-13 20:02:24","","2","2561862","2017-11-17 19:35:31","1","1","1","","2561862","108","15","0"
"47583769","<p>AWS deep learning AMIs come with mxnet 0.12.0 RC. Apparently this version has a bug that sets random initialization weights to 0. How to I remove the preinstalled mxnet and upgrade?</p>

<p>Logged in via SHH as ec2-user, I tried</p>

<pre><code>cd src
sudo rm -rf mxnet
git clone --recursive github.com/apache/incubator-mxnet.git mxnet
</code></pre>

<p>but the R-package build fails. Do I have to make/compile the program prior to R-package? Because that also fails. This package installation only works with a nightmare of inconsistent LD library configurations. </p>
","<r><amazon-ec2><installation><deep-learning><mxnet>","2017-11-30 22:36:08","","0","8268013","2017-12-04 22:36:29","1","1","","","8268013","142","18","5"
"48316400","<p>I am running tornado app as given below </p>

<pre><code>app = make_app()
server = tornado.httpserver.HTTPServer(app)
server.bind(8888)
server.start(0)  # autodetect number of cores and fork a process for each
print(""server started at port 8888"")
tornado.ioloop.IOLoop.instance().start()
</code></pre>

<p>this successfully starts app on available cores . and this is the piece of code which is running on an api call </p>

<pre><code>  ctx = mx.cpu(0)
 _, arg_params, aux_params = mx.model.load_checkpoint(args.prefix, args.epoch)
arg_params, aux_params = ch_dev(arg_params, aux_params, ctx)
sym = resnet_50(num_class=2)
arg_params[""data""] = mx.nd.array(img, ctx)
arg_params[""im_info""] = mx.nd.array(im_info, ctx)
exe = sym.bind(ctx, arg_params, args_grad=None, grad_req=""null"", aux_states=aux_params)
print(""detect 4"")
tic = time.time()
print(""detect 5"")
exe.forward(is_train=False)
print(""detect 6"")
output_dict = {name: nd for name, nd in zip(sym.list_outputs(), exe.outputs)}
rois = output_dict['rpn_rois_output'].asnumpy()[:, 1:] 
</code></pre>

<p>when running tornado app on single core it works fine, but on multi core this runs till the last line of above code, after that i am getting this error</p>

<pre><code>Segmentation fault: 11

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x0000000116ef741f _ . 
ZN5mxnet15segfault_loggerEi + 63
[bt] (1) 1   libsystem_platform.dylib            0x00007fff6ce4af5a _sigtramp 
+ 26
[bt] (2) 2   libsystem_malloc.dylib              0x00007fff6cd73cc0 
malloc_zone_calloc + 87
[bt] (3) 3   CarbonCore                          0x00007fff46798117 
_ZL22connectToCoreServicesDv + 258
[bt] (4) 4   CarbonCore                          0x00007fff46797fe4 
_ZL9getStatusv + 24
[bt] (5) 5   CarbonCore                          0x00007fff46797f62 
scCreateSystemServiceVersion + 49
[bt] (6) 6   CarbonCore                          0x00007fff46799392 
FileIDTreeGetCachedPort + 213
[bt] (7) 7   CarbonCore                          0x00007fff467991f2 
FSNodeStorageGetAndLockCurrentUniverse + 79
[bt] (8) 8   CarbonCore                          0x00007fff46799080 
FileIDTreeGetAndLockVolumeEntryForDeviceID + 38
[bt] (9) 9   CarbonCore                          0x00007fff46798fdd 
_ZN7FSMountC2Ej17FSMountNumberTypePiPKj + 75
child 3 (pid 42579) exited with status 255, restarting
</code></pre>
","<python><python-2.7><image-processing><tornado><mxnet>","2018-01-18 08:02:03","","0","2499914","2018-04-12 21:34:56","1","0","","","2499914","256","20","0"
"49076092","<p>Can I see what are the available gpus with mxnet?</p>

<p>Is there something similar for tensorflow's </p>

<pre><code>tf.test.gpu_device_name()
</code></pre>

<p>in mxnet?</p>
","<tensorflow><gpu><mxnet>","2018-03-02 19:30:26","","3","7136493","2018-03-03 18:58:03","1","0","","","7136493","66","16","0"
"47784114","<p>I want to train siamese net using depth image obtaining from kinect.I want to use contrastive loss function to train this network, but I'm not find contrastive loss function in mxnet.My implement is as follow:</p>

<pre><code>def LossFunc(distance, label, margin):
distance = distance.reshape(label.shape)

dis_positive = distance * label

dis_negative = margin - distance
zeros = nd.zeros(label.shape, ctx=ctx)
dis_negative = nd.concat(dis_negative, zeros, dim=1)
dis_negative = nd.max(dis_negative, axis=1).reshape(label.shape)
dis_negative = (1-label) * dis_negative

return 0.5 * dis_positive**2 + 0.5 * dis_negative**2
</code></pre>

<p>Is it right?</p>
","<mxnet><loss-function>","2017-12-13 01:18:32","","0","8117784","2018-03-07 06:06:32","1","0","","","8117784","11","0","0"
"42051498","<p>When defining segmentation network for R G B images, 
such as the network in fcn-xs example on mxnet, 
the input RGB image layer is fed to multiple convolutions, activations, poolings, etc...</p>

<p>Convolution, for example, is defined as below:  mxnet.symbol.Convolution(data=input, kernel=(3, 3), pad=(1, 1), num_filter=64,
                                workspace=workspace_default, name=""conv1_1"")</p>

<p>On the one hand, convolution filters here are 2D, meaning each color layer R,G,B
is processed separately. On the other hand, it is well known from neuroscience that relevant features are contained in the color contrast, rather than in the color channel itself, i.e., the colors should be subtracted from each other, e.g. Red minus Green or Blue minus Yellow. </p>

<p>How to enforce it by network structure? How the R G B components are mixed and combined?</p>
","<mxnet>","2017-02-05 11:27:30","","0","7518742","2017-02-12 12:27:40","1","1","","","7518742","46","2","0"
"41071422","<p>I following example/warpctc/<a href=""https://github.com/dmlc/mxnet/blob/master/example/warpctc/lstm_ocr.py"" rel=""nofollow noreferrer"">lstm_ocr.py</a> to training a model. Now I had saved a checkpoint mymodel-0100.params and mymodel-symbol.json.<br>
So, How can I make a predict with this checkpoint use only one image?</p>

<p>I had tired to use Predictor interface, code below:</p>

<pre><code># Load the pre-trained model
symbol_file = ""mymodel-symbol.json""
param_file = ""mymodel-0100.params""
predictor = Predictor(open(symbol_file).read(),
    open(param_file).read(),
    {'data':(80, 30)})
</code></pre>

<p>But data shape always raise error and I don't know how to set this value. Anybody help me thank you.</p>

<p>However, I also tried another way:
add one line code in the end of mxnet/example/warpctc/<a href=""https://github.com/dmlc/mxnet/blob/master/example/warpctc/lstm_ocr.py"" rel=""nofollow noreferrer"">lstm_ocr.py</a>:    </p>

<pre><code>model = mx.model.FeedForward(ctx=contexts,
                             symbol=symbol,
                             num_epoch=num_epoch,
                             learning_rate=learning_rate,
                             momentum=momentum,
                             wd=0.00001,
                             initializer=mx.init.Xavier(factor_type=""in"", magnitude=2.34))

model.fit(X=data_train, eval_data=data_val,
          eval_metric = mx.metric.np(Accuracy),
          batch_end_callback=mx.callback.Speedometer(BATCH_SIZE, 50),)

model.save(""ocr"")

# add new line for predict
model.predict(data_val)
</code></pre>

<p>But it is always error output:</p>

<pre><code>Traceback (most recent call last):
File ""lstm_ctc_ocr.py"", line 211, in &lt;module&gt;
training_all()
File ""lstm_ctc_ocr.py"", line 188, in training_all
model.predict(data_val)
File ""/home/bobliu/Work/code/DL/mxnet/python/mxnet/model.py"", line 618, in predict
self._init_predictor(data_shapes, type_dict)
File ""/home/bobliu/Work/code/DL/mxnet/python/mxnet/model.py"", line 541, in _init_predictor
self.ctx[0], grad_req='null', type_dict=type_dict, **dict(input_shapes))
File ""/home/bobliu/Work/code/DL/mxnet/python/mxnet/symbol.py"", line 685, in simple_bind
arg_types, _, aux_types = self.infer_type(**type_dict)
File ""/home/bobliu/Work/code/DL/mxnet/python/mxnet/symbol.py"", line 417, in infer_type
ctypes.byref(complete)))
File ""/home/bobliu/Work/code/DL/mxnet/python/mxnet/base.py"", line 77, in check_call
raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: InferType Error in reshape0: [21:39:03] src/operator/./reshape-inl.h:345: Check failed: (dtype) != (-1) First input must have specified type
</code></pre>
","<lstm><mxnet>","2016-12-10 02:00:36","","0","4952954","2016-12-14 00:51:08","1","0","","","4952954","111","18","0"
"48692154","<p>EDIT 02/2018 <strong><em>After writing my own code with data stored locally and less clunky accuracy metric calculations I saw significant speed up. GPU also rinses CPU in any CNN I have tried building in mxnet; even just using MNIST. I believe my issue was linked to the tutorial code and no longer consider this a real problem.</em></strong></p>

<p>I am running through the 'Multilayer perceptrons in gluon' MNIST tutorial on <a href=""http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-gluon.html"" rel=""nofollow noreferrer"">http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-gluon.html</a></p>

<p>(same code except setting context to gpu(0), sequential model used)</p>

<p>I am in Windows 10. Using python 3 (anaconda), installed CUDA 9.0, and cuDNN v7.0.5 for 9.0, then mxnet_cu90 installed from pip.</p>

<p>I set the data and model contexts to gpu(0), but my gtx 1080 hovers around 1-4% usage (whether or not the script is running), whilst my 8 Xeon cores ramp up to around 50-60% through the epochs. There was no difference in training time regardless of context.  When I print the params after training it says they are NDArray <em>size</em>  gpu(0), so it definitely thinks it's using the gpu.</p>

<p>EDIT: Replicated on my laptop at home (gpu:GTX980m, cpu:I7 4710HQ). In this case the gpu was utilized: 980m went from 0% to 12% use each epoch. However, cpu was also used >40% load, and, the gpu context training was actually slower than on the cpu.</p>

<p>I am starting to think that because this is a simple problem with MNIST/ANN, gpu is just not challenged. Maybe I will see far more impact of gpu usage when training a CNN.</p>

<p>I am still a little confused though, as I never had these issues when I used TensorFlow; where utilizing gpu generally always outperformed my cpu.</p>

<p>Any help appreciated,
Thanks,
T.</p>

<p>EDIT: CODE AS REQUESTED:</p>

<pre><code>#MULTILAYER PERCEPTRONS IN GLUON (MNIST)
#MODIFIED FROM: http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-gluon.html

#IMPORT REQUIRED PACKAGES
import numpy as np
import mxnet as mx
from mxnet import nd, autograd, gluon
import datetime #for comparing training times

#SET THE CONTEXTS (GPU/CPU)
ctx = mx.gpu(0) #note: original tutorial sets separate context variable for data/model. The data_ctx was never used so i submitted an issue on github and use a single ctx here
#ctx = mx.cpu()

#PREDEFINE SOME USEFUL NUMBERS
batch_size = 64
num_inputs = 784
num_outputs = 10 #ten hand written digits [0-9]
num_examples = 60000

#LOAD IN THE MNIST DATASET
def transform(data, label):
    return data.astype(np.float32)/255, label.astype(np.float32)
train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train = True, transform = transform), batch_size, shuffle = True)
test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train = False, transform = transform), batch_size, shuffle = False)

#MAKE SEQUENTIAL MODEL

num_hidden = 64
net = gluon.nn.Sequential()
with net.name_scope():
    net.add(gluon.nn.Dense(num_hidden, activation = ""relu""))
    net.add(gluon.nn.Dense(num_hidden, activation = ""relu""))
    net.add(gluon.nn.Dense(num_outputs))

net.collect_params().initialize(mx.init.Normal(sigma = 0.01), ctx = ctx)

#SETUP THE FUNCTIONS FOR TRAINING

softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss() #LOSS
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01}) #OPTIMIZER

#DEFINE A LOOP TO TEST THE ACCURACY OF THE MODEL ON A TEST SET
def evaluate_accuracy(data_iterator, net):
    acc = mx.metric.Accuracy()
    for i, (data, label) in enumerate(data_iterator):
        data = data.as_in_context(ctx).reshape((-1,784))
        label = label.as_in_context(ctx)
        output = net(data)
        predictions = nd.argmax(output, axis = 1)
        acc.update(preds = predictions, labels = label)
    return acc.get()[1] #get the accuracy value from the mxnet accuracy metric

#TRAINING LOOP
epochs  = 10
smoothing_constant = 0.01
start_time = datetime.datetime.now()

for e in range(epochs):
    cumulative_loss = 0
    for i, (data, label) in enumerate(train_data):
        data = data.as_in_context(ctx).reshape((-1, 784))
        label = label.as_in_context(ctx)
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)
        loss.backward()
        trainer.step(data.shape[0])
        cumulative_loss += nd.sum(loss).asscalar()
    test_accuracy = evaluate_accuracy(test_data, net)
    train_accuracy = evaluate_accuracy(train_data, net)
    print(""Epoch %s. Loss: %s, Train_acc %s, Test_acc %s"" % (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))

#I ADDED THIS TO GET THE FINAL PARAMETERS / NDARRAY CONTEXTS    
params = net.collect_params()
for param in params.values():
    print(param.name,param.data())

#I ADDED THIS TO COMPARE THE TIMING I GET WHEN SETTING THE CTX AS GPU/CPU   
end_time = datetime.datetime.now()
training_time = end_time - start_time
print(""In h/m/s, total training time was: %s"" % training_time)
</code></pre>

<p>RESULTS FOR CPU CONTEXT:
<a href=""https://i.stack.imgur.com/ikA8W.png"" rel=""nofollow noreferrer"">cmd output for params and total training time (cpu)</a></p>

<p>RESULTS FOR GPU CONTEXT (Actually took longer):
<a href=""https://i.stack.imgur.com/jax2b.png"" rel=""nofollow noreferrer"">cmd output for params and total training time (gpu)</a></p>
","<python><python-3.x><mxnet><cudnn>","2018-02-08 18:13:13","","0","9334554","2018-02-21 11:30:47","1","3","","","9334554","13","0","0"
"47477871","<p>I am understanding Mxnet framework. While following this <a href=""http://gluon.mxnet.io/chapter02_supervised-learning/linear-regression-gluon.html"" rel=""nofollow noreferrer"">Linear Regression article</a> I see the following piece of code which is creating a Dense Layer:</p>

<pre><code>net = gluon.nn.Dense(1, in_units=2) # input dimension= 2, output dimension = 1
</code></pre>

<p>but why does <code>print(net.weight)</code> give shape as <code>Parameter dense4_weight (shape=(1, 2), dtype=None)</code></p>

<p>Shouldn't the shape be <code>(2, 1)</code>?</p>

<p>According to my understanding:</p>

<pre><code>input = Shape(n, 2) where n is number of samples
output = Shape(n, 1)
</code></pre>

<p><strong>so the weight matrix should be Shape(2, 1) for the matrix multiplication, isn't it?</strong></p>

<p>What am I missing here?</p>
","<python><deep-learning><mxnet>","2017-11-24 17:31:00","","2","3371460","2017-12-09 03:42:50","1","0","","","3371460","649","104","1"
"47859188","<p>I have an MXNet NDArray that has image data in it. How do I render the NDArray as image in Jupyter Notebook?</p>

<pre><code>type(data)
mxnet.ndarray.ndarray.NDArray

data.shape
(3, 759, 1012)
</code></pre>
","<mxnet>","2017-12-17 20:36:26","","1","124091","2017-12-18 01:38:19","1","0","1","","124091","1107","99","1"
"50929934","<h2>Problem</h2>

<p>I have tried to replace the Mxnet models in <a href=""https://github.com/Leliana/WhatsThis"" rel=""nofollow noreferrer"">WhatsThis</a> with my own Caffe models that I ported to Mxnet with <a href=""https://github.com/Microsoft/MMdnn"" rel=""nofollow noreferrer"">https://github.com/Microsoft/MMdnn</a> . When I run the application, I get a white screen  with no elements and the application crashes. Please advise. Assume that the model is correct as it works perfectly on a PC Mxnet environment. I only changed the model, did nothing else to get this behavior.</p>

<h2>Solutions that I tried</h2>

<ul>
<li>Change the input shape ( model is set for 1,3,128,128) - problem remains</li>
</ul>

<h2>Files used</h2>

<p><a href=""https://github.com/Leliana/WhatsThis/files/21153/symbol.json.txt"" rel=""nofollow noreferrer"">symbol.json</a></p>

<h2>Error log</h2>

<p><a href=""https://pastebin.com/raw/TEY3ZD0R"" rel=""nofollow noreferrer"">Log</a> (full error log pasted to pastebin due to stack overflow's limits)</p>

<pre><code>06-20 10:27:24.335 3960-3960/? E/Zygote: isWhitelistProcess - Process is Whitelisted
...
</code></pre>
","<java><android><neural-network><mxnet>","2018-06-19 13:40:31","","0","8856083","2018-07-10 01:11:09","1","3","","","8856083","35","9","0"
"41392201","<p>There are 2 parts to this question. Suppose we are looking at sales S of a product across $> 1000$ stores where a it sells. For each of these 1000 stores we have 24 months recorded data. </p>

<ol>
<li>We want to be able to predict S_t &lt;- f(S_{t-1}). We could build a RNN for each of the store time series, calculate test RMSE and then take an average after taking care of normalizing values etc. But the problem is there are very few samples per time series. If we were to segment stores into groups (by say Dynamic Time Warping) then could we create a monologue of text sentiment mining where like in text two sentences are separated by a dot here we would have two time series separated by a special symbol (let's say). In that case, we would generate a RNN model on </li>
</ol>

<p>Train_1 | Train_2 |...|Train_t  </p>

<p>data and predict on </p>

<p>Test_1 | Test_2 |...|Test_t</p>

<ol start=""2"">
<li>After this, we would like to set it up as a panel data problem where S_t &lt;- f(x_{t1},x_{t2},...,x_{tn}). In that case should I build a separate neural network for each t and then connect the hidden layers from t -> t+1 -> t+2 .... </li>
</ol>

<p>How should I implement these through packages like Keras/Theano/Mxnet etc.? Any help would be great! </p>
","<keras><recurrent-neural-network><panel-data><mxnet>","2016-12-30 07:11:19","","2","1190427","2018-03-04 20:28:01","1","0","","","1190427","72","1","0"
"41088972","<p>I am dockerizing a shiny app that uses 'mxnet' package. After lots of efforts I concluded that I need to build and install the package instead of just installing it normally from the dmlc repos. Below is me simplified dockerfile that tries to build and install the mxnet:</p>

<pre><code>FROM r-base:latest


RUN apt-get update &amp;&amp; apt-get install -y \
sudo \
gdebi-core \
pandoc \
pandoc-citeproc \
libcurl4-gnutls-dev \
libcairo2-dev/unstable \
libxt-dev \
libssl-dev

# Download and install shiny server
RUN wget --no-verbose https://s3.amazonaws.com/rstudio-shiny-server-os-   build/ubuntu-12.04/x86_64/VERSION -O ""version.txt"" &amp;&amp; \
VERSION=$(cat version.txt)  &amp;&amp; \
wget --no-verbose ""https://s3.amazonaws.com/rstudio-shiny-server-os- build/ubuntu-12.04/x86_64/shiny-server-$VERSION-amd64.deb"" -O ss-latest.deb &amp;&amp; \
gdebi -n ss-latest.deb &amp;&amp; \
rm -f version.txt ss-latest.deb

# Here comes the installation of other required packages:
# .......



#*** Here comes the problamatic bit: building Installing mxnet
RUN sudo apt-get update
RUN sudo apt-get install -y build-essential git libatlas-base-dev libopencv-dev

RUN git clone --recursive https://github.com/dmlc/mxnet
RUN cd mxnet; make -j$(nproc)

RUN Rscript -e ""install.packages('devtools', repo = 'https://cran.rstudio.com')""

RUN cd R-package

RUN Rscript -e ""library('devtools'); library('methods'); options(repos=c(CRAN='https://cran.rstudio.com')); install_deps(dependencies = TRUE)""


RUN cd ..

RUN make rpkg


COPY shiny-server.conf  /etc/shiny-server/shiny-server.conf
COPY /myapp/* /srv/shiny-server/

EXPOSE 80

COPY shiny-server.sh /usr/bin/shiny-server.sh

CMD [""/usr/bin/shiny-server.sh""]
</code></pre>

<p>After running this, I recieve an error saying:</p>

<pre><code>can not cd to R-Package
</code></pre>

<p>Any help? </p>
","<r><docker><shiny><dockerfile><mxnet>","2016-12-11 17:30:42","","2","7246047","2016-12-13 12:05:17","1","0","1","","7246047","446","60","1"
"38197828","<p>Has anyone tried Mxnet amalgamation for android recently. I am getting stuck at the below issue. Have tried setting jni path etc, but to no avail</p>

<pre><code>python ./amalgamation.py mxnet_predict0.d mxnet_predict0.cc mxnet_predict-all.cc 0 
Not processed: mxnet_predict0.o:
g++ -std=c++11 -Wno-unknown-pragmas -Wall -I/home/ubuntu/newopenblas -mhard-float -D_NDK_MATH_NO_SOFTFP=1 -O3 -fPIC -o jni_libmxnet_predict.o -c jni/predictor.cc
jni/predictor.cc:1:17: fatal error: jni.h: No such file or directory
 #include &lt;jni.h&gt;
compilation terminated.
</code></pre>
","<android><mxnet>","2016-07-05 07:40:21","","0","3550694","2017-03-21 11:48:01","1","0","","","3550694","41","1","0"
"41539361","<p>When enabling the shuffle of the data using a NDArrayIter, do you know is the shuffling happens once at the beginning, or the data is re-shuffled at the end of each epoch?</p>

<p>Many thanks!</p>
","<mxnet>","2017-01-09 00:15:12","","1","7350566","2017-05-26 19:02:32","2","0","","","7350566","24","2","0"
"50411245","<p>I would like to test the trained built-in VGG16 network in MxNet. The experiment is to feed the network with an image from ImageNet. Then, I would like to see whether the result is correct.</p>

<p>However, the results are always error! Hi, how stupid the network is! Well, that cannot be true. I must do something wrong.</p>

<pre><code>from mxnet.gluon.model_zoo.vision import vgg16
from mxnet.image import color_normalize
import mxnet as mx
import numpy as np
import cv2
path=‘http://data.mxnet.io/models/imagenet-11k/’
data_dir = ‘F:/Temps/Models_tmp/’
k = ‘synset.txt’
#gluon.utils.download(path+k, data_dir+k)
img_dir = ‘F:/Temps/DataSets/ImageNet/’
img = cv2.imread(img_dir + ‘cat.jpg’)
img = mx.nd.array(img)
img,_ = mx.image.center_crop(img,(224,224))
img = img/255
img = color_normalize(img,mean=mx.nd.array([0.485, 0.456, 0.406]),std=mx.nd.array([0.229, 0.224, 0.225]))
img = mx.nd.transpose(img, axes=(2, 0, 1))
img = img.expand_dims(axis=0)
with open(data_dir + ‘synset.txt’, ‘r’) as f:
labels = [l.rstrip() for l in f]
aVGG = vgg16(pretrained=True,root=‘F:/Temps/Models_tmp/’)
features = aVGG.forward(img)
features = mx.ndarray.softmax(features)
features = features.asnumpy()
features = np.squeeze(features)
a = np.argsort(features)[::-1]
for i in a[0:5]:
  print(‘probability=%f, class=%s’ %(features[i], labels[i]))
</code></pre>

<p>The outputs from color_normalize seems not right for the absolute values of some numbers are greater than one.</p>

<p>This is my figure of cat which is downloaded from the ImageNet. </p>

<p><a href=""https://i.stack.imgur.com/WsJGN.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WsJGN.jpg"" alt=""enter image description here""></a></p>

<p>These are my outputs.</p>

<blockquote>
  <p>probability=0.218258, class=n01519563 cassowary probability=0.172373,
  class=n01519873 emu, Dromaius novaehollandiae, Emu novaehollandiae
  probability=0.128973, class=n01521399 rhea, Rhea americana
  probability=0.105253, class=n01518878 ostrich, Struthio camelus
  probability=0.051424, class=n01517565 ratite, ratite bird, flightless
  bird</p>
</blockquote>
","<deep-learning><mxnet>","2018-05-18 12:21:41","","0","9033700","2018-05-19 05:17:38","1","0","","","9033700","156","2","0"
"52612038","<p>I have not got a clear idea about how labels for the softmax classifier should be shaped.</p>

<p>What I could understand from my experiments is that a scalar laber indicating the index of class probability output is one option, while another is a 2D label where the rows are class probabilities, or one-hot encoded variable, like c(1, 0, 0).</p>

<p>What puzzles me though is that: </p>

<ul>
<li>I can use sclalar label values that go beyong indexing, like 4 in my
example below -- without warning or error. Why is that?</li>
<li>When my label is a negative scalar or an array with a negative value,
the model converges to uniform probablity distribution over classes.
For example, is this expected that <code>actor_train.y = matrix(c(0, -1,v0), ncol = 1)</code> results in equal probabilities in the softmax output?</li>
<li><p>I try to use softmax MXNET classifier to produce the policy gradient
reifnrocement learning, and my negative rewards lead to the issue
above: uniform probability. Is that expected?</p>

<p>require(mxnet)</p>

<p>actor_initializer &lt;- mx.init.Xavier(rnd_type = ""gaussian"", 
                              factor_type = ""avg"", 
                              magnitude = 0.0001)</p>

<p>actor_nn_data &lt;- mx.symbol.Variable('data') actor_nn_label &lt;- mx.symbol.Variable('label')</p>

<p>device.cpu &lt;- mx.cpu()</p>

<h2>NN architecture</h2>

<p>actor_fc3 &lt;- mx.symbol.FullyConnected(
     data = actor_nn_data
     , num_hidden = 3 )</p>

<p>actor_output &lt;- mx.symbol.SoftmaxOutput(
     data = actor_fc3
     , label = actor_nn_label
     , name = 'actor' )</p>

<p>crossentfunc &lt;- function(label, pred)
     {
     - sum(label * log(pred)) }</p>

<p>actor_loss &lt;- mx.metric.custom(
          feval = crossentfunc
          , name = ""log-loss""
     )</p>

<h1>initialize NN</h1>

<p>actor_train.x &lt;- matrix(rnorm(11), nrow = 1)</p>

<p>actor_train.y = 0 #1 #2 #3 #-3 # matrix(c(0, 0, -1), ncol = 1)</p>

<p>rm(actor_model)</p>

<p>actor_model &lt;- mx.model.FeedForward.create(
     symbol = actor_output,
     X = actor_train.x,
     y = actor_train.y,
     ctx = device.cpu,
     num.round = 100,
     array.batch.size = 1,
     optimizer = 'adam',
     eval.metric = actor_loss,
     clip_gradient = 1,
     wd = 0.01,
     initializer = actor_initializer,
     array.layout = ""rowmajor"" )</p>

<p>predict(actor_model, actor_train.x, array.layout = ""rowmajor"")</p></li>
</ul>
","<r><mxnet><softmax>","2018-10-02 15:53:20","","1","8532487","2018-10-04 19:55:07","1","0","","","8532487","162","20","0"
"41424908","<p>I have a block of code that is supposed to build a RNN model with 5 lag variables for an observation of time series data. Here is the code:</p>

<pre><code>library(Quandl)
key&lt;-""*******************""
Quandl.api_key(key)

sh_stock_ex &lt;- Quandl(""YAHOO/SS_600292"", type=""xts"")
library(xts)
data &lt;- scale(sh_stock_ex[-1,5])
feat &lt;- merge(na.trim(lag(data,1)), na.trim(lag(data,2)), na.trim(lag(data,3)), na.trim(lag(data,4)),
              na.trim(lag(data,5)), all=FALSE)

dataset &lt;- merge(feat, data, all = FALSE)
colnames(dataset) &lt;- c(""lag.1"", ""lag.2"",""lag.3"",""lag.4"",""lag.5"", ""obj"")

index &lt;- 1:4000
training &lt;- as.data.frame(dataset[index,])
testing &lt;- as.data.frame(dataset[-index,])

library(mxnet)
train.x &lt;- data.matrix(training[,-6])
train.y &lt;- training[,6]
test.x &lt;- data.matrix(testing[,-6])
test.y &lt;- testing[,6]

get.label &lt;- function(X) {
  label &lt;- array(0, dim=dim(X))
  d &lt;- dim(X)[1]
  w &lt;- dim(X)[2]
  for (i in 0:(w-1)) {
    for (j in 1:d) {
      label[i*d+j] &lt;- X[(i*d+j)%%(w*d)+1]
    }
  }
  return (label)
}
X.train.label &lt;- get.label(t(train.x))
X.val.label &lt;- get.label(t(test.x))

X.train &lt;- list(data=t(train.x), label=X.train.label)
X.val &lt;- list(data=t(test.x), label=X.val.label)


#X.train &lt;- list(data=t(train.x), label=X.train.label)
#X.val &lt;- list(data=t(test.x), label=X.val.label)

batch.size = 5
seq.len = 5
num.hidden = 3
num.embed = 3
num.rnn.layer = 1
num.lstm.layer = 1
num.round = 1
update.period = 1
learning.rate= 0.1
wd=0.00001
clip_gradient=1

mx.set.seed(0)
model &lt;- mx.rnn(X.train, X.val, num.rnn.layer=num.rnn.layer, seq.len=seq.len, num.hidden=num.hidden,
                num.embed=num.embed, num.label=5, batch.size=batch.size, input.size=5, ctx = mx.cpu(),
                num.round = num.round, update.period = update.period, initializer = mx.init.uniform(0.01),
                dropout = 0, optimizer = ""sgd"", batch.norm = FALSE,
                learning.rate=learning.rate, wd=wd, clip_gradient=clip_gradient)

#preds = predict(model,t(test.x))

mx.rnn.inference(num.rnn.layer = num.rnn.layer,input.size = 5,num.hidden = num.hidden,
                 num.embed = num.embed,num.label = 5,batch.size = batch.size,ctx = mx.cpu(),
                 dropout = 0,batch.norm = FALSE,arg.params = model$arg.params)
</code></pre>

<p>In the call to mx.rnn it raises the following error:</p>

<pre><code>[15:36:29] src/operator/./reshape-inl.h:311: Using target_shape will be deprecated.
[15:36:29] src/operator/./reshape-inl.h:311: Using target_shape will be deprecated.
[15:36:29] src/operator/./reshape-inl.h:311: Using target_shape will be deprecated.
[15:36:29] src/operator/./reshape-inl.h:311: Using target_shape will be deprecated.
[15:36:29] C:/Users/qkou/mxnet/dmlc-core/include/dmlc/logging.h:235: [15:36:29] src/ndarray/ndarray.cc:231: Check failed: from.shape() == to-&gt;shape() operands shape mismatch
Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
  [15:36:29] src/ndarray/ndarray.cc:231: Check failed: from.shape() == to-&gt;shape() operands shape mismatch
</code></pre>

<p>Is it not that I get this everytime. A couple of runs before this code actually ran. 
Could you please help me in figuring out what's happening?</p>
","<r><recurrent-neural-network><mxnet>","2017-01-02 10:20:08","","2","1190427","2018-03-09 19:28:25","1","1","4","","1190427","72","1","0"
"50458412","<p>I am reading a tutorial about MxNet. The writers use ‘mxnet.gluon.nn.Sequential()’ as a container to store some blocks (see code 1); then, they rewrite the connection of blocks in ‘def forward(self, x)’ (see codes 2 and 3). Is there any side effect by doing this? By the way, what is the difference between ‘Sequential()’ and ‘HybridSequential()’. I try a list to replace the ‘Sequential’, and I get following warnings doing the initialization process. </p>

<blockquote>
  <p><em>“ToySSD.downsamplers” is a container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically.
  Make sure to register them using register_child() or switching to
  nn.Sequential/nn.HybridSequential instead.’</em></p>
</blockquote>

<p>As far as I know, if you put some blocks in ‘mxnet.gluon.nn.Sequential()’ or ‘mxnet.gluon.nn.HybridSequential()’, this action is telling the computer that these blocks are connected. However, if you design the relationship of blocks in the ‘forward’ function, you are telling the computer to connect these blocks in another way. Will it lead to confusion? If I only design some block connections in ‘forward’, what are the relationships of the other blocks in ‘Sequential()’ that are not designed in ‘forward’ function? </p>

<p>The entire tutorial can be found in <a href=""https://github.com/mli/gluon-tutorials-zh/blob/master/chapter_computer-vision/ssd.md"" rel=""nofollow noreferrer"">here</a>.</p>

<p>code 1：</p>

<pre><code>def toy_ssd_model(num_anchors, num_classes):
    downsamplers = nn.Sequential()
    for _ in range(3):
        downsamplers.add(down_sample(128))

    class_predictors = nn.Sequential()
    box_predictors = nn.Sequential()    
    for _ in range(5):
        class_predictors.add(class_predictor(num_anchors, num_classes))
        box_predictors.add(box_predictor(num_anchors))

    model = nn.Sequential()
    model.add(body(), downsamplers, class_predictors, box_predictors)
    return model
</code></pre>

<p>code 2:</p>

<pre><code>def toy_ssd_forward(x, model, sizes, ratios, verbose=False):    
    body, downsamplers, class_predictors, box_predictors = model
    anchors, class_preds, box_preds = [], [], []
    # feature extraction    
    x = body(x)
    for i in range(5):
        # predict
        anchors.append(MultiBoxPrior(
            x, sizes=sizes[i], ratios=ratios[i]))
        class_preds.append(
            flatten_prediction(class_predictors[i](x)))
        box_preds.append(
            flatten_prediction(box_predictors[i](x)))
        if verbose:
            print('Predict scale', i, x.shape, 'with', 
                  anchors[-1].shape[1], 'anchors')
        # down sample
        if i &lt; 3:
            x = downsamplers[i](x)
        elif i == 3:
            x = nd.Pooling(
                x, global_pool=True, pool_type='max', 
                kernel=(x.shape[2], x.shape[3]))
    # concat data
    return (concat_predictions(anchors),
            concat_predictions(class_preds),
            concat_predictions(box_preds))
</code></pre>

<p>code 3:</p>

<pre><code>from mxnet import gluon
class ToySSD(gluon.Block):
    def __init__(self, num_classes, verbose=False, **kwargs):
        super(ToySSD, self).__init__(**kwargs)
        # anchor box sizes and ratios for 5 feature scales
        self.sizes = [[.2,.272], [.37,.447], [.54,.619], 
                      [.71,.79], [.88,.961]]
        self.ratios = [[1,2,.5]]*5
        self.num_classes = num_classes
        self.verbose = verbose
        num_anchors = len(self.sizes[0]) + len(self.ratios[0]) - 1
        # use name_scope to guard the names
        with self.name_scope():
            self.model = toy_ssd_model(num_anchors, num_classes)

    def forward(self, x):
        anchors, class_preds, box_preds = toy_ssd_forward(
            x, self.model, self.sizes, self.ratios, 
            verbose=self.verbose)
        # it is better to have class predictions reshaped for softmax computation       
        class_preds = class_preds.reshape(shape=(0, -1, self.num_classes+1))
        return anchors, class_preds, box_preds
</code></pre>
","<python><deep-learning><computer-vision><mxnet>","2018-05-22 01:04:44","","1","9033700","2018-05-22 23:21:57","1","0","","","9033700","156","2","0"
"43517960","<p>I am using MXnet for training a CNN (in R) and I can train the model without any error with the following code:</p>

<pre><code>model &lt;- mx.model.FeedForward.create(symbol=network,
                                     X=train.iter,
                                     ctx=mx.gpu(0),
                                     num.round=20,
                                     array.batch.size=batch.size,
                                     learning.rate=0.1,
                                     momentum=0.1,  
                                     eval.metric=mx.metric.accuracy,
                                     wd=0.001,
                                     batch.end.callback=mx.callback.log.speedometer(batch.size, frequency = 100)
    )
</code></pre>

<p>But as this process is time-consuming, I run it on a server during the night and I want to save the model for the purpose of using it after finishing the training.</p>

<p>I used:</p>

<pre><code>save(list = ls(), file=""mymodel.RData"")
</code></pre>

<p>and </p>

<pre><code>mx.model.save(""mymodel"", 10)
</code></pre>

<p>But none of them can save the model! for example when I load the <code>""mymodel.RData""</code>, I can not predict the labels for the test set!</p>

<p>Another example is when I load the <code>""mymodel.RData""</code> and try to plot it with the following code:</p>

<pre><code>graph.viz(model$symbol$as.json())
</code></pre>

<p>I get the following error:</p>

<pre><code>Error in model$symbol$as.json() : external pointer is not valid
</code></pre>

<p>Can anybody give me a solution for saving and then loading this model for future use?</p>

<p>Thanks</p>
","<r><deep-learning><mxnet>","2017-04-20 11:14:27","","2","4288229","2017-05-26 06:19:28","2","2","","","4288229","454","61","3"
"38422636","<p>I recently installed mxnet (python package) with GPU support on Windows 10 and Python 3.5. I run through a couple of examples and they seem to work fine.</p>

<p>I am used to scikit-learn style machine learning packages and very new to Python deep learning packages such as Mxnet although I have already used Mxnet in R. I'm having a hard time understanding how to feed .csv training data to the model.</p>

<p>I would like to feed to a simple CNN some images. The images are 28x28 pixel and stored as flattened arrays in a .csv. I have two .csv files, one for training and the other for testing. Each .csv file has the following structure:</p>

<pre><code>label, pixel1, pixel2, ..., pixel784
0,...
1,...
</code></pre>

<p>There are 10 labels in total and around 1000/300 images in the training set/test set.</p>

<p>I am using the following code to load the data and train the model:</p>

<pre><code>import mxnet as mx
import pandas as pd
import numpy as np
import os

path = ""C://users//me//data""
os.chdir(path)

df_train = pd.read_csv(""train_28.csv"")
df_test = pd.read_csv(""test_28.csv"")

keys = ['pixel.'+str(i) for i in range(1,785)]

X_train = df_train[keys].get_values().T
X_train = X_train.reshape((1200,28,28,1))
y_train = df_train['label'].get_values().reshape((1200,1))
#y_train = y_train.reshape((28,28,1,1200))



data = mx.symbol.Variable('data')

# First conv layer
conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)
tanh1 = mx.symbol.Activation(data=conv1, act_type=""tanh"")
pool1 = mx.symbol.Pooling(data=tanh1, pool_type=""max"",
                              kernel=(2,2), stride=(2,2))

# Second conv layer
conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)
tanh2 = mx.symbol.Activation(data=conv2, act_type=""tanh"")
pool2 = mx.symbol.Pooling(data=tanh2, pool_type=""max"",
                              kernel=(2,2), stride=(2,2))

# First fully connected
flatten = mx.symbol.Flatten(data=pool2)
fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh3 = mx.symbol.Activation(data=fc1, act_type=""tanh"")
# second fullc
fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
# loss
lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')                              

device = mx.gpu()                              

model = mx.model.FeedForward.create(lenet,
                                    X = X_train,
                                    y = y_train,
                                    ctx = device,
                                    num_epoch = 30)
</code></pre>

<p>I am using this approach which is similar to the one I was using with mxnet in R, (btw on R it works perfectly, however I cannot use the GPU on R so I need to use Python for better performances...) however I am getting the following error:</p>

<pre><code>[16:54:11] D:\chhong\mxnet\dmlc-core\include\dmlc/logging.h:235: [16:54:11] d:\chhong\mxnet\src\operator\./convolution-inl.h:347: Check failed: ksize_x &lt;= dshape[3] &amp;&amp; ksize_y &lt;= dshape[2] kernel size exceed input
Traceback (most recent call last):
  File ""C:\Users\Me\Desktop\esempio_lenet.py"", line 57, in &lt;module&gt;
    num_epoch = 30)
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\model.py"", line 901, in create
    eval_batch_end_callback=eval_batch_end_callback)
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\model.py"", line 745, in fit
    self._init_params(dict(data.provide_data+data.provide_label))
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\model.py"", line 485, in _init_params
    arg_shapes, _, aux_shapes = self.symbol.infer_shape(**input_shapes)
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\symbol.py"", line 453, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\symbol.py"", line 513, in _infer_shape_impl
    ctypes.byref(complete)))
  File ""C:\Users\Me\Anaconda3\lib\site-packages\mxnet-0.7.0-py3.5.egg\mxnet\base.py"", line 77, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: InferShape Error in convolution0: [16:54:11] d:\chhong\mxnet\src\operator\./convolution-inl.h:347: Check failed: ksize_x &lt;= dshape[3] &amp;&amp; ksize_y &lt;= dshape[2] kernel size exceed input
</code></pre>

<p>And I cannot figure out what I am doing wrong. Could please someone tell me what is this error about and provide me with a clear set of instructions on how to load .csv files with the same structure as above and train a mxnet model? I took a look at the documentation but could not figure out on my own how to load .csv files properly...</p>

<p>The reason why I am asking for a procedure for loading such .csv files is that I mostly deal with data in that format and it would be very valuable to me to be able to run a script against a folder with these .csv files and have them ready to be used for training a deep convolutional neural network.</p>

<p>A set of train and test .csv files are available <a href=""https://www.dropbox.com/s/pkrymi1x0v8776g/example_csv.zip?dl=0"" rel=""nofollow"">here</a> should you need them to reproduce the example code I wrote.</p>

<p>Thank you</p>
","<python><csv><deep-learning><mxnet>","2016-07-17 15:04:23","","3","3775577","2017-01-24 19:52:40","1","0","0","","3775577","520","23","2"
"49217210","<p>I am training a model using multi-label logistic regression on MxNet (gluon api) as described here: <a href=""http://gluon.mxnet.io/chapter02_supervised-learning/softmax-regression-gluon.html"" rel=""nofollow noreferrer"">multi-label logit in gluon</a>
My custom dataset has 13 features and one label of shape [,6].
My features are normalized from original values to [0,1]
I use simple dense neural net with 2 hidden layers.</p>

<p>I noticed when I don't normalize labels (which take discrete values of 1,2,3,4,5,6 and are purely my choice to map categorical values to these numbers), my training process slowly converges to some minima for example:</p>

<pre><code>Epoch: 0, ela: 8.8 sec, Loss: 1.118188, Train_acc 0.5589, Test_acc 0.5716
Epoch: 1, ela: 9.6 sec, Loss: 0.916276, Train_acc 0.6107, Test_acc 0.6273
Epoch: 2, ela: 10.3 sec, Loss: 0.849386, Train_acc 0.6249, Test_acc 0.6421
Epoch: 3, ela: 9.2 sec, Loss: 0.828530, Train_acc 0.6353, Test_acc 0.6304
Epoch: 4, ela: 9.3 sec, Loss: 0.824667, Train_acc 0.6350, Test_acc 0.6456
Epoch: 5, ela: 9.3 sec, Loss: 0.817131, Train_acc 0.6375, Test_acc 0.6455
Epoch: 6, ela: 10.6 sec, Loss: 0.815046, Train_acc 0.6386, Test_acc 0.6333
Epoch: 7, ela: 9.4 sec, Loss: 0.811139, Train_acc 0.6377, Test_acc 0.6289
Epoch: 8, ela: 9.2 sec, Loss: 0.808038, Train_acc 0.6381, Test_acc 0.6484
Epoch: 9, ela: 9.2 sec, Loss: 0.806301, Train_acc 0.6405, Test_acc 0.6485
Epoch: 10, ela: 9.4 sec, Loss: 0.804517, Train_acc 0.6433, Test_acc 0.6354
Epoch: 11, ela: 9.1 sec, Loss: 0.803954, Train_acc 0.6389, Test_acc 0.6280
Epoch: 12, ela: 9.3 sec, Loss: 0.803837, Train_acc 0.6426, Test_acc 0.6495
Epoch: 13, ela: 9.1 sec, Loss: 0.801444, Train_acc 0.6424, Test_acc 0.6328
Epoch: 14, ela: 9.4 sec, Loss: 0.799847, Train_acc 0.6445, Test_acc 0.6380
Epoch: 15, ela: 9.1 sec, Loss: 0.795130, Train_acc 0.6454, Test_acc 0.6471
</code></pre>

<p>However, when I normalize labels and train again I get this wired result showing 99.99% accuracy on both training and testing:</p>

<pre><code>Epoch: 0, ela: 12.3 sec, Loss: 0.144049, Train_acc 0.9999, Test_acc 0.9999
Epoch: 1, ela: 12.7 sec, Loss: 0.023632, Train_acc 0.9999, Test_acc 0.9999
Epoch: 2, ela: 12.3 sec, Loss: 0.013996, Train_acc 0.9999, Test_acc 0.9999
Epoch: 3, ela: 12.7 sec, Loss: 0.010092, Train_acc 0.9999, Test_acc 0.9999
Epoch: 4, ela: 12.7 sec, Loss: 0.007964, Train_acc 0.9999, Test_acc 0.9999
Epoch: 5, ela: 12.6 sec, Loss: 0.006623, Train_acc 0.9999, Test_acc 0.9999
Epoch: 6, ela: 12.6 sec, Loss: 0.005700, Train_acc 0.9999, Test_acc 0.9999
Epoch: 7, ela: 12.4 sec, Loss: 0.005026, Train_acc 0.9999, Test_acc 0.9999
Epoch: 8, ela: 12.6 sec, Loss: 0.004512, Train_acc 0.9999, Test_acc 0.9999
</code></pre>

<p>How is this possible? Why normalizing labels affects training accuracy in such way?</p>
","<machine-learning><training-data><feature-selection><mxnet><loss-function>","2018-03-11 06:12:58","","0","1157401","2018-03-17 20:08:04","1","1","1","","1157401","538","45","4"
"49226287","<p>How to use MxNet <a href=""https://mxnet.incubator.apache.org/api/python/metric/metric.html"" rel=""nofollow noreferrer"">metrics api</a> to calculate accuracy of the <strong>multiclass</strong> logistic regression classifier with vector labels?
Here is an example for labels:</p>

<pre><code>Class1: [1,0,0,0]
Class2: [0,1,0,0]
Class3: [0,0,1,0]
Class4: [0,0,0,1]
</code></pre>

<p>The naive way to use this function would produce wrong result as argmax will squash the model output into an index having max probability value</p>

<pre><code>def evaluate_accuracy(data_iterator, ctx, net):
    acc = mx.metric.Accuracy()
    for i, (data, label) in enumerate(data_iterator):
        data = data.as_in_context(ctx)
        label = label.as_in_context(ctx)
        out = net(data)
        p = nd.argmax(out, axis=1)
        acc.update(preds=p, labels=label)
    return acc.get()[1]
</code></pre>

<p>My current solution is little hacky:</p>

<pre><code>def evaluate_accuracy(data_iterator, ctx, net):
    acc = mx.metric.Accuracy()
    for i, (data, label) in enumerate(data_iterator):
        data = data.as_in_context(ctx)
        label = label.as_in_context(ctx)
        out = net(data)
        p = nd.argmax(out, axis=1)
        l = nd.argmax(label, axis=1)
        acc.update(preds=p, labels=l)
    return acc.get()[1]
</code></pre>
","<python><logistic-regression><mxnet><multiclass-classification>","2018-03-11 23:38:14","","0","1157401","2018-03-12 18:36:19","1","0","","","1157401","538","45","4"
"49094777","<p>How can I set keras's backend to be MXNet? </p>

<p>I have found only <a href=""https://github.com/deep-learning-tools/keras/wiki/Installation-Guide---Keras-with-MXNet-backend"" rel=""nofollow noreferrer"">this installation guide</a>, but after I install keras by hand in this way, Anaconda does not recognize this installation.</p>

<p>In other words, this command:</p>

<pre><code>KERAS_BACKEND=mxnet python -c ""from keras import backend""
</code></pre>

<p>works only in the ""keras"" installation folder.</p>

<p>Therefore, I can not use keras in a Jupyter Notebook, for example.</p>

<p>Do you know another way to install keras in order to be compatible with mxnet (as it is for example on aws's AMIs) ?</p>
","<keras><anaconda><ami><mxnet>","2018-03-04 11:16:29","","0","7136493","2018-03-04 21:11:35","1","1","","","7136493","66","16","0"
"48090102","<p>While trying to train a lenet model for multiclass classification using h2o deepwater using mxnet backed I am getting the following errors:</p>

<p><code>Loading H2O mxnet bindings.
Found CUDA_HOME or CUDA_PATH environment variable, trying to connect to GPU devices.
Loading CUDA library.
Loading mxnet library.
Loading H2O mxnet bindings.
Done loading H2O mxnet bindings.
Constructing model.
Done constructing model.
Building network.
mxnet data input shape: (32,100)
[10:40:16] /home/jenkins/slave_dir_from_mr-0xb1/workspace/deepwater-master/thirdparty/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:40:16] src/operator/./convolution-inl.h:349: Check failed: (dshape.ndim()) == (4) Input data should be 4D in batch-num_filter-y-x
[10:40:16] src/symbol.cxx:189: Check failed: (MXSymbolInferShape(GetHandle(), keys.size(), keys.data(), arg_ind_ptr.data(), arg_shape_data.data(), &amp;in_shape_size, &amp;in_shape_ndim, &amp;in_shape_data, &amp;out_shape_size, &amp;out_shape_ndim, &amp;out_shape_data, &amp;aux_shape_size, &amp;aux_shape_ndim, &amp;aux_shape_data, &amp;complete)) == (0)</code> </p>

<p>The details of my setup :<br>
* Ubuntu : 16.04<br>
* Ram : 12gb<br>
* Graphics card : Nvidia 920mx driver version : 384.90<br>
* Cuda : 8.0.61<br>
* cudnn : 6.0<br>
* R version : 3.4.3<br>
* H2o version : 3.15.0.393 &amp; h2o-R package : 3.16.0.2<br>
* mxnet : 0.11.0<br>
* Train data size : 400mb (when converting to the h2o frame object it comes around 822mb)  </p>

<p>Things I have done :<br>
1.) Gave enough memory to java heap while running h2o cluster (java -Xmx9g -jar h2o.jar)<br>
2.) Build the mxnet from source for gpu<br>
3.) Monitored the gpu and system via nvidia-smi and system monitor. At no point do they eat up all the ram to show ""out of memory"" issue. I still will be having around 2-3gb free before the error shows up<br>
4.) Have tried with tensorflow-gpu(build from source). Checking the pip list made sure that its installed but during model creation in R it gives the error :<br>
    <code>Error: java.lang.RuntimeException: Unable to initialize the native Deep Learning backend: null</code><br>
 5.) The only method I got it the h2o deepwater to work with all the backend and w/wo GPU is through docker setup provided in the installation tutorials. </p>

<p>I wanted the same functionality on my laptop instead of using Docker. Also is there any way to run deepwater using just CPU? The link <a href=""https://stackoverflow.com/questions/43545511/is-it-possible-to-build-deep-water-tensorflow-model-in-h2o-without-cuda"">Is it possible to build Deep Water/TensorFlow model in H2O without CUDA</a> doesn't provide any helpful answers. Any help or advice will be greatly appreciated!</p>
","<r><nlp><h2o><tensorflow-gpu><mxnet>","2018-01-04 06:52:21","","2","8979422","2018-03-02 01:34:04","1","1","1","","8979422","164","25","1"
"42503828","<p>I installed mxnet in python in windows.</p>

<pre><code>&gt;&gt;&gt; import mxnet
</code></pre>

<p>There is a mistake.</p>

<p><code>Traceback (most recent call last):
    File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
    File ""d:\Anaconda2\lib\site-packages\mxnet-0.7.0-    py2.7.egg\mxnet\__init__.py"", line 7, in &lt;module&gt;
    from .base import MXNetError
     File ""d:\Anaconda2\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\base.py"", line 43, in &lt;module&gt;
      _LIB = _load_lib()
     File ""d:\Anaconda2\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\base.py"", line 35, in _load_lib
     lib = ctypes.cdll.LoadLibrary(lib_path[0])
     File ""d:\Anaconda2\lib\ctypes\__init__.py"", line 440, in LoadLibrary
    return self._dlltype(name)
     File ""d:\Anaconda2\lib\ctypes\__init__.py"", line 362, in __init__
    self._handle = _dlopen(self._name, mode)
    WindowsError: [Error 126]</code> </p>

<p>I  have reinstalled mxnet and anaconda2 many times but it is still wrong.I made mxnet install successfully once 5 months ago.
I used Dependency Walker to see what lost,but there are too many to find files.I don't know where to find these DLL files.<a href=""https://i.stack.imgur.com/lA6DL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lA6DL.png"" alt=""enter image description here""></a></p>

<p>I want to know which step i do wrong.</p>
","<windows><python-2.7><mxnet>","2017-02-28 08:37:34","","0","7194417","2017-06-06 00:09:10","3","1","","","7194417","13","0","0"
"41705395","<p>I realize I can make my own module/optimizer to do this, but can existing mxnet modules be told to optimize only a subset of variables? </p>

<p>Along those same lines, how does a module determine which symbols to optimize as it is? For example, unlike tensorflow in MXNet, both data and variables to be optimized are just ""Variable"" symbols, but somehow MXNet only affects the NDArrays for the actual variables and not data NDArrays. How does it check? Is there a naming convention it uses? If so, what is that convention? (Any symbol with a name containing 'data' in it is not optimized?)</p>
","<mxnet>","2017-01-17 19:29:14","","0","6106700","2017-01-17 21:26:09","1","0","","","6106700","25","1","0"
"41073812","<p>I am trying to add DMLC repos in my Dokerfile so that I can install mxnet package. I am doing this as follows:</p>

<pre><code>RUN R -e ""install.packages('drat', repos='https://cran.rstudio.com')""
RUN R -e ""drat::addRepo('dmlc')""
RUN R -e ""install.packages('mxnet', #repos='https://dmlc.github.io/drat',   dependencies=TRUE)""
</code></pre>

<p>This does not work. Surprisingly, I noticed that even though I am adding the dmlc repos, in fact it is not added when I print out the output of the following command:  </p>

<pre><code>RUN R -e ""print(getOption('repos'))""
</code></pre>

<p>To resolve this, I specified the repos explicitly as follows:</p>

<pre><code>#RUN R -e ""install.packages('mxnet', #repos='https://dmlc.github.io/drat', dependencies=TRUE)""
</code></pre>

<p>Still this did not work. It throws an error saying:</p>

<p><a href=""https://i.stack.imgur.com/K7C6K.png"" rel=""nofollow noreferrer"">this is screenshot of the error</a></p>

<p>Any help? All what I am trying to do is to install mxnet in my Dockerfile when I prepare my container.  </p>
","<r><docker><repository><dockerfile><mxnet>","2016-12-10 08:57:59","","2","7246047","2017-12-10 22:54:00","1","1","1","","7246047","446","60","1"
"52617911","<p>I am playing around the SageMaker example for Caltech Image Classification notebook: <a href=""https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-transfer-learning.ipynb"" rel=""nofollow noreferrer"">link</a>. I followed the steps in the notebook but changed the resource section to use <code>ml.p3.16xlarge</code> which has 8 V100 GPU's as follows:</p>

<pre><code>""ResourceConfig"": {
    ""InstanceCount"": 1,
    ""InstanceType"": ""ml.p3.16xlarge"",
    ""VolumeSizeInGB"": 50
}
</code></pre>

<p>When I checked the log file after training, I found that the speed is only
<code>895 images/s</code>, which is quite similar to using single GPU (p3.2xlarge).  I guess the speed is for single GPU only and the actual speed for my case using 8 GPU's should be <code>895 * 8 = 7160</code>. Can anybody confirm this? Or I am wrong at it.</p>

<p>See bellow for the full logs:</p>

<pre><code>Docker entrypoint called with argument(s): train
[10/02/2018 21:40:21 INFO 139764860892992] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}
[10/02/2018 21:40:21 INFO 139764860892992] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'use_pretrained_model': u'1', u'epochs': u'2', u'num_training_samples': u'15420', u'num_layers': u'18', u'mini_batch_size': u'512', u'image_shape': u'3,224,224', u'num_classes': u'257'}
[10/02/2018 21:40:21 INFO 139764860892992] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'2', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float32', u'mini_batch_size': u'512', u'num_classes': u'257', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'15420'}
[10/02/2018 21:40:21 INFO 139764860892992] Using pretrained model for initalizing weights
[10/02/2018 21:40:21 INFO 139764860892992] ---- Parameters ----
[10/02/2018 21:40:21 INFO 139764860892992] num_layers: 18
[10/02/2018 21:40:21 INFO 139764860892992] data type: &lt;type 'numpy.float32'&gt;
[10/02/2018 21:40:21 INFO 139764860892992] epochs: 2
[10/02/2018 21:40:21 INFO 139764860892992] optimizer: sgd
[10/02/2018 21:40:21 INFO 139764860892992] momentum: 0.900000
[10/02/2018 21:40:21 INFO 139764860892992] weight_decay: 0.000100
[10/02/2018 21:40:21 INFO 139764860892992] learning_rate: 0.010000
[10/02/2018 21:40:21 INFO 139764860892992] lr_scheduler_step defined without lr_scheduler_factor, will be ignored...
[10/02/2018 21:40:21 INFO 139764860892992] mini_batch_size: 512
[10/02/2018 21:40:21 INFO 139764860892992] image_shape: 3,224,224
[10/02/2018 21:40:21 INFO 139764860892992] num_classes: 257
[10/02/2018 21:40:21 INFO 139764860892992] num_training_samples: 15420
[10/02/2018 21:40:21 INFO 139764860892992] augmentation_type: None
[10/02/2018 21:40:21 INFO 139764860892992] kv_store: device
[10/02/2018 21:40:21 INFO 139764860892992] checkpoint_frequency: 2
[10/02/2018 21:40:21 INFO 139764860892992] multi_label: 0
[10/02/2018 21:40:21 INFO 139764860892992] --------------------
[21:40:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
[21:40:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
[10/02/2018 21:40:21 INFO 139764860892992] Setting number of threads: 63
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:634: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: .vvvv...
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: v.vv.v..
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: vv.v..v.
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: vvv....v
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: v....vvv
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: .v..v.vv
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: ..v.vv.v
[21:41:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/kvstore/././comm.h:643: ...vvvv.
[21:41:03] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.2.x.288.0/RHEL5_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[10/02/2018 21:41:18 INFO 139764860892992] Epoch[0] Batch [20]#011Speed: 903.34 samples/sec#011accuracy=0.020554
[10/02/2018 21:41:23 INFO 139764860892992] Epoch[0] Train-accuracy=0.055990
[10/02/2018 21:41:23 INFO 139764860892992] Epoch[0] Time cost=21.168
[10/02/2018 21:41:30 INFO 139764860892992] Epoch[0] Validation-accuracy=0.257747
[10/02/2018 21:41:42 INFO 139764860892992] Epoch[1] Batch [20]#011Speed: 895.73 samples/sec#011accuracy=0.393694
[10/02/2018 21:41:47 INFO 139764860892992] Epoch[1] Train-accuracy=0.439128
[10/02/2018 21:41:47 INFO 139764860892992] Epoch[1] Time cost=17.307
[10/02/2018 21:41:48 INFO 139764860892992] Saved checkpoint to ""/opt/ml/model/image-classification-0002.params""
[10/02/2018 21:41:53 INFO 139764860892992] Epoch[1] Validation-accuracy=0.561719
</code></pre>
","<mxnet><amazon-sagemaker>","2018-10-02 23:52:37","","0","909920","2018-10-09 18:52:20","1","0","","","909920","378","102","2"
"41438218","<p>I did a little modification to the fit.py mxnet python example file (image-classification) by adding the rmse loss:</p>

<pre><code># evaluation metrices
eval_metrics = ['accuracy']
eval_metrics.append('rmse') 
</code></pre>

<p>Then running the MNIST training example, one can observe that the rmse is about 5.2 all the way, while the accuracy goes up to around 99%.</p>

<p>Should we not observe a decreasing RMSE ?</p>

<p>Many thanks
AL</p>
","<deep-learning><mxnet>","2017-01-03 07:11:33","","1","7350566","2017-02-03 20:09:57","1","0","","","7350566","24","2","0"
"47661254","<p>I'm using AWS p2.x8large and trying to evaluate my model using k-fold cross validation. 
After the first repetition my GPUs memory is full and when I try to train once again I receive a cuda memory problem.</p>

<p>My question is how to reset the GPU memory within the loop? I used K.clear_session() and also gc.collect() but none of them worked.</p>

<p>the error message:</p>

<pre><code>&gt; MXNetError                                Traceback (most recent call
&gt; last) ~/anaconda3/lib/python3.6/site-packages/mxnet/symbol.py in
&gt; simple_bind(self, ctx, grad_req, type_dict, group2ctx,
&gt; shared_arg_names, shared_exec, shared_buffer, **kwargs)    1472       
&gt; shared_exec_handle,
&gt; -&gt; 1473                                                  ctypes.byref(exe_handle)))    1474         except MXNetError as e:
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/base.py in
&gt; check_call(ret)
&gt;     128     if ret != 0:
&gt; --&gt; 129         raise MXNetError(py_str(_LIB.MXGetLastError()))
&gt;     130 
&gt; 
&gt; MXNetError: [19:24:04] src/storage/./pooled_storage_manager.h:102:
&gt; cudaMalloc failed: out of memory
&gt; 
&gt; Stack trace returned 10 entries: [bt] (0)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d57cc)
&gt; [0x7f55ce9fe7cc] [bt] (1)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1242238)
&gt; [0x7f55cfa6b238] [bt] (2)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1244c0a)
&gt; [0x7f55cfa6dc0a] [bt] (3)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe4d4db)
&gt; [0x7f55cf6764db] [bt] (4)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe549cd)
&gt; [0x7f55cf67d9cd] [bt] (5)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe59f95)
&gt; [0x7f55cf682f95] [bt] (6)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe5d6ee)
&gt; [0x7f55cf6866ee] [bt] (7)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe5dcd4)
&gt; [0x7f55cf686cd4] [bt] (8)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2261)
&gt; [0x7f55cf605291] [bt] (9)
&gt; /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c)
&gt; [0x7f560d6c4ec0]
&gt; 
&gt; 
&gt; During handling of the above exception, another exception occurred:
&gt; 
&gt; RuntimeError                              Traceback (most recent call
&gt; last) &lt;ipython-input-4-0720b69f15af&gt; in &lt;module&gt;()
&gt;      33 if val_batches.n&gt;0:
&gt;      34     hist = model.fit_generator(generator=train_gen, samples_per_epoch=batches.n,
&gt; ---&gt; 35         nb_epoch=epochs, verbose=True, validation_data=val_gen, nb_val_samples=val_batches.n,
&gt; callbacks=callbacks)
&gt;      36 else:
&gt;      37     model.fit_generator(generator=train_gen, samples_per_epoch=batches.n,
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/Keras-1.2.2-py3.6.egg/keras/engine/training.py
&gt; in fit_generator(self, generator, samples_per_epoch, nb_epoch,
&gt; verbose, callbacks, validation_data, nb_val_samples, class_weight,
&gt; max_q_size, nb_worker, pickle_safe, initial_epoch)    1557            
&gt; outs = self.train_on_batch(x, y,    1558                              
&gt; sample_weight=sample_weight,
&gt; -&gt; 1559                                                class_weight=class_weight)    1560     1561                     if not
&gt; isinstance(outs, list):
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/Keras-1.2.2-py3.6.egg/keras/engine/training.py
&gt; in train_on_batch(self, x, y, sample_weight, class_weight)    1320    
&gt; ins = x + y + sample_weights    1321        
&gt; self._make_train_function()
&gt; -&gt; 1322         outputs = self.train_function(ins)    1323         if len(outputs) == 1:    1324             return outputs[0]
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/Keras-1.2.2-py3.6.egg/keras/engine/training.py
&gt; in train_function(inputs)    1952         def
&gt; _make_train_function(self):    1953             def train_function(inputs):
&gt; -&gt; 1954                 data, label, _, data_shapes, label_shapes = self._adjust_module(inputs, 'train')    1955     1956                
&gt; batch = K.mx.io.DataBatch(data=data, label=label, bucket_key='train',
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/Keras-1.2.2-py3.6.egg/keras/engine/training.py
&gt; in _adjust_module(self, inputs, phase)    1908             if not
&gt; self._mod.binded:    1909                
&gt; self._mod.bind(data_shapes=data_shapes, label_shapes=None,
&gt; -&gt; 1910                                for_training=True)    1911                 self._set_weights()    1912                
&gt; self._mod.init_optimizer(kvstore=self._kvstore,
&gt; optimizer=self.optimizer)
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py
&gt; in bind(self, data_shapes, label_shapes, for_training,
&gt; inputs_need_grad, force_rebind, shared_module, grad_req)
&gt;     322                         state_names=self._state_names)
&gt;     323         module.bind(data_shapes, label_shapes, for_training, inputs_need_grad,
&gt; --&gt; 324                     force_rebind=False, shared_module=None, grad_req=grad_req)
&gt;     325         self._curr_module = module
&gt;     326         self._curr_bucket_key = self._default_bucket_key
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/module/module.py in
&gt; bind(self, data_shapes, label_shapes, for_training, inputs_need_grad,
&gt; force_rebind, shared_module, grad_req)
&gt;     415                                                      fixed_param_names=self._fixed_param_names,
&gt;     416                                                      grad_req=grad_req,
&gt; --&gt; 417                                                      state_names=self._state_names)
&gt;     418         self._total_exec_bytes = self._exec_group._total_exec_bytes
&gt;     419         if shared_module is not None:
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py
&gt; in __init__(self, symbol, contexts, workload, data_shapes,
&gt; label_shapes, param_names, for_training, inputs_need_grad,
&gt; shared_group, logger, fixed_param_names, grad_req, state_names)
&gt;     229         self.num_outputs = len(self.symbol.list_outputs())
&gt;     230 
&gt; --&gt; 231         self.bind_exec(data_shapes, label_shapes, shared_group)
&gt;     232 
&gt;     233     def decide_slices(self, data_shapes):
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py
&gt; in bind_exec(self, data_shapes, label_shapes, shared_group, reshape)
&gt;     325             else:
&gt;     326                 self.execs.append(self._bind_ith_exec(i, data_shapes_i, label_shapes_i,
&gt; --&gt; 327                                                       shared_group))
&gt;     328 
&gt;     329         self.data_shapes = data_shapes
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py
&gt; in _bind_ith_exec(self, i, data_shapes, label_shapes, shared_group)
&gt;     601                                            type_dict=input_types, shared_arg_names=self.param_names,
&gt;     602                                            shared_exec=shared_exec,
&gt; --&gt; 603                                            shared_buffer=shared_data_arrays, **input_shapes)
&gt;     604         self._total_exec_bytes += int(executor.debug_str().split('\n')[-3].split()[1])
&gt;     605         return executor
&gt; 
&gt; ~/anaconda3/lib/python3.6/site-packages/mxnet/symbol.py in
&gt; simple_bind(self, ctx, grad_req, type_dict, group2ctx,
&gt; shared_arg_names, shared_exec, shared_buffer, **kwargs)    1477       
&gt; error_msg += ""%s: %s\n"" % (k, v)    1478             error_msg += ""%s""
&gt; % e
&gt; -&gt; 1479             raise RuntimeError(error_msg)    1480     1481         # update shared_buffer
&gt; 
&gt; RuntimeError: simple_bind error. Arguments: input_1_1: (64, 3, 224,
&gt; 224) [19:24:04] src/storage/./pooled_storage_manager.h:102: cudaMalloc
&gt; failed: out of memory
&gt; 
&gt; Stack trace returned 10 entries: [bt] (0)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d57cc)
&gt; [0x7f55ce9fe7cc] [bt] (1)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1242238)
&gt; [0x7f55cfa6b238] [bt] (2)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1244c0a)
&gt; [0x7f55cfa6dc0a] [bt] (3)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe4d4db)
&gt; [0x7f55cf6764db] [bt] (4)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe549cd)
&gt; [0x7f55cf67d9cd] [bt] (5)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe59f95)
&gt; [0x7f55cf682f95] [bt] (6)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe5d6ee)
&gt; [0x7f55cf6866ee] [bt] (7)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0xe5dcd4)
&gt; [0x7f55cf686cd4] [bt] (8)
&gt; /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2261)
&gt; [0x7f55cf605291] [bt] (9)
&gt; /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c)
&gt; [0x7f560d6c4ec0]
</code></pre>

<p><a href=""https://i.stack.imgur.com/wIwOL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wIwOL.png"" alt=""enter image description here""></a></p>
","<keras><gpu><mxnet><pyhook>","2017-12-05 19:29:56","","2","8224316","2018-05-01 20:47:13","1","2","","","8224316","123","13","0"
"42591866","<p>I am working on MXNet, a library for deep learning. My implemented structure is in both single machine and distributed CPU machines. I followed the <a href=""http://mxnet.io/how_to/multi_devices.html"" rel=""nofollow noreferrer"">tutorial</a> on the MXNet official site.
The implementation on single machine was running without any issue and I got the result. </p>

<p>Then I tried distributed training with multiple CPU machines.
I created an account on AWS, amazon virtual machine, and launched 3 of t2.micro ubuntu.
I typed the following command line:</p>

<pre><code>../../tools/launch.py -n 2 python train_mnist.py --kv-store dist_sync
</code></pre>

<p>This command line above suppose to run a distributed version training with 2 workers and 1 server. </p>

<p>Unfortunately, I got an error. I understand there is a permission denied, but I tried to access other two workers from server by the following command and it works:</p>

<pre><code>ssh -i key.pem ubuntu@ip number.
</code></pre>

<p>Here is the error</p>

<pre><code>Permission denied (publickey).
Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/Research/code/mxnet/tools/../dmlc-core/tracker/dmlc_tracker/ssh.py"", line 60, in run
    subprocess.check_call(prog, shell = True)
  File ""/usr/lib/python2.7/subprocess.py"", line 540, in check_call
    raise CalledProcessError(retcode, cmd)
CalledProcessError: Command 'ssh -o StrictHostKeyChecking=no ip -p 22 'export LD_LIBRARY_PATH=:/usr/local/cuda/lib64; export DMLC_SERVER_ID=0; export DMLC_WORKER_ID=0; export DMLC_PS_ROOT_URI=ip; export DMLC_ROLE=worker; export DMLC_PS_ROOT_PORT=9091; export DMLC_NUM_WORKER=1; export DMLC_NUM_SERVER=1; cd /home/ubuntu/Research/code/mxnet/example/image-classification/; python train_mnist.py --network lenet --kv-store dist_sync'' returned non-zero exit status 255

Permission denied (publickey).
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/Research/code/mxnet/tools/../dmlc-core/tracker/dmlc_tracker/ssh.py"", line 60, in run
    subprocess.check_call(prog, shell = True)
  File ""/usr/lib/python2.7/subprocess.py"", line 540, in check_call
    raise CalledProcessError(retcode, cmd)
CalledProcessError: Command 'ssh -o StrictHostKeyChecking=no ip -p 22 'export LD_LIBRARY_PATH=:/usr/local/cuda/lib64; export DMLC_SERVER_ID=0; export DMLC_PS_ROOT_URI=ip; export DMLC_ROLE=server; export DMLC_PS_ROOT_PORT=9091; export DMLC_NUM_WORKER=1; export DMLC_NUM_SERVER=1; cd /home/ubuntu/Research/code/mxnet/example/image-classification/; python train_mnist.py --network lenet --kv-store dist_sync'' returned non-zero exit status 255

[03:48:39] /home/ubuntu/mxnet/dmlc-core/include/dmlc/./logging.h:300: [03:48:39] src/kvstore/kvstore.cc:37: compile with USE_DIST_KVSTORE=1 to use dist_sync

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7ff5b87a156c]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet7KVStore6CreateEPKc+0x5f4) [0x7ff5b91323d4]
[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(MXKVStoreCreate+0xd) [0x7ff5b905b14d]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff5bb86dadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7ff5bb86d40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7ff5bba845fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7ff5bba85f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (8) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (9) python(PyEval_EvalFrameEx+0x7e8) [0x524338]

Traceback (most recent call last):
  File ""train_mnist.py"", line 76, in &lt;module&gt;
    fit.fit(args, sym, get_mnist_iter)
  File ""/home/ubuntu/Research/code/mxnet/example/image-classification/common/fit.py"", line 97, in fit
    kv = mx.kvstore.create(args.kv_store)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/kvstore.py"", line 403, in create
    ctypes.byref(handle)))
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/base.py"", line 77, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [03:48:39] src/kvstore/kvstore.cc:37: compile with USE_DIST_KVSTORE=1 to use dist_sync

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7ff5b87a156c]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet7KVStore6CreateEPKc+0x5f4) [0x7ff5b91323d4]
[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(MXKVStoreCreate+0xd) [0x7ff5b905b14d]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff5bb86dadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7ff5bb86d40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7ff5bba845fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7ff5bba85f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (8) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (9) python(PyEval_EvalFrameEx+0x7e8) [0x524338]

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/Research/code/mxnet/tools/../dmlc-core/tracker/dmlc_tracker/tracker.py"", line 363, in &lt;lambda&gt;
    target=(lambda: subprocess.check_call(self.cmd, env=env, shell=True)), args=())
  File ""/usr/lib/python2.7/subprocess.py"", line 540, in check_call
    raise CalledProcessError(retcode, cmd)
CalledProcessError: Command 'python train_mnist.py --network lenet --kv-store dist_sync' returned non-zero exit status 1
</code></pre>
","<python><mxnet>","2017-03-04 03:51:08","","0","3381072","2017-03-22 14:59:47","1","0","","","3381072","27","16","0"
"42629919","<p>The installation instructions at <a href=""http://mxnet.io/get_started/ubuntu_setup.html"" rel=""nofollow noreferrer"">http://mxnet.io/get_started/ubuntu_setup.html</a> tell to run the .sh file after cd into an appropriate directory but it throws following error:</p>

<pre><code>avijit@avijit-Inspiron-3521:~/mxnet/setup-utils$ bash install-mxnet-ubuntu-r.sh
MXNet root folder: /home/avijit/mxnet/
Building MXNet core. This can take few minutes...
make: *** No targets specified and no makefile found.  Stop.
</code></pre>

<p>It seems to have some additional steps prior to it, BUT are ommitted from the installation steps in the link. What's is the issue?</p>

<p>NOTE: I'm following ""Quick Installation"" at <a href=""http://mxnet.io/get_started/ubuntu_setup.html#install-mxnet-for-r"" rel=""nofollow noreferrer"">http://mxnet.io/get_started/ubuntu_setup.html#install-mxnet-for-r</a> and NOT building it from source.</p>
","<r><bash><ubuntu><mxnet>","2017-03-06 15:50:59","","0","6723438","2017-03-06 18:01:58","1","0","","","6723438","18","0","0"
"42641657","<p>I am using MXNet on IRIS dataset which has 4 features and it classifies the flowers as -'setosa', 'versicolor', 'virginica'. My training data has 89 rows. My label data is a row vector of 89 columns. I encoded the flower names into number -0,1,2 as it seems mx.io.NDArrayIter does not accept numpy ndarray with string values. Then I tried to predict using</p>

<p><code>re = mod.predict(test_iter)</code>    </p>

<p>I get a result which has the shape 14 * 10.
Why am I getting 10 columns when I have only 3 labels and how do I map these results to my labels. The result of predict is shown below:</p>

<blockquote>
  <p>[[ 0.11760861 0.12082944 0.1207106 0.09154381 0.09155304 0.09155869
  0.09154817 0.09155204 0.09154914 0.09154641] [ 0.1176083 0.12082954 0.12071151 0.09154379 0.09155323 0.09155825
  0.0915481 0.09155164 0.09154923 0.09154641] [ 0.11760829 0.1208293 0.12071083 0.09154385 0.09155313 0.09155875
  0.09154838 0.09155186 0.09154932 0.09154625] [ 0.11760861 0.12082901 0.12071037 0.09154388 0.09155303 0.09155875
  0.09154829 0.09155209 0.09154959 0.09154641] [ 0.11760896 0.12082863 0.12070955 0.09154405 0.09155299 0.09155875
  0.09154839 0.09155225 0.09154996 0.09154646] [ 0.1176089 0.1208287 0.1207095 0.09154407 0.09155297 0.09155882
  0.09154844 0.09155232 0.09154989 0.0915464 ] [ 0.11760896 0.12082864 0.12070941 0.09154408 0.09155297 0.09155882
  0.09154844 0.09155234 0.09154993 0.09154642] [ 0.1176088 0.12082874 0.12070983 0.09154399 0.09155302 0.09155872
  0.09154837 0.09155215 0.09154984 0.09154641] [ 0.11760852 0.12082904 0.12071032 0.09154394 0.09155304 0.09155876
  0.09154835 0.09155209 0.09154959 0.09154631] [ 0.11760963 0.12082832 0.12070873 0.09154428 0.09155257 0.09155893
  0.09154856 0.09155177 0.09155051 0.09154671] [ 0.11760966 0.12082829 0.12070868 0.09154429 0.09155258 0.09155892
  0.09154858 0.0915518 0.09155052 0.09154672] [ 0.11760949 0.1208282 0.12070852 0.09154446 0.09155259 0.09155893
  0.09154854 0.09155205 0.0915506 0.09154666] [ 0.11760952 0.12082817 0.12070853 0.0915444 0.09155261 0.09155891
  0.09154853 0.09155206 0.09155057 0.09154668] [ 0.1176096 0.1208283 0.12070892 0.09154423 0.09155267 0.09155882
  0.09154859 0.09155172 0.09155044 0.09154676]]</p>
</blockquote>
","<python><mxnet>","2017-03-07 06:29:44","","1","7463041","2017-04-01 02:54:11","1","1","","","7463041","81","8","0"
"42506907","<p>I am trying to understand the Handwritten Digit recognition for MXNet in python <a href=""http://mxnet.io/tutorials/python/mnist.html"" rel=""nofollow noreferrer"">here</a></p>

<p>The code which creates the training data and label data is shown below:</p>

<pre><code>def read_data(label_url, image_url):
    with gzip.open(download_data(label_url)) as flbl:
        magic, num = struct.unpack(""&gt;II"", flbl.read(8))
        label = np.fromstring(flbl.read(), dtype=np.int8)
    with gzip.open(download_data(image_url), 'rb') as fimg:
        magic, num, rows, cols = struct.unpack(""&gt;IIII"", fimg.read(16))
        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)
    return (label, image)
</code></pre>

<p>Then the numbers are predicted using the code below:</p>

<pre><code>prob = model.predict(val_img[0:1].astype(np.float32)/255)[0]
assert max(prob) &gt; 0.99, ""Low prediction accuracy.""
print 'Classified as %d with probability %f' % (prob.argmax(), max(prob))
</code></pre>

<p>The output is - Classified as 7 with probability 0.999391.
My question is how MXNet was able to determine that the index returned by argmax function corresponds to label -7  </p>
","<python><mxnet>","2017-02-28 10:59:02","","1","7463041","2017-12-08 23:54:13","1","0","","","7463041","81","8","0"
"42611245","<p>I'm using Centos 6.6 on a GPU server. I installed mxnet following the instructions <a href=""http://mxnet.io/get_started/centos_setup.html"" rel=""nofollow noreferrer"">here</a>. Everything goes right until I tried to test the installation. I run the following commands:</p>

<pre><code>python
&gt;&gt; import mxnet
</code></pre>

<p>Then I got errors saying</p>

<pre><code>Check failed: e == fmap_.at(alias) (0x10fc620 vs. 0x103adf0) Entry add_n already registered under different entry
</code></pre>

<p>The full error message is as follows:</p>

<pre><code>[16:38:16] /home/mypath/software/try_mxnet/mxnet/dmlc-core/include/dmlc/./logging.h:300: [16:38:16] /home/mypath/software/try_mxnet/mxnet/dmlc-core/include/dmlc/registry.h:66: Check failed: e == fmap_.at(alias) (0x10fc620 vs. 0x103adf0) Entry add_n already registered under different entry

Stack trace returned 4 entries:
[bt] (0) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(ZN4dmlc8RegistryIN4nnvm2OpEE8AddAliasERKSsS5+0x79b) [0x7fa4c820635b]
[bt] (1) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN4nnvm2Op9add_aliasERKSs+0x1f) [0x7fa4c820493f]
[bt] (2) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(+0xb3cea9) [0x7fa4c7073ea9]
[bt] (3) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(+0x1cff226) [0x7fa4c8236226]

terminate called after throwing an instance of 'dmlc::Error'
what(): [16:38:16] /home/mypath/software/try_mxnet/mxnet/dmlc-core/include/dmlc/registry.h:66: Check failed: e == fmap_.at(alias) (0x10fc620 vs. 0x103adf0) Entry add_n already registered under different entry

Stack trace returned 4 entries:
[bt] (0) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(ZN4dmlc8RegistryIN4nnvm2OpEE8AddAliasERKSsS5+0x79b) [0x7fa4c820635b]
[bt] (1) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(_ZN4nnvm2Op9add_aliasERKSs+0x1f) [0x7fa4c820493f]
[bt] (2) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(+0xb3cea9) [0x7fa4c7073ea9]
[bt] (3) /home/mypath/anaconda2/lib/python2.7/site-packages/mxnet-0.9.4-py2.7.egg/mxnet/libmxnet.so(+0x1cff226) [0x7fa4c8236226]

Aborted
</code></pre>

<p>I have no idea what's wrong with my installation. The server has 2 x Nvidia Tesla K80 and 128 GB memory, it should be powerful enough. I hope there is someone who can give me some help. Thank you very much!!!</p>
","<python><centos><failed-installation><mxnet>","2017-03-05 17:00:10","","0","5005808","2017-03-08 14:07:20","1","2","","","5005808","776","53","2"
"42671658","<p>I'm testing the RNN model of mxnet. The tutorial <a href=""http://mxnet.io/tutorials/python/char_lstm.html"" rel=""nofollow noreferrer"">here</a> does not work and the error message said many functions had been deprecated. I did not find the up-to-date tutorial for RNN.
There are still some examples in the mxnet project. But for RNN, the <a href=""https://github.com/dmlc/mxnet/blob/master/example/rnn/lstm_bucketing.py"" rel=""nofollow noreferrer"">examples</a> only show how to train a model using training set. They don't show how to use the trained model to make further prediction. The training code is as follows:</p>

<pre><code>model.fit(
    train_data          = data_train,
    eval_data           = data_val,
    eval_metric         = mx.metric.Perplexity(invalid_label),
    kvstore             = args.kv_store,
    optimizer           = args.optimizer,
    optimizer_params    = { 'learning_rate': args.lr,
                            'momentum': args.mom,
                            'wd': args.wd },
    initializer         = mx.init.Xavier(factor_type=""in"", magnitude=2.34),
    num_epoch           = args.num_epochs,
    batch_end_callback  = mx.callback.Speedometer(args.batch_size, args.disp_batches))
</code></pre>

<p>Does someone know how to use the trained <strong>RNN model</strong> to make inference or prediction?</p>

<p>I must clearify that I'm looking for how to use <strong>RNN model</strong> to make prediction, not CNN or other models.</p>

<p>Thank you very much for helping me!!!</p>
","<python><recurrent-neural-network><mxnet>","2017-03-08 12:40:18","","2","5005808","2017-10-06 00:10:05","1","3","","","5005808","776","53","2"
"41704949","<p>I have a CSV file with 4 columns. 3 inputs and one output. Already normalized. I can use nnet and neuralnet to train a network with 3 inputs, 3 hidden layers with 3 nodes each and one output. It works.</p>

<p>I would like to do the same with MXNET but the parameter for a ""FullyConected"" has to be hidden = 1 when doing a regression. Any other value just throws an Error message.</p>

<p>How do I build a network as the one in the title or in this image?</p>

<p><a href=""https://i.stack.imgur.com/1Nl4o.png"" rel=""nofollow noreferrer"">NeuralNet Plot</a></p>

<p>This is the code:</p>

<pre><code>csvIn &lt;- read.csv(""normalized.csv"")

require(mxnet)

inputData &lt;- csvIn[,1:3]
outputData &lt;- csvIn[,4]

lcinm &lt;- data.matrix(inputData, rownames.force = ""NA"")
lcoutm &lt;- data.matrix(outputData, rownames.force = ""NA"")
lcouta &lt;- as.numeric(lcoutm)

data &lt;- mx.symbol.Variable(""data"")
fc1 &lt;- mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=3)
act1 &lt;- mx.symbol.Activation(fc1, name=""sigm1"", act_type=""sigmoid"")
fc2 &lt;- mx.symbol.FullyConnected(act1, name=""fc2"", num_hidden=3)
act2 &lt;- mx.symbol.Activation(fc2, name=""sigm2"", act_type=""sigmoid"")
fc3 &lt;- mx.symbol.FullyConnected(act2, name=""fc3"", num_hidden=3)
softmax &lt;- mx.symbol.LinearRegressionOutput(fc3, name=""softmax"")

mx.set.seed(0)
mxn &lt;- mx.model.FeedForward.create(array.layout = ""rowmajor"", softmax, X = lcinm, y = lcouta, learning.rate=0.07, eval.metric=mx.metric.rmse)
</code></pre>

<p>This is the error message:</p>

<pre><code>Start training with 1 devices
[08:54:33] C:/Users/qkou/mxnet/dmlc-core/include/dmlc/logging.h:235: [08:54:33] src/ndarray/ndarray.cc:231: Check failed: from.shape() == to-&gt;shape() operands shape mismatch
Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
  [08:54:33] src/ndarray/ndarray.cc:231: Check failed: from.shape() == to-&gt;shape() operands shape mismatch
</code></pre>

<p>Input data (3 nodes)</p>

<pre><code>&gt; lcinm
                  INA          INV        INC
     [1,] 0.327172792 0.1842063931 0.50227366
     [2,] 0.328585645 0.1911366252 0.50394467
     [3,] 0.329998499 0.1980668574 0.50557458
     [4,] 0.333367019 0.1994041603 0.50606766
     [5,] 0.338691205 0.2007416800 0.50656075
     [6,] 0.344015391 0.2020789830 0.50705383
     [7,] 0.345432095 0.2021049795 0.50698534
     [8,] 0.346848798 0.2021309760 0.50691686
     [9,] 0.348355970 0.2026784188 0.50617724
    [10,] 0.349953611 0.2032256450 0.50542391
</code></pre>

<p>Output data (1 node)</p>

<pre><code>&gt; lcouta
   [1] 0.6334235 0.6336314 0.6338394 0.6339434 0.6339434 0.6339434
   [7] 0.6306156 0.6272879 0.6241681 0.6212562 0.6183444 0.6170965
</code></pre>
","<r><neural-network><mxnet>","2017-01-17 19:01:06","","1","7432103","2017-01-24 05:51:38","2","0","","","7432103","25","0","0"
"50420311","<p>I'm trying to convert 20 images using cv2 into ndarry and then train a CNN model (mxnet) using the ndarry.  First I'm converting color images with various pixels into gray and 128 by 128 pixel images.  So at the end of the 2nd for-loop, i get a (20, 128, 128) ndarry.  I use ndarry iter function (mxnet) to iterate the ndarry for training and evaluating.  When I run the rest of the code, I get the following error messages: </p>

<pre><code>Traceback (most recent call last):
  File ""mx_n.py"", line 43, in &lt;module&gt;
    train_iter = mx.io.NDArrayIter(datan[:ntrain, :], label[:ntrain], batch_size, shuffle=True)
IndexError: too many indices for array
</code></pre>

<p>Here is the code:</p>

<pre><code>import numpy as np
import cv2
import time
import subprocess
import scipy as sp
import glob, os
import mxnet as mx
import pickle
import random
from pandas import *
from sklearn import preprocessing
from PIL import Image
from resizeimage import resizeimage

f_path = ""/Users/phillipkim/fd""

img_name = ""IMG_17""

filelist = glob.glob(f_path + ""/IMG*.jpg"")
length = len(filelist) + 1
label = []
data_label = []

for i in range(1,129):
    data_label.append('pixel' + str(i))

for i in range(1,length):
    img = cv2.imread(os.path.join(f_path,img_name) + str(10 + i) + "".jpg"")
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.resize(gray, (128,128))
    cv2.imwrite(os.path.join(f_path,img_name) + ""g"" + str(10 + i) + "".jpg"",gray)
    if(1 &lt;= i &lt;= 10):
        label.append(1)
    elif(11 &lt;= i &lt;= 20):
        label.append(2)

filelist = glob.glob(f_path + ""/*g.jpg"")
label = np.array(label)
datan = np.array([preprocessing.MinMaxScaler().fit_transform(np.array(Image.open(fname))) for fname in filelist])

batch_size = 4
ntrain = int(datan.shape[0]*0.8)
train_iter = mx.io.NDArrayIter(datan[:ntrain, :], label[:ntrain], batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(datan[ntrain:, :], label[ntrain:], batch_size)

# Set up the symbolic model
#-------------------------------------------------------------------------------

data = mx.symbol.Variable('data')
# 1st convolutional layer
conv_1 = mx.symbol.Convolution(data = data, kernel = (5, 5), num_filter = 20)
tanh_1 = mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 = mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel = (2, 2), stride = (2, 2))
# 2nd convolutional layer
conv_2 = mx.symbol.Convolution(data = pool_1, kernel = (5, 5), num_filter = 50)
tanh_2 = mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 = mx.symbol.Pooling(data=tanh_2, pool_type = ""max"", kernel = (2, 2), stride = (2, 2))
# 1st fully connected layer
flatten = mx.symbol.Flatten(data = pool_2)
fc_1 = mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 = mx.symbol.Activation(data = fc_1, act_type = ""tanh"")
# 2nd fully connected layer
fc_2 = mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
# Output. Softmax output since we'd like to get some probabilities.
NN_model = mx.symbol.SoftmaxOutput(data = fc_2)

# Pre-training set up
#-------------------------------------------------------------------------------

# Device used. CPU in my case.
devices = mx.cpu()

# Training
#-------------------------------------------------------------------------------
train_iter.reset()

# Train the model
model = mx.mod.Module(NN_model,
                        data_names = ['data'],
                        label_names = ['softmax_label'],
                        context = devices)

model.fit(train_iter, eval_data=val_iter, num_epoch = 160,
            optimizer_params={'learning_rate':0.01, 'momentum': 0.9},
            eval_metric = mx.metric.Accuracy(),
            epoch_end_callback = mx.callback.log_train_metric(100))
</code></pre>

<p>I compared my code with example code on the mxnet website but I can't seem to find what's wrong.  Can you help me?</p>
","<python><opencv3.0><mxnet><convolutional-neural-network>","2018-05-18 23:11:52","","1","8197225","2018-06-08 17:52:02","1","0","","","8197225","37","1","0"
"50332567","<p>I already added in pom.xml but when run the program it produce error "" 
couldn't load main class? 
code: <a href=""https://github.com/ali2210/Mxnet"" rel=""nofollow noreferrer"">https://github.com/ali2210/Mxnet</a>
reference:
<a href=""https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html</a></p>
","<scala><mxnet>","2018-05-14 14:17:13","","-2","4980294","2018-05-14 18:48:12","1","0","","","4980294","1","0","0"
"42696418","<p>I have been able to use nnet and neuralnet to predict values in a conventional backprop network, but have been strugling to do the same with MXNET and R for many reasons.</p>

<p>This is the file (simple CSV with headers, columns have been normalized)
<a href=""https://files.fm/u/cfhf3zka"" rel=""nofollow noreferrer"">https://files.fm/u/cfhf3zka</a></p>

<p>And this is the code I use:</p>

<pre><code>filedata &lt;- read.csv(""example.csv"")

require(mxnet)

datain &lt;- filedata[,1:3]
dataout &lt;- filedata[,4]

lcinm &lt;- data.matrix(datain, rownames.force = ""NA"")
lcoutm &lt;- data.matrix(dataout, rownames.force = ""NA"")
lcouta &lt;- as.numeric(lcoutm)

data &lt;- mx.symbol.Variable(""data"")
fc1 &lt;- mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=3)
act1 &lt;- mx.symbol.Activation(fc1, name=""sigm1"", act_type=""sigmoid"")
fc2 &lt;- mx.symbol.FullyConnected(act1, name=""fc2"", num_hidden=3)
act2 &lt;- mx.symbol.Activation(fc2, name=""sigm2"", act_type=""sigmoid"")
fc3 &lt;- mx.symbol.FullyConnected(act2, name=""fc3"", num_hidden=3)
act3 &lt;- mx.symbol.Activation(fc3, name=""sigm3"", act_type=""sigmoid"")
fc4 &lt;- mx.symbol.FullyConnected(act3, name=""fc4"", num_hidden=1)
softmax &lt;- mx.symbol.LogisticRegressionOutput(fc4, name=""softmax"")

mx.set.seed(0)
mxn &lt;- mx.model.FeedForward.create(array.layout = ""rowmajor"", softmax, X = lcinm, y = lcouta, learning.rate=0.01, eval.metric=mx.metric.rmse)

preds &lt;- predict(mxn, lcinm)

predsa &lt;-array(preds)

predsa
</code></pre>

<p>The console output is: </p>

<pre><code>Start training with 1 devices
[1] Train-rmse=0.0852988247858687
[2] Train-rmse=0.068769514264606
[3] Train-rmse=0.0687647380075881
[4] Train-rmse=0.0687647164103567
[5] Train-rmse=0.0687647161066822
[6] Train-rmse=0.0687647160828069
[7] Train-rmse=0.0687647161241598
[8] Train-rmse=0.0687647160882147
[9] Train-rmse=0.0687647160594508
[10] Train-rmse=0.068764716079949
&gt; preds &lt;- predict(mxn, lcinm)
Warning message:
In mx.model.select.layout.predict(X, model) :
  Auto detect layout of input matrix, use rowmajor..

&gt; predsa &lt;-array(preds)
&gt; predsa
   [1] 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764
  [10] 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764 0.6776764
</code></pre>

<p>So it gets an ""average"" but is not able to predict values, have tried other ways and learningrates to avoid overprediction but have never reached an even variable output.</p>
","<r><neural-network><predict><mxnet>","2017-03-09 13:16:14","","1","7432103","2017-03-10 09:57:55","1","0","1","","7432103","25","0","0"
"52787234","<p>We are mainly using C++ and want to use Mxnet. I found some discussion that C++ prediction or future extraction slower than Python version ?</p>

<p>Is there any experienced Mxnet C++ engineers to expedite this subject including the a decent way to using Python generated Mxnet model in C++?</p>

<p>prediction.cpp in Mxnet is not so user friendly.</p>
","<deep-learning><mxnet>","2018-10-12 21:30:03","","-1","9188950","2019-02-18 05:35:52","1","1","1","","9188950","137","10","0"
"41829833","<p>Under Multilayer Perceptron subsection, the documentation says that weight matrix has a dimension of m<em>k.However, I think it should be k</em>m because the output layer-Y has the dimension of n*k.</p>

<p>Is my understanding correct?</p>
","<mxnet>","2017-01-24 13:45:25","","0","7463041","2017-12-11 20:10:52","1","0","","","7463041","81","8","0"
"42548799","<p>In Deep learning the predictions are often encoded using one hot vector. I am using MXNet for creating a simple Neural Network which classifies images of animals as cats,dogs,horses etc. When I call the Predict method of MXNet it returns me a softmax output. Now, how do I determine that the index of the entry in the softmax output corresponding to maximum probability is Cats or Dogs or Horses. The softmax output only gives an array without any mapping of the results with the corresponding label.</p>
","<neural-network><mxnet>","2017-03-02 07:00:48","","0","7463041","2017-03-03 04:23:42","1","0","","","7463041","81","8","0"
"52015855","<p>I am trying to setup my machine learning environment on AWS as follows :- </p>

<pre><code>OS: windows server 2012 r2 , 64 bit
instance: p2.xlarge
GPU : Tesla K80 series
CUDA: 9.2.148
Graphis driver: 398.26 (installed by cuda toolkit)
python : 3.5 ( tested using 2.7.15 as well) ,64 bit
IDE: Pycharm Community 2018.2, 64 bit
mxnet librabry: mxnet-cu92
</code></pre>

<p>now when I run following code :</p>

<pre><code>import mxnet as mx
from mxnet import nd
mx.random.seed(1)
z = nd.ones(shape=(3,3), ctx=mx.cpu())
print(z)
</code></pre>

<p>it works fine , but when I change <strong>ctx=mx.gpu() or ctx=mx.gpu(0)</strong> , I get error python stopped working.</p>

<p>cuda setup is working fine I compiled and ran <code>deviceQuery</code> , <code>bandwidthTest</code> sample application, these are giving output as expected.</p>

<p>EDIT:: python crash details gives me following information :</p>

<pre><code>Fault Module Name:  ucrtbase.DLL
</code></pre>

<p>I tried with Cuda Graphis driver: 398.44 (recommended from cuda website for my gpu and os ) still no luck so far.</p>

<p>Any idea for resolving this issue?</p>
","<python><amazon-web-services><gpu><mxnet>","2018-08-25 09:28:12","","-1","1613219","2018-09-03 08:14:01","1","0","","","1613219","672","23","0"
"42979797","<p>I'm trying to go through the MXNET tutorial (<a href=""https://statist-bhfz.github.io/cats_dogs_finetune"" rel=""nofollow noreferrer"">https://statist-bhfz.github.io/cats_dogs_finetune</a>), but have trouble making the RecordIO "".rec"" files used to process the pictures. </p>

<p>I have tried the suggested approach:
python C:/mxnet-20170203/tools/im2rec.py --list=1 --recursive=1 --train-ratio=0.8 cats_dogs train_pad_224x224</p>

<p>python C:/mxnet-20170203/tools/im2rec.py --num-thread=4 --pass-through=1 cats_dogs_train.lst train_pad_224x224</p>

<p>python C:/mxnet-20170203/tools/im2rec.py --num-thread=4 --pass-through=1 cats_dogs_val.lst train_pad_224x224</p>

<p>But i get the error: ""AttributeError: 'module' object has no attribute 'MXIndexedRecordIO'""
when doing so.</p>

<p>Is there a way to generate the "".rec"" files in R directly? And if not, how do i get pass the error?</p>

<p>Thanks.</p>

<p>Kr,</p>

<p>Daniel</p>
","<python><r><jpeg><mxnet>","2017-03-23 15:01:23","","0","3599865","2018-03-22 04:15:20","1","1","","","3599865","25","0","0"
"51332912","<p>I would like to know how to convert between the two versions because it seems the quantization capabilities are mainly for the <code>syms, arg_params, aux_params</code> tuple style passing, which can be wrapped around modules well, but not gluon models(correct me if I'm wrong).</p>

<p>Here's a small code snippet that trains a cnn model:</p>

<pre><code>batch_size = 64
num_inputs = 784
num_outputs = 10
data_iter = mx.io.NDArrayIter(x, y, batch_size=batch_size)

num_fc = 512
net = gluon.nn.HybridSequential()
with net.name_scope():
    net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))
    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))
    net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))
    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))
    net.add(gluon.nn.Flatten())
    net.add(gluon.nn.Dense(num_fc, activation=""relu""))
    net.add(gluon.nn.Dense(num_outputs))

net.hybridize()
# Parameter initialization
net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
for i, batch in enumerate(data_iter):
    data = batch.data[0].as_in_context(ctx)
    label = batch.label[0].as_in_context(ctx)
    with autograd.record():
        output = net(data)
        loss = softmax_cross_entropy(output, label)
    loss.backward()
    trainer.step(data.shape[0])
</code></pre>

<p>If I want to quantize a gluon model, I would try to serialize gluon into disk, and then bring it back out as module. This may cause troubles:</p>

<pre><code>import os
net.export('mxnet')
mod = mx.module.Module.load('mxnet', 0) # 0 epoch
</code></pre>

<p>and as per the module API:</p>

<pre><code>mod.bind( data_shapes = data_iter.provide_data, 
          label_shapes = data_iter.provide_label)
mod.predict(x)
</code></pre>

<p>but it does not work upon predict, with the following stacktrace:</p>

<pre><code>----------------------------------------------
KeyError     Traceback (most recent call last)
&lt;ipython-input-10-f53137bb5e95&gt; in &lt;module&gt;()
      1 mod.bind( data_shapes = data_iter.provide_data, 
----&gt; 2           label_shapes = data_iter.provide_label)
      3 mod.predict(x)

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/module.py in bind(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)
    434                                                      fixed_param_names=self._fixed_param_names,
    435                                                      grad_req=grad_req, group2ctxs=self._group2ctxs,
--&gt; 436                                                      state_names=self._state_names)
    437         self._total_exec_bytes = self._exec_group._total_exec_bytes
    438         if shared_module is not None:

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/executor_group.py in __init__(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, logger, fixed_param_names, grad_req, state_names, group2ctxs)
    281 
    282         eprint(sys._getframe().f_lineno, data_shapes, label_shapes)
--&gt; 283         self.bind_exec(data_shapes, label_shapes, shared_group)
    284 
    285     def decide_slices(self, data_shapes):

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/executor_group.py in bind_exec(self, data_shapes, label_shapes, shared_group, reshape)
    388         if label_shapes is not None:
    389             self.label_names = [i.name for i in self.label_shapes]
--&gt; 390         self._collect_arrays()
    391 
    392     def reshape(self, data_shapes, label_shapes):

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/executor_group.py in _collect_arrays(self)
    324             self.label_arrays = [[(self.slices[i], e.arg_dict[name])
    325                                   for i, e in enumerate(self.execs)]
--&gt; 326                                  for name, _ in self.label_shapes]
    327         else:
    328             self.label_arrays = None

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/executor_group.py in &lt;listcomp&gt;(.0)
    324             self.label_arrays = [[(self.slices[i], e.arg_dict[name])
    325                                   for i, e in enumerate(self.execs)]
--&gt; 326                                  for name, _ in self.label_shapes]
    327         else:
    328             self.label_arrays = None

~/anaconda3/envs/idp3/lib/python3.6/site-packages/mxnet/module/executor_group.py in &lt;listcomp&gt;(.0)
    323                 eprint(323, e.arg_dict.keys())
    324             self.label_arrays = [[(self.slices[i], e.arg_dict[name])
--&gt; 325                                   for i, e in enumerate(self.execs)]
    326                                  for name, _ in self.label_shapes]
    327         else:

KeyError: 'softmax_label'
</code></pre>

<p>Which is complaining about me missing that label in my <code>e.arg_dict</code>.</p>

<p>I printed out <code>e.arg_dict</code>:</p>

<p><code>(['data', 'hybridsequential1_conv0_weight', 'hybridsequential1_conv0_bias', 'hybridsequential1_conv1_weight', 'hybridsequential1_conv1_bias', 'hybridsequential1_dense0_weight', 'hybridsequential1_dense0_bias', 'hybridsequential1_dense1_weight', 'hybridsequential1_dense1_bias'])</code></p>

<p>And indeed, <code>softmax_label</code> is not in there. Where is this label coming from and how can I convert module to gluon correctly?</p>
","<python><mxnet>","2018-07-13 21:16:59","","1","3781180","2018-07-24 20:52:31","1","0","","","3781180","1555","81","21"
"41876553","<p>I am getting <strong>""could not find function MXSymbolGetAtomicSymbolName""</strong> error in windows 10 on Julia command prompt when I enter:</p>

<p><code>julia&gt; using MXNet</code> </p>

<p>What should I do to fix this error</p>
","<julia><mxnet>","2017-01-26 15:08:55","","2","7463041","2018-03-01 03:17:13","1","2","","","7463041","81","8","0"
"42536556","<p>I am trying to play with the alexnet code in the /mxnet/example/image-classification/symbols directory using MxNet Framework. I am not an expert in AI. Can some explain explain how to run it using GPUs? I have tried the following for single GPU:</p>

<p>python alexnet.py --network resnet --num-layers 110 --batch-size 128 --gpus 0</p>

<p>It didn't do anything. I have HPC background. I want to test the scalability of this framework per node and across the nodes ( distributed ). Any help would be appreciated.</p>

<p>Thanks,</p>
","<python><mxnet>","2017-03-01 16:06:53","","1","7608304","2017-06-16 20:38:16","1","1","","","7608304","6","0","0"
"52027323","<p>I am using Pycharm, importing <code>mxnet</code> to the project</p>

<p>I think I meet a file loss error but I could not find the solution    </p>

<pre><code>Traceback (most recent call last):
  File ""C:/E/ZJL_Test_package/ZJL_Test/feature/extract_image.py"", line 1, in &lt;module&gt;
from mxnet import nd, image
  File ""C:\D\Programs\Python37\lib\site-packages\mxnet\__init__.py"", line 25, in &lt;module&gt;
from . import engine
  File ""C:\D\Programs\Python37\lib\site-packages\mxnet\engine.py"", line 23, in &lt;module&gt;
from .base import _LIB, check_call
  File ""C:\D\Programs\Python37\lib\site-packages\mxnet\base.py"", line 113, in &lt;module&gt;
    _LIB = _load_lib()
  File ""C:\D\Programs\Python37\lib\site-packages\mxnet\base.py"", line 105, in _load_lib
lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""C:\D\Programs\Python37\lib\ctypes\__init__.py"", line 356, in __init__
self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found
</code></pre>

<p>The version of Pycharm and Python are both the up to date(the latest), with 64-bit windows 10 and 64-bit Python, 64-bit PyCharm</p>

<p>This problem seems disappear after I restart the computer and open PyCharm again. I did nothing else... So if anyone could explain this, please give your answer, thanks</p>
","<python><pycharm><mxnet>","2018-08-26 14:41:26","","0","6761900","2018-10-07 10:49:10","1","0","","","6761900","160","22","0"
"48455833","<p>Model train system: AWS Ubuntu p2.xlarge, R 3.4.0, mxnet_1.0.1.
Saved via:</p>

<pre><code>mx.model.save(A3.MXmodel, ""Action/A3.MXmodel"", iteration = 3000)
</code></pre>

<p>Loading on same system works fine via:</p>

<pre><code>A3.MXmodel &lt;- mx.model.load(""A3.MXmodel"", iteration=3000)
A3.pred &lt;- predict(A3.MXmodel, as.matrix(nNewVector))
A3.pred.label = max.col(t(A3.pred))-1
</code></pre>

<p>Moving the model files to a new system (AMI clone of first instance BUT on g2.xlarge). And attempting to predict:</p>

<pre><code>A3.pred &lt;- predict(A3.MXmodel, as.matrix(nNewVector))
</code></pre>

<p>Leads to an immediate crash of rstudio, no data saved or error messages.
I can confirm mxnet is working on the new instance via the installation check:</p>

<pre><code>library(mxnet)
a &lt;- mx.nd.ones(c(2,3), ctx = mx.gpu())
b &lt;- a * 2 + 1
b
</code></pre>

<p>Do I have to specifify somewhere on the new isntance that the models are based on GPU devices?
Can a model trained on a GPU instance be run on a CPU instance with CPU mxnet build?</p>
","<r><amazon-ec2><mxnet>","2018-01-26 04:32:03","","1","8268013","2018-03-02 19:33:26","1","5","","","8268013","142","18","5"
"43046571","<p>Can we use spacy with MXnet to build a deep neural network(NLP)</p>

<p>We are building an application using mxnet. How to use spacy with Mxnet </p>
","<spacy><mxnet>","2017-03-27 12:32:24","","1","7398075","2018-01-20 00:16:10","1","2","","","7398075","16","2","0"
"51379082","<p>I'm using mxnet to do deep reinforcement learning. I have a simple generator that yields observations from a random walk through a game (from openai gym):</p>

<pre><code>import mxnet as mx
from mxnet import *
from mxnet.ndarray import *

import gym

def random_walk(env_id):
    env, done = gym.make(env_id), True
    min_rew, max_rew = env.reward_range
    while True:
        if done:
            obs = env.reset()
        action = env.action_space.sample()
        obs, rew, done, info = env.step(action)

        # some preprocessing ommited...

        yield obs, rew, action # all converted to ndarrays now
</code></pre>

<p>I want to be able to save this data to a big file containing rows of <code>(observation, reward, action)</code>, so I can later easily load, shuffle, and batch them with <code>mxnet</code>.</p>

<p>Is it possible to do using <code>mxnet</code> if so, how?</p>
","<dataframe><iterator><batch-processing><reinforcement-learning><mxnet>","2018-07-17 10:26:44","","0","9020093","2018-07-17 17:28:41","1","0","","","9020093","25","1","0"
"42636025","<p>Can anyone tell me if it is possible to use mxnet with matlab on windows? Using the windows packaged releases from <a href=""https://github.com/dmlc/mxnet/releases"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/releases</a>, there is no ""matlab"" directory, which I can see is present in the newer versions, which do not have windows packages. </p>

<p>is there a way to get the best of both worlds?</p>
","<matlab><mxnet>","2017-03-06 21:37:16","","0","1196979","2017-03-14 10:45:04","2","0","","","1196979","317","52","0"
"43009881","<p>How do i find the actual numerical values held in an MXNet symbol.</p>

<p>Suppose I have,</p>

<pre><code>x = mx.sym.Variable('x')
y = mx.sym.Variable('y')
z = x + y, 
</code></pre>

<p>if x = [100,200] and y=[300,400],
I want to print:</p>

<p><code>z = [400,600]</code>, </p>

<p>sort of like tensorflow's eval() method</p>
","<python><machine-learning><deep-learning><mxnet>","2017-03-24 22:03:36","","5","2857133","2017-03-24 22:11:56","1","0","1","","2857133","1246","32","2"
"43010286","<p>I have 2 symbols in MXNet and would like to concatenate them. How can i do this:</p>

<p>eg: <code>a = [100,200]</code>, <code>b = [300,400]</code>, Id like to get</p>

<p><code>c = [100,200,300,400]</code></p>
","<python><machine-learning><nlp><deep-learning><mxnet>","2017-03-24 22:42:00","","5","2857133","2017-03-24 22:44:30","1","0","1","","2857133","1246","32","2"
"51814476","<p>i used command ""pip install mxnet-mkl"" ,when i import mxnet get Floating point exception (core dumped) </p>

<pre><code>        import mxnet
        Floating point exception (core dumped)
</code></pre>

<p>more detail <a href=""https://github.com/apache/incubator-mxnet/issues/12105"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/issues/12105</a></p>

<p>anybody can help me?</p>
","<intel-mkl><mxnet>","2018-08-13 02:27:25","","0","10197053","2018-09-12 06:35:54","1","0","","","10197053","6","0","0"
"52889727","<p>The repository is <a href=""https://github.com/qubvel/segmentation_models"" rel=""nofollow noreferrer"">https://github.com/qubvel/segmentation_models</a>. I am doing the semantic segmentation task. Could anybody please share me a demo?</p>
","<artificial-intelligence><image-segmentation><mxnet>","2018-10-19 09:38:52","","-1","10521733","2018-10-31 21:08:23","1","1","","","10521733","1","0","0"
"51338162","<p>I am studying MXNet framework and I need to input a matrix into the network during every iteration. The matrix is stored in external memory, it is not the training data and it is updated by the output of the network at the end of each iteration. During the iteration, the matrix must be input into the network. </p>

<p>If I use high level APIs, i.e.</p>

<p><code>model = mx.mod.Module(context=ctx, symbol=sym)
... ...
model.fit(train_data_iter, begin_epoch=begin_epoch, 
          end_epoch=end_epoch, ......)</code></p>

<p>Can this be implemented?</p>
","<deep-learning><mxnet>","2018-07-14 11:43:48","","0","9119995","2018-07-16 18:49:31","1","0","","","9119995","7","0","0"
"51718438","<p>Is it possible to reuse GPU's memory when training a network?
I am following the official instructions to build an SSD (<a href=""https://gluon-cv.mxnet.io/build/examples_detection/train_ssd_voc.html#sphx-glr-build-examples-detection-train-ssd-voc-py"" rel=""nofollow noreferrer"">https://gluon-cv.mxnet.io/build/examples_detection/train_ssd_voc.html#sphx-glr-build-examples-detection-train-ssd-voc-py</a>)
When I try to train on GPU. I find that the batch size is limit by the video memory. There are guidelines about how to use many GPUs (<a href=""http://zh.gluon.ai.s3-website-us-west-2.amazonaws.com/chapter_computational-performance/multiple-gpus.html"" rel=""nofollow noreferrer"">http://zh.gluon.ai.s3-website-us-west-2.amazonaws.com/chapter_computational-performance/multiple-gpus.html</a>). Obviously, if I have enough money, I certainly have many GPUs. But, if I have a cheap GPU with a little memory, I will never use big batch sizes. The problem associated with the small batch is that the training process may never converge.  Note that the parameters in a neural network are not using at the same time. We can move the in-use parameters to GPU and move others out. This idea is common because we reuse memory when we play games. No game will put all the figures into the GPU at the same time. I suppose that this strategy will slow down the GPU, but it should be faster than using CPU alone. Furthermore, the big batch size can be used. </p>
","<machine-learning><mxnet>","2018-08-07 03:32:34","","-1","9033700","2018-08-07 06:08:06","1","0","","","9033700","156","2","0"
"52124584","<p>In this example, I have a list of 1-d ndarray, with length 9, the list has 9 elements, and each one has <code>shape=(2048,)</code>, so totally <code>9 * (2048,)</code>, I get these <code>ndarray</code> from <code>mxnet</code> so that each of the <code>ndarray</code> is <code>&lt;NDArray 2048 @cpu(0)&gt;</code> the array <code>dtype=numpy.float32</code></p>

<p>If I use <code>np.asarray</code> to transform this list, it becomes the following result</p>

<p><code>shape=&lt;class 'tuple'&gt;: (9, 2048, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</code></p>

<p>Obviously, I want a 2-D array, with <code>shape=(9, 2048)</code>, how to solve this problem?</p>

<p>ps: I discover this problem by saving a <code>npy</code> file and load it. I directly saved the list before converting it to a <code>ndarray</code> (so the <code>np.save</code> would transform the list to the <code>ndarrary</code> automatically) and after I loaded it, I found the shape has become something above, which is really abnormal</p>

<p><strong>The answer below, <code>np.vstack</code> and <code>np.array</code> both works for the common <code>list</code> to <code>ndarray</code> problem but could not solve mine, so I doubt it is some special case of <code>mxnet</code></strong></p>
","<python><numpy><mxnet><numpy-ndarray>","2018-09-01 03:19:01","","2","6761900","2018-09-01 07:25:06","2","8","","","6761900","160","22","0"
"48753849","<p>I am new to mxnet. I just installed mxnet 1.0.0 and python 3.5 on a Ubuntu 14.04 machine with CUDA 8.0 and cudnn 7.0.5.</p>

<p>My code is given below. I am trying to store image data in an ndarray. (see <a href=""https://github.com/ypwhs/DogBreed_gluon/blob/master/get_features_v3.ipynb"" rel=""nofollow noreferrer"">https://github.com/ypwhs/DogBreed_gluon/blob/master/get_features_v3.ipynb</a> for the original code)
 -</p>

<pre><code>X_224 = nd.zeros((n, 3, 224, 224))
X_299 = nd.zeros((n, 3, 299, 299))

mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])

for i, (fname, breed) in tqdm(df.iterrows(), total=n):
    img = cv2.imread('data/train/%s.jpg' % fname)
    img_224 = ((cv2.resize(img, (224, 224))[:, :, ::-1] / 255.0 - mean) / std).transpose((2, 0, 1))
    img_299 = ((cv2.resize(img, (299, 299))[:, :, ::-1] / 255.0 - mean) / std).transpose((2, 0, 1))

    X_224[i] = nd.array(img_224) &lt;-- I get error in this line
    X_299[i] = nd.array(img_299)
</code></pre>

<p>Here is the error I get:</p>

<blockquote>
  <p>ValueError: Indexing NDArray with index=0 and type=class 'numpy.int64' is not supported.</p>
</blockquote>

<p>I am assuming it has to with indexing a multi dimensional nd array. So I tried slicing <code>- X_224[i:i+1] = ....</code> but that gave me another error.</p>
","<python><mxnet>","2018-02-12 19:14:25","","1","8854868","2018-02-23 21:15:23","1","0","","","8854868","33","2","0"
"51002079","<p>the version of mxnet is 0.9, I use the Deconvolution operator base on resnet-50 for instance segmentation, but after dealing with several batch， the program breaks down, the error message is  </p>

<pre><code>[17:36:55] /home/gnss/mxnet/dmlc-core/include/dmlc/./logging.h:300: [17:36:55] src/operator/./cudnn_deconvolution-inl.h:205: Check failed: req[deconv::kBias] != kWriteInplace (2 vs. 2)
</code></pre>
","<mxnet><deconvolution>","2018-06-23 14:21:55","","0","8411445","2018-06-25 21:01:40","1","0","1","","8411445","1","0","0"
"51732726","<p>Naive model-partitioning across several GPUs results in the workload moving from GPU to GPU during the forward and backward pass. At any instant, one GPU is busy. Here's the naive version. </p>

<pre><code>with tf.device('/gpu:0'):
    model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

with tf.device('/gpu:1'):
    model.add(Conv2D(128, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

with tf.device('/gpu:2'):
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(1500, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
</code></pre>

<p>We need sample code (template) that pipelines the work and keeps all GPUs busy by sending waves of batches and coordinates the work on each GPU (forward, gradient calc, parameter updates).</p>

<p>A hint is provided <a href=""https://www.tensorflow.org/performance/performance_models#software_pipelining"" rel=""nofollow noreferrer"">here</a> via the use of a <code>data_flow_ops.StagingArea</code> but a concrete example would be helpful. </p>

<p>I understand that data-partitioning (or data-parallel) is the way to go, but there exist use-cases where the model needs to be partitioned across CPU+GPUs. </p>

<p>Grateful for any pointer or sample (pseudo)code.</p>
","<tensorflow><machine-learning><pytorch><mxnet><caffe2>","2018-08-07 17:53:27","","0","1363774","2018-08-07 19:42:02","1","0","","","1363774","495","136","4"
"51727604","<p>What is the recommended operation to protect some weights from being changed by the trainer in MxNet?</p>

<p>As far as I know, if I want to protect some weights in TenserFlow, I should prevent them from being passed to the optimizer. So, I do the same in MxNet with following codes.</p>

<pre><code>all_params = net.collect_params()

 while True:

    firstKey = next(iter(all_params._params))

    if 'resnet' not in firstKey:

        break

    all_params._params.popitem(last = False)
trainer = mx.gluon.Trainer(all_params,'sgd')
</code></pre>

<p>The variable <code>all_params._params</code> belongs to a rare type called <code>OrderedDict</code>. I think it means that the order in this dictionary is very important. I should not change the order. As shown above, I can only remove some parameters from the beginning of the network. It is very inconvenient. The ”params” gets a ”underline _” at the beginning, which means it should not be charged by the general user. </p>

<p>I do not receive any errors, but I wonder this is not the recommended operation. </p>
","<python><machine-learning><mxnet>","2018-08-07 13:08:13","","0","9033700","2018-08-07 17:57:29","1","0","","","9033700","156","2","0"
"51734736","<p>I am trying to train a 3D convolutional neural network using 3D spatial data. The network trains ok but when I check its accuracy I get the following error: ValueError: Shape of labels 64 does not match shape of predictions 1. I do not know why the shape of my labels is 64 (my batch_size) and not just a single classification. I have attached my code (which is just slightly modified from the mxnet 2d convnet tutorial). How can I fix my network's output? </p>

<pre><code>train_data = mx.gluon.data.DataLoader(train_dataset, batch_size= 64,shuffle= True, num_workers = cpucount)
test_data = mx.gluon.data.DataLoader(test_dataset,batch_size= 64,shuffle= True, num_workers = cpucount)

batch_size = 64
num_inputs = 2541
num_outputs = 2
num_fc = 512
net = gluon.nn.Sequential()
with net.name_scope():
    net.add(gluon.nn.Conv3D(channels=1, kernel_size=3,   activation='relu'))
    net.add(gluon.nn.MaxPool3D(pool_size=2, strides=2))
    net.add(gluon.nn.Conv3D(channels=1, kernel_size=3, activation='relu'))
    net.add(gluon.nn.MaxPool3D(pool_size=2, strides=2))

    net.add(gluon.nn.Flatten())

    net.add(gluon.nn.Dense(num_fc, activation=""relu""))
    net.add(gluon.nn.Dense(num_outputs))

net.collect_params().initialize(mx.init.Xavier(magnitude=2.24),   ctx=ctx)
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})

def evaluate_accuracy(data_iterator, net):
acc = mx.metric.Accuracy()
for i, (data, label) in enumerate(data_iterator):
    data = data.as_in_context(ctx)
    label = label.as_in_context(ctx)
    output = net(data)
    predictions = nd.argmax(output)
    acc.update(preds=predictions, labels=label)
return acc.get()[1]

epochs = 1
smoothing_constant = .01

for e in range(epochs):
for i, (data, label) in enumerate(train_data):
    data = data.as_in_context(ctx)
    label = label.as_in_context(ctx)
    with autograd.record():
        output = net(data)
        loss = softmax_cross_entropy(output, label)
    loss.backward()
    trainer.step(data.shape[0])

    ##########################
    #  Keep a moving average of the losses
    ##########################
    curr_loss = nd.mean(loss).asscalar()
    moving_loss = (curr_loss if ((i == 0) and (e == 0))
                   else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)

test_accuracy = evaluate_accuracy(test_data, net)
train_accuracy = evaluate_accuracy(train_data, net)
print(""Epoch %s. Loss: %s, Train_acc %s, Test_acc %s"" % (e, moving_loss, train_accuracy, test_accuracy))
</code></pre>
","<python><conv-neural-network><mxnet>","2018-08-07 20:15:30","","0","10171841","2018-09-10 18:39:17","1","0","","","10171841","6","0","0"
"42785437","<p>I'm trying to build a neural network that can answer to the xor problem. My code is the following:</p>

<pre><code>using MXNet
using Distributions
using PyPlot

xor_data = zeros(4,2)
xor_data[1:0] = 1
xor_data[1:1] = 1
xor_data[2:0] = 1
xor_data[2:1] = 0
xor_data[3:0] = 0
xor_data[3:1] = 1
xor_data[4:0] = 0
xor_data[4:1] = 0

xor_labels = zeros(4)
xor_labels[1] = 0
xor_labels[2] = 1
xor_labels[3] = 1
xor_labels[4] = 0

batchsize = 4
trainprovider = mx.ArrayDataProvider(:data =&gt; xor_data, batch_size=batchsize, shuffle=true, :label =&gt; xor_labels)
evalprovider = mx.ArrayDataProvider(:data =&gt; xor_data, batch_size=batchsize, shuffle=true, :label =&gt; xor_labels)

data = mx.Variable(:data)
label = mx.Variable(:label)
net = @mx.chain     mx.Variable(:data) =&gt;
                    mx.FullyConnected(num_hidden=2) =&gt;
                    mx.Activation(act_type=:relu) =&gt;
                    mx.FullyConnected(num_hidden=2) =&gt;
                    mx.Activation(act_type=:relu) =&gt;
                    mx.FullyConnected(num_hidden=1) =&gt;
                    mx.Activation(act_type=:relu) =&gt;

model = mx.FeedForward(net, context=mx.cpu())
optimizer = mx.SGD(lr=0.01, momentum=0.9, weight_decay=0.00001)
initializer = mx.NormalInitializer(0.0,0.1)
eval_metric = mx.MSE()

mx.fit(model, optimizer, initializer, eval_metric, trainprovider, eval_data = evalprovider, n_epoch = 100)
mx.fit(model, optimizer, eval_metric, trainprovider, eval_data = evalprovider, n_epoch = 100)
</code></pre>

<p>But I'm getting the following error:</p>

<blockquote>
  <p>LoadError: AssertionError: Number of samples in  label is mismatch
  with data
  in expression starting on line 22  in #ArrayDataProvider#6428(::Int64,
  ::Bool, ::Int64, ::Int64, ::Type{T}, ::Pair{Symbol,Array{Float64,2}},
  ::Pair{Symbol,Array{Float64,1}}) at io.jl:324  in
  (::Core.#kw#Type)(::Array{Any,1}, ::Type{MXNet.mx.ArrayDataProvider},
  ::Pair{Symbol,Array{Float64,2}}, ::Pair{Symbol,Array{Float64,1}}) at
  :0  in include_string(::String, ::String) at loading.jl:441 
  in include_string(::String, ::String) at sys.dylib:?  in
  include_string(::Module, ::String, ::String) at eval.jl:32  in
  (::Atom.##59#62{String,String})() at eval.jl:81  in
  withpath(::Atom.##59#62{String,String}, ::String) at utils.jl:30  in
  withpath(::Function, ::String) at eval.jl:46  in macro expansion at
  eval.jl:79 [inlined]  in (::Atom.##58#61{Dict{String,Any}})() at
  task.jl:60</p>
</blockquote>

<p>I want to feed to the network to values (0 or 1) and get a single value. Were is my error?</p>
","<neural-network><julia><mxnet>","2017-03-14 11:59:40","","0","7006585","2017-03-14 13:27:06","1","0","","","7006585","40","11","0"
"51996906","<p>It is weird that no such questions yet on stackoverflow.</p>

<p>I am using MXNet, trying to run the VQA example on my PC, using <code>mx.io.DataIter</code> to read the data, but</p>

<pre><code>mxnet.base.MXNetError: [11:05:07] c:\projects\mxnet-distro-win\mxnet-build\src\storage\./cpu_device_storage.h:70: Failed to allocate CPU Memory
</code></pre>

<p>on these two code</p>

<pre><code>File ""E:\PyProjects\TestVqa\VQAtrainIter.py"", line 71, in reset
self.nd_img.append(mx.ndarray.array(self.img, dtype=self.dtype))
File ""E:\PyProjects\Pro\venv\lib\site-packages\mxnet\ndarray\utils.py"", line 146, in array
return _array(source_array, ctx=ctx, dtype=dtype)
</code></pre>

<p>The above is my code and the below is the library code</p>

<p>So what is exactly the  ""Failed to allocated to CPU memory"" mean?</p>

<p>The part of code of <code>VQAtrainIter.py</code> is as below</p>

<pre><code>def reset(self):
    self.curr_idx = 0
    self.nd_text = []
    self.nd_img = []
    self.ndlabel = []
    for buck in self.data:
        label = self.answer # self.answer, self.img are get from npy file
        self.nd_text.append(mx.ndarray.array(buck, dtype=self.dtype))
        self.nd_img.append(mx.ndarray.array(self.img, dtype=self.dtype))
        self.ndlabel.append(mx.ndarray.array(label, dtype=self.dtype))
</code></pre>
","<python><memory><mxnet>","2018-08-24 03:09:56","","0","6761900","2018-09-18 02:48:28","1","5","","","6761900","160","22","0"
"52008294","<p>I have trained a 3D convnet using mxnet. I saved the network architecture and parameters with an intention of testing more data with it to check its performance. Since I am not training, I do not want to obtain batches of the dataset. How do I get the network to read in the entire dataset as input? Just passing the network the dataset object directly is only a 4D tensor whereas the network wants 5D. Right now I am using the dataloader but setting batch size as the entire dataset, and I feel like there is a more efficient way to do this. </p>
","<python><machine-learning><mxnet>","2018-08-24 16:16:26","","-2","10171841","2018-08-27 22:25:26","1","0","","","10171841","6","0","0"
"42431107","<p>I have a Convolution layer in my R code, created as:<br>
<code>conv1 &lt;- mx.symbol.Convolution(data=data, kernel=c(10,1), num_filter=10)</code></p>

<p>Once the net is fully trained, how can I extract the 10 filters?</p>
","<r><mxnet>","2017-02-24 05:02:32","","1","7614942","2017-11-28 00:49:29","1","0","","","7614942","6","0","0"
"44514852","<p>I have saved the model using</p>

<pre><code>mx.model.save(model = fit_dl, prefix = ""model"", iteration = 10)
</code></pre>

<p>and loaded later </p>

<pre><code>fit &lt;- mx.model.load(prefix = ""model"", iteration = 10)
</code></pre>

<p>Now, using object fit, I want to extract the input features (column names of train data). How to do that</p>
","<deep-learning><mxnet>","2017-06-13 07:23:15","","0","4836299","2017-06-15 03:35:28","1","0","","","4836299","92","0","0"
"52163294","<p>I am using mxnet to train a VQA model, the input is <code>(6244,)</code> vector and the output is a single label</p>

<p>During my epoch, the loss never change but the accuracy is oscillating in a small range, the first 5 epochs are</p>

<pre><code>Epoch 1. Loss: 2.7262569132562255, Train_acc 0.06867348986554285
Epoch 2. Loss: 2.7262569132562255, Train_acc 0.06955649207304837
Epoch 3. Loss: 2.7262569132562255, Train_acc 0.06853301224162152
Epoch 4. Loss: 2.7262569132562255, Train_acc 0.06799116997792494
Epoch 5. Loss: 2.7262569132562255, Train_acc 0.06887417218543046
</code></pre>

<p>This is a multi-class classification problem, with each answer label stands for a class, so I use softmax as final layer and cross-entropy to evaluate the loss, the code of them are as follows</p>

<p>So why the loss never change?... I just directly get if from <code>cross_entropy</code></p>

<pre><code>trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})
loss = gluon.loss.SoftmaxCrossEntropyLoss()

epochs = 10
moving_loss = 0.
best_eva = 0
for e in range(epochs):
    for i, batch in enumerate(data_train):
        data1 = batch.data[0].as_in_context(ctx)
        data2 = batch.data[1].as_in_context(ctx)
        data = [data1, data2]
        label = batch.label[0].as_in_context(ctx)
        with autograd.record():
            output = net(data)
            cross_entropy = loss(output, label)
            cross_entropy.backward()
        trainer.step(data[0].shape[0])

        moving_loss = np.mean(cross_entropy.asnumpy()[0])

    train_accuracy = evaluate_accuracy(data_train, net)
    print(""Epoch %s. Loss: %s, Train_acc %s"" % (e, moving_loss, train_accuracy))
</code></pre>

<p>The eval function is as follows</p>

<pre><code>def evaluate_accuracy(data_iterator, net, ctx=mx.cpu()):
numerator = 0.
denominator = 0.
metric = mx.metric.Accuracy()
data_iterator.reset()
for i, batch in enumerate(data_iterator):
    with autograd.record():
        data1 = batch.data[0].as_in_context(ctx)
        data2 = batch.data[1].as_in_context(ctx)
        data = [data1, data2]
        label = batch.label[0].as_in_context(ctx)
        output = net(data)

    metric.update([label], [output])
return metric.get()[1]
</code></pre>
","<python><machine-learning><computer-vision><mxnet>","2018-09-04 09:38:58","","0","6761900","2018-09-04 17:33:55","1","0","","","6761900","160","22","0"
"43039294","<p>I have my own dataset. I want to do a classification task. But I built same symbol network in Mxnet and Keras. Even the optimizer rules are same. But the results are different.</p>

<p>my Mxnet code is here: 
<a href=""https://i.stack.imgur.com/7s8vT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7s8vT.png"" alt=""enter image description here""></a></p>

<p>and results: it looks like ramdon?
<a href=""https://i.stack.imgur.com/Bmlpj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Bmlpj.png"" alt=""enter image description here""></a></p>

<p>But my keras code are same network:
<a href=""https://i.stack.imgur.com/Vv7UP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Vv7UP.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/EtQpO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EtQpO.png"" alt=""enter image description here""></a></p>

<p>but the result is much better. In training set, i can be 100%
<a href=""https://i.stack.imgur.com/LEJIN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LEJIN.png"" alt=""enter image description here""></a></p>

<p>I still cannot figure out why there are same network architectures and data are same. However, the classification result between two frames is large.</p>

<p>Hope someone could give some suggestion. Thx.</p>
","<keras><convolution><mxnet>","2017-03-27 06:28:50","","1","6294455","2018-02-28 22:49:06","1","3","","","6294455","43","1","0"
"51049937","<p>I am trying to implement a custom loss function in Mxnet, using its C++ API. The question of loss function has already been risen in python (<a href=""https://stackoverflow.com/questions/49430560/how-to-use-customized-loss-function-with-mxnet"">how to use customized loss function with mxnet?</a>) even though it doesn't address the specific question of the output.</p>

<p>Let say I want to create my own softmax function, I could do the following:</p>

<pre><code>         Symbol expFc2 = exp(fc2);
         Symbol sumExp = sum(""sumExp"", expFc2, dmlc::optional&lt;Shape&gt;(Shape(1)));
         Symbol expandedSumExp = expand_dims(""expandedSumExp"", sumExp, 1);
         Symbol customSoftmax = broadcast_div(expFc2, expandedSumExp);
         Symbol cross_entropy = (-1) * (one_hot(""OneHotDataLabel"", data_label, 10) * log(customSoftmax) + (1 - one_hot(""OneHotDataLabel"", data_label, 10)) * log(1 - customSoftmax));
         Symbol lenet = MakeLoss(cross_entropy);
</code></pre>

<p>However, whenever I get the output, <code>auto curOutput = exe-&gt;outputs;</code>, I seem to get the value after the computation of the loss function, which would be the <code>cross_entropy</code>.</p>

<p>How to get the result of the <code>customSoftmax</code> computation?</p>
","<c++><mxnet><loss-function>","2018-06-26 19:10:40","","0","7128430","2018-06-28 20:18:10","1","0","","","7128430","100","17","0"
"41978582","<p>I have a basic understanding of neural networks. I understand that there should be a y matrix (expected result)  which stores 0 or 1 corresponding to different category labels. As an example, for digit recognition, if the number to be identified is 6 then the y vector should be <code>[0,0,0,0,0,1,0,0,0,0]</code>. However, when I see the MXNet example <a href=""https://github.com/dmlc/MXNet.jl"" rel=""nofollow noreferrer"">in MXNet.jl repository on Github</a>, I could not identify any code which prepares this kind of result matrix. I think the magic lies in the <code>get_mnist_providers()</code> method which returns 2 providers:</p>

<pre><code>train_provider, eval_provider = get_mnist_providers(batch_size)
</code></pre>

<p>I have no idea what these providers are - train_provider, eval_provider.
Please help me understand these providers. I am trying to write an algorithm which has different classifications, so understanding this provider is vital.</p>
","<julia><mnist><mxnet><mxnet.jl>","2017-02-01 11:24:15","","1","7463041","2017-10-13 06:26:39","1","2","","","7463041","81","8","0"
"46285711","<p>I am new to MXNet (I am using it in Python3)</p>

<p>Their tutorial series encourages you define your own <a href=""http://gluon.mxnet.io/chapter03_deep-neural-networks/plumbing.html"" rel=""nofollow noreferrer""><code>gluon</code> blocks</a>.</p>

<p>So lets say this is your block (a common convolution structure):</p>

<pre><code>class CNN1D(mx.gluon.Block):
    def __init__(self, **kwargs):
        super(CNN1D, self).__init__(**kwargs)
        with self.name_scope():
            self.cnn = mx.gluon.nn.Conv1D(10, 1)
            self.bn = mx.gluon.nn.BatchNorm()
            self.ramp = mx.gluon.nn.Activation(activation='relu')

    def forward(self, x):
        x = mx.nd.relu(self.cnn(x))
        x = mx.nd.relu(self.bn(x))
        x = mx.nd.relu(self.ramp(x))
        return x
</code></pre>

<p>This is mirror the structure of their example.
What is the difference of <code>mx.nd.relu</code> vs <code>mx.gluon.nn.Activation</code>?</p>

<p>Should it be</p>

<pre><code>x = self.ramp(x)
</code></pre>

<p>instead of </p>

<pre><code>x = mx.nd.relu(self.ramp(x))
</code></pre>
","<python-3.x><mxnet>","2017-09-18 18:12:30","","2","5623899","2017-09-20 21:15:29","2","0","","","5623899","1380","181","12"
"45809154","<p>How do I create a custom loss function in MXNET? For example, instead of computing cross-entropy loss for one label (using standard mx.sym.SoftmaxOutput layer which computes cross-entropy loss and returns a symbol that can be passed as a loss symbol to the fit function), I want to compute weighted cross-entropy loss for each possible label. The MXNET tutorials mention using </p>

<pre><code>mx.symbol.MakeLoss(scalar_loss_symbol, normalization='batch')
</code></pre>

<p>However, when I use <code>MakeLoss</code> function, the standard <code>eval_metric - ""acc""</code> does not work (obviously as the model doesn't know what is my predicted probability vector). Therefore I need to write my own <code>eval_metric</code>. </p>

<p>Further, at the time of prediction, I need to predict the probability vector as well, which cannot be accessed unless I group the final probability vector with the loss symbol and <code>block_grad</code> on it. </p>
","<mxnet>","2017-08-22 04:54:56","","3","8497527","2017-08-22 19:19:08","1","0","1","","8497527","96","2","0"
"54702600","<p>I have a CNN model that I made using Keras using MXNet as the backend. I am able to create, train, and export a model without a hitch. However, when I attempted to load this model to the DeepLens, I get the following error:</p>

<pre><code>ValueError: [91mYou created Module with Module(..., data_names=['data']) but input with name 'data' is not found in symbol.list_arguments(). Did you mean one of:
        /conv2d_1_input1
        conv2d_1/kernel1
        conv2d_1/bias1
        conv2d_2/kernel1
        conv2d_2/bias1
        conv2d_3/kernel1
        conv2d_3/bias1
        dense_1/kernel1
        dense_1/bias1
        dense_2/kernel1
        dense_2/bias1
        dense_3/kernel1
        dense_3/bias1[0m
</code></pre>

<p>I never made an argument for a symbol named <code>data</code>. All of the other symbols make sense because those were derived from my model. I have added all the code associated with Keras CNN creation below.</p>

<pre><code>model = Sequential()
model.add(Conv2D(8, (1,1), input_shape=inputShape))
model.add(Dropout(0.5))
model.add(Activation('relu'))

model.add(Conv2D(16, (1,1), padding='same'))
model.add(Dropout(0.5))
model.add(Activation('relu'))

model.add(Conv2D(32, (1,1), padding='same'))
model.add(Dropout(0.5))
model.add(Activation('relu'))

model.add(Flatten())
model.add(Dense(240))

model.add(Activation('relu'))
model.add(Dense(120))

model.add(Dense(2))
model.add(Activation('sigmoid'))
</code></pre>

<p>Is there a way around this or a way to work with this using Keras with MXNet as the backend? Do I have to run a command on the Amazon Deeplens? Is there something I have to add into the model?</p>
","<python><machine-learning><keras><mxnet><amazon-deeplens>","2019-02-15 04:14:46","","0","10992468","2019-04-12 19:03:50","1","0","","","10992468","1","0","0"
"40539662","<p>I'm using the <code>CustomOp</code> class in MXNet to create a new transformation layer.  This layer has <code>output_dimensionality</code> as a hyper-parameter for the layer.  This dimensionality can't automatically be inferred from the data, but needs to be chosen by the caller who is building the network graph, so it should be a constructor argument for the new symbol, like</p>

<pre><code>net = mx.symbol.Custom(data=data, op_type='mycustomop', output_dimensionality=1024)
</code></pre>

<p>which would be consumed by the <code>__init__</code> constructor of my <code>CustomOp</code> subclass.  But when I try this, I get:</p>

<p><code>Traceback (most recent call last):
  File ""_ctypes/callbacks.c"", line 314, in 'calling callback function'
  File ""python/mxnet/operator.py"", line 602, in creator
    op_prop = prop_cls(**kwargs)
TypeError: __init__() got an unexpected keyword argument 'output_dimensionality'
Segmentation fault (core dumped)
</code></p>
","<python><deep-learning><mxnet>","2016-11-11 01:05:56","","1","303056","2018-03-07 18:29:44","1","0","","","303056","26323","4114","191"
"52961671","<p>I dont understand the following code. when im executing it is giving the value error too many values to unpack</p>

<pre><code>train_data=[data, Label]
print train_data
for data, Label in train_data:
     print data
     print Label


 output 
 [array([[23., 114., 49., ..., 61., 66., 75.,],
        [134., 345., 123., ..., 252., 249., 255.],
        ....
        [123., 97., 45., ..., 33., 234.,132.],
        [76., 98., 54., ..., 243., 211.,187.]], dtypye=float32), 
        array([0,0,1,0,2,1,1,0,0,2,2,2,0,0,0,0,2,0,0,2,2,2,0,2,2,1,1,0])]
</code></pre>

<hr>

<pre><code> ValueError Traceback(most recent call last)
      1. print train_data
  ---&gt;2. for data,Label in train_data
 ValueError: too many values to unpack
</code></pre>

<p>please help me to solve this issue.</p>
","<python><numpy><mxnet><valueerror>","2018-10-24 05:34:00","","-4","5130084","2018-10-24 05:48:44","1","3","","","5130084","3","0","0"
"54330236","<p>My code is:</p>

<pre><code>import gluoncv as gcv

net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_voc', pretrained=True)

windowName = ""ssdObject""
cv2.namedWindow(windowName, cv2.WINDOW_NORMAL)
cv2.resizeWindow(windowName, 1280, 720)
cv2.moveWindow(windowName, 0, 0)
cv2.setWindowTitle(windowName, ""SSD Object Detection"")
while True:
    # Check to see if the user closed the window
    if cv2.getWindowProperty(windowName, 0) &lt; 0:
        # This will fail if the user closed the window; Nasties get printed to the console
        break
    ret_val, frame = video_capture.read()

    frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')
    rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)

    # # Run frame through network
    class_IDs, scores, bounding_boxes = net(rgb_nd)

    displayBuf = frame
    cv2.imshow(windowName, displayBuf)
    cv2.waitKey(0)
</code></pre>

<p>I somehow need to draw the <code>bounding_codes</code>, <code>class_IDs</code>, and <code>scores</code> onto the image and output it via <code>imshow</code>.</p>

<p>How can I accomplish this?</p>
","<python><opencv><object-detection><mxnet>","2019-01-23 15:09:39","","5","239879","2019-01-24 02:30:39","1","5","","","239879","11414","1913","53"
"46306782","<p><strong>NOTE:</strong></p>

<p>I am new to MXNet. </p>

<p>It seems that the <code>Gluon</code> module is meant to replace(?) the <code>Symbol</code> module as the high level neural network (<code>nn</code>) interface. So this question <em>specifically</em> seeks an answer utilizing the <code>Gluon</code> module.</p>

<h1>Context</h1>

<p><a href=""https://blog.waya.ai/deep-residual-learning-9610bb62c355"" rel=""nofollow noreferrer"">Residual neural networks</a> (res-NNs) are fairly popular architecture (the link provides a review of res-NNs). In brief, res-NNs is an architecture where the input undergoes a (series of) transformation(s) (e.g. through a standard nn layer) and at the end is combined with its unadulterated self prior to an activation function: </p>

<p><a href=""https://i.stack.imgur.com/NwtLT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NwtLT.png"" alt=""res-NN""></a></p>

<p>So the <strong>main</strong> question here is ""How to implement a res-NN structure with a custom <code>gluon.Block</code>?"" What follows is:</p>

<ol>
<li>my attempt at doing this (which is incomplete and probably has errors)</li>
<li>as subquestions highlighted as block questions.</li>
</ol>

<p>Normally sub-questions are seen as concurrent main questions resulting in the post being flagged as too general. In this case, they are legit sub questions, as my inability to solve my main questions stems from these sub-questions <em>and</em> the partial / first-draft documentation of the gluon module is insufficient to answer them.</p>

<h1>Main Question</h1>

<p>""How to implement a res-NN structure with a custom <code>gluon.Block</code>?""</p>

<p>First lets do some imports:</p>

<pre><code>import mxnet as mx
import numpy as np
import math
import random
gpu_device=mx.gpu()
ctx = gpu_device
</code></pre>

<p>Prior to defining our res-NN structure, first we define a common convolution NN (cnn) architecture; namely, convolution → batch norm. → ramp.</p>

<pre><code>class CNN1D(mx.gluon.Block):
    def __init__(self, channels, kernel, stride=1, padding=0, **kwargs):
        super(CNN1D, self).__init__(**kwargs) 
        with self.name_scope():
            self.conv = mx.gluon.nn.Conv1D(channels=channels, kernel_size=kernel, strides=1, padding=padding)      
            self.bn = mx.gluon.nn.BatchNorm()
            self.ramp = mx.gluon.nn.Activation(activation='relu')

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.ramp(x)
        return x
</code></pre>

<blockquote>
  <p><strong>Subquestion</strong>: <a href=""https://stackoverflow.com/questions/46285711/mxnet-nn-activation-vs-nd-relu"">mx.gluon.nn.Activation vs <code>NDArray</code> module's nd.relu</a>? When to use which and why. In all MXNet tutorials / demos I saw in their documentation, custom <code>gluon.Block</code>s use <code>nd.relu(x)</code> in the <code>forward</code> function.</p>
  
  <p><strong>Subquestion</strong>: <code>self.ramp(self.conv(x))</code> vs <code>mx.gluon.nn.Conv1D(activation='relu')(x)</code>? i.e. what is the consequence of adding the activation argument to a layer? Does that mean the activation is automatically applied in the <code>forward</code> function when that layer is called?</p>
</blockquote>

<p>Now that we have a re-usable cnn chuck, let's define a res-NN where:</p>

<ol>
<li>there are <code>chain_length</code> number of cnn chucks</li>
<li>the first cnn chuck uses a different stride than all the subsequent</li>
</ol>

<p>so here is my attempt:</p>

<pre><code>class RES_CNN1D(mx.gluon.Block):
    def __init__(self, channels, kernel, initial_stride, chain_length=1, stride=1, padding=0, **kwargs):
        super(RES_CNN1D, self).__init__(**kwargs)
        with self.name_scope():
            num_rest = chain_length - 1
            self.ramp = mx.gluon.nn.Activation(activation='relu')
            self.init_cnn = CNN1D(channels, kernel, initial_stride, padding)
            # I am guessing this is how to correctly add an arbitrary number of chucks
            self.rest_cnn = mx.gluon.nn.Sequential()
            for i in range(num_rest):
                self.rest_cnn.add(CNN1D(channels, kernel, stride, padding))


    def forward(self, x):
        # make a copy of untouched input to send through chuncks
        y = x.copy()
        y = self.init_cnn(y)
        # I am guess that if I call a mx.gluon.nn.Sequential object that all nets inside are called / the input gets passed along all of them?
        y = self.rest_cnn(y)
        y += x
        y = self.ramp(y)
        return y
</code></pre>

<blockquote>
  <p><strong>Subquestion</strong>: adding a variable number of layers, should one use the hacky <code>eval(""self.layer"" + str(i) + "" = mx.gluon.nn.Conv1D()"")</code> or is this what <code>mx.gluon.nn.Sequential</code> is meant for?</p>
  
  <p><strong>Subquestion</strong>: when defining the <code>forward</code> function in a custom <code>gluon.Block</code> which has an instance of <code>mx.gluon.nn.Sequential</code> (let us refer to it as <code>self.seq</code>), does <code>self.seq(x)</code> just pass the argument <code>x</code> down the line? e.g. if this is <code>self.seq</code></p>
  
  <p><code>self.seq = mx.gluon.nn.Sequential()</code></p>
  
  <p><code>self.conv1 = mx.gluon.nn.Conv1D()</code></p>
  
  <p><code>self.conv2 = mx.gluon.nn.Conv1D()</code></p>
  
  <p><code>self.seq.add(self.conv1)</code></p>
  
  <p><code>self.seq.add(self.conv2)</code></p>
  
  <p>is <code>self.seq(x)</code> equivalent to <code>self.conv2(self.conv1(x))</code>?</p>
</blockquote>

<p>Is this correct?</p>

<p>The desired result for </p>

<pre><code>RES_CNN1D(10, 3, 2, chain_length=3)
</code></pre>

<p>should look like this</p>

<pre><code>Conv1D(10, 3, stride=2)  -----
BatchNorm                    |
Ramp                         |
Conv1D(10, 3)                |
BatchNorm                    |
Ramp                         |
Conv1D(10, 3)                |
BatchNorm                    |
Ramp                         |
  |                          |
 (+)&lt;-------------------------
  v
Ramp
</code></pre>
","<python-3.x><mxnet>","2017-09-19 17:44:37","","3","5623899","2017-09-20 21:06:10","1","0","","","5623899","1380","181","12"
"46407347","<p>I also post this question in the <a href=""https://github.com/apache/incubator-mxnet/issues/8023"" rel=""nofollow noreferrer"">repository</a>.</p>

<p>I'm trying to load a model previously saved in files following the tutorial <a href=""https://mxnet.incubator.apache.org/versions/master/tutorials/python/predict_image.html"" rel=""nofollow noreferrer"">here</a>. I use exactly the same command as shown in the tutorial, but I meet with the following error message:</p>

<pre><code>Traceback (most recent call last):
  File ""test.py"", line 153, in &lt;module&gt;
    num_epoch=num_epoch)
  File ""/home/mypath/software/try_mxnet2/mxnet/python/mxnet/module/base_module.py"", line 496, in fit
    self.update_metric(eval_metric, data_batch.label)
  File ""/home/mypath/software/try_mxnet2/mxnet/python/mxnet/module/module.py"", line 735, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File ""/home/mypath/software/try_mxnet2/mxnet/python/mxnet/module/executor_group.py"", line 567, in update_metric
    for label, axis in zip(labels, self.label_layouts):
TypeError: zip argument #2 must support iteration
</code></pre>

<p>The code of loading and retraining the files is as follows:</p>

<pre><code>sym, arg_params, aux_params = mx.model.load_checkpoint('../model/test_mymodel', 25)
lenet_model = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)

lenet_model.bind(for_training=True, data_shapes=[('data', (batch_size,3,16,16))], 
         label_shapes=lenet_model._label_shapes)
lenet_model.set_params(arg_params, aux_params, allow_missing=True)
lenet_model.fit(train_iter,
                optimizer='adam',
                optimizer_params={'learning_rate':0.001,'wd':0.0005},
                eval_metric='acc',
                batch_end_callback = mx.callback.Speedometer(batch_size, n_report), 
                epoch_end_callback  = mx.callback.do_checkpoint(""../model/test_mymodel"", 5),
                num_epoch=num_epoch)
</code></pre>

<p>As I have tested, when I comment out the line <code>lenet_model.fit(...)</code>, no error is reported. It seems the loaded model cannot be trained continuously, or there is something wrong with my code.</p>

<p>I'm looking forward to kind solutions. Thanks!</p>
","<python><deep-learning><mxnet>","2017-09-25 14:13:49","","0","5005808","2018-02-28 23:28:55","1","4","","","5005808","776","53","2"
"43684975","<p>I have a big dataset (around 20GB for training and 2GB for testing) and I want to use MXnet and R. Due to lack of memory, I search for an iterator to load the training and test set by a custom iterator and I found <a href=""https://github.com/dmlc/mxnet/blob/master/docs/tutorials/r/CustomIteratorTutorial.md"" rel=""nofollow noreferrer"">this</a> solution. </p>

<p>Now, I can train the model using the code on this page, but the problem is that if I read the test set with the save iterator as follow:</p>

<pre><code>test.iter &lt;- CustomCSVIter$new(iter = NULL, data.csv = ""test.csv"", data.shape = 480, batch.size = batch.size)
</code></pre>

<p>Then, the prediction command does not work and there is no prediction template in the <a href=""https://github.com/dmlc/mxnet/blob/master/docs/tutorials/r/CustomIteratorTutorial.md"" rel=""nofollow noreferrer"">page</a>;</p>

<pre><code>preds &lt;- predict(model, test.iter)
</code></pre>

<p>So, my specific problem is, if I build my model using the code on the page, how can I read my test set and predict its labels for the evaluation process? My test set and train set is in <a href=""https://github.com/ozt-ca/tjo.hatenablog.samples/raw/master/r_samples/public_lib/jp/mnist_reproduced/short_prac_test.csv"" rel=""nofollow noreferrer"">this format</a>.</p>

<p>Thank you for your help</p>
","<r><image-processing><deep-learning><mxnet>","2017-04-28 16:31:39","","0","4288229","2018-04-12 20:46:27","1","0","","","4288229","454","61","3"
"49788025","<p>I am having trouble with basic IO with <code>mxnet</code>.  I am attempting to use  <code>mxnet.io.NDArrayIter</code> to read in-memory datasets for training in mxnet.  I have the below code (condensed for brevity) which preprocesses the code and attempt to iterate through it (heavily based on the <a href=""https://mxnet.incubator.apache.org/tutorials/basic/data.html#reading-data-in-memory"" rel=""nofollow noreferrer"">tutorial</a>):</p>

<pre class=""lang-python prettyprint-override""><code>import csv
import mxnet as mx
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.pipeline import Pipeline


with open('data.csv', 'r') as data_file:
    data = list(csv.reader(data_file))

labels = np.array(map(lambda x: x[1], data)) # one-hot encoded classes
data = map(lambda x: x[0], data) # raw text in need of pre-processing

transformer = Pipeline(steps=(('count_vectorizer', CountVectorizer()),
                              ('tfidf_transformer', TfidfTransformer())))

preprocessed_data = np.array([np.array(row) for row in transformer.fit_transform(data)])

training_data = mx.io.NDArrayIter(data=preprocessed_data, label=labels, batch_size=50)

for i, batch in enumerate(training_data):
    print(batch)
</code></pre>

<p>When executing this code, I receive the following error:</p>

<pre><code>    Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/io.py"", line 510, in _init_data
    data[k] = array(v)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/utils.py"", line 146, in array
    return _array(source_array, ctx=ctx, dtype=dtype)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py"", line 2245, in array
    arr[:] = source_array
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py"", line 437, in __setitem__
    self._set_nd_basic_indexing(key, value)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py"", line 698, in _set_nd_basic_indexing
    self._sync_copyfrom(value)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py"", line 856, in _sync_copyfrom
    source_array = np.ascontiguousarray(source_array, dtype=self.dtype)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py"", line 581, in ascontiguousarray
    return array(a, dtype, copy=False, order='C', ndmin=1)
TypeError: float() argument must be a string or a number, not 'csr_matrix'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""mxnet_test.py"", line 20, in &lt;module&gt;
    training_data = mx.io.NDArrayIter(data=preprocessed_data, label=labels, batch_size=50)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/io.py"", line 643, in __init__
    self.data = _init_data(data, allow_empty=False, default_name=data_name)
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/io.py"", line 513, in _init_data
    ""should be NDArray, numpy.ndarray or h5py.Dataset"")
TypeError: Invalid type '&lt;class 'numpy.ndarray'&gt;' for data, should be NDArray, numpy.ndarray or h5py.Dataset
</code></pre>

<p>which I do not understand, as my data is being converted to a <code>numpy.ndarray</code> before creating the <code>NDArrayIter</code> instance.  Would someone be willing to provide some insight on how to read data in <code>mxnet</code>?  </p>

<p>The code above is currently using the following versions:</p>

<ul>
<li>mxnet-1.1.0</li>
<li>numpy-1.14.2</li>
</ul>
","<python><numpy><mxnet>","2018-04-12 04:31:00","","1","2829487","2018-04-12 18:43:37","1","3","","","2829487","362","109","1"
"54801596","<p>Is there any way to prevent full GPU memory allocation for MXNet? So that it only allocates what it needs and not the whole GPU memory.</p>

<p>I want to use another model in Tensorflow/Keras on the same GPU alongside MXNet and it seems that the whole memory gets reserved by MXNet.</p>
","<mxnet>","2019-02-21 07:36:29","","1","1417053","2019-03-05 21:23:20","1","0","","","1417053","591","377","13"
"53640462","<p>I am frequently rerunning the same <code>mxnet</code> script while I try to iron out some bugs in a new script (and I am new to <code>mxnet</code>). Pretty often when I try to run my script I get an error that the GPU is out of memory, and when I use <code>nvidia-smi</code> to check, this is what I see:</p>

<pre><code>Wed Dec  5 15:41:29 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.24.02              Driver Version: 396.24.02                 |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:65:00.0  On |                  N/A |
|  0%   54C    P2    68W / 300W |  10891MiB / 11144MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1446      G   /usr/lib/xorg/Xorg                            40MiB |
|    0      1481      G   /usr/bin/gnome-shell                         114MiB |
|    0     10216      G   ...-token=8422C9FC67F51AEC1893FEEBE9DB68C6    31MiB |
|    0     18221      G   /usr/lib/xorg/Xorg                           458MiB |
|    0     18347      G   /usr/bin/gnome-shell                         282MiB |
+-----------------------------------------------------------------------------+
</code></pre>

<p>So it seems like most of the memory is in use (10891/11144) BUT I don't see any process in the list taking up a large portion of the GPU, so there doesn't seem to be anything to call. And my mxnet script has been exited out, so I assume it shouldn't be that. I would understand if there were some seconds or even tens of seconds lagging if the GPU does not know right away that the script no longer needs memory, but <strong>I am going on many minutes and still see the same display. What gives, and is there some memory cleanup I should do? If so, how? Thank you for any tips to a newbie.</strong></p>
","<gpu><mxnet>","2018-12-05 20:45:38","","1","8762321","2018-12-06 03:58:09","1","0","","","8762321","116","7","0"
"51726732","<p>I have a collection of <code>11*11*21</code> 3D data that I want to use a 3D convnet to classify. By using gluon's dataloader with a batch size of 64, my input tensor for the network was (64L, 11L, 11L, 21L). When I tried to run the program I got the following error.</p>

<pre><code>""infer_shape error. Arguments:
data: (64L, 11L, 11L, 21L)""
</code></pre>

<p>I then realized that 3D converts take 5D tensors as inputs and thus I am stuck on how to create a 5D tensor input for the network.</p>

<p>If it helps here is the code I am currently using to create my data for the convnet.</p>

<pre><code>train_dataset = mx.gluon.data.ArrayDataset((noA_list+A_list),     (label_noA+label_A))
test_dataset = mx.gluon.data.ArrayDataset((noA_test_list+A_list_test),(label_noA_test+label_A_test))
train_data = mx.gluon.data.DataLoader(train_dataset, batch_size= 64,shuffle= True, num_workers = cpucount)
test_data = mx.gluon.data.DataLoader(test_dataset,batch_size= 64,shuffle= True, num_workers = cpucount)
</code></pre>
","<python><conv-neural-network><mxnet>","2018-08-07 12:23:29","","0","10171841","2018-08-08 07:14:37","1","0","","","10171841","6","0","0"
"44873008","<p>I was using the mxnet example for Faster R-CNN on the official GitHub:
<a href=""https://github.com/dmlc/mxnet/tree/master/example/rcnn"" rel=""nofollow noreferrer"">Faster R-CNN</a></p>

<p>I created my own dataset and adapted the <code>pascal_voc.py</code> file. This included changing the number of classes to 13.
The resolution of my pictures is 600*800 pixel, so a bit larger than the VOC dataset.
In my trainval images, I have 2000 examples, so 3000 less than than in VOC.
I am using mxnet 0.10 in python for this.</p>

<p>I am getting no error in the training, the loss is decreasing, but when I use the model after 10 epochs, I am getting no results, just the:</p>

<pre><code>class ---- [[x1, x2, y1, y2, confidence]]
</code></pre>

<p>Does anyone has an idea what I am might missing?</p>
","<python><mxnet>","2017-07-02 16:38:06","","0","2662629","2018-09-11 18:34:28","1","2","","","2662629","230","29","0"
"44910776","<p>I'm predicting roughly one of 100K possible outputs with a MXNet model, using a fairly standard softmax output. I want to compare the probability assigned to the true label versus the top predictions under the model. To get the former I'm using the pick operator; the later I've tried the cheap version (topk operator) and the expensive version (sort/argsort + slice).</p>

<p>In both cases I'm getting contradictory results. Specifically, there are numerous cases where the probability of the true label (retrieved with pick) is significantly higher than the highest probability output (retrieved with topk/sort). I think this means I'm doing something wrong but don't understand what. It does not happen for all predictions, but it does for a significant fraction.</p>

<p>Can anybody give me a hint as to what is going on?</p>

<p>Code follows:</p>

<pre><code>for batch in data_iter:
    model.forward(batch, is_train=False)
    predictions = model.get_outputs()[0]
    labels = batch.label[0].as_in_context(predictions.context)

    # scores = mx.nd.topk(predictions, axis=1, k=6, ret_typ='value')
    scores = mx.nd.sort(predictions, axis=1, is_ascend=0)
    scores = mx.nd.slice_axis(scores, axis=1, begin=0, end=6)

    label_score = mx.nd.pick(predictions, labels, axis=1)
    equal = label_score.asnumpy() &lt;= scores.asnumpy()[:, 0]

    if not np.all(equal):
        #I think this should never happen but it does frequently
</code></pre>
","<python><mxnet>","2017-07-04 16:38:41","","3","1740708","2018-03-01 03:38:09","1","1","","","1740708","5649","31","6"
"53041443","<p>In the code of custom operators, I have such lines:</p>

<pre><code> for i in xrange(batch_size):
    numpy.XXX
</code></pre>

<p>for better performance, I use multiprocessing. But it's stuck.</p>
","<python><mxnet>","2018-10-29 08:26:20","","-1","6313573","2018-11-06 00:00:52","1","0","","","6313573","8","0","0"
"53745482","<p>I was thinking about how one should deploy multiple models for use. I am currently dealing with tensorflow. I was referring <a href=""https://medium.freecodecamp.org/how-to-deploy-tensorflow-models-to-production-using-tf-serving-4b4b78d41700"" rel=""nofollow noreferrer"">this</a> and <a href=""https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198"" rel=""nofollow noreferrer"">this</a> article. </p>

<p>But I am not able to find any article which targets need to serve several models distributed manner. <strong>Q.1.</strong> Does tensorflow serving serve models off from single machine? Is there any way to set up a cluster of machines running tensorflow serving? So that multiple machines serve same model somewhat working as master and slave or say load balance between them while serving different models.</p>

<p><strong>Q.2.</strong> Does similar functionality exist for other deep learning frameworks, say keras, mxnet etc (not just restricting to tensorflow and serving models from different frameworks)?</p>
","<tensorflow><keras><deep-learning><mxnet>","2018-12-12 14:43:56","","0","6357916","2018-12-13 20:21:58","1","1","","","6357916","440","13","0"
"53666550","<p>I have this code:</p>

<pre><code>import cv2
im = cv2.imread(""0.jpg"")
print(len(im.tobytes()))
fp = open(""0.jpg"", 'rb')
imb = fp.read()
print(len(imb))
</code></pre>

<p>They are different! Now a function take 'imb' format as input. But I just have 'im'. I must use the cv2.imwrite to the disk and then use fp.read()?
Is there a faster way?</p>

<p>I use the mxnet image imdecode. imdecode take 'imb' as input. But im is what I get. How to pass the 'im' to the mx.img.imdecode?</p>

<p><a href=""https://github.com/apache/incubator-mxnet/issues/13545"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/issues/13545</a></p>
","<numpy><opencv><mxnet>","2018-12-07 09:21:13","","1","6313573","2018-12-07 12:00:42","1","2","","","6313573","8","0","0"
"45050459","<p>For example</p>

<blockquote>
  <p>Assume the Variables are:</p>
</blockquote>

<ul>
<li>inputs_a = mx.sym.Variable('inputs_a')   </li>
<li>inputs_b = mx.sym.Variable('inputs_b')</li>
</ul>

<blockquote>
  <p>Assume the network is:</p>
</blockquote>

<ol>
<li>inputs_a[batch_size], 100]-->FullyConnected(10)-->outputs_a[batch, 10]</li>
<li>inputs_b[batch_size], 50]-->FullyConnected(10)-->outputs_b[batch,
10]</li>
<li>prediction = outputs_a + outputs_b</li>
</ol>

<blockquote>
  <p>Assume the datas(numpy) are:</p>
</blockquote>

<ul>
<li>data_a which size is [batch_size, 100]</li>
<li>data_b which size is [batch_size, 50]</li>
<li>data_label which size is [batch_size, 10]</li>
</ul>

<blockquote>
  <p>I want to know how to build the model?</p>
</blockquote>

<pre><code>mod = mx.mod.Module(context=mx.gpu(), symbol=prediction,
                    data_names=['inputs_a', 'inputs_b'], label_names=['label'])
</code></pre>

<blockquote>
  <p>And I want to know how to build the data iter?</p>
</blockquote>

<pre><code>train_iter = mx.io.NDArrayIter(data=[data_a, data_b], label=data_label,batch_size=3,data_name=['inputs_a', 'inputs_b'],label_name='label')
</code></pre>

<p>But this format is wrong.And I can not find this kind of multi inputdata demo in MXNet's tutorial and API documents.What's more, there are few blog of MXNet demo.
So can you show me the right way to do it? Or show me your demo. Thanks!</p>
","<python><deep-learning><mxnet>","2017-07-12 06:53:59","","2","8269755","2017-07-18 23:58:29","1","2","0","","8269755","21","0","0"
"45619738","<p>Suppose I have a data file that has entries that look like this</p>

<pre><code>0.00,2015-10-21,1,Y,798.78,323793701,6684,0.00,Q,H2512,PE0,1,0000
</code></pre>

<p>I would like to use this as an input to an mxnet model (basic Feed Forward Multi-layer Perecptron). A single input record has data types, in the order show above</p>

<pre><code>float,date,int,categorical,float,int,int,float,categorical,categorical,categorical,int, float
</code></pre>

<p>each record is a meaningful representation of a specific entity. how do I represent this sort of data to mxnet? also, to complicate things a bit, suppose I want to one-hot encode the categorical columns? And what if each record has these fields, in the order show, but repeated multiple times in some cases such that each record may have a different length?</p>

<p>The docs are great for the basic cases where you have input data that is all of the same type and can all be loaded into the same input without any transformation but how to handle this case?</p>

<p>Update: adding some additional details. to keep this as simple as possible, let's say I just want to feed this into a simple network. something like:</p>

<pre><code>my $data = mx-&gt;symbol-&gt;Variable(""data"");
my $fc = mx-&gt;symbol-&gt;FullyConnected($data, num_hidden =&gt; 1);
my $softmax=mx-&gt;symbol-&gt;SoftmaxOutput(data =&gt; $fc, name =&gt; ""softmax"");
my $module = mx-&gt;mod-&gt;new(symbol =&gt; $softmax);
</code></pre>

<p>in the simple case of the data being all one type and not requiring much in the way of pre-processing I then could just do something along the lines of</p>

<pre><code>$module-&gt;fit(
    $train_iter,
    eval_data =&gt; $eval_iter,
    optimizer =&gt; ""adam"",
    optimizer_params=&gt;{learning_rate=&gt;0.001},
    eval_metric =&gt; ""mse"",
    num_epoch =&gt; 25
);
</code></pre>

<p>where <code>$train_iter</code> is a simple NDArray iterator over the training data. (Well, with the Perl API it's not exactly an NDArray, but has complete parity with that interface so it is conceptually identical).</p>
","<mxnet>","2017-08-10 17:09:40","","0","4705722","2017-08-22 01:13:24","1","2","","","4705722","118","1397","0"
"42423387","<p>I am trying to use R-CNN in mxnet. I had a working mxnet installation. I upgraded it using git pull so I can use the latest version. Then I followed the instructions in the <a href=""https://github.com/dmlc/mxnet/tree/master/example/rcnn"" rel=""nofollow noreferrer"">github repo</a> to install the additional dependencies and run the demo. Afetr I run the line</p>

<pre><code>bash script/vgg_voc07.sh 0,1
</code></pre>

<p>I get the error:
AttributeError: 'module' object has no attribute 'Proposal' when running RCNN train_end2end.py</p>

<p>This is exactly what I did:</p>

<pre><code>    1  cd mxnet
    2  git pull
    3  cd example/rcnn
    4  ls
    5  bash script/additional_deps.sh
    6  pip install matplotlib
    7  bash script/get_voc.sh
    8  bash script/get_pretrained_model.sh
    9  bash script/vgg_voc07.sh 0,1
   10  ls
   11  cd ..
   12  sed -i 's/EXTRA_OPERATORS =/EXTRA_OPERATORS = example\/rcnn\/operator/g' config.mk
   13  make -j""$(nproc)""
   14  cd example
   15  cd rcnn
   16  make
   17  bash script/vgg_voc07.sh 0,1
</code></pre>

<p>I also posted an issue in <a href=""https://github.com/dmlc/mxnet/issues/5102"" rel=""nofollow noreferrer"">github</a></p>
","<python><mxnet>","2017-02-23 18:22:25","","0","4127806","2017-02-24 05:26:34","1","0","","","4127806","670","709","0"
"40494602","<p>When I call <code>module.fit()</code> I'm getting an error
<code>ValueError: Unknown initialization pattern for labelidx</code>.
The symbol ""labelidx"" is the name I'm using for my label data -- I didn't want to use <code>softmax_label</code> because I'm not using softmax output, but that seems to be the default for a lot of thigns.  It seems to be trying to initialize <code>labelidx</code> as a parameter, which is a mistake.  How can I tell it this is an input not a learned parameter?</p>
","<deep-learning><mxnet>","2016-11-08 19:06:25","","2","303056","2016-11-11 00:55:50","1","0","1","","303056","26323","4114","191"
"36047937","<p>I was wondering if anybody could advise on how to get peak performance out of tensorflow in a 4 GPU setting.</p>

<p>As a test I created two of the same network (18 ish layer residual network with small filter banks (ranging from 16-128) on 32x32 inputs. Batch size 512, 128 per GPU.). One in MXNet and one I have modelled off of <a href=""https://github.com/tensorflow/models/tree/master/inception"">the inception example</a>.</p>

<p>My MXNet network can train at around 7k examples a second where tensorflow is only capable of 4.2k with dummy data and 3.7 with real data.</p>

<p>(when running on 1 GPU the numbers are 1.2k examples a second vs 2.1k)</p>

<p>In my experiment I have a few questions in hopes to speed things up.</p>

<ol>
<li><p>GPU utilization seems quite low when training. I noticed that in the tensorflow white paper there is support for running multiple streams on the same GPU. Is this possible in the public release?</p></li>
<li><p>Is there anyway to perform multiple train operations in one execution of <code>session.run()</code>? Or have async execution? This would allow for weight updates to be done at the same time as the next batches forward pass? I have tried using 2 threads (both system and with <code>QueueRunners</code>'s), but this only resulted in a slowdown. MXNet is able to increase speeds by running weight updates on the CPU so that the gpu's can be used for the next batch.</p></li>
<li><p>Will the new distributed run time get around some of these issues by letting me run more than one worker on a single machine?</p></li>
<li><p>Is there something else that can be done?</p></li>
</ol>

<p>I know there are a number of similar questions here on stack overflow, but though my searching I couldn't find a solution to my problems that I have not already tried.</p>

<p><strong>Edit:</strong></p>

<p>I did a little bit of CUDA profiling to see what the expensive kernels were. According to my run, 21.4% of the time is spent inside:</p>

<pre><code>void Eigen::internal::EigenMetaKernel_NonVectorizable&lt;Eigen::TensorEvaluator
&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, int=4, int=1, long&gt;, int=16&gt;,
Eigen::TensorPaddingOp&lt;Eigen::array&lt;std::pair&lt;int, int&gt;,
unsigned long=4&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const,
int=4, int=1, long&gt;, int=16&gt; const &gt; const &gt; const, Eigen::GpuDevice&gt;, long&gt;(float, int=4)
</code></pre>

<p>and 20.0% of the time were spent in </p>

<pre><code>void Eigen::internal::EigenMetaKernel_NonVectorizable&lt;Eigen::TensorEvaluator
&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, int=4, int=1, long&gt;, int=16&gt;,
Eigen::TensorBroadcastingOp&lt;Eigen::array&lt;int, unsigned long=4&gt;
const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, int=4, int=1, long&gt;,
int=16&gt; const &gt; const &gt; const, Eigen::GpuDevice&gt;, long&gt;(float, int=4)
</code></pre>

<p>Off of the Signature I am not exactly sure what these are doing. Do these make sense?</p>

<p>In addition to this, the analysis reports low kernel concurrency, 0%, as expected.
And Low compute utilization 34.9% (granted this includes start-up time and a little bit of python in train loop. Around 32 seconds total out of 91. This comes out to around 50% utilization inside tensorflow.)</p>

<p><strong>Edit 2:</strong></p>

<p>I have attached a copy of the trimmed down <a href=""https://gist.github.com/lukemetz/2072e9f7b3f2b9325e25"">source code</a>. In general though I am more concerned about question 1-3 and don't want to take too much of ever bodies time.</p>

<p>In addition I am running on tensorflow built from: f07234db2f7b316b08f7df25417245274b63342a</p>

<p><strong>Edit 3:</strong></p>

<p>Updated to the most recent tensorflow (63409bd23facad471973b110df998782c0e19c06) same code, default data format (NHWC) and that seemed to speed this up a lot.
On fake data 6.7k-6.8k (thermal dependence I think?) examples a second 4gpu. 1gpu -- 2.0k examples a second.
Real data performance is around 4.9k examples a second for 4gpu. 1gpu -- 1.7k examples a second.</p>

<p><strong>Edit 4:</strong></p>

<p>In addition I tried out switching data formats to BCHW. I made the conversion modelled off of <a href=""https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_googlenet.py"">Soumith's benchmarks</a>. The convolution parts were indeed faster, but batch norm appears to be messing everything up. With a <a href=""https://gist.github.com/lukemetz/2072e9f7b3f2b9325e25#file-batchnorm_function-py"">naive implementation</a> (fixing axis, and making weights [1,C,1,1] instead of [C,]) I am only able to get 1.2k examples a second on 4 gpu (fake data). Where as with a transpose before and after the batch norm op I am able to get 6.2k examples a second (fake data). Still slower than the NHWC data_format.</p>
","<c++><performance><gpu><tensorflow><mxnet>","2016-03-16 22:12:17","","11","258834","2016-03-21 19:54:37","1","0","3","","258834","329","24","0"
"45807556","<p>How do I create a combined iterator in MXNET? For example, given a record (.rec) iterator if I want to change the labels corresponding to each image then there are two options:
a) Create a new rec iterator with the same data(images) and new labels.
b) Create a multi-iterator using the original rec iterator and an NDArray iterator such that the multi-iterator reads data(images) from the original .rec iterator and labels from the NDArray iterator.
The option (a) is tedious. Any suggestions on how to create such a multi-iterator?</p>
","<mxnet>","2017-08-22 01:17:09","","2","8497527","2017-08-22 01:49:04","1","0","","","8497527","96","2","0"
"53660631","<p>I have some experience with Tensorflow but only about a week with mxnet. I am trying to understand the behavior of some code when I hit a break point in the function below:</p>

<pre><code>def train_and_eval(lr, end_date_str, pred):
    model.collect_params().initialize(mx.init.Xavier(), ctx=ctx, force_reinit=True)
    mgr      = ProcessMgr(2, end_date_str)

    for epoch in range(args_epochs):    
        for i in range(2):
            if i == TRAIN_MODE:
                mgr.switch_to_train()
            elif epoch == args_epochs - 1 and i == VALIDATE_MODE:
                mgr.switch_to_validate()
            else:
                break

            while True:
                try:
                    data, target, eval_target, date_str = mgr.get_batch()
                    data        = gluon.utils.split_and_load(data, ctx)
                    target      = gluon.utils.split_and_load(target, ctx)
                    eval_target = gluon.utils.split_and_load(eval_target, ctx)
                    data        = [mx.nd.swapaxes(d, 0, 1) for d in data]

                    with autograd.record():                    
                        losses = [loss(model(X)[-args_batch_size:], Y) for X, Y in zip(data, target)]
                        null_loss_vals = sum([Y.square().sum().asscalar() for Y in target])
                        model_loss_vals = sum([sum(l).asscalar() for l in losses])
                        null_loss[i] += null_loss_vals
                        model_loss[i] += model_loss_vals

                        **pdb.set_trace() ## BREAK POINT IS HERE**
                        if i == TRAIN_MODE:
                            for l in losses:
                                l.backward()
                            x = 18
                            grads = [i.grad(ctx) for i in model.collect_params().values() if i._grad is not None]
                            gluon.utils.clip_global_norm(grads, args_clip)
                            trainer.step(GPU_COUNT * args_batch_size)
                except:
                    print(""completed an epoch"")
                    break
</code></pre>

<p>I am getting some unexpected values for the losses I am calculating, so I put a break point in to see what was going on. The problem is that when I run the same data through the model, I get different outputs each time. Below I paste some of the outputs I have when I hit the <code>pdb</code> breakpoint and try to run data through the <code>model</code>.</p>

<pre><code>&lt;NDArray 38400x1 @gpu(0)&gt;
(Pdb) model(data[0])

[[ 2.9265028e-01]
 [ 9.3701184e-03]
 [ 4.3234527e-02]
 ...
 [-5.0668776e-09]
 [-2.7628975e-08]
 [-1.9340845e-08]]
&lt;NDArray 38400x1 @gpu(0)&gt;
(Pdb) model(data[0])

[[ 1.5275864e-01]
 [ 2.0615126e-01]
 [ 4.6957955e-02]
 ...
 [-2.6077061e-08]
 [-9.2040580e-09]
 [-3.2883932e-08]]
&lt;NDArray 38400x1 @gpu(0)&gt;
(Pdb) data[0]

[[[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 [[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 [[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 ...

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]]
&lt;NDArray 128x300x2 @gpu(0)&gt;
(Pdb) data[0]

[[[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 [[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 [[ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]
  ...
  [ 0. -4.]
  [ 0. -4.]
  [ 0. -4.]]

 ...

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]

 [[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  ...
  [ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]]]
&lt;NDArray 128x300x2 @gpu(0)&gt;
(Pdb) 
</code></pre>

<p>I am perplexed as to what is going on here. I do realize my code may not be entirely proper in that I am not running anything in a predict or inference model (was planning to check/tackle that later), but <strong>I don't understand how the model itself seems to changing each time I run input into the model even though I am not running  <code>backward()</code> or <code>trainer.step()</code>.</strong> Any insight would be appreciated. Why is this happening? </p>

<p>My only guess is that perhaps the hidden state is preserved between runs. But I thought I had not coded it to do so (I saw an example where this was done and the hidden state had to be explicitly saved and fed back into the RNN). In particular, I have not implemented a <code>begin_state</code> method for my <code>gluon.Block</code>. I am not sure how to verify or disprove this guess.</p>

<p>Here is my gluon.Block as implemented in case that is relevant:</p>

<pre><code>class RNNModel(gluon.Block):
    def __init__(self, mode, num_inputs, num_embed, num_hidden,
                 num_layers, dropout=0.5, tie_weights=False, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        with self.name_scope():
            self.drop = nn.Dropout(dropout)
            self.rnn = rnn.GRU(num_hidden, num_layers, dropout=dropout,
                               input_size=num_inputs)
            self.decoder = nn.Dense(1, in_units = num_hidden)
            self.num_hidden = num_hidden

    def forward(self, inputs):
        output = self.rnn(inputs)
        output = self.drop(output)
        decoded = self.decoder(output.reshape((-1, self.num_hidden)))
        return decoded
</code></pre>
","<rnn><mxnet>","2018-12-06 22:26:23","","0","8762321","2018-12-13 08:28:58","1","0","","","8762321","116","7","0"
"53676981","<p>My mxnet script is likely limited by i/o of data loading into the GPU, and I am trying to speed this up by prefetching. The trouble is I can't figure out how to prefetch with a custom data iterator.</p>

<p><strong>My first hypothesis/hope was that it would be enough to set the values of self.preprocess_threads and self.prefetch_buffer</strong>, as I had seen <a href=""https://mxnet.incubator.apache.org/api/python/io/io.html"" rel=""nofollow noreferrer"">here</a> for iterators such as <code>mxnet.io.ImageRecordUInt8Iter</code>. However, when I did this I saw no performance change relative to the script before I had set these variables, so clearly setting these did not work.</p>

<p><strong>Then I noticed, the existence of a class <code>mx.io.PrefetchingIter</code></strong> in addition to the base class for which I had implemented a child class <code>mx.io.DataIter</code>. I found this <a href=""http://beta.mxnet.io/api/gluon-related/_autogen/mxnet.io.PrefetchingIter.html"" rel=""nofollow noreferrer"">documentation</a>, but I have not been able to find any examples, and I am a little confused about what needs to happen where/when. However, I am not clear on how to use this. For example. I see that in addition to <code>next()</code> it has an <code>iter_next()</code> method, which simply says ""move to the next batch"". What does this mean exactly? What does it mean to ""move"" to the next batch without producing it? I found the <a href=""http://mxnet.incubator.apache.org/versions/1.0.0/_modules/mxnet/io.html"" rel=""nofollow noreferrer"">source code</a> for this class, and based on a brief reading, it seems as though it takes multiple iterators and creates one thread per iterator. This likely would not work for my current design, as I really want multiple threads used to prefetch from the same iterator.</p>

<p>Here is what I am trying to do via a custom data iterator</p>

<ol>
<li>I maintain a global <code>multiprocessing.Queue</code> on which I pop data as it becomes available</li>
<li>I produce that data by running (via <code>multiprocessing</code>) a command line script that executes a c++ binary which produces a <code>numpy</code> file</li>
<li>I open the <code>numpy</code> file and load its contents into memory, process them, and put the processed bits on the global <code>multiprocessing.Queue</code></li>
<li>My custom iterator pulls off this queue and also kicks off more jobs to produce more data when the queue is empty.</li>
</ol>

<p>Here is my code:</p>

<pre><code>def launchJobForDate(date_str):
### this is a function that gets called via multiprocessing
### to produce new data by calling a c++ binary
### whenever data queue is empty so that we need to produce more data
    try:
        f = ""testdata/data%s.npy""%date_str
        if not os.path.isfile(f):
            cmd = CMD % ( date_str, JSON_FILE, date_str, date_str, date_str)
            while True:
                try:
                    output = subprocess.check_output(cmd, shell=True)
                    break
                except:
                    pass
        while True:
            try:
                d = np.load(f)
                break
            except:
                pass
        data_queue.put((d, date_str))
    except Exception as ex:
        print(""launchJobForDate: ERROR "", ex)

class ProduceDataIter(mx.io.DataIter):
    @staticmethod
    def processData(d, time_steps, num_inputs):
       try: 
            ...processes data...
            return [z for z in zip(bigX, bigY, bigEvalY, dates)]
        except Exception as ex:
            print(""processData: ERROR "", ex)

    def __init__(self, num_mgrs, end_date_str):
        ## iter stuff
        self.preprocess_threads = 4
        self.prefetch_buffer = 1

        ## set up internal data to preserve state
        ## and make a list of dates for which to run binary

    @property
    def provide_data(self):
        return [mx.io.DataDesc(name='seq_var', 
                               shape=(args_batch_size * GPU_COUNT, 
                                      self.time_steps, 
                                      self.num_inputs), 
                               layout='NTC')]

    @property
    def provide_label(self):
        return [mx.io.DataDesc(name='bd_return', 
                                shape=(args_batch_size * GPU_COUNT)),             
                mx.io.DataDesc(name='bd_return', 
                                shape=(args_batch_size * GPU_COUNT, num_y_cols)), 
                mx.io.DataDesc(name='date', 
                               shape=(args_batch_size * GPU_COUNT))]                 


    def __next__(self):
        try:
            z = self.z.pop(0)       
            data = z[0:1]
            label = z[1:]
            return mx.io.DataBatch(data, label) 
        except Exception as ex:
            ### if self.z (a list) has no elements to pop we need
            ### to get more data off the queue, process it, and put it
            ### on self.x so it's ready for calls to __next__()
            while True:
                try:
                    d = data_queue.get_nowait()
                    processedData = ProduceDataIter.processData(d, 
                                                            self.time_steps, 
                                                            self.num_inputs)
                    self.z.extend(processedData)
                    counter_queue.put(counter_queue.get() - 1)

                    z = self.z.pop(0)
                    data = z[0:1]
                    label = z[1:]
                    return mx.io.DataBatch(data, label)

                except queue.Empty:
                    ...this is where new jobs to produce new data and put them 
                    ...on the queue would happen if nothing is left on the queue
</code></pre>

<p>I have then tried making one of these iterators as well as a prefetch iterator like so:</p>

<pre><code>mgr      = ProcessMgr(2, end_date_str)
mgrOuter = mx.io.PrefetchingIter([mgr])
</code></pre>

<p>The problem is that <code>mgrOuter</code> immediately throws a <code>StopIteration</code> as soon as <code>__next__()</code> is called the first time, and without invoking <code>mgr.__next__()</code> as I thought it might.</p>

<p>Finally, I also noticed that <code>gluon</code> has a <code>DataLoader</code> object which <a href=""https://mxnet.incubator.apache.org/api/python/gluon/data.html?highlight=dataset#mxnet.gluon.data.Dataset"" rel=""nofollow noreferrer"">seems like it might handle prefetching</a>, however in this case it also seems to assume that the underlying data is from a <code>Dataset</code> which has a finite and unchanging layout (based on the fact that it is implemented in terms of <code>getitem</code>, which takes an index). So I have not pursued this option as it seem unpromising given the dynamic queue-like nature of the data I am generating as training input.</p>

<p>My questions are:</p>

<ul>
<li><strong>How do I need to modify my code above so that there will be prefetching for my custom iterator?</strong></li>
<li><strong>Where might I find an example or more detailed documentation of how mx.io.PrefetchingIter works?</strong></li>
<li>Are there other strategies I should be aware of for getting more performance out of my GPUs via a custom iterator? Right now they are only operating at around 50% capacity, and upping (or lowering) the batch size doesn't change this. What other knobs might I be able to turn to increase GPU use efficiency?</li>
</ul>

<p>Thanks for any feedback and advice.</p>
","<python><iterator><gpu><mxnet><prefetch>","2018-12-07 21:26:26","","0","8762321","2019-01-03 18:07:39","1","0","","","8762321","116","7","0"
"45079947","<p>How can I modify the iterator in this example (<a href=""https://github.com/dmlc/mxnet/blob/master/example/fcn-xs/data.py"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/blob/master/example/fcn-xs/data.py</a>) to read images from AWS s3. I have .png images in a folder in AWS s3. I tried passing the rootdir as s3://bucketname/folder. I have also tried to change the function that reads images from Image (by PIL) to imdecode (by mx.image). I had no luck in both cases.
I have an image segmentation problem. my input is an image and my output is an image too.</p>
","<mxnet>","2017-07-13 11:57:30","","0","4127806","2017-07-18 17:47:34","1","1","","","4127806","670","709","0"
"54110436","<p>I am working in Mxnet for image classification. I loaded dataset with RecordFileDetection class. I want to print the shape of data and label. But it shows the error.</p>

<p>My code segment is:</p>

<pre><code>  from gluoncv.data import RecordFileDetection
  train_data_loader=RecordFileDetection('/home/vj/
                    Desktop/example_rec.rec',coord_normalized=True)
  print(len(train_data_loader))
  data =train_data_loader[0][1]
  print(data.shape)
</code></pre>

<hr>

<p>Traceout</p>

<h2>939</h2>

<pre><code> IndexError                                Traceback (most recent call 
 last)
 &lt;ipython-input-70-3bc3bb8bd0b5&gt; in &lt;module&gt;()
  2 
 train_data_loader=RecordFileDetection('/home/vj/
 Desktop/example_rec.rec',coord_normalized=True)
       3 print(len(train_data_loader))
 ----&gt; 4 data =train_data_loader[0][1]
       5 print(data.shape)

 /usr/local/lib/python2.7/dist-packages/gluoncv/data/
recordio/detection.pyc in __getitem__(self, idx)
      71         h, w, _ = img.shape
      72         if self._coord_normalized:
 ---&gt; 73             label = _transform_label(label, h, w)
      74         else:
      75             label = _transform_label(label)

 /usr/local/lib/python2.7/dist- 
 packages/gluoncv/data/recordio/detection.pyc in 
 _transform_label(label, height, width)
       8     label = np.array(label).ravel()
       9     header_len = int(label[0])  # label header
 ---&gt; 10     label_width = int(label[1])  # the label width for each 
                                                object, &gt;= 5
      11     if label_width &lt; 5:
      12         raise ValueError(

      IndexError: index 1 is out of bounds for axis 0 with size 1
</code></pre>

<p>I am not getting what is the error. Please kindly help me.</p>

<p>Thanks in advance</p>
","<python><mxnet><index-error>","2019-01-09 12:42:34","","1","10170614","2019-01-10 23:57:34","0","2","","","10170614","26","0","0"
"53752811","<p>My desktop has 2 gpu installed: 1080 and 1080Ti
nvidia-smi shows that gpu-0 is 1080 and gpu-1 is 1080Ti</p>

<pre><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 00000000:01:00.0 Off |                  N/A |
| 26%   57C    P2    53W / 215W |    696MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
| 55%   70C    P2   204W / 250W |   8641MiB / 11178MiB |     28%      Default |
+-------------------------------+----------------------+----------------------+
</code></pre>

<p>Right now both <strong>tensorflow</strong> and <strong>mxnet</strong> use reversed order: 1080ti when I specify gpu=0 and 1080 when I specify gpu=1.</p>

<p><strong>Why is it happening and how to synchronize tensorflow and mxnet gpu order with nvidia-smi gpu order?</strong></p>

<p>Code snippets for mxnet:</p>

<pre><code>mod = mx.mod.Module(symbol, label_names=None, context=mx.gpu(0))
</code></pre>

<p>For tensorflow I use environment variable</p>

<pre><code>CUDA_VISIBLE_DEVICES=""0""   
</code></pre>
","<python><tensorflow><mxnet>","2018-12-12 23:12:20","","2","5623476","2018-12-13 09:28:32","1","0","2","","5623476","161","1490","0"
"54142313","<p>I'm tried to train my code with gpu in jupyter .But i don't get the right gpu.</p>

<p>my environment is :
windows10, 
 cuda8, 
 python3.6,
 mxnetgpu,
jupyter .</p>

<p>my code is:</p>

<pre><code>a = nd.array([1, 2, 3], ctx=mx.gpu())
</code></pre>

<p>But my error like this:</p>

<pre><code>MXNetError                                Traceback (most recent call last)
    &lt;ipython-input-6-3c78e5d2ccff&gt; in &lt;module&gt;
    ----&gt; 1 a = nd.array([1, 2, 3], ctx=mx.gpu())
          2 a

    d:\data\python\lib\site-packages\mxnet\ndarray\utils.py in array(source_array, ctx, dtype)
    144         return _sparse_array(source_array, ctx=ctx, dtype=dtype)
    145     else:
--&gt; 146         return _array(source_array, ctx=ctx, dtype=dtype)
    147 
    148 

d:\data\python\lib\site-packages\mxnet\ndarray\ndarray.py in array(source_array, ctx, dtype)
   2432             except:
   2433                 raise TypeError('source_array must be array like object')
-&gt; 2434     arr = empty(source_array.shape, ctx, dtype)
   2435     arr[:] = source_array
   2436     return arr

d:\data\python\lib\site-packages\mxnet\ndarray\ndarray.py in empty(shape, ctx, dtype)
   3818     if dtype is None:
   3819         dtype = mx_real_t
-&gt; 3820     return NDArray(handle=_new_alloc_handle(shape, ctx, False, dtype))
   3821 
   3822 

d:\data\python\lib\site-packages\mxnet\ndarray\ndarray.py in _new_alloc_handle(shape, ctx, delay_alloc, dtype)
    137         ctypes.c_int(int(delay_alloc)),
    138         ctypes.c_int(int(_DTYPE_NP_TO_MX[np.dtype(dtype).type])),
--&gt; 139         ctypes.byref(hdl)))
    140     return hdl
    141 

d:\data\python\lib\site-packages\mxnet\base.py in check_call(ret)
    250     """"""
    251     if ret != 0:
--&gt; 252         raise MXNetError(py_str(_LIB.MXGetLastError()))
    253 
    254 

MXNetError: [15:25:07] C:\Jenkins\workspace\mxnet-tag\mxnet\src\storage\storage.cc:137: Compile with USE_CUDA=1 to enable GPU usage
</code></pre>

<p>I amend my configuration file adding path and USE CUDA.But it don't work!How to solve it?</p>
","<jupyter><mxnet>","2019-01-11 07:47:09","","1","7786383","2019-01-16 01:22:32","1","0","","","7786383","27","0","0"
"45798125","<p>I am new to <em>MXNet</em> and want to solve a simple example that uses 1 layer network to solve the digit classification problem. My program goes as follows:</p>

<pre><code>import math
import numpy as np
import mxnet as mx
import matplotlib.pyplot as plt
import logging
logging.getLogger().setLevel(logging.DEBUG)
#============================================================
with np.load(""notMNIST.npz"") as data:

    images, labels = data[""images""], data[""labels""]

# Reshape the images from 28x28 into 784 1D-array and flaten the labels. 
images = images.reshape(784, 18720) labels = labels.reshape(18720)

# Apply one-hot encoding. 
Images = images.T.astype(np.float32) 
Labels = np.zeros((18720, 10)).astype(np.float32) 
Labels[np.arange(18720), labels] = 1

# Segment the data into training, evaluation and testing. 
X_train = Images[0 : 15000] 
y_train = Labels[0 : 15000]

X_eval = Images[15000 : 16000] 
y_eval = Labels[ 1200 :  2200] # IMPORTANT!!!

X_test = Images[16000 : 18720] 
y_test = Labels[16000 : 18720]

train_iter = mx.io.NDArrayIter(X_train, y_train, 100, shuffle=False)
_eval_iter = mx.io.NDArrayIter(X_eval , y_eval , 100, shuffle=False)
#============================================================
# Variables
X = mx.sym.Variable(name='data')

# Neural Network Layers
fully_connected_layer = mx.sym.FullyConnected(data=X, name='fc1', num_hidden=10)

# Outputs
lro = mx.sym.SoftmaxOutput(data=fully_connected_layer, name=""softmax"")
#============================================================

model = mx.mod.Module(symbol=lro)

model.fit(train_data=train_iter, eval_data=_eval_iter, 
          optimizer='sgd', optimizer_params={
              'learning_rate' : 1e-5, 
              'momentum' : 0.1}, 
          eval_metric=""acc"",
          num_epoch=500)
</code></pre>

<p>After running the program with evaluation label <code>15000</code> to <code>16000</code>, the final step is reporting a validation accuracy of <code>97%</code>, which I personally argue is too high for a 1-layer network. Therefore, I deliberately changed the evaluation labels to <code>1200</code> to <code>2200</code> and saw that the program is still reporting an accuracy at around <code>83~86%</code> (at first I thought that maybe it is just a coincidence and tried several different evaluation labels but still got similar results).</p>

<p>What mistakes have I made in my program? </p>
","<mxnet>","2017-08-21 13:15:24","","0","6320608","2018-01-27 00:01:13","1","0","","","6320608","92","42","0"
"46312238","<p>I've see some benchmark about <code>tensorflow</code> and <code>pytorch</code>. <code>Tensorflow</code> maybe faster but seems not that faster even sometimes slower. </p>

<p>Is there any benchmark on specifically testing on static graph and dynamic graph demonstrating that static graph is much faster that dynamic graph?</p>
","<tensorflow><torch><tensorflow-gpu><pytorch><mxnet>","2017-09-20 02:18:50","","1","1831512","2017-09-24 18:27:03","2","0","","","1831512","995","306","132"
"43720898","<p>I was following this tutorial <a href=""http://mxnet.io/tutorials/r/fiveMinutesNeuralNetwork.html#regression"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/r/fiveMinutesNeuralNetwork.html#regression</a>
Everything worked accordingly but when I changed:</p>

<pre><code>fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden=1)
</code></pre>

<p>to</p>

<pre><code>fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden=2)
</code></pre>

<p>And among the stacks of error logs I thought may be this is the most interesting:</p>

<pre><code>    Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
    [20:22:59] src/ndarray/ndarray.cc:239: Check failed: from.shape() == to-&gt;shape() 
 shape mismatchfrom.shape = (20,) to.shape=(20,2)
</code></pre>

<p>How do I diagnose this problem? </p>

<p>Here is the output of sessionInfo():</p>

<pre><code>R version 3.3.3 RC (2017-02-27 r72279)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mlbench_2.1-1 mxnet_0.9.5  

loaded via a namespace (and not attached):
 [1] igraph_1.0.1       Rcpp_0.12.10       rstudioapi_0.6     magrittr_1.5       munsell_0.4.3      colorspace_1.3-2  
 [7] viridisLite_0.2.0  R6_2.2.0           brew_1.0-6         stringr_1.2.0      plyr_1.8.4         dplyr_0.5.0       
[13] visNetwork_1.0.3   Rook_1.1-1         tools_3.3.3        grid_3.3.3         gtable_0.2.0       DBI_0.6           
[19] influenceR_0.1.0   DiagrammeR_0.9.0   htmltools_0.3.5    lazyeval_0.2.0     digest_0.6.12      assertthat_0.1    
[25] tibble_1.2         gridExtra_2.2.1    RColorBrewer_1.1-2 ggplot2_2.2.1      codetools_0.2-8    htmlwidgets_0.8   
[31] viridis_0.4.0      rgexf_0.15.3       stringi_1.1.3      scales_0.4.1       XML_3.98-1.6       jsonlite_1.3   
</code></pre>
","<r><deep-learning><mxnet>","2017-05-01 14:36:44","","0","3508066","2018-03-09 00:07:27","1","2","","","3508066","25","15","0"
"50204374","<p>I am trying to implement my customer layer for neural network using mxnet. I was wondering if there is a function in mxnet similar to <a href=""https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.bincount.html"" rel=""nofollow noreferrer"">np.bincount</a>. If not, is there a way I can calculate it without having to convert my <code>mx.ndarray</code> to <code>numpy</code>?</p>
","<mxnet>","2018-05-06 20:46:25","","0","2796123","2018-05-12 00:14:15","1","0","","","2796123","193","62","1"
"44992631","<p>I want to add some conditional control in my symbol, it seems that if-else is evaluated in symbol construction time. But I want it to evaluated in symbol run time.</p>

<pre><code>a = mx.symbol.Variable(name='a')
b = mx.symbol.Variable(name='b')

if a&gt;b:
    c = a-b
else:
    c = a+b
</code></pre>

<p>TensorFlow provides the tf.cond() operator to deal with it, is there a counterpart in mxnet?</p>
","<mxnet>","2017-07-09 03:11:53","","2","7324721","2017-07-11 03:54:18","1","0","","","7324721","79","14","0"
"45691432","<p>I want to use mxnet Image API to load grayscale png file.
But Image API became 3channel RGB data.
How to convert from 3channel data to 1channel data?</p>
","<mxnet>","2017-08-15 10:54:18","","0","2850652","2017-08-15 18:58:02","1","0","","","2850652","31","0","0"
"41294025","<p>I want to train an lstm neural net using the mx.lstm function in the R package mxnet. My data comprises <em>n</em> feature vectors, a vector of labelled classes and a time vector, much like this dummy example where X1, X2, X3 are the features:</p>

<pre><code>dat &lt;- data.frame(
  X1 = rnorm(100, 1, sd = 1),
  X2 = rnorm(100, 2, sd = 1),
  X3 = rnorm(100, 3, sd = 1),
  class = sample(c(1,0), replace = T, 100),
  time =  seq(0.01,1,0.01))
</code></pre>

<p>Help for mx.lstm states that the train.data argument requires ""mx.io.DataIter or list(data=R.array, label=R.array) The Training set"".</p>

<p>I have tried this:</p>

<pre><code>library(mxnet)

# Convert dummy data into suitable format
trainDat &lt;- list(data = array(c(dat$X1, dat$X2, dat$X3), dim = c(100,3)), 
label = array(dat[,4], dim = c(100,1)))

# Set the basic network parameters for the lstm (arbitrary for this example)
batch.size = 32
seq.len = 32
num.hidden = 16
num.embed = 16
num.lstm.layer = 1
num.round = 1
learning.rate = 0.1
wd = 0.00001
clip_gradient = 1
update.period = 1

# Run the model
model &lt;- mx.lstm(train.data = trainDat,
             ctx=mx.cpu(),
             num.round=num.round, 
             update.period=update.period,
             num.lstm.layer=num.lstm.layer, 
             seq.len=seq.len,
             num.hidden=num.hidden, 
             num.embed=num.embed, 
             num.label=vocab,
             batch.size=batch.size, 
             input.size=vocab,
             initializer=mx.init.uniform(0.1), 
             learning.rate=learning.rate,
             wd=wd,
             clip_gradient=clip_gradient)
</code></pre>

<p>Which returns ""Error in mx.io.internal.arrayiter(as.array(data), as.array(label), unif.rnds,  : 
  basic_string::_M_replace_aux""</p>

<p>There is an example lstm on the mxnet website, but the data used are quite different to mine and I can't make sense of it.</p>

<p><a href=""http://mxnet.io/tutorials/r/charRnnModel.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/r/charRnnModel.html</a></p>

<p>So, my question is how do I transform my data into a suitable format for mx.lstm?</p>
","<r><neural-network><mxnet>","2016-12-23 01:29:10","","2","3260632","2016-12-28 20:08:10","1","0","1","","3260632","20","2","0"
"44582493","<p>I'm a newbie in mshadow, I can not understand why I got those outpus from the following code snippet:</p>

<pre><code>TensorContainer&lt;cpu, 2&gt; lhs(Shape2(2, 3));
lhs = 1.0;
printf(""%u %u\n"", lhs.size(0), lhs.size(1));
printf(""%u %u\n"", lhs[0].shape_[0], lhs[0].shape_[1]);
printf(""%u %u\n"", lhs[0].size(0), lhs[0].size(1));
</code></pre>

<p>The output is:</p>

<pre><code>2 3
3 4
3 3
</code></pre>

<p>Why are the second and third outputs those numbers? Because <code>lhs[0]</code> is one-dimensional, I think they should be exactly the same, i.e. <code>3 0</code>. Could anyone tell me where I was wrong? Thanks in advance!</p>
","<shape><mxnet><tensor>","2017-06-16 06:41:53","","1","4394807","2017-08-02 21:55:45","1","0","","","4394807","499","28","1"
"44632332","<p>I am writing a custom op, and I got stucked when writing the backward part. </p>

<p>When I call <em>out_grad[0].asnumpy()</em> or do any manipulation of the out_grad, the program crash without any error message. </p>

<p>I tried fill the in_grad with zeros, the program run smoothly, but I need the grad to flow backward.
<code>
    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):
            self.assign(in_grad[0], req[0], 0)
            self.assign(in_grad[1], req[1], 0)
</code></p>

<p>What's going wrong here?</p>
","<mxnet>","2017-06-19 13:46:16","","0","7324721","2017-06-21 08:01:17","2","2","","","7324721","79","14","0"
"51092421","<h2>Error from importing <code>keras</code></h2>

<pre><code>&gt;&gt;&gt; import keras
/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/daal/__init__.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/keras/__init__.py"", line 3, in &lt;module&gt;
    from . import utils
  File ""/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/keras/utils/__init__.py"", line 6, in &lt;module&gt;
    from . import conv_utils
  File ""/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/keras/utils/conv_utils.py"", line 9, in &lt;module&gt;
    from .. import backend as K
  File ""/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/keras/backend/__init__.py"", line 98, in &lt;module&gt;
    raise ValueError('Invalid backend. Missing required entry : ' + e)
ValueError: Invalid backend. Missing required entry : placeholder
</code></pre>

<h3>I installed mxnet correctly:</h3>

<pre><code>&gt;&gt;&gt; import mxnet as mx
/Users/ray_zhang/anaconda3/envs/idp3/lib/python3.6/site-packages/daal/__init__.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
&gt;&gt;&gt; a = mx.nd.ones((2,3))
&gt;&gt;&gt; b = a*2+1
&gt;&gt;&gt; b.asnumpy()
array([[3., 3., 3.],
       [3., 3., 3.]], dtype=float32)
</code></pre>

<h3>My keras in pip</h3>

<pre><code>(idp3) ❯ pip freeze | grep keras
keras-mxnet==2.2.0
</code></pre>

<h3><code>~/.keras/keras.json</code></h3>

<pre><code>(idp3) ❯ cat ~/.keras/keras.json
{
    ""floatx"": ""float32"",
    ""epsilon"": 1e-07,
    ""backend"": ""mxnet"",
    ""image_data_format"": ""channels_last""
}
</code></pre>

<p>It appears that my <code>__init__.py</code> in my keras site packages is not the same as the current github version's:</p>

My <code>keras/backend/__init__.py</code>

<pre><code># Import backend functions.
if _BACKEND == 'cntk':
    sys.stderr.write('Using CNTK backend\n')
    from .cntk_backend import *
elif _BACKEND == 'theano':
    sys.stderr.write('Using Theano backend.\n')
    from .theano_backend import *
elif _BACKEND == 'tensorflow':
    sys.stderr.write('Using TensorFlow backend.\n')
    from .tensorflow_backend import *
else:
    # Try and load external backend.
    ...
</code></pre>

<p>But in <a href=""https://github.com/awslabs/keras-apache-mxnet/blob/332c62f7b521b109431c0ef91317b2ce00e4cfb7/keras/backend/__init__.py#L79"" rel=""nofollow noreferrer"">keras-mxnet's github rep</a>o:</p>

<pre><code># Import backend functions.
if _BACKEND == 'cntk':
    sys.stderr.write('Using CNTK backend\n')
    from .cntk_backend import *
elif _BACKEND == 'theano':
    sys.stderr.write('Using Theano backend.\n')
    from .theano_backend import *
elif _BACKEND == 'tensorflow':
    sys.stderr.write('Using TensorFlow backend.\n')
    from .tensorflow_backend import *
elif _BACKEND == 'mxnet':
    sys.stderr.write('Using MXNet backend\n')
    from .mxnet_backend import *
else:
    # Try and load external backend.
    ...
</code></pre>
","<python><pip><keras><mxnet>","2018-06-28 23:31:40","","0","3781180","2018-07-08 20:49:47","1","0","","","3781180","1555","81","21"
"45113786","<p>I would like to supply to a network many training images that are sampled from a dataset by following certain sampling rules. Now I have two choices:</p>

<ol>
<li><p>Use the sampling logic to generate a list of images offline, then convert the .lst file to .rec file and use an sequential DataIter to access it.</p></li>
<li><p>Write my own child class of DataIter that can sample the images online. As a result, the class need to support random access, maybe inheriting from MXIndexedRecordIO. I will need to create a .rec file for the original dataset.</p></li>
</ol>

<p>My intuition tells me that sequential access will be faster than random access for a .rec file. But I don't know if the difference is big enough to worth the additional time I spend in writing and testing my own iterator class. Could anyone give me a hint on this?</p>
","<mxnet>","2017-07-15 02:11:00","","0","8310455","2017-07-22 03:50:18","2","1","","","8310455","3","0","0"
"45731727","<p>I am trying to understand how PyTorch works and want to replicate a simple CNN training on CIFAR. The <a href=""https://github.com/ilkarman/Blog/blob/master/DL-Examples/CNTK_CIFAR.ipynb"" rel=""nofollow noreferrer"">CNTK</a> script gets to <strong>0.76</strong> accuracy after 168 seconds of training (10 epochs), which is similar to my <a href=""https://github.com/ilkarman/Blog/blob/master/DL-Examples/MXNet_CIFAR.ipynb"" rel=""nofollow noreferrer"">MXNet</a> script (<strong>0.75</strong> accuracy after 153 seconds).</p>

<p>However, my <a href=""https://github.com/ilkarman/Blog/blob/master/DL-Examples/PyTorch_CIFAR.ipynb"" rel=""nofollow noreferrer"">PyTorch</a> script is lagging behind a lot at <strong>0.71</strong> accuracy and 354 seconds. I appreciate I will get differences in accuracy due to stochastic weight initialisation, etc. However the difference across frameworks is much greater than difference within a framework, initialising randomly between runs.</p>

<p>The reasons I can think of:</p>

<ul>
<li>MXNet and CNTK are initialized to xavier/glorot uniform; not sure how to do this in PyTorch and so perhaps the weights are initialised to 0</li>
<li>CNTK does gradient-clipping by default; not sure if PyTorch has the equivalent</li>
<li>Perhaps the bias is dropped in PyTorch by default</li>
<li>I use SGD with momentum; perhaps the PyTorch implementation of momentum is a bit different</li>
</ul>

<p>Edit:</p>

<p>I have tried specifying the weight initialisation, however it seems to have no big effect:</p>

<pre><code>self.conv1 = nn.Conv2d(3, 50, kernel_size=3, padding=1)
init.xavier_uniform(self.conv1.weight, gain=np.sqrt(2.0))
init.constant(self.conv1.bias, 0)
</code></pre>
","<machine-learning><deep-learning><cntk><pytorch><mxnet>","2017-08-17 09:45:08","","1","6772173","2017-08-17 21:48:03","1","0","","","6772173","29","2","0"
"44558127","<p>The command ""ctx=mx.cpu()"" is taking all available CPU. How to restrict to use a certain number only - say 6 out of 8 core</p>
","<deep-learning><mxnet>","2017-06-15 03:40:43","","0","4836299","2017-08-03 23:11:03","1","2","1","","4836299","92","0","0"
"50652176","<p>How can I perform data augmentation when I use ROI-Pooling in a CNN network which I developed using MXnet ?</p>

<p>For example suppose I have a resnet50 architecture which uses a roi-pooling layer and I want to use random-crops data augmentation in the ImageRecord Iterator.</p>

<p>Is there an automatic way that data coordinates in the rois passed to the roi pooling layer, transform so as to be applied in images generated by the data-augmentation process of the ImageRecord Iterator ?</p>
","<deep-learning><mxnet><convolutional-neural-network>","2018-06-01 23:40:31","","0","1351721","2018-06-08 18:11:50","1","0","","","1351721","270","113","3"
"44717363","<p>I have a training set looks something like this.</p>

<p>features:categorical/numerical</p>

<p>output:binary 1/0</p>

<pre><code>[1] feature[1][1] feature[1][2] ... feature[1][j]
[2] feature[2][1] feature[2][2] ... feature[2][j]
.
.
.
[i] feature[i][1] feature[i][2] ... feature[i][j]
</code></pre>

<p>Suppose some samples(row) have ""good"" value combinations that are likely to yield similar output, whereas others have ""bad"" value combinations thus difficult to predict.</p>

<p>My goal is, by getting rid of of those bad samples which lack regularity, I want to improve final accuracy. Can someone tell me what could be the best algorithm or preprocess to automatically detect those samples so that only the good samples are going to be trained? Thank you in advance!</p>

<p>ENV: MXNet, R</p>
","<r><ruby><machine-learning><deep-learning><mxnet>","2017-06-23 09:03:36","","0","8182049","2018-05-04 22:31:43","1","4","","","8182049","3","0","0"
"53367724","<p>In the tensor flow Github repository, in the file <a href=""https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L1025"" rel=""nofollow noreferrer"">attentionwrapper.py</a>, hardmax operator has been defined. On the docs, it has been mentioned <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/hardmax"" rel=""nofollow noreferrer"">tf.contrib.seq2seq.hardmax</a></p>

<p>I want to know what's the theoretical underpinning behind providing this functionality for hardmax operator. Prima facie google searches for past few weeks haven't led me to concrete understanding of the concept. </p>

<ol>
<li><p>If softmax is differentiable (soft), why would hardmax be ever used? If it can't be used in back propagation (due to non-differentiability required in gradient calculation), where else can it be used?</p></li>
<li><p>Reinforcement learning literature talks about Soft vs Hard attention. However I couldn't see concrete examples nor explanations of where the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/hardmax"" rel=""nofollow noreferrer"">tf.contrib.seq2seq.hardmax</a> can be actually used in some RL model.</p></li>
<li><p>By the looks of it, since it is mentioned in seq2seq, it should be obviously having some application in Natural Language Processing. But exactly where? There are tonnes of NLP tasks. Couldn't find any direct task SOTA algorithm which uses hardmax.</p></li>
</ol>
","<python><tensorflow><pytorch><mxnet>","2018-11-19 02:59:07","","0","5157515","2018-11-19 03:05:38","1","0","","","5157515","327","1003","6"
"52448466","<p>I have my workload partitioned on two GPUs (aka, model partitioning). By default, TF/Keras allocates all the gradients on GPU0 but I want to use the <code>colocate_gradients_with_ops</code> to spread the allocation across two GPU. </p>

<p>I'm looking for a simple way to do that in Keras. My way was to create a new optimizer subclassed from <code>tf.train.AdamOptimizer</code> just to flip the default value of <code>colocate_gradients_with_ops</code> (from <code>False</code> to <code>True</code>) . Also I have to flip it in two methods!</p>

<p>I'm looking for a shorter, more direct way than the one below in Keras. </p>

<pre><code>class MyAdamOptimizer(tf.train.AdamOptimizer):
    def compute_gradients(self,
                          loss,
                          var_list=None,
                          gate_gradients=tf.train.Optimizer.GATE_OP,
                          aggregation_method=None,
                          colocate_gradients_with_ops=True,
                          grad_loss=None):
        return super(MyAdamOptimizer, self).compute_gradients(
            loss,
            var_list=None,
            gate_gradients=tf.train.Optimizer.GATE_OP,
            aggregation_method=None,
            colocate_gradients_with_ops=True,
            grad_loss=None)

    def minimize(
            loss,
            global_step=None,
            var_list=None,
            gate_gradients=tf.train.Optimizer.GATE_OP,
            aggregation_method=None,
            colocate_gradients_with_ops=True,
            name=None,
            grad_loss=None):
        return super(MyAdamOptimizer, self).minimize(
            loss,
            global_step=None,
            var_list=None,
            gate_gradients=tf.train.Optimizer.GATE_OP,
            aggregation_method=None,
            colocate_gradients_with_ops=True,
            name=None,
            grad_loss=None)
</code></pre>

<p>Then I call</p>

<pre><code>model.compile(optimizer=MyAdamOptimizer(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
</code></pre>
","<tensorflow><keras><mxnet>","2018-09-21 17:22:01","","0","1363774","2018-10-25 16:59:09","1","0","","","1363774","495","136","4"
"54401868","<p>trying to run a script, when i get </p>

<pre><code>(infacepytorch) ryan@ryan-7570:/media/ryan/shakira/InsightFace_Pytorch$ python face_verify.py 
Traceback (most recent call last):
  File ""face_verify.py"", line 9, in &lt;module&gt;
from Learner import face_learner
  File ""/media/ryan/shakira/InsightFace_Pytorch/Learner.py"", line 1, in &lt;module&gt;
    from data.data_pipe import de_preprocess, get_train_loader, get_val_data
  File ""/media/ryan/shakira/InsightFace_Pytorch/data/data_pipe.py"", line 12, in &lt;module&gt;
import mxnet as mx
  File ""/home/ryan/virtualenvs/infacepytorch/lib/python3.5/site-packages/mxnet/__init__.py"", line 24, in &lt;module&gt;
from .context import Context, current_context, cpu, gpu, cpu_pinned
  File ""/home/ryan/virtualenvs/infacepytorch/lib/python3.5/site-packages/mxnet/context.py"", line 24, in &lt;module&gt;
from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
  File ""/home/ryan/virtualenvs/infacepytorch/lib/python3.5/site-packages/mxnet/base.py"", line 213, in &lt;module&gt;
_LIB = _load_lib()
  File ""/home/ryan/virtualenvs/infacepytorch/lib/python3.5/site-packages/mxnet/base.py"", line 204, in _load_lib
lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""/usr/lib/python3.5/ctypes/__init__.py"", line 347, in __init__
self._handle = _dlopen(self._name, mode)
OSError: libcudart.so.9.2: cannot open shared object file: No such file or directory
</code></pre>

<p>I have tried </p>

<pre><code>export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64 &amp;&amp; sudo ldconfig
</code></pre>

<p>but i still get the same error,
Any suggestions would be really helpfull, Thanks in advance.</p>
","<cuda><mxnet>","2019-01-28 12:17:27","","0","8176285","2019-03-01 23:24:53","1","1","","","8176285","1121","122","23"
"45383926","<p>So I am trying to use image recognition using the mxnet package in R using a CNN to try and predict a scalar output (in my case wait time) based on the image. </p>

<p>However, when I do this, I get the same resultant output (it predicts the same number which is probably just the average of all of the results). How do I get it to predict the scalar output correctly.</p>

<p>Also, my image has already been pre-processed by greyscaling it and converting into the pixel format below.
I am essentially using images to predict wait times which is why my train_y is the current wait times in seconds, hence why I didn't convert it into a [0,1] range. I would prefer a regression type output or some kind of scalar output that outputs the predicted wait time based on the image.</p>

<p>What other ways would you recommend to tackle this problem, not sure if my approach is correct.</p>

<p>Here is my reproducible code: </p>

<pre><code>set.seed(0)

df &lt;- data.frame(replicate(784,runif(7538)))
df$waittime &lt;- 1000*runif(7538)


training_index &lt;- createDataPartition(df$waittime, p = .9, times = 1)
training_index &lt;- unlist(training_index)

train_set &lt;- df[training_index,]
dim(train_set)
test_set &lt;- df[-training_index,]
dim(test_set)


## Fix train and test datasets
train_data &lt;- data.matrix(train_set)
train_x &lt;- t(train_data[, -785])
train_y &lt;- train_data[,785]
train_array &lt;- train_x
dim(train_array) &lt;- c(28, 28, 1, ncol(train_array))


test_data &lt;- data.matrix(test_set)
test_x &lt;- t(test_set[,-785])
test_y &lt;- test_set[,785]
test_array &lt;- test_x
dim(test_array) &lt;- c(28, 28, 1, ncol(test_x))




library(mxnet)
## Model
mx_data &lt;- mx.symbol.Variable('data')
## 1st convolutional layer 5x5 kernel and 20 filters.
conv_1 &lt;- mx.symbol.Convolution(data = mx_data, kernel = c(5, 5), num_filter = 20)
tanh_1 &lt;- mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 &lt;- mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel = c(2, 2), stride = c(2,2 ))
## 2nd convolutional layer 5x5 kernel and 50 filters.
conv_2 &lt;- mx.symbol.Convolution(data = pool_1, kernel = c(5,5), num_filter = 50)
tanh_2 &lt;- mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 &lt;- mx.symbol.Pooling(data = tanh_2, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))
## 1st fully connected layer
flat &lt;- mx.symbol.Flatten(data = pool_2)
fcl_1 &lt;- mx.symbol.FullyConnected(data = flat, num_hidden = 500)
tanh_3 &lt;- mx.symbol.Activation(data = fcl_1, act_type = ""tanh"")
## 2nd fully connected layer
fcl_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 1)
## Output
#NN_model &lt;- mx.symbol.SoftmaxOutput(data = fcl_2)
label &lt;- mx.symbol.Variable(""label"")
#NN_model &lt;- mx.symbol.MakeLoss(mx.symbol.square(mx.symbol.Reshape(fcl_2, shape = 0) - label))
NN_model &lt;- mx.symbol.LinearRegressionOutput(fcl_2)


## Device used. Sadly not the GPU :-(
#device &lt;- mx.gpu
#Didn't work well, predicted same number continuously regardless of image
## Train on 1200 samples
model &lt;- mx.model.FeedForward.create(NN_model, X = train_array, y = train_y,
                                     #                                     ctx = device,
                                     num.round = 30,
                                     array.batch.size = 100,
                                     initializer=mx.init.uniform(0.002), 
                                     learning.rate = 0.00001,
                                     momentum = 0.9,
                                     wd = 0.00001,
                                     eval.metric = mx.metric.rmse)
                                     epoch.end.callback = mx.callback.log.train.metric(100))



pred &lt;- predict(model, test_array)
#gives the same numeric output 
</code></pre>
","<r><image-processing><conv-neural-network><image-recognition><mxnet>","2017-07-29 00:02:25","","0","8277792","2018-01-08 08:07:49","2","4","","","8277792","76","5","0"
"46007285","<p>Given an index array <code>index</code> and, say, a matrix <code>A</code> I want a matrix <code>B</code> with the corresponding permutation of the columns of <code>A</code>.</p>

<p>In Numpy I would do the following,</p>

<pre><code>&gt;&gt;&gt; A = np.arange(6).reshape(2,3); A
array([[0, 1, 2],
       [3, 4, 5]])
&gt;&gt;&gt; index = [2,0,1]
&gt;&gt;&gt; A[:,index]
array([[2, 0, 1],
       [5, 3, 4]])
</code></pre>

<p>Is there a <strong><em>natural</em></strong> or <strong><em>efficient</em></strong> way to do this in MXNet? The functions <a href=""https://mxnet.incubator.apache.org/api/python/ndarray.html#mxnet.ndarray.pick"" rel=""nofollow noreferrer""><code>pick()</code></a> and <a href=""https://mxnet.incubator.apache.org/api/python/ndarray.html#mxnet.ndarray.take"" rel=""nofollow noreferrer""><code>take()</code></a> don't seem to work in this way. I managed to come up with the following but it's not elegant.</p>

<pre><code>&gt;&gt;&gt; mx.nd.take(A.T, mx.nd.array([[2],[0],[1]])).T.reshape((2,3))

[[ 2.  0.  1.]
 [ 5.  3.  4.]]
&lt;NDArray 2x3 @cpu(0)&gt;
</code></pre>

<p>Finally, to throw a wrench into the works, is there a way to do this in-place?</p>

<p><strong>Update</strong> Here is a slightly more elegant, but presumably not as efficient (due to the transposition), version of above:</p>

<pre><code>&gt;&gt;&gt; mx.nd.take(A.T, mx.nd.array([2,0,1])).T
[[ 2.  0.  1.]
 [ 5.  3.  4.]]
&lt;NDArray 2x3 @cpu(0)&gt;
</code></pre>
","<mxnet>","2017-09-01 20:02:49","","2","645494","2017-10-18 05:50:41","1","1","","","645494","331","21","1"
"54935190","<p>I am currently training a convolutional neural network using Mxnet, with the C++ Symbol API. This network contains some Batchnormalization layers, which contains the four parameter NDArray. Two of them, the moving_mean and moving_variance parameter are supposed to be updated at every batch during the training.</p>

<p>I was guessing that, since the boolean for the forward pass of the executor is set to <code>true</code>, it would update automatically the new parameters. However, for some reasons, these two NDArray remains still, without any update of the parameter.  How so? Besides, since there are no gradients computed for these two NDArray, because it is not ""learnable"" parameters, I have no way to update the values through the regular optimizer update function. How to tell Mxnet, using the symbol API, to update the moving_mean and moving_variance NDArrays?</p>
","<c++><mxnet>","2019-02-28 22:21:18","","0","7128430","2019-04-04 23:57:37","1","0","","","7128430","100","17","0"
"55017740","<ul>
<li>os : windows 10 64bits</li>
<li>compiler : vc2015 64bits update 3</li>
<li>mxnet : 1.3.1</li>
</ul>

<p>Building mxnet 1.3.1（mxnet1.4.0 has bugs, can't build it under windows，please check<a href=""https://github.com/apache/incubator-mxnet/issues/11769"" rel=""nofollow noreferrer"">14203</a> for more details).</p>

<p>I can build the mxnet with cpp-package, but when I call the forward function o the Executor, it keep throwing</p>

<p><strong>Intel MKL FATAL ERROR: Cannot load mkl_intel_thread.dll.</strong></p>

<p>Following are my steps to build the mxnet</p>

<ol>
<li>git clone --recursive <a href=""https://github.com/apache/incubator-mxnet"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet</a> mxnet</li>
<li>cd mxnet</li>
<li>Download intel mkl(w_mkl_2019.2.190.exe)</li>
<li>install it</li>
<li>open cmake3.11.0</li>
<li><a href=""https://i.stack.imgur.com/p9Twz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/p9Twz.jpg"" alt=""enter image description here""></a></li>
<li><p><a href=""https://i.stack.imgur.com/GxwoO.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GxwoO.jpg"" alt=""enter image description here""></a></p>

<ul>
<li>I disable cpp_package,opencv,cuda,USE_MKLML_MKL(else mshadow will use openBLAS).</li>
<li>I disable USE_TENSORRT and USE_VTUNE too</li>
</ul></li>
<li><p>press configure，disable BUILD_TESTING</p></li>
<li>press configure again, all green</li>
<li>press generate，all green</li>
<li>open ALL_BUILD.vcxproj</li>
<li>Select Release build</li>
<li>All build</li>
<li>All green, except install project fail</li>
</ol>

<p><strong>>file cannot create directory: C:/Program Files/mxnet/lib.  Maybe need</strong>
<strong>1>    administrative privileges.</strong></p>

<p>Already open vc as admin, still the same error</p>

<ol start=""15"">
<li>Add Anaconda3 into PATH</li>
<li>Add libmxnet.dll and C:\Program Files (x86)\IntelSWTools\compilers_and_libraries_2019.2.190\windows\redist\intel64_win\mkl\mkl_rt.dll into a folder which could be found by the os</li>
<li>select build with cpp_package from cmake gui</li>
<li>configure->generate</li>
<li>reopen ALL_BUILD.vcxproj</li>
<li>Select ALL_BUILD->build</li>
<li>Because install do not work，I copy the files lib to build_cpu/install</li>
</ol>

<p><a href=""https://i.stack.imgur.com/Dm389.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Dm389.jpg"" alt=""enter image description here""></a></p>

<ol start=""22"">
<li>Because lrs and wds of op.h do not declare type，I need to add mx_float for them</li>
<li>write a simple program, can compile</li>
<li>When I call forward of the Executor，the program throw <strong>Intel MKL FATAL ERROR: Cannot load mkl_intel_thread.dll.</strong></li>
<li>Add C:\Program Files (x86)\IntelSWTools\compilers_and_libraries_2019.2.190\windows\redist\intel64_win\mkl的mkl_intel_thread.dll into the folder could be found by the os
26.Run again，still the same error <strong>Intel MKL FATAL ERROR: Cannot load mkl_intel_thread.dll.</strong></li>
</ol>

<p>My Anaconda3 install mxnet，it got mkl_intel_thread.dll and mkl_rt.dll too，I wonder there are confliction，problem is I did not add the bin path of Anaconda3 into the PATH.</p>

<p>I tried to copy different mkl_intel_thread.dll and mkl_rt.dll into the folder where the exe at, but every combination of them give me same error.</p>

<p>Those dll come from following path</p>

<ul>
<li>C:\Program Files (x86)\IntelSWTools\compilers_and_libraries_2019.2.190\windows\redist\intel64_win\mkl</li>
<li>C:\Users\yyyy\Anaconda3\envs\gluon\Library\bin</li>
<li>C:\Users\yyyy\Anaconda3\Library\bin</li>
<li>C:\Users\yyyy\Anaconda3\pkgs\mkl-2019.1-144\Library\bin</li>
</ul>

<p>Do anyone know how to solve this issue?Thanks</p>
","<c++><dll><intel-mkl><mxnet>","2019-03-06 07:29:08","","0","1281264","2019-03-06 09:46:05","0","0","","","1281264","2794","196","3"
"50467369","<p>Question: is there any open source project which covers all ML framework management in a single system?</p>

<p>Scenario Description： in some education scenario, many studies and teachers would like to use different ML frameworks such as Tensorflow, Caffe, Mxnet, etc. It's hard for environment guys to prepare all of them one by one.</p>
","<tensorflow><caffe><mxnet>","2018-05-22 12:12:53","","0","2947823","2018-05-22 16:36:40","1","1","","","2947823","1","0","0"
"44567698","<p>I use mxnet to do image regression(4 labels) by fine-tuning resnet50.</p>

<ol>
<li>I changed SoftmaxOutput with LinearRegressionOutput in symbol</li>
<li>I changed image label into a number</li>
<li>I used metric=mx.metric.MSE() instead of training acc.</li>
</ol>

<p>So the symbol is like in the last layer.</p>

<pre><code>{
""op"": ""FullyConnected"",
""name"": ""fc"",
""attr"": {""num_hidden"": ""4""},
""inputs"": [[430, 0, 0], [431, 0, 0], [432, 0, 0]]
},
{
""op"": ""null"",
""name"": ""lro_label"",
""inputs"": []
},
{
""op"": ""LinearRegressionOutput"",
""name"": ""lro"",
""inputs"": [[433, 0, 0], [434, 0, 0]]
}
],
</code></pre>

<p>But when I run the code I have an error like simple_bind error.</p>

<p>simple_bind error. Arguments:
lro_label: (36,)
data: (36, 3, 227, 227)
Traceback (most recent call last):
File ""finetune.py"", line 59, in 
for_training=True)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/module/module.py"", line 388, in bind
state_names=self._state_names)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/module/executor_group.py"", line 214, in init
self.bind_exec(data_shapes, label_shapes, shared_group)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/module/executor_group.py"", line 310, in bind_exec
shared_group))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/module/executor_group.py"", line 582, in _bind_ith_exec
shared_buffer=shared_data_arrays, **input_shapes)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/symbol.py"", line 1375, in simple_bind
raise RuntimeError('simple_bind failed')
RuntimeError: simple_bind failed</p>

<p>It seems the error happened in</p>

<pre><code>mod = mx.module.Module( symbol=new_sym, context=ctx, data_names=('data',), label_names=('lro_label',)) 
mod.bind(data_shapes=[('data', (batch_size, 3, 227, 227))], label_shapes=[('lro_label', (batch_size,))], for_training=True)
</code></pre>

<p>Input and output is not same, but when I use softmax, there is no such problem.
What happened?</p>
","<regression><bind><conv-neural-network><mxnet><resnet>","2017-06-15 12:35:30","","1","1617034","2018-02-28 18:58:09","1","0","","","1617034","330","66","0"
"42356662","<p>When I test an image use Faster R-CNN in mxnet<a href=""https://i.stack.imgur.com/78OQz.jpg"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>How to set MXNET_CUDNN_AUTOTUNE_DEFAULT?</p>
","<deep-learning><mxnet>","2017-02-21 00:36:52","","0","7425553","2017-10-13 21:07:52","1","0","","","7425553","18","4","0"
"46534617","<p>I want to N-gram a set of strings in MxNet. Perferably, I would do something like <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"" rel=""nofollow noreferrer"">TFIDF Vectorizing</a>, but even a simple N-gram with count and feature limits would be fine. Is there a built in function for this? What would be the best approach?</p>

<p>Currently, I am computing it with Python,</p>

<pre><code>def tfidf(str_list, ngram_width=3):
    tf = {}
    for s in str_list:
        for start, end in zip(range(len(s) - ngram_width),
                              range(ngram_width, len(s))):
            if s[start:end] not in tf:
                tf[s[start:end]] = 0
            tf[s[start:end]] += 1

    idf = {}
    for t in tf.keys():
        cnt = 0
        for s in str_list:
            if t in s:
                cnt += 1
            idf[t] = len(str_list)/(cnt + 1.0)

    return {t:tf[t]*idf[t] for t in tf.keys()}
</code></pre>
","<n-gram><mxnet>","2017-10-02 22:28:03","","0","3002273","2017-12-11 21:05:46","1","0","","","3002273","2301","192","12"
"53195631","<p>I'm finding a hardtime figuring out how to correctly define a mxnet net so that i can serialize/convert this model to a json file.</p>

<p>The pipeline is composed of a CNN + biLSTM + CTC.</p>

<p>I now i must use HybridBlock and hybridize() but i can't seem to make it work or if its even possible or if there is any other way around.</p>

<p>I'm sure its lack of knowledge on my part and wonder is anyone can help.</p>

<p>Here is the net definition in python:</p>

<pre><code>NUM_HIDDEN = 200
NUM_CLASSES = 13550
NUM_LSTM_LAYER = 1
p_dropout = 0.5
SEQ_LEN = 32

def get_featurizer():
    featurizer = gluon.nn.HybridSequential()
    # conv layer
    featurizer.add(gluon.nn.Conv2D(kernel_size=(3,3), padding=(1,1), channels=32, activation=""relu""))
    featurizer.add(gluon.nn.BatchNorm())

    ....
    featurizer.hybridize()
    return featurizer

class EncoderLayer(gluon.Block):
    def __init__(self, **kwargs):
        super(EncoderLayer, self).__init__(**kwargs)
        with self.name_scope():
            self.lstm = mx.gluon.rnn.LSTM(NUM_HIDDEN, NUM_LSTM_LAYER, bidirectional=True)
    def forward(self, x):
        x = x.transpose((0,3,1,2))
        x = x.flatten()
        x = x.split(num_outputs=SEQ_LEN, axis = 1) # (SEQ_LEN, N, CHANNELS)
        x = nd.concat(*[elem.expand_dims(axis=0) for elem in x], dim=0)
        x = self.lstm(x)
        x = x.transpose((1, 0, 2)) # (N, SEQ_LEN, HIDDEN_UNITS)
        return x

def get_encoder():
    encoder = gluon.nn.Sequential()
    encoder.add(EncoderLayer())
    encoder.add(gluon.nn.Dropout(p_dropout))
    return encoder

def get_decoder():
    decoder = mx.gluon.nn.Dense(units=ALPHABET_SIZE, flatten=False)
    decoder.hybridize()
    return decoder

def get_net():
    net = gluon.nn.Sequential()
    with net.name_scope():
        net.add(get_featurizer())
        net.add(get_encoder())
        net.add(get_decoder())
    return net
</code></pre>

<p>Any help would be highly appreciated.
Thank you very much.</p>
","<json><serialization><lstm><mxnet>","2018-11-07 18:30:34","","0","2880065","2018-11-08 19:13:42","1","0","1","","2880065","8","0","0"
"44567799","<p>I am working on a conditional computing framework using MxNet. Assume that we have N samples in our minibatch. I need to execute such kind of operations in my computational graph, using pseudocode:</p>

<pre><code>x = graph.Variable(""x"")
y = graph.DoSomeTranformations(x)
# The following operation generates a Nxk sized matrix, k responses for each sample.
z = graph.DoDecision(y)
for i in range(k):
   argmax_sample_indices_for_i = graph.ArgMaxIndices(z, i)
   y_selected_samples = graph.TakeSelectedSample(y, argmax_sample_indices_for_i )
   result = graph.DoSomeTransformations(y_selected_samples)
</code></pre>

<p>What I want to achieve is the following: After I obtain y, I apply a decision function (this can be a D to k Fully Connected layer, where D is the data dimension) and obtain k activations for each sample in my N sized minibatch. Then, I want to dynamically split my minibatch into k different parts (k may be 2, 3, a small number), based on the column index of the maximum activation for each sample. My hypothetic  ""graph.ArgMaxIndices"" function does that, given z, a Nxk sized matrix, and i, the function looks for the sample indices which give the maximum activations along the column i and returns their indices. (Note that I look for any series or combination of functions which give the equivalent result to ""graph.ArgMaxIndices"", not a single function, specifically). Then finally, for each i, I select the samples with maximum activations and apply specific transformations to them. Currently, to the best of my knowledge, MxNet does not support such kind of conditional calculations in their symbolic networks. Therefore, I build separate symbolic graphs after each decision and had to code my separate bookkeeping - conditional graph structures for each minibatch split, which produces 1) Very complex and cumbersome code to maintain and develop 2) Degraded running performance during training and evaluation. </p>

<p>My question is, can I do the above using the symbolic operators of Tensorflow? Does it allow one to select subsets of the minibatch, based on a criteria? Is a there function or series of functions which is equivalent to the ""graph.ArgMaxIndices"" in the pseudocode above? (Given a Nxk matrix and column index i, returns the indices of rows, which have the maximum activation at column k).</p>
","<python><tensorflow><deep-learning><mxnet>","2017-06-15 12:40:54","","1","1538049","2017-06-15 15:09:06","1","0","1","","1538049","1918","102","1"
"44580068","<p>I'm now writing a custom op, and it's output shape is dynamic, how to define the <em>output_shape</em> in <em>infer_shape</em> function.</p>
","<mxnet>","2017-06-16 02:58:20","","0","7324721","2018-04-12 21:18:35","1","0","","","7324721","79","14","0"
"41496518","<p>We have a Ptr-Net model that we want to run. Can the MXNet be useful for this scenario. If not, what are the other libraries that we can use to run Ptr-Net models?</p>

<p>We are building a Ptr-Net model using TensorFlow as of now.</p>
","<machine-learning><deep-learning><mxnet>","2017-01-05 23:27:54","","1","7381673","2017-01-06 18:50:10","1","0","","","7381673","6","0","0"
"46552333","<p>My batch size is 512, I have 8 GPUs</p>

<p>Should I define:
<em>rescale_grad</em> = 1. / 512 <strong>or</strong> <em>rescale_grad</em> = 1. / (8*512)</p>

<p>Thanks!</p>
","<deep-learning><keras><mxnet>","2017-10-03 19:51:30","","0","8224316","2017-10-05 23:37:44","1","1","","","8224316","123","13","0"
"53219720","<p>TensorFlow Object Detection API prefers TFRecord file format. MXNet and Amazon Sagemaker seem to use RecordIO format. How are these two binary file formats different, or are they the same thing? </p>
","<mxnet><tfrecord>","2018-11-09 04:04:59","","0","2089899","2018-11-09 19:02:06","1","0","","","2089899","1631","382","12"
"53455374","<p>I have a custom dataset of approximately 20k images (10% used of validation).
I have roughly 1/3 in label class 0, 1/3 in label class 1, and 1/3 that do not have class 0, or 1 objects with a -1 label.</p>

<p>I have run approximately 400 epochs, the last 40 epochs validation mAP has increased from 0.817 TO 0.831, and training cross entropy loss from 0.377->0.356</p>

<pre><code>the last epoch had validation mAP &lt;score&gt;=(0.83138943309)
train cross_entropy &lt;loss&gt;=(0.356147519184)
train smooth_l1 &lt;loss&gt;=(0.150637295831)
</code></pre>

<ol>
<li><p>The training loss still seems like its got a reasonable amount to reduce but I don't have any experience with resnet (on yolov3 this data set quickly went below .1)</p></li>
<li><p>Is my approach of have 1/3 of the training images not have either class present reasonable? When I was doing yolov3 training it seemed to help the network avoid false positives. </p></li>
<li><p>Is there any rule of thumb that helps me estimate how many epochs are appropriate based on the number of classes/images?</p></li>
<li><p>Its cost me about 100 bucks on aws to get to this point, I'm not sure if it needs another 100 bucks or 1000 bucks to get to the optimal mAP - at the current rate it appears 1 hour is making about 1% improvement - and i'd expect that to slow down. </p></li>
<li><p>Are there other metrics I should be looking at? (if so how do i export them)? </p></li>
<li><p>are there any hyperparameters I should change, and resume training?</p></li>
</ol>

<p>My hyperparameters are:</p>

<pre><code>base_network='resnet-50',
num_classes=2,
mini_batch_size=32,
epochs=200,
learning_rate=0.001,
lr_scheduler_step='3,6',
lr_scheduler_factor=0.1,
optimizer='sgd',
momentum=0.9,
weight_decay=0.0005,
overlap_threshold=0.5,
nms_threshold=0.45,
image_shape=416,
label_width=480,
num_training_samples=19732)
</code></pre>

<p>thanks,
John</p>
","<python><deep-learning><mxnet><resnet>","2018-11-24 05:14:59","","0","10288357","2019-01-16 00:43:48","1","0","","","10288357","22","2","0"
"53238271","<p>Coming from Keras, I try to reproduce my simple model with MXNet to make prediction using Module.</p>

<p>I'm using that simple dataset: <a href=""https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"" rel=""nofollow noreferrer"">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data</a></p>

<p>I've got 13 inputs (from alcohol to Proline) that I want to send to the model, and I need to classify the first column that is ""wine type"", so I create a nd.array that have 3 entries.</p>

<pre><code>
x = data.values[: , 1:14]
y = data.values[:, 0]

X = mx.nd.array(x)
Y = []
for i, v in enumerate(y):
    d = [0,0,0]
    d[int(v)-1] = 1
    Y.append(d)
Y = mx.nd.array(Y)
Y.shape, X.shape
# ((178, 3), (178, 13))
</code></pre>

<p>Then I create the model and a NDIterator:</p>

<pre><code>
net = mx.symbol.Variable('winechemical')
net = mx.symbol.FullyConnected(net, num_hidden=64)
net = mx.symbol.Activation(net, act_type='relu')
net = mx.symbol.FullyConnected(net, num_hidden=32)
net = mx.symbol.Activation(net, act_type='relu')
net = mx.symbol.FullyConnected(net, num_hidden=16)
net = mx.symbol.SoftmaxOutput(net, name='wineclass')

model = Module(symbol=net, context=mx.cpu(),
                  data_names=['winechemical'],
                  label_names=['wineclass_label'])

gen = mx.io.NDArrayIter(X, label=Y, 
                        batch_size=10, 
                        shuffle=True, data_name='winechemical', 
                        label_name='wineclass_label')
</code></pre>

<p>But when I try to ""train"" the model using the ""fit"" method, I got this error:</p>

<pre>
model.fit(gen, num_epoch=5)

[...]
Error in operator wineclass: Shape inconsistent, Provided = [10,3], inferred shape=[10]
</pre>

<p>I'm pretty sure that I don't understand the shape to uses as I'm coming from Keras that use different shape... But where am I wrong ?</p>

<p>Thanks for your help.</p>
","<python><mxnet>","2018-11-10 11:00:59","","0","1472048","2018-11-30 19:37:58","2","0","","","1472048","2072","63","5"
"44127126","<p>I am trying to install the new MXNet from<br>
<a href=""http://mxnet.io/get_started/install.html#validate-mxnet-installation"" rel=""nofollow noreferrer"">validate-mxnet-installation</a>.<br>
I followed the instructions<br>
(I chose options Linux->python->GPU->pip ) as you can see on the website and they were:  </p>

<ol>
<li>install cuda8 from nvidia website  </li>
<li>install cuDNN 5 library  </li>
<li>update paths ""PATH"" and ""LD_LIBRARY_PATH"" in bashrc file   </li>
<li><p>install pip using these bunch of lines:      </p>

<pre><code>$ sudo apt-get update
$ sudo apt-get install -y wget python
$ wget https://bootstrap.pypa.io/get-pip.py &amp;&amp; sudo python get-pip.py    
</code></pre></li>
<li>install the MXNet by: <code>$ pip install mxnet-cu80</code>   </li>
<li>validate the installation. <strong>I'm stuck here</strong>   </li>
</ol>

<p>To validate I was required to run the following: </p>

<ol>
<li>open terminal and type <code>python</code> to start python  </li>
<li><p>type the following:  </p>

<pre><code>import mxnet as mx
a = mx.nd.ones((2, 3), mx.gpu())
b = a * 2 + 1
b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32)  
</code></pre></li>
</ol>

<p><strong>I am getting the following error</strong> when I try to run the above:    </p>

<pre><code> &gt;&gt;&gt; import mxnet as mx
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
ImportError: No module named mxnet   
</code></pre>

<p>I'm kind of lost.. Does anyone know what should I do?</p>
","<python><linux><ubuntu><mxnet>","2017-05-23 06:17:30","","2","3510989","2017-05-26 19:12:00","2","2","","","3510989","128","27","0"
"44035503","<p>I have setup an emr step in AWS datapipeline. The step command looks like this: </p>

<pre><code>/usr/lib/hadoop-mapreduce/hadoop-streaming.jar,-input,s3n://input-bucket/input-file,-output,s3://output/output-dir,-mapper,/bin/cat,-reducer,reducer.py,-file,/scripts/reducer.py,-file,/params/parameters.bin
</code></pre>

<p>I am getting the following error</p>

<pre><code>Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
    at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:322)
    at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:535)
    at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
    at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:244)
    at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:467)
    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:393)
    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:422)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
    at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:322)
    at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:535)
    at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)
    at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:244)
    at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:467)
    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:393)
    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:422)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143
</code></pre>

<p>I have tried running reducer step separately on my desktop 
(on a single node hadoop setup) and its working. I have already included the <code>#!/usr/bin/env python</code> in the reducer script. <s>I suspect that I am not writing the EMR step correctly.</s></p>

<pre><code>EMR version: 5.5.0
</code></pre>

<p><strong>EDIT:</strong>
After further investigation, I have found out the exact line of code where the reducer code is failing in emr.
I am doing Machine Learning predictions using <a href=""http://mxnet.io/"" rel=""nofollow noreferrer"">mxnet</a> library in the reducer. When I load the model parameters, the reducer fails. Reference to API doc is <a href=""http://mxnet.io/api/python/module.html#mxnet.module.BaseModule.load_params"" rel=""nofollow noreferrer"">here</a></p>

<pre><code>module.load_params('parameters.bin')
</code></pre>

<p>I have checked the current working directory of the EMR node [using <code>os.listdir(os.getcwd())</code>] and it contains the <code>parameters.bin</code> file (I have even printed the file contents successfully). 
I want to point out again that the streaming job is working fine on my single-node local setup.</p>

<p><strong>EDIT2:</strong> I set the number of reducer tasks to 2. I enclosed my reducer code in a try-except block and I see the following error in one of the tasks (the other one runs fine)</p>

<pre><code>[10:27:25] src/ndarray/ndarray.cc:299: Check failed: from.shape() == to-&gt;shape() operands shape mismatchfrom.shape = (119,) to.shape=(111,) 

Stack trace returned 10 entries:    
[bt] (0) /usr/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xc72fc) [0x7f81443842fc]    
[bt] (1) /usr/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xc166f4) [0x7f8144ed36f4]   
[bt] (2) /usr/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xc74c24) [0x7f8144f31c24]   
[bt] (3) /usr/local/lib/python2.7/site-packages/mxnet/libmxnet.so(MXImperativeInvoke+0x2cd) [0x7f8144db935d]    
[bt] (4) /usr/lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f8150b8acec]  
[bt] (5) /usr/lib64/libffi.so.6(ffi_call+0x1f5) [0x7f8150b8a615]    
[bt] (6) /usr/lib64/python2.7/lib-dynload/_ctypes.so(_ctypes_callproc+0x30b) [0x7f8150d9d97b]   
[bt] (7) /usr/lib64/python2.7/lib-dynload/_ctypes.so(+0xa915) [0x7f8150d97915]  
[bt] (8) /usr/lib64/libpython2.7.so.1.0(PyObject_Call+0x43) [0x7f815a69e183]    
[bt] (9) /usr/lib64/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x337d) [0x7f815a73107d] 
</code></pre>
","<hadoop><emr><hadoop-streaming><amazon-data-pipeline><mxnet>","2017-05-17 22:04:58","","5","2545792","2017-08-01 07:10:08","1","4","1","","2545792","488","155","4"
"45430248","<p>The cell is like below, trying to use <code>cifar10_val.rec</code>.The file is there.</p>

<pre><code>def get_data_from_cifar(): 
    train = mx.io.ImageRecordIter() 
    val = mx.io.ImageRecordIter() 
    return train, val 

train, val = get_data_from_cifar() 
</code></pre>

<p>Everytime I run the notebook it dies,telling </p>

<blockquote>
  <p>The kernel appears to have died. It will restart automatically.</p>
</blockquote>

<p>There is a post about <a href=""https://stackoverflow.com/q/34047782/1278112"">jupyter notebook kernel dies when using pandas</a>,it's about memory,however it has <code>to_sparse()</code> to deal with that.</p>

<p>The memory in my pc is not huge also.However,while running the cell,the taks manager doesn't show the memory like to be exhausted. </p>

<p>Could this be some other problem?</p>

<p>UPDATE:</p>

<p>run scripts in python interpreter shell it tells as @leezu said</p>

<blockquote>
  <p>304: [16:36:58] src/io/image_aug_default.cc:282: Check failed:
  static_cast(res.rows) >= param_.data_shape<a href=""https://stackoverflow.com/q/34047782/1278112"">1</a> &amp;&amp;
  static_cast(res.cols) >= param_.data_shape[2] input image
  size smaller than input shape</p>
</blockquote>

<p>guess I used wrong data_shape(3,128,128).Would update after change them acording to cifar10 instance.</p>
","<deep-learning><jupyter-notebook><mxnet>","2017-08-01 06:18:45","","0","1278112","2017-08-02 06:20:33","1","3","","","1278112","1064","356","9"
"53203143","<p>I am trying <a href=""https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html"" rel=""nofollow noreferrer"">gluon model zoo</a>.</p>

<pre class=""lang-py prettyprint-override""><code>import mxnet as mx
from mxnet.gluon.model_zoo import vision
import cv2
import numpy as np

ctx = mx.gpu(6) # successful
net = vision.alexnet(pretrained=True, ctx=ctx)

# preparing input image. 
# You may ignore this process. This just preprocess an image for the net.
# To load input image as shape (batch=1, channel=3, width, height)
im = cv2.imread(‘img.jpg’) # w,h = 4032,3024. rgb color image
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB).astype(float)/255
im = mx.image.color_normalize(im, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) 
im = np.transpose(im, (2,0,1)) # (4032,3024,3) -&gt; (3,4032,3024)
im = im[None,:] # (3,4032,3024) -&gt; (1,3,4032,3024). this means batchsize=1
im = mx.nd.array(im, ctx=ctx)

# run 
r = net(im)
</code></pre>

<p>When I run this, an error occurs.</p>

<pre><code>MXNetError: Shape inconsistent, Provided = [4096,9216], inferred shape=(4096,2976000)
</code></pre>

<p>Do I have to resize image to a specific size? At <a href=""https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html"" rel=""nofollow noreferrer"">manual</a>, gluon needs only minimum sizes of width, height. Should I have to consider maximum size, or fix the input size?</p>
","<mxnet>","2018-11-08 07:32:16","","0","766330","2018-11-09 05:55:01","2","0","","","766330","2630","644","2"
"44113817","<p>I want to see what is the op's <strong>type/name</strong> of one <code>Symbol in MXNet</code>.<br>
e.g:  </p>

<pre><code>c = mxnet.symbol.Convolution()  
</code></pre>

<p><code>type(c)</code> --> will print this symbol is Convolution or others like Pooling etc.  </p>
","<deep-learning><mxnet>","2017-05-22 13:12:43","","0","7989807","2017-05-26 17:13:19","1","0","","","7989807","1","0","0"
"53962281","<p>I'm training a model for multi-class image classification on AWS sagemaker using a custom dataset. The dataset has around 50 classes. I'm following this notebook: <a href=""https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-transfer-learning-highlevel.ipynb"" rel=""nofollow noreferrer"">Image classification transfer learning demo</a> </p>

<p>According to my understanding, the final layer of the model outputs probabilities corresponding to each class in our dataset. Sagemaker expects the dataset to be provided in mxnet recordio's .rec format. Since I'm not manually converting the labels to one-hot-encoded, I don't know which layer is ouputing probabilities for which class. How can I get an ordered list of classes where indexes corresponds to the output of final layer of the model.</p>

<p>Even the notebook provided by AWS (Link above) has that ordered list (list: object_categories) hard-coded.</p>

<p>My dataset before converting to .rec format looks like this:</p>

<pre><code>./train/object1/
   -image1.jpg
   -image2.jpg
   -image3.jpg
   -...image500.jpg
./train/object2/
   -image1.jpg
   -image2.jpg
   -image3.jpg
   -...image500.jpg
.
.
.
./train/object50/
   -image1.jpg
   -image2.jpg
   -image3.jpg
   -...image500.jpg
</code></pre>

<p>Any help will be highly appreciated.</p>
","<python><deep-learning><mxnet><multilabel-classification><amazon-sagemaker>","2018-12-28 17:37:31","","1","9420717","2019-02-23 00:21:39","2","0","","","9420717","26","19","0"
"45521103","<p>I am following along with the tutorials here: <a href=""http://gluon.mxnet.io/P01-C02-ndarray.html"" rel=""nofollow noreferrer"">http://gluon.mxnet.io/P01-C02-ndarray.html</a>.  I installed mxnet for windows according to the instructions here: <a href=""http://mxnet.io/get_started/windows_setup.html"" rel=""nofollow noreferrer"">http://mxnet.io/get_started/windows_setup.html</a>.</p>

<p>I did not get so far before running into some difficultly.  For instance running the following</p>

<pre><code>import mxnet as mx
from mxnet import nd
mx.random.seed(1)
y = nd.random_normal(shape=(3,4))
print(y.asnumpy())
</code></pre>

<p>gives this error:</p>

<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-16-a96a0205f28b&gt; in &lt;module&gt;()
----&gt; 1 y = nd.random_normal(shape=(3,4))
      2 print(y.asnumpy())

AttributeError: 'module' object has no attribute 'random_normal'
</code></pre>

<p>I tried printing out the module methods and indeed there appears to be no <code>nd.random_normal</code>, <code>nd.random_uniform</code>, or any of the other <code>nd.random_...</code> methods I would have expected to find from the docs here: <a href=""http://mxnet.io/api/python/ndarray.html#the-ndarray-class"" rel=""nofollow noreferrer"">http://mxnet.io/api/python/ndarray.html#the-ndarray-class</a>.  Here are the packages that I do have:</p>

<pre><code>dir(mx)
['AttrScope',
 'Context',
 'MXNetError',
 '__builtins__',
 '__doc__',
 '__file__',
 '__name__',
 '__package__',
 '__path__',
 '__version__',
 'absolute_import',
 'attribute',
 'base',
 'callback',
 'context',
 'cpu',
 'current_context',
 'executor',
 'executor_manager',
 'gpu',
 'init',
 'initializer',
 'io',
 'kv',
 'kvstore',
 'kvstore_server',
 'libinfo',
 'lr_scheduler',
 'metric',
 'mod',
 'model',
 'module',
 'mon',
 'monitor',
 'name',
 'nd',
 'ndarray',
 'operator',
 'optimizer',
 'random',
 'recordio',
 'rnd',
 'rtc',
 'sym',
 'symbol',
 'symbol_doc',
 'th',
 'torch',
 'visualization',
 'viz']
</code></pre>

<p>Have I somehow managed an incomplete install or were these methods possibly moved to another part of the namespace in a recent update?</p>
","<python><mxnet>","2017-08-05 10:55:34","","0","2690677","2017-08-05 11:26:51","1","0","","","2690677","427","493","2"
"44947104","<p>I wrote a script to do the classification of a single input image using a model I trained with MxNet. To classify the incoming image I feedforward them in through network.</p>

<p>In short here is what I am doing:</p>

<pre><code>symbol, arg_params, aux_params = mx.model.load_checkpoint('model-prefix', 42)
model = mx.mod.Module(symbol=symbol, context=mx.cpu())
model.bind(data_shapes=[('data', (1, 3, 224, 244))], for_training=False)
model.set_params(arg_params, aux_params)

# ... loading the image &amp; resizing ...
# img is the image to classify as numpy array of shape (3, 244, 244)

Batch = namedtuple('Batch', ['data'])
self._model.forward(Batch(data=[mx.nd.array(img)]))
probabilities = self._model.get_outputs()[0].asnumpy()

print(str(probabilities))
</code></pre>

<p>This works fine, except that I am getting the following warning</p>

<pre><code>UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
</code></pre>

<p><strong>What should I change to avoid getting this warning?</strong> It is not clear to me what the <em>label_shapes</em> and <em>label_names</em> parameters are meant for, and what I am expect to fill them with. </p>

<p><em>Note: I found some thread about them, but none enabled me to solve the problem. Similarly the MxNet documentation doesn't provide much details on what those parameters are and on how they are supposed to be filled.</em> </p>
","<python><machine-learning><computer-vision><deep-learning><mxnet>","2017-07-06 11:01:57","","1","1162647","2019-03-25 13:26:59","1","0","","","1162647","5649","160","1"
"53356694","<p>I'm working a multi-layer RNN for a word-level language model. It has a one-to-one configuration so that for each step in the training set a prediction is validated against an eval set of the same dimensions. The model borrows almost entirely from the example laid out <a href=""https://mxnet.incubator.apache.org/tutorials/r/charRnnModel.html"" rel=""nofollow noreferrer"">here</a> but adapted for word-level modeling. My variation is <a href=""https://github.com/connermcb/next_word_predictor/blob/master/small_rnn.R"" rel=""nofollow noreferrer"">here</a>. </p>

<p>Another difference is between the example script linked above is the data I'm working with has multiple buckets. I believe that I've bucketed the data correctly but when it's fed to <code>mx.model.buckets</code>, I get some variation of this error:</p>

<pre><code>Start training with 1 devices
Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
  [17:25:59] `c:\jenkins\workspace\mxnet\mxnet\src\operator\tensor\../elemwise_op_common.h:123: Check failed: assign(&amp;dattr, (*vec)[i]) Incompatible attr in node  at 0-th output: expected [32,7], got [32,8]`
</code></pre>

<p>The issue appears to be a mismatch between the actual and expected input dimensions. The batch size is 32, and the values of 7 and 8 appear related to consecutive buckets in <code>bucket.plan</code>. </p>

<pre><code>train_data &lt;- mx.io.bucket.iter(buckets = train_buckets$buckets,
                                batch.size = batch_size, 
                                data.mask.element = 0, shuffle = TRUE)

eval_data &lt;- mx.io.bucket.iter(buckets = eval_buckets$buckets,
                               batch.size = batch_size,
                               data.mask.element = 0, shuffle = TRUE)
</code></pre>

<p>From the iterators above, I can pull the batch and bucket data:</p>

<pre><code>&gt; head(train_data$bucket.plan, 10)
 8  9 10  3 22 10 10  8 15 21 
 1  1  1  1  1  2  3  2  1  1 
&gt; train_data$batch
[1] 1
&gt; train_data$bucketID
8 
1 
</code></pre>

<p>The value at <code>train_data$batch</code> is used in <code>bucket.iter</code> as an index for pulling the next bucket name from <code>train_data$bucket.plan</code>:</p>

<pre><code>iter.next = function() {
        .self$batch &lt;- .self$batch + 1
        .self$bucketID &lt;- .self$bucket.plan[batch]
</code></pre>

<p>The bucket names correspond the length of the sentences assigned to them minus 1. So for bucket 8, the batch dimension should be [32, 7], what the training function expects. But as stated in the error it's actually picking up the input dimensions for <code>bucket.plan[2]</code>. </p>

<p>On other occasions, the first batch trains successfully only to have an error thrown on the second batch in which the input dimensions for the bucket at <code>bucket.plan[n]</code> are expected, but the dimensions for <code>bucket.plan[n-1]</code> are returned instead:</p>

<pre><code>Start training with 1 devices
Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
  [17:37:53] c:\jenkins\workspace\mxnet\mxnet\src\operator\tensor\../elemwise_op_common.h:123: Check failed: assign(&amp;dattr, (*vec)[i]) Incompatible attr in node  at 0-th output: expected [32,42], got [32,10]
&gt; head(train_data$bucket.plan, 10)
11 43  8  6  7  3  6 12 15 12 
 1  1  1  1  1  1  2  1  1  2 
&gt; train_data$batch
[1] 2
&gt; train_data$bucketID
43 
 1 
</code></pre>

<p>There doesn't appear to be a mismatch between the data and labels:</p>

<pre><code>&gt; dim(train_data$buckets[[names(train_data$bucketID)]]$data)
[1]  42 186
&gt; dim(train_data$buckets[[names(train_data$bucketID)]]$label)
[1]  42 186
</code></pre>

<p>The scripts that I believe are at issue here are <a href=""https://github.com/apache/incubator-mxnet/blob/master/R-package/R/mx.io.bucket.iter.R"" rel=""nofollow noreferrer"">incubator-mxnet/R-package/R/mx.io.bucket.iter.R</a> and <a href=""https://github.com/apache/incubator-mxnet/blob/master/R-package/R/executor.R"" rel=""nofollow noreferrer"">incubator-mxnet/R-package/R/executor.R</a>. For some reason, the indices for iterating through <code>bucket.plan</code> appear not to be updating correctly.</p>

<p>I've found some other threads on this topic, but nothing that has helped me resolve the error. </p>

<p>Any ideas?</p>
","<r><rnn><mxnet>","2018-11-17 23:55:03","","1","7332065","2018-11-17 23:55:03","0","0","","","7332065","560","115","4"
"54348348","<p>I am getting ""Illegal instruction (core dumped)"" exception while calling import mxnet. I am using CUDA 9.0, and did mxnet installation using anaconda. My python version is 2.7. As a side note, CUDA 10.0 is also installed on my machine.</p>

<p>Any help will be much appreciated.</p>
","<python-2.7><mxnet>","2019-01-24 13:58:32","","0","3946761","2019-04-11 17:40:11","1","2","","","3946761","41","1","0"
"43391400","<p>I'm looking for implementations of convolutional autoencoder using MxNet. But there is only one example of autoencoder based on Fully Connected Networks, which is <a href=""https://github.com/dmlc/mxnet/tree/master/example/autoencoder"" rel=""nofollow noreferrer"">here</a>. There is also an issue asking similar questions in github, but receives very few responses. Is there any toy example of convolutional autoencoders implemented using MxNet?</p>
","<machine-learning><computer-vision><convolution><autoencoder><mxnet>","2017-04-13 11:43:22","","0","5005808","2019-04-02 07:25:46","2","4","","","5005808","776","53","2"
"43964821","<p>Mxnet and Tensorflow both declare that they has auto-differentiation feature.</p>

<p>In Mxnet, I need to define the backward part when creating a new op(like loss function), but not in Tensorflow.</p>

<p>In my knowledge, auto-differentiation means I don't need to care about the backward part. So, does mxnet has auto-differentiation feature?</p>
","<tensorflow><mxnet>","2017-05-14 14:05:57","","0","7324721","2018-01-14 08:25:32","1","0","","","7324721","79","14","0"
"45497860","<p>I'm having some trouble understanding how MXNet ImageRecordIter works. <a href=""http://mxnet.io/tutorials/basic/data.html#image-io"" rel=""nofollow noreferrer"">Here</a> is the reference I've been using  </p>

<p>For one, what does the --test-ratio flag actually do? When generating an lst file, I can't tell which lines are test data.</p>

<p>Another larger issue I'm having is the format of labels. If we have N classes, a standard neural net output might be a softmax'd vector with N dimensions. A normal label in this case would be a 1 hot encoding with a 1 in the dimension which maps to our class. But ImageRecordIter seems like it's label format is just a single number? Is there some behind the scene magic going on?</p>
","<machine-learning><deep-learning><data-science><mxnet>","2017-08-04 03:36:08","","0","4718854","2017-10-05 21:09:36","1","0","","","4718854","1","0","0"
"53987847","<p>I want to reduce a memory copy step during my data processing pipeline.</p>

<p>I want to do the following:</p>

<ol>
<li><p>Generate some data from a custom C library</p></li>
<li><p>Feed the  generated data into a MXNet model running on GPU.</p></li>
</ol>

<p>For now, my pipeline does the following:</p>

<ol>
<li><p>Create a C-contiguous numpy array via <code>np.empty(...)</code>.</p></li>
<li><p>Get the pointer to numpy array via <code>np.ndarray.__array_interface__</code></p></li>
<li><p>Call the C library from python (via ctypes) to fill the numpy array.</p></li>
<li><p>Convert the numpy array into mxnet <code>NDArray</code>, this will <strong>copy</strong> the underlying memory buffer.</p></li>
<li><p>Pack <code>NDArray</code>s into a <code>mx.io.DataBatch</code> instance, then feed into model.</p></li>
</ol>

<p>Please note, before being fed into model, all arrays stay in CPU memory.</p>

<p>I noticed a <code>mx.io.DataBatch</code> can only take a list of <code>mx.ndarray.NDArray</code>s as <code>data</code> and <code>label</code> parameter, but <strong>not</strong> numpy arrays. <a href=""https://github.com/apache/incubator-mxnet/issues/4382"" rel=""nofollow noreferrer"">It works until you feed it into a model.</a> On the other hand, I have a C library that can write directly to a C-contiguous array.</p>

<p><strong>I would like to avoid the <em>memory copying</em> in step 3.</strong> One possible way is somehow getting a raw pointer to buffer of <code>NDArray</code>, while totally ignoring numpy. But whatever works.</p>
","<python><numpy><multidimensional-array><copy><mxnet>","2018-12-31 13:03:49","","0","1950580","2019-02-25 10:12:40","1","0","","","1950580","1574","45","16"
"54501813","<p>I am using MXNet library in RStudio to train a neural network model. </p>

<p>When training the model using caret, I can tune (among others) the ""momentum"" parameter. Is this related with the Stochastic Gradient Descent optimizer?</p>

<p>I know that this is the default optimizer when training using ""mx.model.FeedForward.create"", but what happens when I am using caret:::train??</p>
","<r><optimization><r-caret><gradient-descent><mxnet>","2019-02-03 10:09:48","","0","11008049","2019-03-05 00:30:51","1","0","","","11008049","1","0","0"
"36245048","<p>I would like to run this function from a script instead of the command line. For example, the function is:</p>

<pre><code>def main():
    parser = argparse.ArgumentParser(description='Caffe prototxt to mxnet model parameter converter.\
                    Note that only basic functions are implemented. You are welcomed to contribute to this file.')
    parser.add_argument('caffe_prototxt', help='The prototxt file in Caffe format')
    parser.add_argument('caffe_model', help='The binary model parameter file in Caffe format')
    parser.add_argument('save_model_name', help='The name of the output model prefix')
    args = parser.parse_args()
    ...
</code></pre>

<p>How can i run it like this?</p>

<pre><code>file.main('file_1.csv', 'file_2.csv', 'name')
</code></pre>

<p>And why would someone write a function that I can only run from the command line? It feels inconvenient. </p>
","<python-2.7><argparse><mxnet>","2016-03-27 07:45:54","","2","2014905","2016-11-07 20:42:57","2","6","","","2014905","368","245","2"
"45257390","<p>I am using R mxnet package. Here is the code block that I am currently using. But I am not sure how to specify regularization. </p>

<pre><code>dpLnModel &lt;- mx.model.FeedForward.create(symbol             = out,
                                         X                  = trainX,
                                         y                  = trainY,
                                         ctx                = mx.cpu(),
                                         num.round          = numIter,
                                         eval.metric        = mx.metric.rmse,
                                         array.batch.size   = 50,
                                         array.layout       = ""rowmajor"",
                                         verbose            = TRUE,
                                         optimizer          = ""rmsprop"",
                                         eval.data          = list(data  = testX,
                                                                   label = testY
                                         ),
                                         initializer        = mx.init.normal(initValVar),
                                         epoch.end.callback = mx.callback.log.train.metric(5, logger)
)
</code></pre>
","<r><neural-network><deep-learning><mxnet>","2017-07-22 17:31:11","","2","8284995","2018-02-13 17:01:11","2","1","","","8284995","90","22","0"
"53384859","<p>I'm trying to pip install the python binding of MXNet library from source code:</p>

<p><a href=""https://mxnet.incubator.apache.org/install/ubuntu_setup.html#install-mxnet-for-python"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/install/ubuntu_setup.html#install-mxnet-for-python</a></p>

<p>After the main binary is built successfully using g++, there is no problem in installing its python binding in dev/editable mode:</p>

<p><code>pip install -e .
</code></p>

<p>however when I try to deploy the full package (instead of just creating a symbolic link)</p>

<p><code>pip install .
</code></p>

<p>I encounter the following error:</p>

<pre><code>Processing ~/git-fork/mxnet/python
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):
      File ""&lt;string&gt;"", line 1, in &lt;module&gt;
      File ""/tmp/pip-req-build-k3hfc693/setup.py"", line 47, in &lt;module&gt;
        LIB_PATH = libinfo['find_lib_path']()
      File ""/tmp/pip-req-build-k3hfc693/mxnet/libinfo.py"", line 74, in find_lib_path
        'List of candidates:\n' + str('\n'.join(dll_path)))
    RuntimeError: Cannot find the MXNet library.
    List of candidates:
    /tmp/pip-req-build-k3hfc693/mxnet/libmxnet.so
    /tmp/pip-req-build-k3hfc693/mxnet/../../lib/libmxnet.so
    /tmp/pip-req-build-k3hfc693/mxnet/../../build/libmxnet.so
    ../../../libmxnet.so

    ----------------------------------------
Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-req-build-k3hfc693/
</code></pre>

<p>It appears that pip didn't copy <code>../../lib/libmxnet.so</code> into tmp since it is outside the python package directory. What should I do to instruct pip to copy that file (and if possible, everything under parent directory) when installing?</p>
","<python><pip><mxnet>","2018-11-20 01:13:25","","0","1732418","2018-11-30 18:32:00","1","0","","","1732418","2047","186","16"
"46427792","<p>I currently try to build MLPs with multiple Outputs.</p>

<p>For single Output MLPs I normally use the H2o packge implementation which has a nice random grid search function implemented. Since H2o does not support multiple outputs I switched to the mxnet package.</p>

<p>Now I am trying to find a way to tune my parameters for my MLP. I can't find any package inside R which provides parameter tuning for multiple outputs and allows me to use mxnet. </p>

<p>Do you know any packages or do you have self implemented functions for a hyper parameter search?
Thank you!</p>

<p><em>Edit in cause of comment:</em></p>

<p>With multiple outputs i mean multiple response variables (MIMO problem). For example one of my researched tasks is the prediction of a RRSB distribution. A RRSB distribution has two parameters: n,x. I hope this clears your question</p>
","<r><mxnet><hyperparameters>","2017-09-26 13:23:26","","0","8676626","2018-03-07 01:18:34","2","2","","","8676626","1","0","0"
"46419954","<p>My mxnet code - which consists of a series of complex connections and slicing raises the following error:</p>

<pre><code>Error in operator concat0: [03:03:51] src/operator/./concat-inl.h:211: Not enough information to infer type in Concat.
</code></pre>

<p>Im not sure how to interpret that or what information to provide to help debug it. Concat0 is part of the operation:</p>

<pre><code># Define take_column function as transpose(take(transpose(x), i))

for i in range(47):
    y_hat_lt = take_column(y_hat,
                mx.sym.concat(mx.sym.slice(some_indices, begin=i, end=i+1), self.label_dim + mx.sym.slice(some_indices, begin=i, end=i+1), dim=0))
</code></pre>

<p>here some_indices is a variable which I fix to be a list. Do let me know!</p>
","<deep-learning><mxnet>","2017-09-26 07:13:46","","1","8196682","2017-09-28 08:53:50","2","1","","","8196682","30","0","0"
"44605831","<p>I am trying to use a RNN in MXNet to do a classification. My data roughly looks like the matrices m0 and m1 I created.
m0 represents e.g. energy consumption of a device over time, while m1 is my label to tell how the device is to be classified (e.g. binary in this case).
My goal is to detect the category of a device by looking at the energy consumption over time.
I keep getting errors about a shape mismatch and can't find a solution by changing input parameters. You can see my code and error messages below.
I appreciate any suggestions on how to handle this problem.</p>

<pre><code>require(mxnet)

m0 &lt;- matrix(runif(200*100), 100, 200)
m1 &lt;- matrix(round(runif(1*200)), 1, 200)

num.round      &lt;- 10
update.period  &lt;- 1
num.rnn.layer  &lt;- 1
seq.len        &lt;- 100
num.hidden     &lt;- 1
num.embed      &lt;- 1
num.label      &lt;- 1
batch.size     &lt;- 1
input.size     &lt;- 1
learning.rate  &lt;- 0.1

X.train &lt;- list(data = m0, label = m1)

model &lt;- mx.rnn(train.data = X.train,
                eval.data = NULL,
                num.rnn.layer = num.rnn.layer,
                seq.len = seq.len,
                num.hidden = num.hidden,
                num.embed = num.embed,
                num.label = num.label,
                batch.size = batch.size,
                input.size = input.size,
                ctx = mx.cpu(),
                num.round = num.round,
                update.period = update.period,
                initializer = mx.init.uniform(0.1),
                learning.rate = learning.rate)
</code></pre>

<blockquote>
  <p>[16:07:02] d:\program files
  (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:144:
  Using target_shape will be deprecated.</p>
  
  <p>[16:07:02] d:\program files
  (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:144:
  Using target_shape will be deprecated.</p>
  
  <p>[16:07:02] d:\program files
  (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:144:
  Using target_shape will be deprecated.</p>
  
  <p>[16:07:02] D:\Program Files
  (x86)\Jenkins\workspace\mxnet\mxnet\dmlc-core\include\dmlc/logging.h:304:</p>
  
  <p>[16:07:02] D:\Program Files
  (x86)\Jenkins\workspace\mxnet\mxnet\src\ndarray\ndarray.cc:299: Check
  failed: from.shape() == to->shape() operands shape
  mismatchfrom.shape=(1,1) to.shape=(1,100) Error in
  exec$update.arg.arrays(arg.arrays, match.name, skip.null):</p>
  
  <p>[16:07:02] D:\Program Files
  (x86)\Jenkins\workspace\mxnet\mxnet\src\ndarray\ndarray.cc:299: Check
  failed: from.shape() == to->shape() operands shape
  mismatchfrom.shape=(1,1) to.shape=(1,100)</p>
</blockquote>
","<r><deep-learning><recurrent-neural-network><mxnet>","2017-06-17 14:35:26","","1","8154300","2017-12-29 01:23:11","1","0","1","","8154300","6","0","0"
"53467556","<p>I know that it is possible to freeze  layers in a network for example to train only the last layers of a pre-trained model. 
However, I want to know is there any way to apply certain learning rates to different layers. For example, in pytorch it would be:</p>

<pre><code>    optimizer = torch.optim.Adam([
                    {'params': paras['conv1'], 'lr': learning_rate / 10},
                    {'params': paras['middle'], 'lr': learning_rate / 3},
                    {'params': paras['fc'], 'lr': learning_rate }
                 ], lr=learning_rate)
</code></pre>

<p>Interfaces of gluon and torch are pretty much the same. Any idea how I can do this in gluon?</p>
","<machine-learning><deep-learning><mxnet>","2018-11-25 12:44:05","","2","7811775","2018-11-29 20:43:36","1","0","","","7811775","21","1","0"
"44793696","<p>I'm trying to use MXNet's gradient descent optimizers to minimize a function. The equivalent example in Tensorflow would be:</p>

<pre><code>import tensorflow as tf

x = tf.Variable(2, name='x', dtype=tf.float32)
log_x = tf.log(x)
log_x_squared = tf.square(log_x)

optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(log_x_squared)

init = tf.initialize_all_variables()

def optimize():
  with tf.Session() as session:
    session.run(init)
    print(""starting at"", ""x:"", session.run(x), ""log(x)^2:"", session.run(log_x_squared))
    for step in range(10):  
      session.run(train)
      print(""step"", step, ""x:"", session.run(x), ""log(x)^2:"", session.run(log_x_squared))
</code></pre>

<p>I am not sure how to accomplish the same in MXNet. The optimizer API <a href=""http://mxnet.io/api/python/optimization.html#the-mxnet-optimizer-package"" rel=""nofollow noreferrer"">documentation</a> does not appear to have an equivalent method. Here's what I've tried so far. The main confusion has been around the need to pass training data:</p>

<pre><code>import mxnet as mx

x = mx.sym.Variable('data')
log_x = mx.sym.log(x)
log_x_squared = mx.sym.square(log_x)

mod = mx.mod.Module(log_x_squared)  # Create a module where the loss function
                                    # is the one we want to optimize
mod.bind(data_shapes=[('data', (1,1))])  # ?? not sure if this is correct - we
                                         # are saying our input is a scalar
mod.init_params()
mod.init_optimizer()  # SGD is default

mod.fit()  # ?? must pass data_iter to fit
</code></pre>

<p>It seems like the <code>x</code> variable should be somehow fed back in as the <code>data_iter</code> but I don't know how to accomplish this.</p>

<p><strong>Update:</strong> thanks to <a href=""https://stackoverflow.com/a/44810723/3363678"">kevinthesun</a> for their excellent answer! Here is a working minimization routine built on top of a single hidden-layer neural net:</p>

<pre><code>import mxnet as mx
import numpy as np


def minimize(objective_function,
             initial_params,
             max_iters=1000,
             optimizer='sgd',
             optimizer_params=(('learning_rate', 0.1),),
             tol=1e-8):

    class InitialParam(mx.init.Initializer):

        def __init__(self, vals):
            super(InitialParam, self).__init__()
            self._vals = vals

        def _init_weight(self, _, arr):
            arr[:] = self._vals.asnumpy()[:, np.newaxis]


    x = mx.sym.Variable('data')
    params_len = initial_params.shape[0]
    fc = mx.sym.FullyConnected(data=x, name='fc1',
                               num_hidden=params_len,
                               no_bias=True)

    # Passing the FullyConnected layer into the objective function
    # is difficult to manipulate. If the fully connected layer represents
    # [x, y] for optimizing a 2 dimensional function f(x, y) it is easier
    # to work with x, and y. So we split the fully connected layer into a
    # number of symbols for each parameter:
    param_syms = []
    for i in range(params_len):
        ps = mx.sym.slice(fc, begin=(0, i), end=(1, i + 1))
        param_syms.append(ps)

    # The loss function for the network is our objective function.
    loss = mx.sym.MakeLoss(objective_function(param_syms))
    mod = mx.mod.Module(loss)

    mod.bind(data_shapes=[('data', (1,))])
    mod.init_params(InitialParam(initial_params))
    mod.init_optimizer(optimizer=optimizer,
                       optimizer_params=optimizer_params)

    (o_name, o_shape), = mod.output_shapes

    i = 0
    params = initial_params
    old_val = np.full(o_shape, np.nan)
    while i &lt; max_iters:
        mod.forward_backward(mx.io.DataBatch(
            data=[mx.nd.ones((1,))])) 
        mod.update()
        params = mod.get_params()[0]['fc1_weight']
        val = mod.get_outputs()[0].asnumpy()
        if np.allclose(old_val, val, atol=tol):
            print 'Function value: {}'.format(val)
            print 'Iterations: {}'.format(i)
            return params

        old_val = val
        i += 1

    return params
</code></pre>

<p>and using it:</p>

<pre><code>def my_func(x):
    return (x[0] + 1) ** 2

p = minimize(my_func, mx.nd.array([1.0]))
p.asnumpy()

&gt;&gt;&gt; array([[-0.99999988]], dtype=float32)
</code></pre>

<p>and another:</p>

<pre><code>def my_func(x):
    return (x[0] + 1) ** 2 + (x[1] - 2) ** 2 + (x[2] + 3) ** 2

p = minimize(my_func, mx.nd.array([1.0, 1.5, 2.0]))
p.asnumpy()

&gt;&gt;&gt; array([[-0.99996436],
           [ 1.99999106],
           [-2.99991083]], dtype=float32)
</code></pre>
","<python><gradient-descent><mxnet>","2017-06-28 04:32:21","","4","3363678","2017-06-29 23:39:33","2","0","1","","3363678","23","10","0"
"53990417","<p>When training MXNet, if the batch size is large(say 128), and the number of GPUs is small(say 2), and each GPU can only handle a few samples each iteration(say 16). By default, the maximum batch size of this configuration is 16 * 2 = 32.</p>

<p>In theory, we can run 4 iterations before updating the weights, to make effective batch size 128. Is this possible with MXNet?</p>
","<machine-learning><deep-learning><gpu><mxnet>","2018-12-31 18:30:23","","0","3380501","2019-01-24 19:38:03","1","0","","","3380501","22","18","0"
"45930003","<p>Hi I try to install mxnet R in windows.
Followed by mxnet.com web page, <a href=""https://mxnet.incubator.apache.org/get_started/install.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/get_started/install.html</a>,
I ran the prebuild package. The command looks to be run successfully. But when I start mxnet by ""library(mxnet)"", I see the following error.</p>

<p>library(mxnet)
Error: package or namespace load failed for ‘mxnet’:
.onLoad failed in loadNamespace() for 'mxnet', details:
call: inDL(x, as.logical(local), as.logical(now), ...)
error: unable to load shared object 'C:/Program Files/R/R-3.4.1patched/library/mxnet/libs/x64/libmxnet.dll':
LoadLibrary failure: The specified module could not be found.</p>

<p>I checked the directory. The dll was found.</p>

<p>What is wrong?</p>
","<r><installation><windows-10><gpu><mxnet>","2017-08-29 02:51:58","","0","7420349","2018-03-09 00:48:36","1","2","","","7420349","1","0","0"
"45360332","<p>I am trying to get running mxnet but I still get this error, can you help me please ?</p>

<pre><code>Error: package or namespace load failed for ‘mxnet’:

 .onLoad failed in loadNamespace() for 'mxnet', details:

  call: inDL(x, as.logical(local), as.logical(now), ...)

  error: unable to load shared object 'C:/Users/patrik/Documents/R/win-library/3.4/mxnet/libs/x64/libmxnet.dll':

LoadLibrary failure:  The specified module could not be found.
</code></pre>
","<r><windows><mxnet>","2017-07-27 20:20:18","","0","8378438","2018-03-16 21:49:48","1","2","","","8378438","38","1","0"
"36148052","<p>I have tried to run install Mxnet deeplearning framework but I failed because of the following error when I tried to run the python example, and I could not find the best treatment in the web.</p>

<pre><code>MacBook-Pro-4:mxnet chinhiroshi$ python example/image-classification/train_mnist.py
2016-03-22 11:51:59,386 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus=None, kv_store='local', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='mlp', num_epochs=10, num_examples=60000)
Traceback (most recent call last):
  File ""example/image-classification/train_mnist.py"", line 130, in &lt;module&gt;
    train_model.fit(args, net, get_iterator(data_shape))
  File ""/Users/chinhiroshi/Dropbox/code/python/package/mxnet/example/image-classification/train_model.py"", line 41, in fit
    save_model_prefix = args.save_model_prefix
AttributeError: 'Namespace' object has no attribute 'save_model_prefix'
</code></pre>
","<python><namespaces><mxnet>","2016-03-22 07:03:15","","0","5184972","2017-09-10 03:26:48","1","0","","","5184972","1","0","0"
"53353380","<p>I classify five classes, color, 128x128 pixel images, batch size = 64, using the Generative Adversarial Network. When creating a discriminator module, when execution </p>

<p><code>discriminator.bind(data_shapes = image_iter.provide_data, label_shapes = [('label', (batch_size, ))], inputs_need_grad = True)</code></p>

<p>I get an error:</p>

<p><code>data: (64, 3, 128, 128)
label: (64,)
Error in operator dloss: Shape inconsistent, Provided=[64], inferred shape=[64,25]</code></p>

<p>And I do not understand where does the number ""25"" come from?
Operator dloss:</p>

<p><code>discriminatorSymbol = mx.sym.LogisticRegressionOutput(data = fl5, label = label, name = 'dloss')</code></p>

<p>I took all the information from this <a href=""http://mxnet.apache.org/tutorials/unsupervised_learning/gan.html"" rel=""nofollow noreferrer"">example</a>. And everything works there.</p>
","<python><python-3.x><jupyter-notebook><mxnet>","2018-11-17 16:51:24","","0","10667603","2018-11-30 19:27:06","1","0","1","","10667603","4","0","0"
"53286509","<p>I've been trying to create a simple <em>.exe</em> file to receive a parameter and return the output of a my net, in alternative to use a C++ wrapper. </p>

<p>I'm using pyinstaller because it's the one that has worked better for me in the past. </p>

<p>Right now I'm only building a <em>.py</em> file only with the imports but I'm already getting the following error:</p>

<pre><code>RuntimeError: Cannot find the MXNet library.
List of candidates:
C:\Users\&lt;user&gt;\AppData\Local\Temp\_MEI52802\mxnet\libmxnet.dll
...
</code></pre>

<p>My imports.py</p>

<pre><code>import time
import numpy as np
import mxnet as mx
from mxnet import gluon, autograd, nd
from mxnet.gluon import nn, rnn
import string
import cv2
import glob
import time
import model
</code></pre>

<p><strong>What I've tried:</strong></p>

<ul>
<li>Using pyinstaller in python 3.6/3.5/3.4;</li>
<li>Edit the <em>.spec</em> and adding the <em>dll</em> missing to the binaries list;</li>
<li>Adding mxnet as a hidden import.</li>
</ul>

<p>Regards.</p>
","<python><exe><pyinstaller><mxnet>","2018-11-13 17:27:04","","2","8444657","2019-03-01 22:47:27","1","3","","","8444657","11","0","0"
"45710565","<p>Here I would like to generate a tutorial usage of LSTM in MxNet, with the example for Tensorflow. (location at <a href=""https://github.com/mouradmourafiq/tensorflow-lstm-regression/blob/master/lstm_sin.ipynb"" rel=""nofollow noreferrer"">https://github.com/mouradmourafiq/tensorflow-lstm-regression/blob/master/lstm_sin.ipynb</a>""
Here is my major code</p>

<pre><code>import mxnet as mx
import numpy as np
import pandas as pd
import argparse
import os
import sys
from data_processing import generate_data
import logging
head = '%(asctime)-15s %(message)s'
logging.basicConfig(level=logging.DEBUG, format=head)
TIMESTEPS = 3
BATCH_SIZE = 100
X, y = generate_data(np.sin, np.linspace(0, 100, 10000), TIMESTEPS, seperate=False)
train_iter = mx.io.NDArrayIter(X['train'], y['train'], batch_size=BATCH_SIZE, shuffle=True, label_name='lro_label')
eval_iter = mx.io.NDArrayIter(X['val'], y['val'], batch_size=BATCH_SIZE, shuffle=False)
test_iter = mx.io.NDArrayIter(X['test'], batch_size=BATCH_SIZE, shuffle=False)
num_layers = 3
num_hidden = 50

data = mx.sym.Variable('data')
label = mx.sym.Variable('lro_label')

stack = mx.rnn.SequentialRNNCell()
for i in range(num_layers):
    stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix='lstm_l%d_'%i))
#stack.reset()
outputs, states = stack.unroll(length=TIMESTEPS,
                               inputs=data,
                               layout='NTC',
                               merge_outputs=True)

outputs = mx.sym.reshape(outputs, shape=(BATCH_SIZE, -1))
# purpose of fc1 was to make shape change to (batch_size, *), or label shape won't match LSTM unrolled output shape.
outputs = mx.sym.FullyConnected(data=outputs, num_hidden=1, name='fc1')
label = mx.sym.reshape(label, shape=(-1,))
outputs = mx.sym.LinearRegressionOutput(data=outputs, 
                               label=label,
                               name='lro')
contexts = mx.cpu(0)
model = mx.mod.Module(symbol = outputs,
                     data_names = ['data'],
                     label_names = ['lro_label'])
model.fit(train_iter, eval_iter,
         optimizer_params = {'learning_rate':0.005},
         num_epoch=4,
         batch_end_callback=mx.callback.Speedometer(BATCH_SIZE, 2))
</code></pre>

<p>This code runs but the train_accuracy is Nan.
The question is how to make it correct?
And since unrolled out shape has sequence_length, how can it match to label shape? Did my FC1 net make sense?</p>
","<mxnet>","2017-08-16 10:01:29","","0","2189731","2018-01-10 18:34:09","1","1","","","2189731","102","9","0"
"53692644","<p>Hi I am trying to extract the output of the penulitmate layer from a pre trained model(RsNet-152) in MxNet. As I need the script to work with a java application, I going with scala as the choice of language.</p>

<p>I followed the steps mentioned here <a href=""https://mxnet.incubator.apache.org/tutorials/python/predict_image.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/python/predict_image.html</a></p>

<p>and modified by script accordingly. 
Here is the loadModel function.</p>

<pre><code>  def loadResnetModel(modelPath: String): Module = {
val (net, argParams, auxParams) = Model.loadCheckpoint(modelPath, modelFileNumber)
val allLayer = net.getInternals()
val secondLastLayer = allLayer.get(""flatten0_output"")
val mod = new Module(symbolVar = secondLastLayer, contexts = Context.cpu(), labelNames =null)
val dataShape = ListMap(""data"" -&gt; Shape(1, 3, 224, 224))
mod.bind(dataShapes=dataShape, forTraining = false)
mod.setParams(argParams, auxParams, allowMissing=true)
mod
</code></pre>

<p>when trying to run the script, I am getting the following error.</p>

<pre><code> Exception in thread ""main"" java.lang.IllegalArgumentException: requirement failed: Find name fc1_bias that is not in the arguments
 [java]     at scala.Predef$.require(Predef.scala:224)
 [java]     at org.apache.mxnet.Executor$$anonfun$copyParamsFrom$1.apply(Executor.scala:274)
 [java]     at org.apache.mxnet.Executor$$anonfun$copyParamsFrom$1.apply(Executor.scala:270)
 [java]     at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)
 [java]     at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
 [java]     at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
 [java]     at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
 [java]     at org.apache.mxnet.Executor.copyParamsFrom(Executor.scala:270)
 [java]     at org.apache.mxnet.module.DataParallelExecutorGroup$$anonfun$setParams$1.apply(DataParallelExecutorGroup.scala:452)
 [java]     at org.apache.mxnet.module.DataParallelExecutorGroup$$anonfun$setParams$1.apply(DataParallelExecutorGroup.scala:452)
 [java]     at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
 [java]     at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
 [java]     at org.apache.mxnet.module.DataParallelExecutorGroup.setParams(DataParallelExecutorGroup.scala:452)
 [java]     at org.apache.mxnet.module.Module.setParams(Module.scala:201)
</code></pre>

<p>P.S : I am new to mxnet and scala. Is there any obvious mistake I am not seeing?</p>
","<scala><mxnet>","2018-12-09 13:12:33","","1","6700514","2018-12-18 01:18:51","1","1","1","","6700514","6","0","0"
"45719597","<p>I am following the description and example for creating a custom iterator as described here: <a href=""http://mxnet.io/tutorials/basic/data.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/basic/data.html</a></p>

<p>The following code produces a ValueError:</p>

<pre><code>mod.fit(data_iter, num_epoch=5)
</code></pre>

<blockquote>
  <p>ValueError: Shape of labels 0 does not match shape of predictions 1</p>
</blockquote>

<p>My questions:</p>

<ul>
<li>Can anyone reproduce this problem? </li>
<li>Does anyone know a solution?</li>
</ul>

<p>I am using jupyter on a mac with everything freshly installed, including python...
I have also tested on python directly using:</p>

<pre><code>Python 3.6.1 |Anaconda custom (x86_64)| (default, May 11 2017, 13:04:09) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
</code></pre>

<p><strong>Code</strong>:</p>

<pre><code>import mxnet as mx
import os
import subprocess
import numpy as np
import matplotlib.pyplot as plt
import tarfile

import warnings
warnings.filterwarnings(""ignore"", category=DeprecationWarning)


import numpy as np
data = np.random.rand(100,3)
label = np.random.randint(0, 10, (100,))
data_iter = mx.io.NDArrayIter(data=data, label=label, batch_size=30)
for batch in data_iter:
    print([batch.data, batch.label, batch.pad])

#[[&lt;NDArray 30x3 @cpu(0)&gt;], [&lt;NDArray 30 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], [&lt;NDArray 30 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], [&lt;NDArray 30 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], [&lt;NDArray 30 @cpu(0)&gt;], 20]


#lets save `data` into a csv file first and try reading it back
np.savetxt('data.csv', data, delimiter=',')
data_iter = mx.io.CSVIter(data_csv='data.csv', data_shape=(3,), batch_size=30)
for batch in data_iter:
    print([batch.data, batch.pad])

#[[&lt;NDArray 30x3 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], 0]
#[[&lt;NDArray 30x3 @cpu(0)&gt;], 20]

class SimpleIter(mx.io.DataIter):
    def __init__(self, data_names, data_shapes, data_gen,
                 label_names, label_shapes, label_gen, num_batches=10):
        self._provide_data = zip(data_names, data_shapes)
        self._provide_label = zip(label_names, label_shapes)
        self.num_batches = num_batches
        self.data_gen = data_gen
        self.label_gen = label_gen
        self.cur_batch = 0

    def __iter__(self):
        return self

    def reset(self):
        self.cur_batch = 0

    def __next__(self):
        return self.next()

    @property
    def provide_data(self):
        return self._provide_data

    @property
    def provide_label(self):
        return self._provide_label

    def next(self):
        if self.cur_batch &lt; self.num_batches:
            self.cur_batch += 1
            data = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_data,\
                                                        self.data_gen)]
            label = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_label,\
                                                        self.label_gen)]
            return mx.io.DataBatch(data, label)
        else:
            raise StopIteration


import mxnet as mx
num_classes = 10
net = mx.sym.Variable('data')
net = mx.sym.FullyConnected(data=net, name='fc1', num_hidden=64)
net = mx.sym.Activation(data=net, name='relu1', act_type=""relu"")
net = mx.sym.FullyConnected(data=net, name='fc2', num_hidden=num_classes)
net = mx.sym.SoftmaxOutput(data=net, name='softmax')
print(net.list_arguments())
print(net.list_outputs())

#['data', 'fc1_weight', 'fc1_bias', 'fc2_weight', 'fc2_bias', 'softmax_label']
#['softmax_output']



import logging
logging.basicConfig(level=logging.INFO)

n = 32
data_iter = SimpleIter(['data'], [(n, 100)],
                  [lambda s: np.random.uniform(-1, 1, s)],
                  ['softmax_label'], [(n,)],
                  [lambda s: np.random.randint(0, num_classes, s)])

mod = mx.mod.Module(symbol=net)
mod.fit(data_iter, num_epoch=5)
</code></pre>

<p><strong>Error</strong>:</p>

<pre><code>ValueError                                Traceback (most recent call last)
 &lt;ipython-input-57-6ceb7dd11508&gt; in &lt;module&gt;()
         9 
        10 mod = mx.mod.Module(symbol=net)
        ---&gt; 11 mod.fit(data_iter, num_epoch=5)/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/module/base_module.py in fit(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)
            493                     end_of_batch = True
            494 
        --&gt; 495                 self.update_metric(eval_metric, data_batch.label)
            496 
            497                 if monitor is not None:
/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/module/module.py in update_metric(self, eval_metric, labels)
            678             Typically ``data_batch.label``.
            679         """"""
        --&gt; 680         self._exec_group.update_metric(eval_metric, labels)
            681 
            682     def _sync_params_from_devices(self):
/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/module/executor_group.py in update_metric(self, eval_metric, labels)
            561             labels_ = OrderedDict(zip(self.label_names, labels_slice))
            562             preds = OrderedDict(zip(self.output_names, texec.outputs))
        --&gt; 563             eval_metric.update_dict(labels_, preds)
            564 
            565     def _bind_ith_exec(self, i, data_shapes, label_shapes, shared_group):
/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/metric.py in update_dict(self, label, pred)
             89             label = label.values()
             90 
        ---&gt; 91         self.update(label, pred)
             92 
             93     def update(self, labels, preds):
/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/metric.py in update(self, labels, preds)
            369             Predicted values.
            370         """"""
        --&gt; 371         check_label_shapes(labels, preds)
            372 
            373         for label, pred_label in zip(labels, preds):
/Users/bernd/anaconda/lib/python3.6/site-packages/mxnet/metric.py in check_label_shapes(labels, preds, shape)
             22     if label_shape != pred_shape:
             23         raise ValueError(""Shape of labels {} does not match shape of ""
        ---&gt; 24                          ""predictions {}"".format(label_shape, pred_shape))
             25 
             26 
ValueError: Shape of labels 0 does not match shape of predictions 1
</code></pre>
","<python><iterator><mxnet>","2017-08-16 17:21:59","","1","5692106","2017-08-20 08:33:56","1","2","","","5692106","68","10","0"
"45165443","<p>I'm trying to use MXNet to do some constrained optimization that isn't backpropogation in a feedforward network, but involves similar computations, products of large arrays, some gradient descent, etc... </p>

<p>For example, to minimize the trace of M-2*Id as M varies over the set of orthogonal matrices, I could use numpy and scipy to do this by vectorizing the matrices, as in the following:</p>

<pre><code>import numpy as np
from scipy.optimize import minimize

# make matrix to vector and vector to matrix functions
def toVector(m):
    return np.hstack(m.flatten())
def toMatrix(vec):
    return vec[:4*4].reshape(4,4)

# Define objective function to minimize
def f(x):
    matM=toMatrix(x)
    return(np.trace(matM-2*np.identity(4)))

# Define the constraint that X be orthogonal, i.e. X X^t = I
cons = ({'type': 'eq',
    ... 'fun' : lambda x: np.array(np.linalg.norm(
    ... np.dot(toMatrix(x),np.transpose(toMatrix(x)))-np.eye(4)))
    ... })

# Define an initial point randomly
m0=np.random.rand(4,4)

# And minimize
result = minimize(f, toVector(m0), constraints=cons,
    ... method='SLSQP', options={'disp': True})
toMatrix(result.x)
</code></pre>

<p>Now, suppose that I'm doing this kind of computation for NxN matrices where N is large, and I want to repeat the computation many times, updating some parameters.  Is there a good way to do this kind of constrained optimization using MXNet to work across GPU cores, compute constraint gradients, etc... without vectorizing the input and using a feedforward network workaround described in <a href=""https://stackoverflow.com/questions/44793696/simple-gradient-descent-using-mxnet"">simple-gradient-descent-using-mxnet</a>.  </p>
","<optimization><multidimensional-array><mxnet>","2017-07-18 11:25:06","","1","8320849","2018-02-16 20:22:25","1","0","","","8320849","6","0","0"
"54780877","<p>I'm running into a memory leak when performing inference on an mxnet model (i.e. converting an image buffer to tensor and running one forward pass through the model).</p>

<p>A minimal reproducable example is below:</p>

<pre><code>import mxnet
from gluoncv import model_zoo
from gluoncv.data.transforms.presets import ssd

model = model_zoo.get_model('ssd_512_resnet50_v1_coco')
model.initialize()

for _ in range(100000):
  # note: an example imgbuf string is too long to post
  # see gist or use requests etc to obtain
  imgbuf = 
  ndarray = mxnet.image.imdecode(imgbuf, to_rgb=1)
  tensor, orig = ssd.transform_test(ndarray, 512)
  labels, confidences, bboxs = model.forward(tensor)
</code></pre>

<p>The result is a linear increase of RSS memory (from 700MB up to 10GB+). </p>

<p>The problem persists with other pretrained models and with a custom model that I am trying to use. And using garbage collectors does not show any increase in objects. </p>

<p>This <a href=""https://gist.github.com/elliebirbeck/e2cf91a6bda0bc10115a47c93eed3755"" rel=""nofollow noreferrer"">gist</a> has the full code snippet including an example imgbuf.</p>

<p>Environment info:</p>

<p>python 2.7.15</p>

<p>gcc 4.2.1</p>

<p>mxnet-mkl 1.3.1</p>

<p>gluoncv 0.3.0</p>
","<memory-leaks><deep-learning><intel-mkl><mxnet><numpy-ndarray>","2019-02-20 07:22:55","","0","7705530","2019-04-11 21:53:38","1","0","","","7705530","3","0","0"
"45820231","<p>I want to try out some new activation functions and I have successfully created custom operators in C++ on top of the latest mxnet source code. But what I really like to have is to build a separate library (.so file in ubuntu) just for my custom operators so I can leave mxnet source code and its library as it is and I do not have to worry about merging my code to mxnet source code every time I need to use newer mxnet releases. I understand that if this is working, I need both libmxnet.so and mycustom.so in order to use my new activation functions. Any help is appreciated.
Thanks in advance.</p>
","<c++><mxnet>","2017-08-22 14:20:31","","2","5136105","2019-01-16 01:10:21","1","3","","","5136105","11","0","0"
"53272705","<p>I am trying to modify the weight of convolution like this.
To do this, I make, initialize my parameters(weight, bias), convolute input image using them. 
But, it shows an error because my parameters are not arguments in symbol. </p>

<p>How to add my parameters to arguments in symbol?
If you let me know, I would be very grateful.</p>
","<arguments><symbols><mxnet>","2018-11-13 02:02:07","","1","7017923","2018-11-20 21:42:32","1","1","1","","7017923","6","0","0"
"44942531","<p>trying to run this <a href=""https://github.com/zhreshold/mxnet-ssd"" rel=""nofollow noreferrer"">project</a></p>

<p>and got an error when typing:</p>

<pre><code>             python demo.py --gpu 0 
</code></pre>

<p>on my terminal </p>

<p>the error:</p>

<pre><code>Using mxnet as:
&lt;module 'mxnet' (namespace)&gt;
Warning: using pre-installed version of mxnet may cause unexpected error...
(export MXNET_EXAMPLE_SSD_DISABLE_PRE_INSTALLED=1) to prevent loading pre-installed mxnet.
Traceback (most recent call last):
  File ""demo.py"", line 6, in &lt;module&gt;
    from detect.detector import Detector
  File ""/home/ubuntu-linux/mxnet-ssd/detect/detector.py"", line 6, in &lt;module&gt;
    from dataset.iterator import DetIter
  File ""/home/ubuntu-linux/mxnet-ssd/dataset/iterator.py"", line 6, in &lt;module&gt;
    class DetRecordIter(mx.io.DataIter):
AttributeError: module 'mxnet' has no attribute 'io'
</code></pre>

<p>help</p>

<p>after running (git clone --recursive <a href=""https://github.com/zhreshold/mxnet-ssd.git"" rel=""nofollow noreferrer"">https://github.com/zhreshold/mxnet-ssd.git</a>)</p>

<p>the old error was gone but got this new error:</p>

<pre><code>Traceback (most recent call last):
  File ""demo.py"", line 2, in &lt;module&gt;
    import tools.find_mxnet
  File ""/home/ubuntu-linux/mxnet-ssd/tools/find_mxnet.py"", line 15, in &lt;module&gt;
    import mxnet as mx
  File ""/home/ubuntu-linux/mxnet-ssd/tools/../mxnet/python/mxnet/__init__.py"", line 7, in &lt;module&gt;
    from .base import MXNetError
  File ""/home/ubuntu-linux/mxnet-ssd/tools/../mxnet/python/mxnet/base.py"", line 52, in &lt;module&gt;
    _LIB = _load_lib()
  File ""/home/ubuntu-linux/mxnet-ssd/tools/../mxnet/python/mxnet/base.py"", line 43, in _load_lib
    lib_path = libinfo.find_lib_path()
  File ""/home/ubuntu-linux/mxnet-ssd/tools/../mxnet/python/mxnet/libinfo.py"", line 42, in find_lib_path
    'List of candidates:\n' + str('\n'.join(dll_path)))
RuntimeError: Cannot find the files.
List of candidates:
/home/ubuntu-linux/mxnet-ssd/mxnet/python/mxnet/libmxnet.so
/home/ubuntu-linux/mxnet-ssd/mxnet/python/mxnet/../../lib/libmxnet.so
/home/ubuntu-linux/mxnet-ssd/mxnet/python/mxnet/../../build/Release/libmxnet.so
/usr/local/cuda-8.0/lib64/libmxnet.so
libmxnet.so
../../../libmxnet.so
</code></pre>
","<python><ssd><mxnet>","2017-07-06 07:35:33","","-5","6391102","2017-07-13 06:54:52","1","8","","","6391102","20","0","0"
"43755868","<p>I have been trying to compile the prediction API using the amalgamation but when I try to use the library I get the following error:</p>

<p><strong>mxnet/nnvm/src/core/pass.cc:30: Check failed: reg != nullptr Cannot find pass LoadLegacyJSON in the registry</strong></p>

<p>here is the load code which works against the full libmxnet library</p>

<pre><code>retval = MXPredCreate((const char*) symbol,
            (const char* ) params,
            params_fsz,
            1,
            0,
            num_input_nodes,
            (const char**) input_keys,
            input_shape_indptr,
            input_shape_data,
            &amp;dnn
    );
</code></pre>

<p>Is there a compiler flag I'm missing?</p>
","<c><mxnet>","2017-05-03 09:16:29","","1","2182663","2017-06-01 13:52:58","1","0","","","2182663","351","9","1"
"43712101","<p>I'm trying to setup a LSTM RNN by using mxnet in R, however, while trying to train my network I get this error and R is showing me a fatal error all the time: 
<em>""[00:36:08] d:\program files (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:155: Using target_shape will be deprecated.
[00:36:08] d:\program files (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:155: Using target_shape will be deprecated.
[00:36:08] d:\program files (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor./matrix_op-inl.h:155: Using target_shape will be deprecated.""</em></p>

<p>here is my code:</p>

<pre><code># install.packages(""drat"", repos=""https://cran.rstudio.com"")
# drat:::addRepo(""dmlc"")
# install.packages(""mxnet"")

rm(list = ls())
require(mxnet)
require(mlbench)

inputData &lt;- read.table(file.path(getwd(), ""Data"", ""input.csv""),
                     header = TRUE, sep = "","")
inputData$X &lt;- as.Date(inputData$X)
inputData &lt;- na.omit(inputData)

index &lt;- 1:nrow(inputData)*0.8

train.dates &lt;- inputData[index,1]
test.dates &lt;- inputData[-index,1]
inputData[,1] &lt;- NULL

train &lt;- inputData[index,]
test &lt;- inputData[-index,]

train.x &lt;- data.matrix(train[,-ncol(train)])
test.x &lt;- data.matrix(test[,-ncol(test)])

train.y &lt;- train[,ncol(train)]
test.y &lt;- test[,ncol(test)]

get.label &lt;- function(X) {
  label &lt;- array(0, dim=dim(X))
  d &lt;- dim(X)[1]
  w &lt;- dim(X)[2]
  for (i in 0:(w-1)) {
    for (j in 1:d) {
      label[i*d+j] &lt;- X[(i*d+j)%%(w*d)+1]
    }
  }
  return (label)
}

X.train.label &lt;- get.label(t(train.x))
X.val.label &lt;- get.label(t(test.x))

X.train &lt;- list(data=t(train.x), label=X.train.label)
X.val &lt;- list(data=t(test.x), label=X.val.label)

batch.size = 1
seq.len = 32
num.hidden = 16
num.embed = 16
num.lstm.layer = 1
num.round = 1
learning.rate= 0.1
wd=0.00001
clip_gradient=1
update.period = 1

model &lt;- mx.lstm(X.train, X.val,
                 ctx=mx.cpu(),
                 num.round=num.round,
                 update.period=update.period,
                 num.lstm.layer=num.lstm.layer,
                 seq.len=seq.len,
                 num.hidden=num.hidden,
                 num.embed=num.embed,
                 num.label=15,
                 batch.size=batch.size,
                 input.size=15,
                 initializer=mx.init.uniform(0.1),
                 learning.rate=learning.rate,
                 wd=wd,
                 clip_gradient=clip_gradient)
</code></pre>

<p>Input dataset consists of Date column, 15 features, and the target value.
Please hep me. Thanks in advance!</p>
","<r><machine-learning><neural-network><lstm><mxnet>","2017-04-30 22:42:28","","0","7944891","2018-04-12 21:09:18","1","1","","","7944891","1","0","0"
"54746323","<p>I see that this question has been asked before, however none of the solutions seem to work for me.</p>

<p>I am trying to install mxnet on MacOS Mojave ver 10.14.3 for R. But I just can't get it to work.</p>

<p>I followed the installation instructions on the mxnet website and tried to build from source but to no success. Here's the error I get:</p>

<pre><code>Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so':

  dlopen(/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so, 10): Library not loaded: /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so
  Reason: image not found 
</code></pre>

<p>I tried adding the soft link for openBlas using:</p>

<pre><code>ln -sf /usr/local/opt/openblas/lib/libopenblasp-r0.3.* /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib
</code></pre>

<p>but it didn't work. When I run <code>sessioninfo()</code> in R, this is the output I get:</p>

<pre><code>&gt; sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS  10.14.3

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_IE.UTF-8/en_IE.UTF-8/en_IE.UTF-8/C/en_IE.UTF-8/en_IE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] usethis_1.4.0  devtools_2.0.1

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.0         tidyr_0.8.1        prettyunits_1.0.2 
 [4] ps_1.1.0           visNetwork_2.0.5   assertthat_0.2.0  
 [7] rprojroot_1.3-2    digest_0.6.18      R6_2.3.0          
[10] plyr_1.8.4         backports_1.1.2    ggplot2_3.0.0     
[13] pillar_1.3.1       rlang_0.3.1        lazyeval_0.2.1    
[16] rstudioapi_0.8     callr_3.0.0        DiagrammeR_1.0.0  
[19] desc_1.2.0         downloader_0.4     readr_1.3.1       
[22] stringr_1.3.1      htmlwidgets_1.3    igraph_1.2.2      
[25] munsell_0.5.0      compiler_3.5.1     influenceR_0.1.0  
[28] rgexf_0.15.3       pkgconfig_2.0.2    base64enc_0.1-3   
[31] pkgbuild_1.0.2     htmltools_0.3.6    tidyselect_0.2.4  
[34] tibble_2.0.1       gridExtra_2.3      XML_3.98-1.16     
[37] viridisLite_0.3.0  crayon_1.3.4       dplyr_0.7.6       
[40] withr_2.1.2        grid_3.5.1         jsonlite_1.6      
[43] gtable_0.2.0       magrittr_1.5       scales_1.0.0      
[46] cli_1.0.1          stringi_1.2.4      fs_1.2.6          
[49] remotes_2.0.2      viridis_0.5.1      testthat_2.0.1    
[52] bindrcpp_0.2.2     brew_1.0-6         RColorBrewer_1.1-2
[55] tools_3.5.1        glue_1.3.0         purrr_0.2.5       
[58] hms_0.4.2          Rook_1.1-1         processx_3.2.0    
[61] pkgload_1.0.2      yaml_2.2.0         colorspace_1.3-2  
[64] sessioninfo_1.1.1  memoise_1.1.0      bindr_0.1.1  
</code></pre>

<p>Any suggestions as to how I'd fix this?</p>
","<r><macos><mxnet>","2019-02-18 11:31:32","","0","3447708","2019-02-18 11:31:32","0","0","","","3447708","69","4","0"
"45849548","<p>Thanks in advance for any help.</p>

<p>I am having some issues getting an mxnet model to converge to anything: it seems stuck close to its initial weights.</p>

<p>A working example (although I have struggled to get many such models working today). I have tried the approach below with a range of epochs (up to 100), and a range of learning rates (0.001 to 10), and cannot get anything sensible out of this.</p>

<pre><code>import mxnet as mx
import numpy as np

inputs = np.expand_dims(np.random.uniform(size=10000), axis=1)
labels = np.sin(inputs)

data_iter = mx.io.NDArrayIter(data=inputs, label=labels, data_name='data', label_name='label', batch_size=50)

data = mx.sym.Variable('data')
label = mx.sym.Variable('label')

fc1 = mx.sym.FullyConnected(data=data, num_hidden=128)
ac1 = mx.sym.Activation(data=fc1, act_type='relu')

fc2 = mx.sym.FullyConnected(data=ac1, num_hidden=64)
ac2 = mx.sym.Activation(data=fc2, act_type='relu')

fc3 = mx.sym.FullyConnected(data=ac2, num_hidden=16)
ac3 = mx.sym.Activation(data=fc3, act_type='relu')

output = mx.sym.FullyConnected(data=ac3, num_hidden=1)
loss = mx.symbol.MakeLoss(mx.symbol.square(output - label), name=""loss"")

model = mx.module.Module(symbol=loss, data_names=('data',), label_names=('label',))

import logging
logging.getLogger().setLevel(logging.DEBUG)
model.fit(data_iter,
          optimizer='sgd',
          optimizer_params={'learning_rate':0.1},
          eval_metric='mse',
          num_epoch=5)
</code></pre>

<p>gives rise to:</p>

<pre><code>INFO:root:Epoch[0] Train-mse=0.221155
INFO:root:Epoch[0] Time cost=0.173
INFO:root:Epoch[1] Train-mse=0.225179
INFO:root:Epoch[1] Time cost=0.176
INFO:root:Epoch[2] Train-mse=0.225179
INFO:root:Epoch[2] Time cost=0.179
INFO:root:Epoch[3] Train-mse=0.225179
INFO:root:Epoch[3] Time cost=0.176
INFO:root:Epoch[4] Train-mse=0.225179
INFO:root:Epoch[4] Time cost=0.183
</code></pre>

<p>where it's clear the training isn't really progressing.</p>
","<machine-learning><neural-network><deep-learning><mxnet>","2017-08-23 21:27:41","","1","8508447","2017-09-10 11:09:40","1","2","","","8508447","108","2","0"
"41132794","<p>Running the tutorial at the link below, I get the error below when I get to the step below. No errors before this point.</p>

<p><a href=""http://mxnet.io/tutorials/r/classifyRealImageWithPretrainedModel.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/r/classifyRealImageWithPretrainedModel.html</a></p>

<blockquote>
  <p>prob &lt;- predict(model, X=normed)
  [19:01:35] D:\chhong\mxnet\dmlc-core\include\dmlc/logging.h:235: [19:01:35] d:\chhong\mxnet\src\operator./concat-inl.h:152: Check failed: (dshape[j]) == (tmp[j]) Incorrect shape[2]: (1,320,15,15). (first input shape: (1,576,14,14))
  Error: InferShape Error in ch_concat_3c_chconcat: [19:01:35] d:\chhong\mxnet\src\operator./concat-inl.h:152: Check failed: (dshape[j]) == (tmp[j]) Incorrect shape[2]: (1,320,15,15). (first input shape: (1,576,14,14))</p>
</blockquote>
","<r><mxnet>","2016-12-14 00:19:53","","0","5329033","2018-03-06 01:40:48","2","2","","","5329033","27","0","0"
"49786904","<p>I'm trying to install mxnet on my MacBook Pro. The first step on their website was to install Homebrew by typing: </p>

<pre><code>/usr/bin/ruby -e ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)""
</code></pre>

<p>in the Terminal. </p>

<p>This gave me the error below. </p>

<blockquote>
  <p>Conrados-MBP:~ conrados$ /usr/bin/ruby -e ""$(curl -fsSL <a href=""https://raw.githubusercontent.com/Homebrew/install/master/install"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/Homebrew/install/master/install</a>)""
  curl: (1) Protocol ""https"" not supported or disabled in libcurl</p>
</blockquote>

<p>How do I fix this?    </p>
","<python><curl><mxnet>","2018-04-12 02:09:36","","1","7578876","2018-04-12 19:00:41","2","0","","","7578876","43","3","0"
"51732258","<p>I am having trouble finding the answer to this. </p>

<p>I have an MXNet file in the form of:
<code>model.json</code> and <code>model.params.</code> What is the cleanest way to load the network into a Keras installation with TensorFlow backend?</p>
","<python><machine-learning><keras><mxnet>","2018-08-07 17:21:50","","0","6382547","2018-08-07 20:54:48","1","0","","","6382547","6","0","0"
"43317419","<p>I am trying to install MXNet R version on Amazon Web Service EC2 (ubuntu 14.04LTS) by following the instruction: <a href=""http://mxnet.io/get_started/ubuntu_setup.html"" rel=""nofollow noreferrer"">http://mxnet.io/get_started/ubuntu_setup.html</a>.</p>

<p>First I downloaded CUDA 8toolkit from nvidia.</p>

<pre><code>sudo dpkg -i cuda-repo-ubuntu1404_8.0.61-1_amd64.deb
sudo apt-get update
sudo apt-get install cuda
</code></pre>

<p>Then downloaded the latest cudnn file(cudnn-8.0-linux-x64-v6.0.tgz) and transfer it to ec2 instance by scp.</p>

<p>In ec2 console (accessed by SSH), I typed</p>

<pre><code>tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz
sudo cp -P cuda/include/cudnn.h /usr/local/cuda/include
sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
sudo ldconfig 
</code></pre>

<p>(thou I originally transfered cuda install file on /usr/local/. So the two lines of codes copying files to my local directory.)</p>

<p>Then I install mxnet source file from git, made config.mk file, and modified the config.mk to USE_CUDA=1, and so on (for GPU usage). Moved to set-utils directory and compiled ubuntu r version shell script. </p>

<pre><code>git clone https://github.com/dmlc/mxnet.git ~/mxnet --recursive

cd ~/mxnet
cp make/config.mk .
# If building with GPU, add configurations to config.mk file:
echo ""USE_CUDA=1"" &gt;&gt;config.mk
echo ""USE_CUDA_PATH=/usr/local/cuda"" &gt;&gt;config.mk
echo ""USE_CUDNN=1"" &gt;&gt;config.mk

cd ~/mxnet/setup-utils
bash install-mxnet-ubuntu-r.sh
</code></pre>

<p>Of course I added environment variable by following commands:</p>

<pre><code>export CUDA_HOME=/usr/local/cuda-8.0
export CUDA_ROOT=/usr/local/cuda-8.0/bin
export LD_LIBRARY_PATH=${CUDA_HOME}/lib64
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda
PATH=${CUDA_HOME}/bin:${PATH}
</code></pre>

<p>FYI, I checked the nvidia driver is installed properly by 'nvidia-smi' command.</p>

<p>I launched R and punched,</p>

<pre><code>library(mxnet)
</code></pre>

<p>Then the output was </p>

<pre><code>Rcpp Init&gt; 
</code></pre>

<p>I ran some test code for mxnet and it worked fine. </p>

<p>So I proceed to run GPU using code (Lenet):</p>

<pre><code>require(mxnet)
train &lt;- read.csv('train.csv', header=TRUE)
test &lt;- read.csv('test.csv', header=TRUE)
train &lt;- data.matrix(train)
test &lt;- data.matrix(test)

train.x &lt;- train[,-1]
train.y &lt;- train[,1]

train.x &lt;- t(train.x/255)
test &lt;- t(test/255)

# input
data &lt;- mx.symbol.Variable('data')
# first conv
conv1 &lt;- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 &lt;- mx.symbol.Activation(data=conv1, act_type=""tanh"")
pool1 &lt;- mx.symbol.Pooling(data=tanh1, pool_type=""max"",
                      kernel=c(2,2), stride=c(2,2))
# second conv
conv2 &lt;- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
tanh2 &lt;- mx.symbol.Activation(data=conv2, act_type=""tanh"")
pool2 &lt;- mx.symbol.Pooling(data=tanh2, pool_type=""max"",
                      kernel=c(2,2), stride=c(2,2))
# first fullc
flatten &lt;- mx.symbol.Flatten(data=pool2)
fc1 &lt;- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh3 &lt;- mx.symbol.Activation(data=fc1, act_type=""tanh"")
# second fullc
fc2 &lt;- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
# loss
lenet &lt;- mx.symbol.SoftmaxOutput(data=fc2)

train.array &lt;- train.x
dim(train.array) &lt;- c(28, 28, 1, ncol(train.x))
test.array &lt;- test
dim(test.array) &lt;- c(28, 28, 1, ncol(test))
n.gpu &lt;- 4
device.gpu &lt;- lapply(0:(n.gpu-1), function(i) {
mx.gpu(i)
})
mx.set.seed(0)
tic &lt;- proc.time()
model &lt;- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
                                ctx=device.gpu, num.round=5, array.batch.size=100,
                                learning.rate=0.05, momentum=0.9, wd=0.00001,
                                eval.metric=mx.metric.accuracy,
                                  epoch.end.callback=mx.callback.log.train.metric(100))
</code></pre>

<p>This is a basic tutorial code from mxnet page.</p>

<p>But I got following error messages:</p>

<pre><code>Auto-select kvstore type = local_update_cpu
Start training with 4 devices
[07:05:37] /root/mxnet/dmlc-core/include/dmlc/logging.h:300: [07:05:37] src/storage/storage.cc:77: Compile with USE_CUDA=1 to enable GPU usage

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f296b8659cc]
[bt] (1) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(+0xed1be3) [0x7f296c51cbe3]
[bt] (2) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(+0xed43c3) [0x7f296c51f3c3]
[bt] (3) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(_ZN5mxnet11StorageImpl5AllocEmNS_7ContextE+0x3f) [0x7f296c51f77f]
[bt] (4) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(MXNDArrayCreate+0x63d) [0x7f296c0e83bd]
[bt] (5) /usr/local/lib/R/site-library/mxnet/libs/mxnet.so(_ZN5mxnet1R7NDArray5EmptyERKN4Rcpp9DimensionERKNS2_6VectorILi19ENS2_15PreserveStorageEEE+0xdd) [0x7f295ac7ebbd]
[bt] (6) /usr/local/lib/R/site-library/mxnet/libs/mxnet.so(_ZN4Rcpp12CppFunction2INS_4XPtrIN5mxnet1R6NDBlobENS_15PreserveStorageEXadL_ZNS_25standard_delete_finalizerIS4_EEvPT_EELb0EEERKNS_9DimensionERKNS_6VectorILi19ES5_EEEclEPP7SEXPREC+0xd2) [0x7f295ac8b552]
[bt] (7) /usr/local/lib/R/site-library/Rcpp/libs/Rcpp.so(_Z23InternalFunction_invokeP7SEXPREC+0xd1) [0x7f2971c69cd1]
[bt] (8) /usr/lib/R/lib/libR.so(+0xce3c1) [0x7f29762a83c1]
[bt] (9) /usr/lib/R/lib/libR.so(Rf_eval+0x6fb) [0x7f29762ed5ab]

Error in mx.nd.internal.empty.array(shape, ctx) :
  [07:05:37] src/storage/storage.cc:77: Compile with USE_CUDA=1 to enable GPU usage

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f296b8659cc]
[bt] (1) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(+0xed1be3) [0x7f296c51cbe3]
[bt] (2) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(+0xed43c3) [0x7f296c51f3c3]
[bt] (3) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(_ZN5mxnet11StorageImpl5AllocEmNS_7ContextE+0x3f) [0x7f296c51f77f]
[bt] (4) /usr/local/lib/R/site-library/mxnet/libs/libmxnet.so(MXNDArrayCreate+0x63d) [0x7f296c0e83bd]
[bt] (5) /usr/local/lib/R/site-library/mxnet/libs/mxnet.so(_ZN5mxnet1R7NDArray5EmptyERKN4Rcpp9DimensionERKNS2_6VectorILi19ENS2_15PreserveStorageEEE+0xdd) [0x7f295ac7ebbd]
[bt] (6) /usr/local/lib/R/site-library/mxnet/libs/mxnet.so(_ZN4Rcpp12CppFunction2INS_4XPtrIN5mxnet1R6NDBlobENS_15PreserveStorageEXadL_ZNS_25standard_delete_finalizerIS4_EEvPT_EEL
</code></pre>

<p>I want to make sure:</p>

<ol>
<li>I modified the config.mk file 'before' I actaully compile by 'bash install--mxnet-ubuntu-r.sh' command. </li>
<li>Changed enviornment variables as many ways as possible. </li>
<li>Repeated above steps at least 7 times. </li>
<li>My final goal is to run a code which contains mxnet lenet by batch file(R CMD BATCH ~.R)</li>
</ol>

<p>I would be very appreciated if someone can manage to solve my problem. </p>
","<r><linux><amazon-ec2><mxnet>","2017-04-10 07:42:05","","0","6089083","2018-04-12 19:51:48","1","3","","","6089083","1","0","0"
"48188739","<p>I am trying to import mxnet on a shared cluster, but I encounter errors:</p>

<pre><code>import mxnet as mx
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/ironfs/scratch/carlos/anaconda3/lib/python3.6/site-packages/mxnet/__init__.py"", line 25, in &lt;module&gt;
    from .base import MXNetError
  File ""/home/ironfs/scratch/carlos/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 96, in &lt;module&gt;
    _LIB = _load_lib()
  File ""/home/ironfs/scratch/carlos/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 88, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""/home/ironfs/scratch/carlos/anaconda3/lib/python3.6/ctypes/__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /lib64/libc.so.6: version GLIBC_2.17' not found (required by /home/ironfs/scratch/carlos/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so)
</code></pre>

<p>And I am not admin. Can anyone help me to fix that?</p>
","<python><glibc><mxnet>","2018-01-10 13:40:10","","1","9198768","2018-03-06 20:34:20","1","4","","","9198768","6","0","0"
"48008998","<p>I have installed the newest mxnet version 1.0.0 from pip.
When I print the Layer's weight, it assert a KeyError: ""Shape"". I'm new in mxnet and everything I have followed with the mxnet official tutorial.</p>

<pre><code>import mxnet
from mxnet import nd,gluon,autograd

net=gluon.nn.Dense(10,in_units=30)
print (net.weight)
</code></pre>

<p>The error is:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/user/docs/mxnet/mtcnn/tmp/learn_mxnet.py"", line 5, in &lt;module&gt;
    print (net.weight)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/gluon/parameter.py"", line 120, in __repr__
    return s.format(**self.__dict__)
KeyError: 'shape'
</code></pre>

<p>I think it may be the problem of the version 1.0.0.</p>
","<python><deep-learning><mxnet>","2017-12-28 14:09:46","","0","9149573","2017-12-29 19:40:11","2","0","","","9149573","3","0","0"
"51326908","<p>I make a densenet network from gluon.vision </p>

<pre><code>densenet = vision.densenet121(pretrained=True, ctx=mx.cpu())
</code></pre>

<p>I want to get the outputs of each convolutionnal layer (after a prediction), to plot them afterwards (features maps).
I can't do <code>densenet.get_internals()</code> (as I saw on internet and Github), as my network is not a Symbol but a HybridBlock.</p>
","<mxnet>","2018-07-13 13:59:36","","0","8362947","2018-07-16 08:06:31","1","0","","","8362947","219","130","1"
"51288558","<p>I read about the possibility to use NVidia with mxnet package, however I didn't find anything about using RX Radeon GPU. can I specifically use RX Radeon with mxnet package in R?
Below is the link that explains mxnet Installation with NVidia:
<a href=""https://mxnet.apache.org/install/windows_setup.html"" rel=""nofollow noreferrer"">Installation with NVidia</a> </p>

<pre><code>Installing MXNet on a Computer with a GPU Processor
To install MXNet R package on a computer with a GPU processor, you need the following:

Microsoft Visual Studio 2013
The NVidia CUDA Toolkit
The MXNet package
CuDNN (to provide a Deep Neural Network library)
</code></pre>
","<r><gpu><amd><mxnet>","2018-07-11 14:51:15","","0","3972416","2018-08-07 20:14:56","1","2","","","3972416","85","60","0"
"52889337","<p>I'm trying to load an already trained model from sagemaker MXnet.</p>

<p>I have the model.tar.gz file, however, when I try to do</p>

<pre><code>&gt; %%bash
&gt; tar -xzf model.tar.gz rm model.tar.gz
&gt; prefix = 'model_name' 
&gt; sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, 0) 
&gt; mod = mx.mod.Module(symbol=sym,
&gt; context=ctx, label_names=None) mod.bind(for_training=False, data_shapes=[('data', (1,3,480,480))], label_shapes=mod._label_shapes)
&gt; mod.set_params(arg_params, aux_params)
</code></pre>

<p>I keep getting the error Error in operator multibox_target: [09:08:47] src/operator/contrib/./multibox_target-inl.h:225: Check failed: lshape.ndim() == 3 (0 vs. 3) Label should be [batch-num_labels-(>=5)] tensor</p>

<p>Can anyone help me with this?</p>
","<amazon-web-services><mxnet><amazon-sagemaker>","2018-10-19 09:15:20","","0","8858520","2018-11-24 00:02:27","1","1","1","","8858520","3","0","0"
"39179308","<p>I'm trying to do text classification using CNN. Here's some of my label: <code>dog</code>, <code>cat</code>, <code>bird</code>, <code>football</code>, <code>basketball</code>... As these classes are somehow too fine-grained to have good precision, plus the relatively small amount of training data, I group them into <code>animal</code>, <code>sports</code>.</p>

<p>Then I design a simple multi-task learning structure as below <strong>but it doesn't improve final performance</strong> on my fine-grained label.</p>

<pre><code> 18     data = mx.symbol.Variable('data')
 19     softmax_label = mx.symbol.Variable('softmax_label')
 20     softmax_label_finegrained = mx.symbol.Variable('softmax_label_finegrained')
 21
 22     # embedding layer
 23     if not with_embedding:
 24         word_embed = mx.symbol.Embedding(data=data, input_dim=vocab_size,
 25                                       output_dim=embedding_size, name='word_embedding')
 26         conv_input = mx.symbol.Reshape(data=word_embed, target_shape=(batch_size, 1, sentence_size, embedding_size))  # convolution layer needs 4D input.
 27     else:
 28         logging.info('with pretrained embedding.')
 29         conv_input = data
 30
 31     # convolution and pooling layer
 32     pooled_outputs = []
 33     for i, filter_size in enumerate(filter_list):
 34         convi = mx.symbol.Convolution(data=conv_input, kernel=(filter_size, embedding_size), num_filter=num_filter)
 35         acti  = mx.symbol.Activation(data=convi, act_type='relu')
 36         pooli = mx.symbol.Pooling(data=acti, pool_type='max', kernel=(sentence_size - filter_size + 1, 1), stride=(1,1))  # max pooling on entire sentence feature ma    p.
 37         pooled_outputs.append(pooli)
 38
 39     # combine all pooled outputs
 40     num_feature_maps = num_filter * len(filter_list)
 41     concat = mx.symbol.Concat(*pooled_outputs, dim=1)  # max-overtime pooling. concat all feature maps into a long feature before feeding into final dropout and full    y connected layer.
 42     h_pool = mx.symbol.Reshape(data=concat, shape=(batch_size, num_feature_maps))  # make it flat/horizontal
 43
 44     # dropout
 45     if dropout &gt; 0.0:
 46         logging.info('use dropout.')
 47         drop = mx.symbol.Dropout(data=h_pool, p=dropout)
 48     else:
 49         logging.info('Do not use dropout.')
 50         drop = h_pool
 51
 52     # fully connected and softmax output.
 53     logging.info('num_classes: %d', num_classes)
 54     logging.info('num_fine_classes: %d', num_fine_classes)
 55     fc = mx.symbol.FullyConnected(data=drop, num_hidden= num_classes, name='fc')
 56     fc_fine = mx.symbol.FullyConnected(data=drop, num_hidden= num_fine_classes, name='fc_fine')
 57     softmax = mx.symbol.SoftmaxOutput(data= fc, label= softmax_label)
 58     softmax_fine = mx.symbol.SoftmaxOutput(data= fc_fine, label= softmax_label_finegrained)
 59
 60     return mx.symbol.Group([softmax, softmax_fine])
</code></pre>

<p>I've also tried incorporating more information by adding an internal <code>SoftmaxActivation</code> layer after <code>fc</code> and didn't work:</p>

<pre><code> 52     # fully connected and softmax output.
 53     logging.info('num_classes: %d', num_classes)
 54     logging.info('num_fine_classes: %d', num_fine_classes)
 55     fc = mx.symbol.FullyConnected(data=drop, num_hidden= num_classes, name='fc')
 56     softmax = mx.symbol.SoftmaxOutput(data=fc, label= softmax_label)
 57     softmax_act = mx.symbol.SoftmaxActivation(data=fc)
 58     # make softmax_domain a internal layer for emitting activation, which we take it as a input into downstream task.
 59     drop_act = mx.symbol.Concat(drop, softmax_act, dim=1)
 60     fc_fine = mx.symbol.FullyConnected(data=drop_act, num_hidden= num_fine_classes, name='fc_fine')
 61     softmax_fine = mx.symbol.SoftmaxOutput(data=fc_fine, label= softmax_label_finegrained)
 62
 63     return mx.symbol.Group([softmax, softmax_fine])
 64
</code></pre>

<p>So do you guys have any idea or experience in design such network? Any ideas are welcomed, thank you~</p>
","<deep-learning><mxnet>","2016-08-27 08:57:37","","1","3264215","2018-03-08 23:35:09","1","0","1","","3264215","116","156","0"
"41583479","<p>I am trying to run a compiled version of mxnet in an <a href=""https://github.com/JuliaLang/IJulia.jl"" rel=""nofollow noreferrer"">iJulia</a> notebook, but when I execute the command <code>using MXNet</code>, I get the follow error:</p>

<pre><code>InitError: error compiling __init__: error compiling _populate_symbol_creator_cache!: error compiling _get_atomic_symbol_creators: could not load library ""/home/milton/mxnet/lib/libmxnet.so""
libcudart.so.7.5: cannot open shared object file: No such file or directory
during initialization of module mx

in _include_from_serialized(::String) at ./loading.jl:150
in _require_from_serialized(::Int64, ::Symbol, ::String, ::Bool) at ./loading.jl:187
in _require_search_from_serialized(::Int64, ::Symbol, ::String, ::Bool) at ./loading.jl:217
in require(::Symbol) at ./loading.jl:371
</code></pre>

<p>Figuring it might be ENV getting cleared, I added:</p>

<pre><code>ENV[""MXNET_HOME""] = ""/home/milton/mxnet""
ENV[""LD_LIBRARY_PATH""] = ""/home/milton/mxnet/lib:/usr/local/cuda/lib64""
</code></pre>

<p>This allows me to execute the instruction <code>using MXNet</code> without error, but raises the error again when trying to execute any commands from the mxnet library</p>

<pre><code>error compiling #Variable#215: could not load library ""/home/milton/programming/mxnet/lib/libmxnet.so""
libcudart.so.7.5: cannot open shared object file: No such file or directory

in Variable(::Symbol) at /home/milton/.julia/v0.5/MXNet/src/symbolic-node.jl:232
</code></pre>

<p>How do I fix this?  Is there somewhere else I need to define the path? Everything works fine from the REPL.</p>
","<julia><ijulia-notebook><mxnet.jl>","2017-01-11 05:42:08","","1","4232862","2017-05-02 23:42:43","1","0","","","4232862","194","14","0"
"52625954","<p>On python3 the error stack is:</p>

<pre>
>>> import mxnet
Traceback (most recent call last):
    File """", line 1, in 
    File ""C:\Python36\lib\site-packages\mxnet\__init__.py"", line 24, in 
        from .context import Context, current_context, cpu, gpu, cpu_pinned
    File ""C:\Python36\lib\site-packages\mxnet\context.py"", line 24, in 
        from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
    File ""C:\Python36\lib\site-packages\mxnet\base.py"", line 214, in 
        _LIB = _load_lib()
    File ""C:\Python36\lib\site-packages\mxnet\base.py"", line 205, in _load_lib
        lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
    File ""C:\Python36\lib\ctypes\__init__.py"", line 344, in __init__
        self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found
</pre>
","<python-3.x><windows-8.1><mxnet>","2018-10-03 11:22:13","","0","3036878","2018-10-03 11:22:13","1","0","","","3036878","162","65","2"
"55007556","<p>I trained a model using <a href=""https://mxnet.apache.org/"" rel=""nofollow noreferrer"">mxnet</a> framework. The inference time for the model is ~ 9 milliseconds.
The model mainly consists of conv layers and uses depthwise separable convolution.</p>

<p>I want to run that model in browser. I converted the model to ONNX format then from </p>

<p>ONNX -> tensorflow -> tensorflowjs.</p>

<p>The inference time for tensorflowjs model ~129 milliseconds.</p>

<p>Any suggestion to improve the performance for the model?</p>

<p>I have also tried <a href=""https://github.com/Microsoft/onnxjs"" rel=""nofollow noreferrer"">ONNXJS</a> but it seems it still has few <a href=""https://github.com/Microsoft/onnxjs/issues/94"" rel=""nofollow noreferrer"">bugs</a>.</p>
","<tensorflow><mxnet><onnx><tensorflowjs-converter>","2019-03-05 16:37:46","","0","2670420","2019-03-07 06:57:07","1","1","0","","2670420","68","71","0"
"44087457","<p>I want to upgrade to the pre-release package of mxnet <a href=""https://github.com/dmlc/mxnet/releases"" rel=""nofollow noreferrer"">pre</a>. Can i do this through <code>pip</code>? </p>

<p>I tried <code>pip</code> with <code>--pre --upgrade</code>. This installed the latest official release. Is there a way where I can upgrade to the pre-release version. i am using mac os</p>
","<pip><mxnet>","2017-05-20 15:07:53","","0","4127806","2017-06-16 23:49:21","2","0","","","4127806","670","709","0"
"44175700","<p>I have used im2rec.py to convert ""caltech101 images"" into record io format:</p>

<p>I have created ""caltech.lst"" succesfully using
os.system('python %s/tools/im2rec.py --list=1 --recursive=1 --shuffle=1 data/caltech data/101_ObjectCategories'%MXNET_HOME)
Then, when I run this :
os.system(""python %s/tools/im2rec.py --train-ratio=0.8 --test-ratio=0.2 --num-thread=4 --pass-through=1 data/caltech data/101_ObjectCategories""%MXNET_HOME)
I have this error : attributeError:'module' object has no attribute 'MXIndexedRecordIO'
Please, someone has an idea to fix this error ?
Thanks in advance.</p>

<p>Environment info</p>

<p>Operating System:Windows 8.1</p>

<p>MXNet version:0.9.5</p>
","<python-2.7><cpu><mxnet>","2017-05-25 08:20:53","","1","3824903","2017-06-08 00:05:59","2","0","","","3824903","6","0","0"
"46067530","<p>I started GPU computing by mxnetR in windows 10.</p>

<p>Simple question is if mx.mlp with mx.gpu use multiple cores in GPU. I seems not...</p>

<p>Also as a test, I wrote a simple program of mx.mlp, with doParallel. But it seems not to run the program in multiple cores. only 1 core of GPU usage was increased.</p>

<p>Please give me your ideas on how to ue multiple cores in GPU to maximize a value of GPU computing by mx.mlp with mx.gpu.</p>
","<r><windows-10><gpu><mxnet>","2017-09-06 05:37:23","","0","7420349","2017-12-07 19:20:48","1","2","","","7420349","1","0","0"
"53492219","<p>I met an infer_shape error when I test my custom operator.</p>

<p>Error Message:</p>

<pre><code>Error in &lt;my_operator_name&gt;.infer_shape: Traceback (most recent call last):
  File ""~/anaconda2/envs/mx110-py27/lib/python2.7/site-packages/mxnet/operator.py"", line 658, in infer_shape_entry
    array('I', rshape[i])),
TypeError: an integer is required
</code></pre>

<p>Have anyone met the same problem before? Thanks! </p>
","<python><mxnet>","2018-11-27 03:16:33","","0","10709384","2018-11-27 04:35:13","1","0","","","10709384","1","0","0"
"43901776","<p>I am evaluating MXNet in R and I would like to model mixture density netowrks. An example with Tensorflow, Keras and Edward can be found here: <a href=""http://cbonnett.github.io/MDN_EDWARD_KERAS_TF.html"" rel=""nofollow noreferrer"">http://cbonnett.github.io/MDN_EDWARD_KERAS_TF.html</a></p>

<p>The example shown is a mixture of Normal Distributions. How could one do the same analysis with MXNet?</p>
","<r><regression><gaussian><mxnet><mixture>","2017-05-10 20:03:29","","1","7993865","2018-03-09 20:07:39","1","0","","","7993865","6","0","0"
"43872455","<p>I get plenty of trouble when trying to install <strong>MXNet</strong> package in R
I am using the 3.4.0 version of R and I am on windows 10 CPU intel i3, 64bits  x64-based processor.</p>

<p>I get prompted:</p>

<pre><code>install.packages(""mxnet"")
Warning in install.packages :
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES.rds': HTTP status was '404 Not Found'
Installing package into ‘C:/Users/los40/OneDrive/Documentos/R/win-library/3.4’
(as ‘lib’ is unspecified)
Warning in install.packages :
  package ‘mxnet’ is not available (for R version 3.4.0)
Warning in install.packages :
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.4/PACKAGES.rds': HTTP status was '404 Not Found'
</code></pre>

<p>I've tried downloading the .rar files provided here. I decompress one and get the folder where it says ""R package"" attempting to install it by using:</p>

<pre><code>&gt; install.packages('R.package.rar', lib='D:/mxnet',repos = NULL)
Error in install.packages : type == ""both"" cannot be used with 'repos = NULL'
&gt; install.packages('R.package.rar', lib='D:/mxnet')
Warning in install.packages :
  package ‘R.package.rar’ is not available (for R version 3.4.0)
</code></pre>

<p>The guide found in <a href=""http://mxnet.io/get_started/windows_setup.html"" rel=""noreferrer"">http://mxnet.io/get_started/windows_setup.html</a> makes no sense to me since I cannot find the file required in the steps for installing the prebuild package on windows called <strong>setupenv.cmd</strong></p>
","<r><package><mxnet>","2017-05-09 14:23:55","","5","3910478","2018-10-18 06:23:33","3","4","1","","3910478","168","11","0"
"53818734","<p>When I use multi gpu to train on MXNet(CUDA8.0+cudnn7), I firstly initialize parameters on different context, then I perform scatter_nd on different contexts, the first time scatter nd would work perfectly, but when compute for the second gpu card, I got </p>

<p>F1217 23:53:01.012707  2619 stream_gpu-inl.h:62] Check failed: e == cudaSuccess CUDA: an illegal memory access was encountered</p>
","<deep-learning><pytorch><mxnet><numpy-ndarray>","2018-12-17 15:56:49","","0","5706790","2019-03-06 14:38:45","1","1","","","5706790","40","0","0"
"45320292","<p>So I am trying to use image recognition to output a regression style number using the mxnet package in R using a CNN. </p>

<p>I have used this as the basis of my analysis: <a href=""https://rstudio-pubs-static.s3.amazonaws.com/236125_e0423e328e4b437888423d3821626d92.html"" rel=""nofollow noreferrer"">https://rstudio-pubs-static.s3.amazonaws.com/236125_e0423e328e4b437888423d3821626d92.html</a></p>

<p>This is an image recognition analysis using mxnet in R using CNN, so I have followed these steps to prepare my data for preprocessing by doing the same steps, resizing, grayscaling. </p>

<p>My ""image"" dataset looks like like this, I have 784 columns of pixels, and the last column is a numeric column with the ""label"" that I am trying to predict so it will be: 1132, 1491, 845, etc. </p>

<p><a href=""https://i.stack.imgur.com/ftqRv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ftqRv.png"" alt=""I have pixels in each cell with their numeric values, 784 columns of pixels and the last column is a numeric column with the &quot;label&quot; that I am trying to predict using the images""></a></p>

<p>From there, I create a training and testing: </p>

<pre><code>    library(pbapply)
library(caret)
## test/training partitions
training_index &lt;- createDataPartition(image$STOPPING_TIME, p = .9, times = 1)
training_index &lt;- unlist(training_index)
train_set &lt;- image[training_index,]
dim(train_set)
test_set &lt;- image[-training_index,]
dim(test_set)


## Fix train and test datasets
train_data &lt;- data.matrix(train_set)
train_x &lt;- t(train_data[, -785])
train_y &lt;- train_data[,785]
train_array &lt;- train_x
dim(train_array) &lt;- c(28, 28, 1, ncol(train_x))

test_data &lt;- data.matrix(test_set)
test_x &lt;- t(test_set[,-785])
test_y &lt;- test_set[,785]
test_array &lt;- test_x
dim(test_array) &lt;- c(28, 28, 1, ncol(test_x))
</code></pre>

<p>Now I get onto using the mxnet, which is what is causing problems, not sure what I am doing wrong: </p>

<pre><code>library(mxnet)
## Model
mx_data &lt;- mx.symbol.Variable('data')
## 1st convolutional layer 5x5 kernel and 20 filters.
conv_1 &lt;- mx.symbol.Convolution(data = mx_data, kernel = c(5, 5), num_filter = 20)
tanh_1 &lt;- mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 &lt;- mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel = c(2, 2), stride = c(2,2 ))
## 2nd convolutional layer 5x5 kernel and 50 filters.
conv_2 &lt;- mx.symbol.Convolution(data = pool_1, kernel = c(5,5), num_filter = 50)
tanh_2 &lt;- mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 &lt;- mx.symbol.Pooling(data = tanh_2, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))
## 1st fully connected layer
flat &lt;- mx.symbol.Flatten(data = pool_2)
fcl_1 &lt;- mx.symbol.FullyConnected(data = flat, num_hidden = 500)
tanh_3 &lt;- mx.symbol.Activation(data = fcl_1, act_type = ""tanh"")
## 2nd fully connected layer
fcl_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 2)
## Output
label &lt;- mx.symbol.Variable(""label"")
NN_model &lt;- mx.symbol.MakeLoss(mx.symbol.square(mx.symbol.Reshape(fcl_2, shape = 0) - label))


## Set seed for reproducibility
mx.set.seed(100)


## Train on 1200 samples
model &lt;- mx.model.FeedForward.create(NN_model, X = train_array, y = train_y,
                                     num.round = 30,
                                     array.batch.size = 100,
                                    initializer=mx.init.uniform(0.002), 
                                     learning.rate = 0.05,
                                     momentum = 0.9,
                                     wd = 0.00001,
                                     eval.metric = mx.metric.rmse)
                                     epoch.end.callback = mx.callback.log.train.metric(100))
</code></pre>

<p>I get the error: </p>

<pre><code>[00:30:08] D:\Program Files (x86)\Jenkins\workspace\mxnet\mxnet\dmlc-core\include\dmlc/logging.h:308: [00:30:08] d:\program files (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor\./matrix_op-inl.h:134: Check failed: oshape.Size() == dshape.Size() (100 vs. 200) Target shape size is different to source. Target: (100,)
Source: (100,2)
Error in symbol$infer.shape(list(...)) : 
  Error in operator reshape9: [00:30:08] d:\program files (x86)\jenkins\workspace\mxnet\mxnet\src\operator\tensor\./matrix_op-inl.h:134: Check failed: oshape.Size() == dshape.Size() (100 vs. 200) Target shape size is different to source. Target: (100,)
Source: (100,2)
</code></pre>

<p>I can get it to work using if I use </p>

<p>NN_model &lt;- mx.symbol.SoftmaxOutput(data = fcl_2)</p>

<p>and keep the rmse there, but it doesn't improve performance of my model after 30 iterations. </p>

<p>Thanks! </p>
","<r><conv-neural-network><mxnet>","2017-07-26 07:31:56","","0","8277792","2017-07-26 08:08:46","1","1","1","","8277792","76","5","0"
"54934810","<p>Is there a way that I can use <code>mx.recordio.MXRecordIO</code> to read from a bytes object rather than a file object?</p>

<p>For example I'm currently doing:</p>

<pre><code>import mxnet as mx

results_file = 'results.rec'
with open(results_file, 'wb') as f:
    f.write(results)

recordio = mx.recordio.MXRecordIO(results_file, 'r')
temp = recordio.read()
</code></pre>

<p>But if possible I'd rather not have to write to file as an intermediate step. I've tried using BytesIO, but can't seem to get it to work.</p>
","<python-3.x><mxnet><bytesio>","2019-02-28 21:48:31","","0","2089899","2019-04-11 21:48:46","1","0","","","2089899","1631","382","12"
"44147792","<p>When I was training a CNN to classify images of distorted digits varying from 0 to 9, the accuracy of training set and test set improved obviously.</p>

<pre><code>Epoch[0] Batch [100] Train-multi-accuracy_0=0.296000
...
Epoch[0] Batch [500] Train-multi-accuracy_0=0.881900
</code></pre>

<p>In Epoch[1] and Epoch[2] the accuracy oscillate slightly between 0.85 and 0.95, however,</p>

<pre><code>Epoch[3] Batch [300] Train-multi-accuracy_0=0.926400
Epoch[3] Batch [400] Train-multi-accuracy_0=0.105300
Epoch[3] Batch [500] Train-multi-accuracy_0=0.098200
</code></pre>

<p>Since then, the accuracy was around 0.1 which meant the network only gave random prediction.
I repeated the training several times, this case occurred every time. What's wrong with it?
Is the adapted learning rate strategy the reason?</p>

<pre><code>model = mx.model.FeedForward(...,
                             optimizer = 'adam',
                             num_epoch = 50,
                             wd = 0.00001,
                             ...,
                             )
</code></pre>
","<mxnet>","2017-05-24 02:09:45","","0","7610696","2017-05-26 17:24:14","1","1","","","7610696","18","0","0"
"45555544","<p>I am trying to use the mxnet package in R using a CNN to try and predict a scalar output (in my case wait time) based on the images.</p>

<p>However, when I do this, I get the same resultant output (it predicts the same number which is probably just the average of all of the results). How do I get it to predict the scalar output correctly.</p>

<p>My image has already been pre-processed by greyscaling it and converting into the pixel format below and scaling it to 28 x 28 (I have also tried different sizes with no effect). </p>

<p>I am essentially using images to predict wait times which is why my train_y is the current wait times in seconds. When using this approach, while leaving my train_y as the current wait time in seconds, the algorithm just predicts the same number. </p>

<p>However, when I transform the train_y to a [0,1] by guessing the maximum value (20000), the CNN does output different numbers, but when scaling those numbers again by multiplying by 20000, I seem to get predictions with negative numbers, and numbers that are just way too skewed giving poor results to the model. Negative numbers especially don't make sense since all my train_y are positive and since I am dealing with time, there is no such thing as negative numbers</p>

<p>I have also played around with the learning rate by testing it from 0.05, 0.01, 0.001, 0.0001, 0.00001, and so forth, until 2e-8 with no effect on the model. I have also played around with the initializer</p>

<p>I have also played around with momentum by changing it from 0.9, to 0.95 with no effect on the model.</p>

<p>Here is my reproducible code:</p>

<pre><code>set.seed(0)

df &lt;- data.frame(replicate(784,runif(7538)))
df$waittime &lt;- 1000*runif(7538)


training_index &lt;- createDataPartition(df$waittime, p = .9, times = 1)
training_index &lt;- unlist(training_index)

train_set &lt;- df[training_index,]
dim(train_set)
test_set &lt;- df[-training_index,]
dim(test_set)


## Fix train and test datasets
train_data &lt;- data.matrix(train_set)
train_x &lt;- t(train_data[, -785])
train_y &lt;- train_data[,785]
train_array &lt;- train_x
dim(train_array) &lt;- c(28, 28, 1, ncol(train_array))


test_data &lt;- data.matrix(test_set)
test_x &lt;- t(test_set[,-785])
test_y &lt;- test_set[,785]
test_array &lt;- test_x
dim(test_array) &lt;- c(28, 28, 1, ncol(test_x))




library(mxnet)
## Model
mx_data &lt;- mx.symbol.Variable('data')
## 1st convolutional layer 5x5 kernel and 20 filters.
conv_1 &lt;- mx.symbol.Convolution(data = mx_data, kernel = c(5, 5), num_filter = 20)
tanh_1 &lt;- mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 &lt;- mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel = c(2, 2), stride = c(2,2 ))
## 2nd convolutional layer 5x5 kernel and 50 filters.
conv_2 &lt;- mx.symbol.Convolution(data = pool_1, kernel = c(5,5), num_filter = 50)
tanh_2 &lt;- mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 &lt;- mx.symbol.Pooling(data = tanh_2, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))
## 1st fully connected layer
flat &lt;- mx.symbol.Flatten(data = pool_2)
fcl_1 &lt;- mx.symbol.FullyConnected(data = flat, num_hidden = 500)
tanh_3 &lt;- mx.symbol.Activation(data = fcl_1, act_type = ""tanh"")
## 2nd fully connected layer
fcl_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 1)
## Output
#NN_model &lt;- mx.symbol.SoftmaxOutput(data = fcl_2)
label &lt;- mx.symbol.Variable(""label"")
#NN_model &lt;- mx.symbol.MakeLoss(mx.symbol.square(mx.symbol.Reshape(fcl_2, shape = 0) - label))
NN_model &lt;- mx.symbol.LinearRegressionOutput(fcl_2)




#Didn't work well, predicted same number continuously regardless of image
## Train on samples
model &lt;- mx.model.FeedForward.create(NN_model, X = train_array, y = train_y,
                                     #                                     ctx = device,
                                     num.round = 30,
                                     array.batch.size = 100,
                                    # initializer=mx.init.uniform(0.002),
initializer = mx.init.Xavier(factor_type = ""in"", magnitude = 2.34), 
                                     learning.rate = 0.00001,
                                     momentum = 0.9,
                                     wd = 0.00001,
                                     eval.metric = mx.metric.rmse)
                                     #epoch.end.callback = #mx.callback.log.train.metric(100))



pred &lt;- predict(model, test_array)
#gives the same numeric output 
#or when train_y is scaled to [0,1] gives very poor responses and negative numbers
</code></pre>
","<r><conv-neural-network><image-recognition><mxnet>","2017-08-07 20:53:28","","0","8277792","2018-01-23 00:14:08","1","2","","","8277792","76","5","0"
"45491477","<p>I'm making a neural network with a not very obvious connection architecture. I comes down to 4 chunks of inputs, each of them having their own path towards the final outputlayer, merging them in between in several steps.
I'm using mxnet on R. I defined 4 <code>mx.symbol.Variable(""data"")</code>, each being the input of the 'chunks' of input. Only 1 is shown on the graph (<code>graph.viz(out)</code>). I can understand that, it makes sense that I should provide only 1 large input-vector. However... how do I split that inputvector? (Oh, and to be sure, <code>state.size</code> of a <code>lstm</code> in mxnet, that points to the number of memory blocks, equal to the # input and outputs, right?)</p>

<p>Code (minimal example):</p>

<pre><code>in1 &lt;- mx.symbol.Variable(""data1"") # 7 values
in2 &lt;- mx.symbol.Variable(""data2"") # 7 values

l1.1 &lt;- mx.symbol.RNN(in1, name=""lstm1.1"", mode=""lstm"", num.layers=1, state.size=7) # first nn on the first 7 inputs 
l1.2 &lt;- mx.symbol.RNN(in2, name=""lstm1.2"", mode=""lstm"", num.layers=1, state.size=7) # second nn on the last 7 inputs
l2 &lt;- mx.symbol.RNN(data=l1.1+l1.2, name=""lstml2"", mode=""lstm"", num.layers=1, state.size=14)  # state.size must be 14, since each input separate has 7

out.dens &lt;- mx.symbol.FullyConnected(c.lstm, name=""out-dens"", num.hidden=4) # 

pred &lt;- mx.symbol.LinearRegressionOutput(out, name=""pred"")

graph.viz(pred) # only lstm1.1 has a data input
</code></pre>

<p>So the question is: How to provide 2 inputs, or how to split 1 input-vector in 2? (<code>in1</code> and <code>in2</code> doesn't seem to work out fine)</p>

<p>-- EDIT 1</p>

<p>One could imagine that the name of the symbolic variable first two lines
<code>
    in1 &lt;- mx.symbol.Variable(""data"") # 7 values
    in2 &lt;- mx.symbol.Variable(""data"") # 7 values
</code>
should be different. I'm pretty sure they should, more like:
<code>
    in1 &lt;- mx.symbol.Variable(""data1"") # 7 values
    in2 &lt;- mx.symbol.Variable(""data2"") # 7 values
</code></p>

<p>However, changing them doesn't change the visual computation graph. Well, it does: now again only 1 input is shown, but not as input (green circle), but as an actual layer (pink rectangle). This doesn't seem to help me out...</p>
","<mxnet>","2017-08-03 18:00:21","","0","7659256","2017-08-03 19:29:10","1","0","","","7659256","11","0","0"
"35551692","<p>I am trying to archieve everything described for R in Python 3. But so far, I am not getting any further.</p>

<p>The tutorial in R is described here: <a href=""http://mxnet.readthedocs.org/en/latest/R-package/classifyRealImageWithPretrainedModel.html"" rel=""nofollow"">http://mxnet.readthedocs.org/en/latest/R-package/classifyRealImageWithPretrainedModel.html</a></p>

<p>How can I do the same in Python? Using the following model:
<a href=""https://github.com/dmlc/mxnet-model-gallery/blob/master/imagenet-1k-inception-bn.md"" rel=""nofollow"">https://github.com/dmlc/mxnet-model-gallery/blob/master/imagenet-1k-inception-bn.md</a></p>

<p>Kind regards,
Kevin</p>
","<python><r><machine-learning><deep-learning><mxnet>","2016-02-22 10:51:25","","1","670979","2018-03-07 19:12:22","1","1","1","","670979","1781","136","15"
"52398476","<p>I used docker and deepo from this website:  <a href=""https://github.com/ufoym/deepo#GPU"" rel=""nofollow noreferrer"">https://github.com/ufoym/deepo#GPU</a>,
When I start the container, I can import all the frameworks (tensorflow, caffe, pytorch)except mxnet. I don't know why. What should I do?</p>

<p>The error can be seen from this picture: Illegal instruction(core dumped)
<a href=""https://i.stack.imgur.com/RUh2J.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RUh2J.png"" alt=""image""></a></p>
","<docker><mxnet>","2018-09-19 05:09:18","","0","10300556","2018-10-09 20:08:15","1","0","","","10300556","1","0","0"
"42930072","<p>I'm trying to replicate <a href=""http://mxnet.io/tutorials/nlp/cnn.html"" rel=""nofollow noreferrer"">this tutorial</a> from MXNet in R, but have failed to keep track of all the dicts and tuples from Python. </p>

<p>I was wondering whether some of you awesome people have had succes doing the same thing and wouldn't mind sharing?</p>

<p>Thanks!</p>
","<python><r><neural-network><conv-neural-network><mxnet>","2017-03-21 14:32:55","","2","3599865","2017-06-21 16:44:22","0","4","","2017-06-21 20:35:33","3599865","25","0","0"
"52001865","<p>I have a problem with R code:
-I have this code line</p>

<pre><code>mx.exec.update.arg.arrays(exec_D, arg.arrays = list(data=D_values_fake,label=mx.nd.array(rep(0, batch_size))), match.name=TRUE)
</code></pre>

<p>where exec_D contains:</p>

<pre><code>C++ object &lt;00000000145f0e50&gt; of class 'MXExecutor' &lt;00000000138b30a0&gt;
</code></pre>

<p>arg.arrays contains:</p>

<blockquote>
  <p>$<code>data</code> $<code>data</code>$<code>softmaxoutput0_output</code>
       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23]
  [,24] [,25] [,26] [,27] [,28] [,29] [,30] [1,]    1    1    1    1<br>
  1    1    1    1    1     1     1     1     1     1     1     1     1 
  1     1     1     1     1     1     1     1     1     1     1     1<br>
  1
       [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52]
  [,53] [,54] [,55] [,56] [,57] [,58] [1,]     1     1     1     1     1
  1     1     1     1     1     1     1     1     1     1     1     1<br>
  1     1     1     1     1     1     1     1     1     1     1
       [,59] [,60] [,61] [,62] [,63] [,64] [1,]     1     1     1     1     1     1</p>
  
  <p>$label  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</p>
</blockquote>

<p>but  when run this line I have this error:</p>

<blockquote>
  <p>Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) :<br>
  Expecting an external pointer: [type=list].</p>
</blockquote>
","<arrays><r><list><pointers><mxnet>","2018-08-24 09:52:16","","0","5644103","2018-08-24 12:52:19","0","1","","","5644103","11","0","0"
"38761408","<p>I recently came across the random search option in caret's <code>trainControl()</code> Funktion. How does caret generate the parameters and is there a ways to provide some sort of user-specific input (e.g. a distributions where the parameters are sampled from)? On the <a href=""http://topepo.github.io/caret/random.html"" rel=""nofollow"">website</a> I only found this quote:</p>

<blockquote>
  <p>built-in models contained in caret contain code to generate random tuning parameter combinations</p>
</blockquote>

<p>For example, I tried <code>mxnet</code> with caret and random search:</p>

<pre><code># Train control with random search
rs_control &lt;- trainControl(method = ""boot"", 
                           number = 2, 
                           search = ""random"",
                           verboseIter = TRUE
                           )

# Training
model_fit &lt;- train(form = y ~ .,
                   data = df_train,
                   method = ""avMxnet"",
                   preProcess = c(""center"", ""scale""),
                   tuneLength = 20,
                   trControl = rs_control
                   )    
</code></pre>

<p>Using this code, caret sampled reasonable values for the number of neurons on the first layer and other parameters (learningrate, momentum, dropout and repeats) but keep the second/third layer constant at zero. Is there a ways to tell caret to sample for all three layers with a uniform distribution from e.g. [25, 150]?</p>
","<r><machine-learning><r-caret><hyperparameters><mxnet>","2016-08-04 07:47:05","","1","4282224","2017-09-26 16:34:45","1","0","","","4282224","54","3","0"
"43528997","<p>I am trying to follow the example <a href=""https://github.com/dmlc/mxnet/tree/master/example/image-classification"" rel=""nofollow noreferrer"">here</a> and create my own dataset for training using MXnet.  My data is organized as specified in the example:</p>

<pre><code>/data
    yes/
        file1.png
        file2.png
        ...
    no/
        file1.png
        file2.png
        ...
</code></pre>

<p>The tutorial says the first step is to run <code>im2rec.py</code> to create a .lst file, then run <code>im2rec.py</code> again (different options) to create the .rec file.  To create the .lst file I type:</p>

<pre><code>&gt; python tools/im2rec.py my_data /data --list True --recursive True --train-ratio .75 --exts .png
</code></pre>

<p>After doing this, two files are created (as expected), <code>my_data_train.lst</code> and <code>my_data_val.lst</code>.  The total number of lines in the two files is the same as the number of files in my <code>yes/</code> and <code>no/</code> directory combined.  Then, I attempt to run <code>im2rec</code> a second time to create the <code>.rec</code> file using:</p>

<pre><code>&gt; python tools/im2rec.py my_data /data --resize 227 --num-thread 16
</code></pre>

<p>This runs for a few seconds and then (silently) crashes.  In the process it creates 4 empty files: <code>my_data_train.idx</code>, <code>my_data_train.rec</code>, <code>my_data_val.idx</code>, and <code>my_data_val.rec</code>.</p>

<p><strong>Question:</strong> What do I need to do differently to be able to create a proper <code>.rec</code> file containing my own .png images?</p>

<p><strong>Extra Details:</strong> </p>

<p>I am working inside a docker container (mxnet/python:gpu) provided by dmlc on docker hub; they also provided the example on their github page.  The data is available through a shared directory in the container.  So it is presumably possible that this is a docker issue.  What makes me slightly worried that it is a docker issue is that I had to <code>pip install opencv-python</code> in order for <code>im2rec</code> to be able to import cv2... I would have hoped that the people providing the container would have taken care of this.</p>
","<python-2.7><image-processing><docker><mxnet>","2017-04-20 20:11:10","","3","4187033","2017-06-14 22:15:13","1","0","1","","4187033","927","319","0"
"41469083","<p>I am trying to install mxnet for use with R Studio on my Windows 10 laptop.</p>

<p>I used these instuctions:</p>

<pre><code>install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
</code></pre>

<p>But when I try this:</p>

<pre><code>require(mxnet)
</code></pre>

<p>I get the error message:</p>

<pre><code>Loading required package: mxnet
Error : object ‘combine_edges’ is not exported by 'namespace:DiagrammeR'
</code></pre>

<p>Here is the complete console:</p>

<pre><code>&gt; install.packages(""drat"", repos = ""https://cran.rstudio.com"")
Installing package into ‘C:/Users/bill_/Documents/R/win-library/3.3’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.3/drat_0.1.2.zip'
Content type 'application/zip' length 73095 bytes (71 KB)
downloaded 71 KB

package ‘drat’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
    C:\Users\bill_\AppData\Local\Temp\RtmpIDZk6c\downloaded_packages
&gt; drat:::addRepo(""dmlc"")
&gt; install.packages(""mxnet"")
Installing package into ‘C:/Users/bill_/Documents/R/win-library/3.3’
(as ‘lib’ is unspecified)
trying URL 'https://dmlc.github.io/drat/bin/windows/contrib/3.3/mxnet_0.7.zip'
Content type 'application/zip' length 5196542 bytes (5.0 MB)
downloaded 5.0 MB

package ‘mxnet’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
    C:\Users\bill_\AppData\Local\Temp\RtmpIDZk6c\downloaded_packages
&gt; require(mxnet)
Loading required package: mxnet
Error : object ‘combine_edges’ is not exported by 'namespace:DiagrammeR'
&gt; 
</code></pre>

<p>Can anyone help?</p>

<p>Thanks in advance.</p>

<p><strong><em>SOLUTION FOUND PER AXEMAN'S SUGGESTION...</em></strong></p>

<pre><code># version 0.9.0 of DiagrammeR won't work with mxnet at this time (20170104)
require(devtools)
install_version(""DiagrammeR"", version = ""0.8.1"", repos = ""http://cran.us.r-project.org"")
</code></pre>
","<r><mxnet>","2017-01-04 16:45:26","","2","1217255","2017-01-17 18:37:07","1","5","1","","1217255","105","22","0"
"42051279","<p>I was compiling mxnet(v0.9.3) amalgamation with <strong>android NDK Standalone Toolchain</strong> on Ubuntu 14.04 64bit Desktop but met some errors.
First error is:</p>

<pre><code>arm-linux-androideabi-g++ -std=c++11 -Wall -O3 -msse2 -Wno-unknown-pragmas -funroll-loops -Iinclude -fPIC -M -MT nnvm.o \
    -I `pwd`/../ -I `pwd`/../include \
    -D__MIN__=0 nnvm.cc &gt; nnvm.d
arm-linux-androideabi-g++: error: unrecognized command line option '-msse2'
</code></pre>

<p>When I deleted '-msse2' option and run<code>makefile</code>again, it can compile more but later I met new errors like those:</p>

<pre><code>jni/../mxnet_predict-all.cc:2801:37: error: 'fopen64' was not declared in this scope
jni/../mxnet_predict-all.cc:21495:14: error: 'stoi' is not a member of 'std'
jni/../mxnet_predict-all.cc:30077:52: error: 'to_string' is not a member of 'std'
jni/../mxnet_predict-all.cc:34298:29: error: 'stof' is not a member of 'std'
jni/../mxnet_predict-all.cc:41383:56: error: 'stod' is not a member of 'std'
……
</code></pre>

<p>What should I do to solve those?</p>

<p>BTW:
My android-ndk version is android-ndk-r13b.
To create Standalone Toolchain, I followed those steps:
<code>
$ python NDK/build/tools/make_standalone_toolchain.py --arch arm --api 21 --install-dir /tmp/my-android-toolchain</code></p>

<pre><code>export PATH=$PATH:/tmp/my-android-toolchain/bin
export CXX=arm-linux-androideabi-g++
export CC=arm-linux-androideabi-gcc
</code></pre>

<p>More information:<a href=""https://github.com/dmlc/mxnet/issues/4888"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/issues/4888</a></p>

<hr>

<p>The #includes of my mxnet_predict-all.cc:</p>

<pre><code>#if defined(__MACH__)
#include &lt;mach/clock.h&gt;
#include &lt;mach/mach.h&gt;
#endif

#if !defined(__WIN32__)
#include &lt;sys/stat.h&gt;
#include &lt;sys/types.h&gt;

#if !defined(__ANDROID__) &amp;&amp; (!defined(MSHADOW_USE_SSE) || MSHADOW_USE_SSE == 1)
#include &lt;emmintrin.h&gt;
#endif

#endif

#include &lt;algorithm&gt;
#include &lt;array&gt;
#include &lt;assert.h&gt;
#include &lt;atomic&gt;
#include &lt;cblas.h&gt;
#include &lt;cctype&gt;
#include &lt;cfloat&gt;
#include &lt;chrono&gt;
#include &lt;climits&gt;
#include &lt;cmath&gt;
#include &lt;condition_variable&gt;
#include &lt;cstddef&gt;
#include &lt;cstdint&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;cstring&gt;
#include &lt;ctime&gt;
#include &lt;deque&gt;
#include &lt;dirent.h&gt;
#include &lt;errno.h&gt;
#include &lt;fstream&gt;
#include &lt;functional&gt;
#include &lt;inttypes.h&gt;
#include &lt;iostream&gt;
#include &lt;istream&gt;
#include &lt;limits&gt;
#include &lt;list&gt;
#include &lt;map&gt;
#include &lt;memory&gt;
#include &lt;mutex&gt;
#include &lt;new&gt;
#include &lt;ostream&gt;
#include &lt;queue&gt;
#include &lt;random&gt;
#include &lt;regex&gt;
#include &lt;sched.h&gt;
#include &lt;set&gt;
#include &lt;sstream&gt;
#include &lt;stdbool.h&gt;
#include &lt;stddef.h&gt;
#include &lt;stdexcept&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;streambuf&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
#include &lt;time.h&gt;
#include &lt;tuple&gt;
#include &lt;type_traits&gt;
#include &lt;typeindex&gt;
#include &lt;typeinfo&gt;
#include &lt;unordered_map&gt;
#include &lt;unordered_set&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;
</code></pre>
","<android><c++11><makefile><android-ndk><mxnet>","2017-02-05 11:05:41","","2","7218025","2018-08-07 17:38:54","2","5","","","7218025","33","0","0"
"41217664","<p>I have been unable to get reasonable performance using <code>mxnet</code> <code>LinearRegressionOutput</code> layer.</p>

<p>The self-contained example below attempts to perform regression of a simple polynomial function (<code>y = x1 + x2^2 + x3^3</code>) with a small amount of random noise thrown in.</p>

<p>The mxnet regression example given <a href=""http://mxnet-tqchen.readthedocs.io/en/latest//packages/r/fiveMinutesNeuralNetwork.html#regression"" rel=""nofollow noreferrer"">here</a> is used, along with a slightly more complex network which includes a hidden layer.</p>

<p>The example below also trains regression networks using the <code>neuralnet</code> and <code>nnet</code> packages, which as can be seen from the plots perform much better.</p>

<p>I realize the answer to poorly performing networks is to do some hyper-parameter tuning, however I have tried a range of values without any improvement in performance. So I have the following questions:</p>

<ol>
<li>Do I have an error in my mxnet regression implementation?</li>
<li>Does anyone have experience that could help me in getting reasonable performance from mxnet for a simple regression problem like the one considered here?</li>
<li>Does anyone else have a mxnet regression example with good performance?</li>
</ol>

<p>My set-up as follows:</p>

<pre><code>MXNet version: 0.7
R `sessionInfo()`: R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1
</code></pre>

<p>Poor regression results of <code>mxnet</code>:</p>

<p><a href=""https://i.stack.imgur.com/IyVSf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IyVSf.png"" alt=""mxnet regression performance""></a></p>

<p>From this reproducible example:</p>

<pre><code>## SIMPLE REGRESSION PROBLEM
# Check mxnet out-of-the-box performance VS neuralnet, and caret/nnet

library(mxnet)
library(neuralnet)
library(nnet)
library(caret)
library(tictoc)
library(reshape)

# Data definitions
nObservations &lt;- 1000
noiseLvl &lt;- 0.1

# Network config
nHidden &lt;- 3
learnRate &lt;- 2e-6
momentum &lt;- 0.9
batchSize &lt;- 20
nRound &lt;- 1000
verbose &lt;- FALSE
array.layout = ""rowmajor""

# GENERATE DATA:
df &lt;- data.frame(x1=runif(nObservations),
                 x2=runif(nObservations),
                 x3=runif(nObservations))

df$y &lt;- df$x1 + df$x2^2 + df$x3^3 + noiseLvl*runif(nObservations)
# normalize data columns
# df &lt;- scale(df)

# Seperate data into train/test
test.ind = seq(1, nObservations, 10)    # 1 in 10 samples for testing
train.x = data.matrix(df[-test.ind, -which(colnames(df) %in% c(""y""))])
train.y = df[-test.ind, ""y""]
test.x = data.matrix(df[test.ind, -which(colnames(df) %in% c(""y""))])
test.y = df[test.ind, ""y""]

# Define mxnet network, following 5-minute regression example from here:
# http://mxnet-tqchen.readthedocs.io/en/latest//packages/r/fiveMinutesNeuralNetwork.html#regression
data &lt;- mx.symbol.Variable(""data"")
label &lt;- mx.symbol.Variable(""label"")
fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden=1, name=""fc1"")
lro1 &lt;- mx.symbol.LinearRegressionOutput(data=fc1, label=label, name=""lro"")

# Train MXNET model
mx.set.seed(0)
tic(""mxnet training 1"")
mxModel1 &lt;- mx.model.FeedForward.create(lro1, X=train.x, y=train.y,
                                        eval.data=list(data=test.x, label=test.y),
                                        ctx=mx.cpu(), num.round=nRound,
                                        array.batch.size=batchSize,
                                        learning.rate=learnRate, momentum=momentum,
                                        eval.metric=mx.metric.rmse,
                                        verbose=FALSE, array.layout=array.layout)
toc()

# Train network with a hidden layer
fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden=nHidden, name=""fc1"")
tanh1 &lt;- mx.symbol.Activation(fc1, act_type=""tanh"", name=""tanh1"")
fc2 &lt;- mx.symbol.FullyConnected(tanh1, num_hidden=1, name=""fc2"")
lro2 &lt;- mx.symbol.LinearRegressionOutput(data=fc2, label=label, name=""lro"")
tic(""mxnet training 2"")
mxModel2 &lt;- mx.model.FeedForward.create(lro2, X=train.x, y=train.y,
                                        eval.data=list(data=test.x, label=test.y),
                                        ctx=mx.cpu(), num.round=nRound,
                                        array.batch.size=batchSize,
                                        learning.rate=learnRate, momentum=momentum,
                                        eval.metric=mx.metric.rmse,
                                        verbose=FALSE, array.layout=array.layout)
toc()

# Train neuralnet model
mx.set.seed(0)
tic(""neuralnet training"")
nnModel &lt;- neuralnet(y~x1+x2+x3, data=df[-test.ind, ], hidden=c(nHidden),
                     linear.output=TRUE, stepmax=1e6)
toc()

# Train caret model
mx.set.seed(0)
tic(""nnet training"")
nnetModel &lt;- nnet(y~x1+x2+x3, data=df[-test.ind, ], size=nHidden, trace=F,
                   linout=TRUE)
toc()

# Check response VS targets on training data:
par(mfrow=c(2,2))
plot(train.y, compute(nnModel, train.x)$net.result, 
     main=""neuralnet Train Fitting Fake Data"", xlab=""Target"", ylab=""Response"")
abline(0,1, col=""red"")

plot(train.y, predict(nnetModel, train.x), 
     main=""nnet Train Fitting Fake Data"", xlab=""Target"", ylab=""Response"")
abline(0,1, col=""red"")

plot(train.y, predict(mxModel1, train.x, array.layout=array.layout), 
     main=""MXNET (no hidden) Train Fitting Fake Data"", xlab=""Target"",
     ylab=""Response"")
abline(0,1, col=""red"")

plot(train.y, predict(mxModel2, train.x, array.layout=array.layout),
     main=""MXNET (with hidden) Train Fitting Fake Data"", xlab=""Target"",
     ylab=""Response"")
abline(0,1, col=""red"")
</code></pre>
","<r><regression><mxnet>","2016-12-19 07:25:20","","3","4988601","2016-12-21 02:15:25","1","0","1","","4988601","2347","284","4"
"41574603","<p><code>Rscript.exe</code> is getting hang without closing console after the execution of <em>R</em> script using <code>mxnet</code> package.Can anyone suggest to close the console after the execution </p>

<p><img src=""https://i.stack.imgur.com/IEg5p.png"" alt=""Screenshot is available here ""></p>
","<r><rscript><mxnet>","2017-01-10 17:20:53","","0","2826177","2018-03-22 04:07:51","1","2","","","2826177","6","0","0"
"40798792","<p>I am using my MacBookPro. I am trying to run the mxnet python demo code and the execution time is extremely slow. It takes a lot time to execute the code. Is this normal? Also i want to run mxnet on Raspberry Pi 3.</p>
","<macos><python-2.7><mxnet>","2016-11-25 06:13:52","","1","5039923","2016-11-28 17:14:01","1","0","","","5039923","133","33","1"
"45540893","<p>In MXNet, if I wanted to create a vector of weights that multiplied each input, i.e. to have <code>w*x_i</code> and then backprop over the weights <code>w</code> how would I do this?</p>

<p>I tried:</p>

<pre><code> y_hat = input
 w1 = mx.sym.Variable(""w1"")
 y_hat = mx.symbol.broadcast_mul(w1, y_hat)
</code></pre>
","<python><mxnet>","2017-08-07 06:49:59","","2","8196682","2017-08-07 15:38:59","1","2","","","8196682","30","0","0"
"45448677","<p>I am trying to make an operator in MXNet that will introduce sparsity in the output in the following way:</p>

<ul>
<li>Doing the pruning for each data-point separately (axis 0 is for the data-points)</li>
<li>Dropping lower weights to 0</li>
<li>Keeping the same dimensions as the input</li>
</ul>

<p>I am currently doing this with the following piece of code (assuming act is the input to this operator):</p>

<pre><code>flat = mx.sym.flatten(act)
mask = mx.sym.topk(flat, k = int(frac * flat.infer_shape(data=shape)[1][0][1]), axis = 1, ret_typ = 'mask').reshape(act.infer_shape(data=shape)[1][0])
custom = mx.sym.where(mask == 1, act, mask)
</code></pre>

<p>With this implementation, there is a limit on the dimensionality of the tensor act. A very big tensor, when flattened and passed into topk results in an IndexFill error:</p>

<pre><code>[20:27:53] /home/ubuntu/mxnet/dmlc-core/include/dmlc/logging.h:304: [20:27:53] /home/ubuntu/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:58: too large launch parameter: IndexFill[100352,1], [32,32,1]

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fb593bbc9ac]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZN7mshadow4cuda9IndexFillIffEEvNS_6TensorINS_3gpuELi2ET0_EERKNS2_IS3_Li1ET_EERKS5_+0x492) [0x7fb59581bf82]
[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op8TopKImplIN7mshadow3gpuEEEvNS_10RunContextENS_8ResourceERKNS_5TBlobERKSt6vectorIS6_SaIS6_EERKNS0_9TopKParamE+0x3ca1) [0x7fb595841521]
[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op4TopKIN7mshadow3gpuEEEvRKN4nnvm9NodeAttrsERKNS_9OpContextERKSt6vectorINS_5TBlobESaISC_EERKSB_INS_9OpReqTypeESaISH_EESG_+0x345) [0x7fb595842cc5]
[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(+0x1318cf9) [0x7fb5947aecf9]
[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x8c) [0x7fb5947ef07c]
[bt] (6) /usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/libmxnet.so(_ZNSt17_Function_handlerIFvvEZZN5mxnet6engine23ThreadedEnginePerDevice13PushToExecuteEPNS2_8OprBlockEbENKUlvE1_clEvEUlvE_E9_M_invokeERKSt9_Any_data+0x60) [0x7fb5947f2190]
[bt] (7) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fb5a3c45a60]
[bt] (8) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fb5a9e07184]
[bt] (9) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fb5a9b34bed]
</code></pre>

<p>So my question is:</p>

<ul>
<li>It currently functions with a very small batch-size. But is there a way to increase the batch-size and avoid the error?</li>
<li>Is there a better way of implementing the operator?</li>
</ul>
","<python><mxnet>","2017-08-01 22:32:56","","0","8402235","2017-08-03 23:56:39","1","1","0","","8402235","3","0","0"
"55052611","<p>How do you run fasttext on a corpus and use those embeddings in mxnet symbol embedding layer?</p>
","<mxnet>","2019-03-07 20:52:42","","1","7779183","2019-03-24 00:38:09","1","0","","","7779183","16","0","0"
"54453957","<p>I am trying to process a bunch of images for face recognition.</p>

<p>I have several sets of images which I am trying to process, some of them processed fine but in a particular set there are some images which are not able to process and gives this particular error: <code>could not broadcast input array from shape</code> </p>

<p>I am using MTCNN which is implemented using <strong>mxnet and python</strong> here is the <a href=""https://github.com/kpzhang93/MTCNN_face_detection_alignment"" rel=""nofollow noreferrer"">link</a> to the original repo.</p>

<p>This error comes in the second stage of the mtcnn detector, here is the code:</p>

<pre><code>#############################################
# second stage
#############################################
        num_box = total_boxes.shape[0]

        # pad the bbox
        [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(total_boxes, width, height)
        # (3, 24, 24) is the input shape for RNet
        input_buf = np.zeros((num_box, 3, 24, 24), dtype=np.float32)

        for i in range(num_box):
            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.uint8)
            tmp[dy[i]:edy[i]+1, dx[i]:edx[i]+1, :] = img[y[i]:ey[i]+1, x[i]:ex[i]+1, :]
            input_buf[i, :, :, :] = adjust_input(cv2.resize(tmp, (24, 24)))

        output = self.RNet.predict(input_buf)

        # filter the total_boxes with threshold
        passed = np.where(output[1][:, 1] &gt; self.threshold[1])
        total_boxes = total_boxes[passed]

        if total_boxes.size == 0:
            return None
</code></pre>

<p>In the for loop when it tries to change the shape it throws an error.</p>

<p>If anyone needs to view more code or want the exact pic do let me know.</p>
","<python><face-detection><mxnet>","2019-01-31 05:36:15","","0","3696809","2019-04-10 08:42:27","1","1","","","3696809","165","32","2"
"41071396","<p>The tutorial is on <a href=""http://mxnet.io/tutorials/python/mnist.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/python/mnist.html</a>.
At this step:
""</p>

<pre><code>from IPython.display import HTML
import cv2
import numpy as np
from mnist_demo import html, script
def classify(img):
    img = img[len('data:image/png;base64,'):].decode('base64')
    img = cv2.imdecode(np.fromstring(img, np.uint8), -1)
    img = cv2.resize(img[:,:,3], (28,28))
    img = img.astype(np.float32).reshape((1,1,28,28))/255.0
    return model.predict(img)[0].argmax()

'''
To see the model in action, run the demo notebook at
https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb.
'''
HTML(html + script)
</code></pre>

<h2>""</h2>

<p>ImportError                               Traceback (most recent call last)
 in ()
      2 import cv2
      3 import numpy as np
----> 4 from mnist_demo import html, script
      5 def classify(img):
      6     img = img[len('data:image/png;base64,'):].decode('base64')</p>

<pre><code>ImportError: No module named mnist_demo
</code></pre>

<hr>

<p>I do not know what is the reason and I cannot find the answer on Google.
Does anyone has any idea?</p>
","<python><mxnet>","2016-12-10 01:57:05","","2","6569059","2016-12-18 13:29:54","1","0","","","6569059","113","60","0"
"50392646","<p>I was following Apache's instructions to install MxNet for Python on a MacOS (CPU): <a href=""http://mxnet.incubator.apache.org/install/index.html"" rel=""nofollow noreferrer"">http://mxnet.incubator.apache.org/install/index.html</a></p>

<p>However, when I get to the line </p>

<pre><code>pip install mxnet --pre
</code></pre>

<p>I run into the issue where it quits installing due to the following error:</p>

<blockquote>
  <p>awsebcli 3.12.4 has requirement requests&lt;=2.9.1,>=2.6.1, but you'll have requests 2.18.4 which is incompatible.</p>
</blockquote>

<p>If someone could help me figure out what's going on, that would be really helpful. I'm running this on a Macbook Pro with High Sierra and Python 3.6.5 on it as well as EB CLI 3.12.4</p>

<p>EDIT: I tried using (as suggested):</p>

<pre><code>pip install requests==2.9.1
</code></pre>

<p>However, it results in</p>

<blockquote>
  <p>awsebcli 3.12.4 has requirement requests&lt;=2.9.1,>=2.6.1, but you'll have requests 2.18.4 which is incompatible. </p>
  
  <p>Installing collected packages: requests </p>
  
  <p>Found existing installation: requests 2.9.1 </p>
  
  <p>Uninstalling requests-2.9.1: </p>
  
  <p>Successfully uninstalled requests-2.9.1 </p>
  
  <p>Successfully installed requests-2.18.4</p>
</blockquote>

<p>This prevents me from finishing my installation of MxNet and I'm unsure how to proceed.</p>
","<python><pip><aws-cli><mxnet>","2018-05-17 13:25:34","","1","9206109","2018-05-17 19:32:25","1","0","","","9206109","21","2","0"
"48195293","<p>I am very new to Convolutional Neural Network and I basically followed this example: <a href=""https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html?highlight=convolutional"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html?highlight=convolutional</a> in training my data. </p>

<p>Now I run and had the .params and .json file, I was trying to load the model using this code: </p>

<pre><code>sym, arg_params, aux_params = mx.model.load_checkpoint('cnn', 9)
mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)
mod.bind(for_training=False, data_shapes=[('data', (1,51))], 
         label_shapes=mod._label_shapes)
mod.set_params(arg_params, aux_params, allow_missing=True)
</code></pre>

<p>but it always shows an error like this: </p>

<blockquote>
  <p>MXNetError: Error in operator reshape4: [11:59:49]
  src/operator/tensor/./matrix_op-inl.h:182: Check failed: oshape.Size()
  == dshape.Size() Target shape size is different to source. Target: 255000 Source: 2550</p>
</blockquote>

<p>I am not sure which part did I do wrong.</p>
","<python><conv-neural-network><mxnet>","2018-01-10 20:09:04","","0","8304617","2018-01-11 05:33:01","1","0","","","8304617","35","1","0"
"50725424","<h2>Description</h2>

<p>Index type must be set for one_hot operator, but I do not find where or how to set it.</p>

<h2>Environment info</h2>

<p>----------Python Info----------</p>

<p>Version      : 3.6.5</p>

<p>Compiler     : GCC 7.2.0</p>

<p>Build        : ('default', 'Apr 29 2018 16:14:56')</p>

<p>Arch         : ('64bit', '')</p>

<p>------------Pip Info-----------</p>

<p>Version      : 10.0.1</p>

<p>Directory    : /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/pip</p>

<p>----------MXNet Info-----------</p>

<p>Version      : 1.3.0</p>

<p>Directory    : /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet</p>

<p>Commit Hash   : 247d57944f7a989d8f445856769e704b83765828</p>

<p>----------System Info----------</p>

<p>Platform     : Linux-4.13.0-43-generic-x86_64-with-debian-stretch-sid</p>

<p>system       : Linux</p>

<p>node         : augustinasNT</p>

<p>release      : 4.13.0-43-generic</p>

<p>version      : #48~16.04.1-Ubuntu SMP Thu May 17 12:56:46 UTC 2018</p>

<h2>Error Message:</h2>

<p>RuntimeError: simple_bind error. Arguments:</p>

<p>data: (1, 3, 112, 112)</p>

<p>Error in operator one_hot0: [19:29:50] src/operator/tensor/./indexing_op.h:1002: Check failed: (*in_attrs)[0] != -1 (-1 vs. -1) Index type must be set for one_hot operator</p>

<p>Stack trace returned 10 entries:</p>

<p>[bt] (0) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d7c2a) [0x7fd3b2363c2a]</p>

<p>[bt] (1) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d8261) [0x7fd3b2364261]</p>

<p>[bt] (2) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x211641f) [0x7fd3b42a241f]</p>

<p>[bt] (3) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2672116) [0x7fd3b47fe116]</p>

<p>[bt] (4) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x267b971) [0x7fd3b4807971]</p>

<p>[bt] (5) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x267c3ca) [0x7fd3b48083ca]</p>

<p>[bt] (6) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x266ca22) [0x7fd3b47f8a22]</p>

<p>[bt] (7) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x266d434) [0x7fd3b47f9434]</p>

<p>[bt] (8) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2378) [0x7fd3b47574a8]</p>

<p>[bt] (9) /home/augustinas/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fd3cf795ec0]</p>
","<python><mxnet>","2018-06-06 16:37:20","","0","8856083","2018-06-09 00:45:47","1","1","","","8856083","35","9","0"
"41845286","<p>I am looking for best-practice or case studies using R's ""mxnet"" for the pixel-wise classification of multi-band imagery (RGB, mlutispectral/hyperspectral aerial or satellite remote sensing). Indeed there is bunch of best practise in image tagging (e.g. dogs vs cats in huge image archives like imagenet) where the whole image is classified and usually a lot of training data (or pretrained models) are available. However, I do not find anything concerning pixel-wise image classification/regression, where training data typically is a bit more sparse and applications deal e.g. with land cover categories, objects (like cars, buildings etc.) or biophysical variables (biomass, soil wetness, chlorophyll content etc.).</p>
","<r><image-processing><deep-learning><mxnet><satellite-image>","2017-01-25 06:58:32","","2","7467511","2017-12-18 08:40:01","1","1","","","7467511","11","0","0"
"45656457","<p>I am trying to train my 20x20 images dataset using MXNet deep learning library, you can see the code below:
the question is when I run it, although it shows no errors it returns nothing, I mean it does not show any processing like :</p>

<p>epoch 0 : ........accuracy:.....</p>

<p>epoch 1 : ........accuracy:.....</p>

<p>so, how shall I make it print such processing format, or where might be the problem?
Note: I tried all kinds of the Callback API:<a href=""http://mxnet.io/api/python/callback.html?fref=gc"" rel=""nofollow noreferrer"">http://mxnet.io/api/python/callback.html?fref=gc</a>  and none of them are giving any response; the code work with no errors but no processing steps shown!</p>

<p>Thanks in advance</p>

<pre><code>X_train = []
training_flatten_rows_mxnet_csv=np.loadtxt(""training_set_flatten_rows_mxnet.csv"", delimiter="","")
train_data = training_flatten_rows_mxnet_csv
X_train = train_data.reshape((training_counter,1,20,20))
Y_train = np.loadtxt(""training_labels.csv"", delimiter="","")

X_validate = []
validate_flatten_rows_mxnet_csv=np.loadtxt(""validation_set_flatten_rows_mxnet.csv"", delimiter="","")
validate_data = validate_flatten_rows_mxnet_csv
X_validate = validate_data.reshape((validate_counter,1,20,20))
Y_validate = np.loadtxt(""validate_labels.csv"", delimiter="","")

train_iterator = mx.io.NDArrayIter(X_train, Y_train, batch_size=batch_size,shuffle=True)#,last_batch_handle='discard')
validate_iterator = mx.io.NDArrayIter(X_validate, Y_validate, batch_size=batch_size,shuffle=True)

data = mx.sym.var('data')

conv1 = mx.sym.Convolution(data=data, kernel=(3,3), num_filter=6)
relu1 = mx.sym.Activation(data=conv1, act_type=""relu"")
pool1 = mx.sym.Pooling(data=relu1, pool_type=""max"", kernel=(2,2), stride=(2,2))

conv2 = mx.sym.Convolution(data=pool1, kernel=(6,6), num_filter=12)
relu2 = mx.sym.Activation(data=conv2, act_type=""relu"")
pool2 = mx.sym.Pooling(data=relu2, pool_type=""max"", kernel=(2,2), stride=(2,2))

flatten = mx.sym.flatten(data=pool2)
fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=12 )

lenet = mx.sym.SoftmaxOutput(data=fc1, name='softmax')

lenet_model = mx.mod.Module(symbol=lenet, context=mx.cpu())

lenet_model.fit(train_iterator,
                eval_data=validate_iterator,
                optimizer='sgd',
                optimizer_params={'learning_rate':0.1},
                eval_metric='acc',
                batch_end_callback =mx.callback.Speedometer(batch_size, 100),
                num_epoch=5)
</code></pre>
","<python><mxnet>","2017-08-13 02:09:01","","2","2888046","2017-08-19 02:12:41","1","0","","","2888046","31","75","0"
"45594614","<p>I tried to install mxnet as follows:
Operating System:
RHEL 6.9 (2.6.32-696.el6.x86_64)
Compiler:
gcc (GCC) 5.3.0 also tried with 6.2.0</p>

<p>A. OpenBLAS build as</p>

<pre><code> 1. git clone https://github.com/xianyi/OpenBLAS.git
 2. cd OpenBLAS
 3. make DYNAMIC_ARCH=1 NO_AVX2=1
 4. make PREFIX=~/test/OpenBLAS-1.0 install
</code></pre>

<p>B. mxnet install</p>

<pre><code> 1. git clone --recursive https://github.com/dmlc/mxnet
 2. cd mxnet
 3. modified make/config.mk as follows
    USE_OPENCV = 0  
    USE_BLAS = openblas (#Line no : 93) 
    ADD_LDFLAGS = -I/home_dir/test/OpenBLAS-1.0/lib
    ADD_CFLAGS =  -I/home_dir/test/OpenBLAS-1.0/include

 4. make -j4 #It successfully created lib dir  containing libmxnet.a and libmxnet.so
</code></pre>

<p>Then exported PYTHONPATH as export </p>

<pre><code>`PYTHONPATH=~/test/mxnet/python/`
</code></pre>

<p>After running python in interactive mode I get the following error:</p>

<pre><code>[c244728_lx@brainiac-login-0001 lib]$ python --version
Python 3.5.1
[c244728_lx@brainiac-login-0001 lib]$ python
Python 3.5.1 (default, Mar  2 2016, 08:58:17)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-11)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import mxnet
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/c244728_lx/test/mxnet/python/mxnet/__init__.py"", line 25, in &lt;module&gt;
    from .base import MXNetError
  File ""/home/c244728_lx/test/mxnet/python/mxnet/base.py"", line 86, in &lt;module&gt;
    _LIB = _load_lib()
  File ""/home/c244728_lx/test/mxnet/python/mxnet/base.py"", line 78, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""/lrlhps/apps/python/python-3.5.1/lib/python3.5/ctypes/__init__.py"", line 347, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /home/c244728_lx/test/mxnet/python/mxnet/../../lib/libmxnet.so: undefined symbol: cblas_ddot
&gt;&gt;&gt;
</code></pre>

<p>For more description please follow:
 <a href=""https://github.com/apache/incubator-mxnet/issues/7397"" rel=""nofollow noreferrer"">github issue</a></p>
","<python><gcc><mxnet>","2017-08-09 15:16:43","","0","5777725","2018-07-16 17:35:58","1","0","","","5777725","12","7","0"
"43173963","<p>I have a question regarding the syntax used in creating a custom activation function / op in mxnet. I was looking at this example:
<a href=""https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/custom_softmax.py"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/custom_softmax.py</a></p>

<p>Specifically, this part:</p>

<pre><code>class Softmax(mx.operator.CustomOp):
    def forward(self, is_train, req, in_data, out_data, aux):
        x = in_data[0].asnumpy()
        y = np.exp(x - x.max(axis=1).reshape((x.shape[0], 1)))
        y /= y.sum(axis=1).reshape((x.shape[0], 1))
        self.assign(out_data[0], req[0], mx.nd.array(y))

    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):
        l = in_data[1].asnumpy().ravel().astype(np.int)
        y = out_data[0].asnumpy()
        y[np.arange(l.shape[0]), l] -= 1.0
        self.assign(in_grad[0], req[0], mx.nd.array(y))
</code></pre>

<p>What's up with in_data[0] vs in_data[1], and out_data[0] vs out_data[1]? What do the indices correspond to?</p>

<p>Thanks!</p>
","<python><mxnet>","2017-04-02 21:55:12","","0","7806006","2017-04-03 18:08:14","1","0","","","7806006","3","0","0"
"48743700","<p>I would like to train a simple classifier in C++, very much in the fashion of the <a href=""http://mxnet.incubator.apache.org/tutorials/c%2B%2B/basics.html"" rel=""nofollow noreferrer"">C++ mnist example</a>, where however my data is not stored on the HD but already loaded to the memory, say to an mxnet NDArray. In Python for this purpose one has the handy <code>NDArrayIter</code>, c.f. <a href=""https://mxnet.incubator.apache.org/tutorials/basic/module.html"" rel=""nofollow noreferrer"">Module tutorial</a>.</p>

<p>Is there such an NDArray iterator for C++?</p>

<p>Browsing through the code I found that all possible <code>MXDataIter</code>'s can be read out from <code>MXListDataIters</code> and <code>MXDataIterGetIterInfo</code>:</p>

<pre><code>#include ""mxnet-cpp/io.h""
using namespace std;
using namespace mxnet::cpp;

int main(int argc, char** argv) {
  Context ctx = Context::cpu();  // Use CPU

  mx_uint num_data_iter_creators;
  DataIterCreator *data_iter_creators = nullptr;

  int r = MXListDataIters(&amp;num_data_iter_creators, &amp;data_iter_creators);
  CHECK_EQ(r, 0);
  cout &lt;&lt; ""num_data_iter_creators = "" &lt;&lt; num_data_iter_creators &lt;&lt; endl;
  //output: num_data_iter_creators = 8

  const char *name;
  const char *description;
  mx_uint num_args;
  const char **arg_names;
  const char **arg_type_infos;
  const char **arg_descriptions;

  for (mx_uint i = 0; i &lt; num_data_iter_creators; i++) {
      r = MXDataIterGetIterInfo(data_iter_creators[i], &amp;name, &amp;description,
                                &amp;num_args, &amp;arg_names, &amp;arg_type_infos,
                                &amp;arg_descriptions);
      CHECK_EQ(r, 0);
      cout &lt;&lt; "" i: "" &lt;&lt; i &lt;&lt; "", name: "" &lt;&lt; name &lt;&lt; endl;
  }

  MXNotifyShutdown();
  return 0;
}
</code></pre>

<p>which yields the eight <code>MXDataIter()</code>'s:</p>

<pre><code>num_data_iter_creators = 8
 i: 0, name: ImageDetRecordIter
 i: 1, name: CSVIter
 i: 2, name: ImageRecordIter_v1
 i: 3, name: ImageRecordUInt8Iter_v1
 i: 4, name: MNISTIter
 i: 5, name: ImageRecordIter
 i: 6, name: ImageRecordUInt8Iter
 i: 7, name: LibSVMIter
</code></pre>

<p>So it appears to me that for C++ there is no NDArray iterator and that the easiest solution would be to write my data to csv-files only to then load it again into a <code>MXDataIter(CSVIter)</code>. Another possibility would be to manually split the data into batch NDArray's and feed these into the training, but this also feels clumsy.</p>
","<c++><iterator><mxnet>","2018-02-12 09:59:46","","0","8870433","2018-03-08 01:40:55","1","0","","","8870433","1","0","0"
"50341825","<p>Hi，I have a question that, how can I make predict with unfixed input data?  I will try to describe in detail clear:
  I use MTCNN for face detection(it's ok unfamiliar with that), and it employs 3 networks: PNet, RNet, ONet. PNet detects a mass of proposal face bounding boxes, then these boxes are coarse-to-fine by the rest net one after another, finally get precise face bbox(s). When taking an image as input to PNet, image's size is unfixed, and the output proposal box number from PNet is also unfixed, so as RNet, ONet. Reference to another MTCNN code I set a large data_shapes(e.g., image size, batch size) when I bind the module, and initialize all to zero，then make predict. That works though, Isn't that a redundant calculation? (Question 1)</p>

<h1>PNet:</h1>

<pre><code>max_img_w=1000
max_img_h=1000
sym, arg_params, aux_params = mx.model.load_checkpoint(‘det1’, 0)
self.PNets = mx.mod.Module(symbol=sym, context=ctx,label_names=None)
self.PNets.bind(data_shapes=[(‘data’, (1, 3, max_img_w, max_img_h))],for_training=False)
self.PNets.set_params(arg_params,aux_params)
</code></pre>

<h1>RNet</h1>

<pre><code>sym, arg_params, aux_params = mx.model.load_checkpoint(‘det2’, 0)
self.RNet = mx.mod.Module(symbol=sym, context=ctx,label_names=None)
self.RNet.bind(data_shapes=[(‘data’, (2048,3, 24, 24))],for_training=False)
self.RNet.set_params(arg_params,aux_params,allow_missing=True)
</code></pre>

<h1>ONet</h1>

<pre><code>sym, arg_params, aux_params = mx.model.load_checkpoint(‘det3’, 0)
self.ONet = mx.mod.Module(symbol=sym, context=ctx,label_names=None)
self.ONet.bind(data_shapes=[(‘data’, (256, 3, 48, 48))],for_training=False)
self.ONet.set_params(arg_params,aux_params,allow_missing=True)
</code></pre>

<p>And I try mx.mod.Module.reshape before predict, which will adjust data'shape according to last network's output, but I get this error:(Question 2)
AssertionError: Shape of unspecified array arg:prob1_label changed. This can cause the new executor to not share parameters with the old one. Please check for error in the network. If this is intended, set partial_shaping=True to suppress this warning.</p>

<p>One more thing is that The MTCNN code (<a href=""https://github.com/pangyupo/mxnet_mtcnn_face_detection"" rel=""nofollow noreferrer"">https://github.com/pangyupo/mxnet_mtcnn_face_detection</a>) primary use deprecated function to load models:</p>

<pre><code>self.PNet = mx.model.FeedForward.load(‘det1’,0)
</code></pre>

<p>One single line to work with arbitrary data_shapes, why this function be deprecated..?(Question 3)
I found a little difference that after load model, FeedFroward takes 0MB memory before make one predict, but <code>mx.mod.Module</code> takes up memory once loaded, and increase obviously after making one prediction.</p>
","<mxnet>","2018-05-15 03:17:02","","0","9791657","2018-05-30 00:17:54","1","1","","","9791657","3","0","0"
"44747473","<p>I am totally new to NN and want to classify the almost 6000 images that belong to different games (gathered by IR). I used the steps introduced in the following link, but I get the same training accuracy in each round. 
some info about NN architecture: 2 convloutional, activation, and pooling layers. Activation type: relu, Number of filters in first and second layers are 30 and 70 respectively.
2 fully connected layer with 500 and 2 hidden layers respectively.
<a href=""http://firsttimeprogrammer.blogspot.de/2016/07/image-recognition-in-r-using.html"" rel=""nofollow noreferrer"">http://firsttimeprogrammer.blogspot.de/2016/07/image-recognition-in-r-using.html</a></p>
","<r><conv-neural-network><mxnet>","2017-06-25 14:46:24","","0","8107822","2017-07-24 12:31:07","1","3","","","8107822","11","0","0"
"53191332","<p>I am trying to pass output of some pycuda operation to the input of mxnet computational graph.
I am able to achieve this via numpy conversion with the following code</p>

<pre><code>import pycuda.driver as cuda
import pycuda.autoinit
import numpy as np
import mxnet as mx

batch_shape = (1, 1, 10, 10)
h_input = np.zeros(shape=batch_shape, dtype=np.float32)
# init output with ones to see if contents really changed
h_output = np.ones(shape=batch_shape, dtype=np.float32)
device_ptr = cuda.mem_alloc(input.nbytes)
stream = cuda.Stream()
cuda.memcpy_htod_async(d_input, h_input, stream)

# here some actions with d_input may be performed, e.g. kernel calls
# but for the sake of simplicity we'll just transfer it back to host
cuda.memcpy_dtoh_async(d_input, h_output, stream)
stream.synchronize()
mx_input = mx.nd(h_output, ctx=mx.gpu(0))

print('output after pycuda calls: ', h_output)
print('mx_input: ', mx_input)
</code></pre>

<p>However i would like to avoid the overhead of device-to-host and host-to-device memory copying.</p>

<p>I couldn't find a way to construct <code>mxnet.ndarray.NDArray</code> directly from <code>h_output</code>.
The closest thing that i was able to find is construction of ndarray <a href=""https://mxnet.apache.org/api/python/ndarray/ndarray.html#mxnet.ndarray.from_dlpack"" rel=""nofollow noreferrer"">from dlpack</a>.
But it is not clear how to work with dlpack object from python.</p>

<p>Is there a way fo achieve <code>NDArray &lt;-&gt; pycuda</code> interoperability without copying memory via host?</p>
","<python><mxnet><pycuda>","2018-11-07 14:21:26","","0","668152","2018-11-07 22:24:16","1","0","","","668152","177","60","1"
"55004936","<p>I learn MXNet framework and try to run example of object detection with SSD:
<a href=""https://gluon.mxnet.io/chapter08_computer-vision/object-detection.html"" rel=""nofollow noreferrer"">https://gluon.mxnet.io/chapter08_computer-vision/object-detection.html</a></p>

<p>I use GPU is NVidia GTX 1050, 4GB for training. I work in Jupyter notebook. Versions: Python 3.6, MXNet 1.3.1.</p>

<p>It was said in the tutorial that training from scratch takes about 30 minutes with one GPU. I stopped after 3 hours. The model had processed 24459 batches (batch has size of 32) when I interrupted training. Whole dataset has size of 87.7MB that is less than 24459*32*256*256 (size of image is 256x256). I can't understand why it may takes too much time. Are there maybe any particular features of image.ImageDetIter (for example the one does never stopped by itself)?</p>
","<python><object-detection><mxnet>","2019-03-05 14:20:19","","1","6121822","2019-03-06 20:15:22","1","0","","","6121822","8","0","0"
"54464440","<p>ist there a code example on how to do linear regression on a custom image dataset? I have only found examples using the CIFAR dataset...</p>
","<machine-learning><mxnet>","2019-01-31 15:54:47","","-4","9281100","2019-03-01 23:19:39","1","1","","","9281100","2","0","0"
"45994149","<p>Mxnet is supposed to build and run, on CPU as well as on GPU, for multiple OSs including Windows.</p>

<p>I'm trying to build mxnet from source on Windows Server 2016 that has NVIDIA K80 GPU on it.</p>

<p>I followed all the instructions in <a href=""https://mxnet.incubator.apache.org/get_started/windows_setup.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/get_started/windows_setup.html</a> but not able to move past the point of building mxnet in Visual Studio 2013.</p>

<p>The error I'm seeing is </p>

<p><strong><em>'mshadow::cuda::AddTakeGrad' : ambiguous call to overloaded function indexing_op.h</em></strong></p>

<p>If I fix this generic call to AddTakeGrad to make it a specific call to mshadow::cuda::, then some other polymorphic function ends up with the same error and so on ...</p>

<p>I tried searching a lot to find if anyone was successful in building mxnet for windows (on both cpu mode and gpu mode) but couldn't find any.</p>

<p><strong>Question:</strong> Has anyone been able to successfully build mxnet on Windows? If so, could you help with this error as well as any specific instructions to get it to build for both cpu mode as well as gpu mode?</p>
","<deep-learning><mxnet>","2017-09-01 06:06:17","","0","7613326","2018-03-01 23:28:02","1","9","","","7613326","5","0","0"
"41678185","<p>I installed mxnet in linux mint. I use anaconda for python 3.5. I followed the instruction and it was successfully installed. Both mxnet and the anaconda are latest version. However, when I tried the code:</p>

<pre><code>import mxnet as mx
res = mx.nd.array([1,2,3])
</code></pre>

<p>I got the error:</p>

<blockquote>
  <p>AttributeError: module 'mxnet' has no attribute 'nd'</p>
</blockquote>

<p>if I typed <code>mx</code>, I got: <code>&lt;module 'mxnet' (namespace)&gt;</code></p>

<p>after repeating the installation and checking the scripts, I saw mxnet was installed under python 2.7, and graphviz is also under python 2.7. How can change them to python 3.5?</p>
","<mxnet>","2017-01-16 14:04:20","","2","7425757","2017-07-24 18:18:13","4","1","","","7425757","13","0","0"
"41563291","<p>guys, I download resnet-152 from this url: <a href=""http://data.mxnet.io/models/imagenet-11k/resnet-152/"" rel=""nofollow noreferrer"">http://data.mxnet.io/models/imagenet-11k/resnet-152/</a></p>

<p>Then, I try to plot this resnet with 152 layers in this way:</p>

<pre><code>import mxnet as mx 

sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)
pltn = mx.viz.plot_network(sym, shape = {'data': (1, 3, 224, 224)}, \
node_attrs = {'shape': 'oval', 'fixedsize': 'false'})
pltn.view('resnet-152')
</code></pre>

<p>However, the output pdf file is empty. I can plot LeNet, AlexNet and VGG, but what's wrong with the resnet? Thank you very much.</p>
","<python-2.7><plot><mxnet><resnet>","2017-01-10 07:21:54","","1","7397989","2018-03-03 02:09:56","1","2","","","7397989","6","0","0"
"48199784","<p>I have a problem with Apache MXNet machine learning library on OS X.</p>

<p>I have been able to run Python version of Lenet, convolutional neural network.
I installed these with pip under both Anaconda Python 2.7 and 3.6.</p>

<pre><code>conda create -n mxnet27 python=2.7
conda info --envs
source activate mxnet27
conda list
pip install mxnet==0.12.1
</code></pre>

<p>But when I run C++ example files cpp-package/example/lenet.cpp I get the this segfault:</p>

<pre><code>Segmentation fault: 11
</code></pre>

<p>This is the place in the code where the segfault is thrown:</p>

<pre><code>Symbol conv1 =
    Convolution(""conv1"", data, conv1_w, conv1_b, Shape(5, 5), 20);
</code></pre>

<p>I get similar segfault for the other C++ examples.</p>

<p>I have built MXNet on OS X 10.13.2
I disabled as many libraries as possible, e.g. OpenCV and CUDA.</p>

<p>On Simon Corston-Oliver suggestion I upgraded to MXNet 1.0.0, but that version did not compile with Clang on OS X. Error message:</p>

<pre><code>operator_tune.h:150:36: note: add an explicit instantiation declaration to suppress this
      warning if 'mxnet::op::OperatorTuneByType&lt;float&gt;::tuning_mode_' is explicitly instantiated in another translation unit

/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/unordered_map:601:15: error: object of type 'std::__1::pair&lt;int,
  mxnet::test::perf::TimingInstrument::Info&gt;' cannot be assigned because its copy assignment operator is implicitly deleted
</code></pre>
","<python><c++><macos><mxnet>","2018-01-11 04:32:29","","0","3444107","2018-01-16 15:00:16","2","1","","","3444107","589","117","1"
"48490010","<p>I have installed the mx.net package in R version 3.4.3 using </p>

<blockquote>
  <p>cran &lt;- getOption(""repos"")</p>
  
  <p>cran[""dmlc""] &lt;- ""<a href=""https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"" rel=""nofollow noreferrer"">https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/</a>""</p>
  
  <p>options(repos = cran)</p>
  
  <p>install.packages(""mxnet"").</p>
</blockquote>

<p>Some issues occur while estimating a neural network. </p>

<p>In underneath code, I used the breastcancer dataset available on 
<a href=""https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29"" rel=""nofollow noreferrer"">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29</a>.</p>

<pre><code>BC_data &lt;- read.csv(""Data_breastcancer.csv"", sep = "";"")

# generate a train and test set
trainIndex = sample(1:nrow(BC_data), size = round(0.8*nrow(BC_data)), replace=FALSE)
train_data &lt;- BC_data[trainIndex,]
test_data &lt;- BC_data[-trainIndex,]
X_train &lt;- train_data[,c(-1,-11)]
y_train &lt;- train_data[,11]   

# estimate neural network
model = mx.mlp(as.matrix(X_train), as.numeric(y_train), hidden_node = 10, out_node = 2, out_activation = ""softmax"", learning.rate = 0.1, num.round = 20)
</code></pre>

<p>However, instead of iteratively returning accuracy values, the only output I get is </p>

<pre><code>Start training with 1 devices
Warning message:
In mx.model.select.layout.train(X, y) :
Auto detect layout of input matrix, use rowmajor..
</code></pre>

<p>so it appears that the iterative process hasn't started at all. </p>

<p>Does somebody know how to solve this problem? </p>
","<r><neural-network><mxnet>","2018-01-28 18:42:18","","0","8015099","2018-01-29 21:49:10","1","0","","","8015099","11","0","0"
"45406537","<p>I'm trying to reproduce some Python MXNet code in Julia 0.6.0, and I'm getting a BoundsError if I try to use a batch size that is smaller than the dimension of the output. If I use a larger batch size in a toy example, things work properly and the network converges to the correct solution, but in my application the output dimension is large so this isn't practical. </p>

<p>Here's a linear regression example that gives this error:</p>

<pre><code>using MXNet
net = mx.Variable(:data)
net = mx.FullyConnected(net, name=:fc0, num_hidden=5)
net = mx.LinearRegressionOutput(net, name=:output)
mod = mx.FeedForward(net, context=mx.cpu(0))

batch_size = 4 # works for batch_size &gt; 4

A = randn(5,100)
train_in = randn(100,1000)
train_out = A*train_in + .1*randn(5,1000)
train_provider = mx.ArrayDataProvider(:data=&gt;train_in,
                                      :output_label=&gt;train_out,
                                      shuffle=true,
                                      batch_size=batch_size)

optimizer = mx.SGD(lr=0.001, momentum=0.9, weight_decay=0.00001)
mx.fit(mod, optimizer, train_provider)
</code></pre>

<p>This produces</p>

<pre><code>INFO: Start training on MXNet.mx.Context[CPU0]
INFO: Initializing parameters...
INFO: Creating KVStore...
INFO: TempSpace: Total 0 MB allocated on CPU0
INFO: Start training...
ERROR: LoadError: BoundsError: attempt to access 5×4 Array{Float32,2} at index [Base.Slice(Base.OneTo(5)), 5]
</code></pre>

<p>If I increase the batch size to 5 or greater, it works as expected. What am I missing?</p>
","<julia><mxnet>","2017-07-31 02:04:07","","1","8391191","2018-03-20 19:00:10","1","3","","","8391191","6","0","0"
"50970073","<p>I was trying to evaluate my classification models with log-loss metric using <a href=""https://mxnet.incubator.apache.org/_modules/mxnet/metric.html"" rel=""nofollow noreferrer"">mxnet.metric</a> module.</p>

<p>I came across two classes: <a href=""https://mxnet.incubator.apache.org/api/python/metric/metric.html#mxnet.metric.CrossEntropy"" rel=""nofollow noreferrer""><code>CrossEntropy</code></a> and <a href=""https://mxnet.incubator.apache.org/api/python/metric/metric.html#mxnet.metric.NegativeLogLikelihood"" rel=""nofollow noreferrer""><code>NegativeLogLikelihood</code></a> which have the same definition and very similar implementation. Both have the same core code for calculating metric value:</p>

<p><code>self.sum_metric += (-numpy.log(prob + self.eps)).sum()</code></p>

<p>If they are essentially the same metrics what is the purpose of maintaining both functions in the library? Which metric is preferred for binary and multi-class classification?</p>
","<python><classification><mxnet><loss-function><cross-entropy>","2018-06-21 13:42:04","","2","7488685","2018-06-22 20:04:50","1","0","","","7488685","58","62","0"
"44640052","<p>I am new in python and mxnet, I want to make the example in the link:<a href=""http://mxnet.io/how_to/finetune.html"" rel=""nofollow noreferrer"">http://mxnet.io/how_to/finetune.html</a>
In the ""Prepare data"" part, when i run this script:</p>

<pre><code>mkdir -p caltech_256_train_60
for i in 256_ObjectCategories/*; do
    c=`basename $i`
    mkdir -p caltech_256_train_60/$c
    for j in `ls $i/*.jpg | shuf | head -n 60`; do
        mv $j caltech_256_train_60/$c/
    done
done
</code></pre>

<p>I have the error:</p>

<blockquote>
  <p>""invalid syntax""</p>
</blockquote>

<p>I did</p>

<p><code>os.system ('mkdir -p caltech_256_train_60')</code> </p>

<p>and it worked and the directory was created.</p>

<p>For the rest, it does not work.</p>

<p>I think that this script is made for Linux and I need to ru it on windows 8 and python 2.7, someone can help me translate this code so i can run it.</p>
","<python><windows><mxnet>","2017-06-19 21:13:52","","0","3824903","2017-08-01 23:14:34","1","0","","","3824903","6","0","0"
"44627753","<p>What I am trying here is, by using the Tennis Match Statistics Data Set provided <a href=""https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics"" rel=""nofollow noreferrer"">here</a> as an input, I made a neural network model that predicts the match results (1 or 0).</p>

<p>By following the official mxnet documents, I developed a program below.
I tried with various configuration parameters such as batch_size, unit_size, act_type,learning_rate, but no matter what kind I of modifications that I could think of, the accuracy I got was always been around 0.5 and always predicted either all 1 or 0.</p>

<pre><code>import numpy as np
from sklearn.preprocessing import normalize
import mxnet as mx
import logging
import warnings
warnings.filterwarnings(""ignore"", category=DeprecationWarning)

logging.basicConfig(level=logging.DEBUG, format='%(asctime)-15s %(message)s')

batch_size = 100
train_data = np.loadtxt(""dm.csv"",delimiter="","")
train_data = normalize(train_data, norm='l1', axis=0)
train_lbl = np.loadtxt(""dm_lbl.csv"",delimiter="","")
eval_data = np.loadtxt(""dw.csv"",delimiter="","")
eval_data = normalize(eval_data, norm='l1', axis=0)
eval_lbl = np.loadtxt(""dw_lbl.csv"",delimiter="","")


train_iter = mx.io.NDArrayIter(train_data, train_lbl, batch_size=batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(eval_data, eval_lbl, batch_size=batch_size)


data = mx.sym.var('data')
# The first fully-connected layer and the corresponding activation function
fc1  = mx.sym.FullyConnected(data=data, num_hidden=220)
#bn1 = mx.sym.BatchNorm(data = fc1, name=""bn1"")
act1 = mx.sym.Activation(data=fc1, act_type=""sigmoid"")

# The second fully-connected layer and the corresponding activation function
fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 220)
#bn2 = mx.sym.BatchNorm(data = fc2, name=""bn2"")
act2 = mx.sym.Activation(data=fc2, act_type=""sigmoid"")

# The third fully-connected layer and the corresponding activation function
fc3  = mx.sym.FullyConnected(data=act2, num_hidden = 110)
#bn3 = mx.sym.BatchNorm(data = fc3, name=""bn3"")
act3 = mx.sym.Activation(data=fc3, act_type=""sigmoid"")

# output class(es)
fc4  = mx.sym.FullyConnected(data=act3, num_hidden=2)
# Softmax with cross entropy loss
mlp  = mx.sym.SoftmaxOutput(data=fc4, name='softmax')

mod = mx.mod.Module(symbol=mlp,
                    context=mx.cpu(),
                    data_names=['data'],
                    label_names=['softmax_label'])
mod.fit(train_iter,
        eval_data=val_iter,
        optimizer='sgd',
        optimizer_params={'learning_rate':0.03},
        eval_metric='rmse',
        num_epoch=10,
        batch_end_callback = mx.callback.Speedometer(batch_size, 100)) # output progress for each 200 data batches)

prob = mod.predict(val_iter).asnumpy()
#print(prob)

for unit in prob:
    print 'Classified as %d with probability %f' % (unit.argmax(), max(unit))
</code></pre>

<p>Here is the log output:</p>

<pre><code>2017-06-19 17:18:34,961 Epoch[0] Train-rmse=0.500574
2017-06-19 17:18:34,961 Epoch[0] Time cost=0.007
2017-06-19 17:18:34,968 Epoch[0] Validation-rmse=0.500284
2017-06-19 17:18:34,975 Epoch[1] Train-rmse=0.500703
2017-06-19 17:18:34,975 Epoch[1] Time cost=0.007
2017-06-19 17:18:34,982 Epoch[1] Validation-rmse=0.500301
2017-06-19 17:18:34,990 Epoch[2] Train-rmse=0.500713
2017-06-19 17:18:34,990 Epoch[2] Time cost=0.008
2017-06-19 17:18:34,998 Epoch[2] Validation-rmse=0.500302
2017-06-19 17:18:35,005 Epoch[3] Train-rmse=0.500713
2017-06-19 17:18:35,005 Epoch[3] Time cost=0.007
2017-06-19 17:18:35,012 Epoch[3] Validation-rmse=0.500302
2017-06-19 17:18:35,019 Epoch[4] Train-rmse=0.500713
2017-06-19 17:18:35,019 Epoch[4] Time cost=0.007
2017-06-19 17:18:35,027 Epoch[4] Validation-rmse=0.500302
2017-06-19 17:18:35,035 Epoch[5] Train-rmse=0.500713
2017-06-19 17:18:35,035 Epoch[5] Time cost=0.008
2017-06-19 17:18:35,042 Epoch[5] Validation-rmse=0.500302
2017-06-19 17:18:35,049 Epoch[6] Train-rmse=0.500713
2017-06-19 17:18:35,049 Epoch[6] Time cost=0.007
2017-06-19 17:18:35,056 Epoch[6] Validation-rmse=0.500302
2017-06-19 17:18:35,064 Epoch[7] Train-rmse=0.500712
2017-06-19 17:18:35,064 Epoch[7] Time cost=0.008
2017-06-19 17:18:35,071 Epoch[7] Validation-rmse=0.500302
2017-06-19 17:18:35,079 Epoch[8] Train-rmse=0.500712
2017-06-19 17:18:35,079 Epoch[8] Time cost=0.007
2017-06-19 17:18:35,085 Epoch[8] Validation-rmse=0.500301
2017-06-19 17:18:35,093 Epoch[9] Train-rmse=0.500712
2017-06-19 17:18:35,093 Epoch[9] Time cost=0.007
2017-06-19 17:18:35,099 Epoch[9] Validation-rmse=0.500301
Classified as 0 with probability 0.530638
Classified as 0 with probability 0.530638
Classified as 0 with probability 0.530638
.
.
.
Classified as 0 with probability 0.530638
</code></pre>

<p>Can someone please clue me where I got wrong?</p>

<pre><code>python version == 2.7.10
mxnet == 0.10.0
numpy==1.12.0
</code></pre>

<p>From the dataset I removed some non informative columns, and headers, and then converted it into csv format.</p>

<pre><code>train_data.shape == (491, 22)
train_lbl.shape == (491,)
eval_data.shape == (452, 22)
eval_lbl.shape == (452,) 
</code></pre>
","<python><machine-learning><deep-learning><mxnet>","2017-06-19 10:10:59","","0","8182049","2017-06-20 23:54:33","1","1","","","8182049","3","0","0"
"54228870","<p>In numpy, one can delete an element in an array by using numpy.delete().
Now I use mxnet ndarray to calculate data, but I have got a problem.</p>

<p>How can I <strong>delete</strong> an element for the <strong>mxnet ndarray</strong> ?</p>
","<python><numpy><multidimensional-array><mxnet>","2019-01-17 04:07:38","","-1","9729151","2019-02-14 00:13:56","1","0","","","9729151","1","0","0"
"54248787","<p>I want to realize the “resume training” function for my training program. But I don’t know how to correctly resume the optimizer status.</p>

<p>My program is like this:</p>

<pre><code>opt = mx.optimizer(learning_rate=lr, ....)

ctx = [...]
sym = get_symbol() # The function define network
model = mx.mod.Module(sym=sym, ctx=ctx)

model.fit(...)
</code></pre>

<p>Now I want to save the model after training 1k steps and then resume it from the checkpoint. Since the optimizer status are also required to be resumed (i.e. The momentum of parameters for a momentum optimizer), I use the mxnet.Module API, and the codes to perform saving and loading are:</p>

<pre><code>##### save #####
def batch_callback(params):
    if global_step == 1000:
        model.save_checkpoint(prefix, 0, save_optimizer_states=True)
        sys.exit(0)
</code></pre>

<p>The batch_callback is registered to the model.fit() function.</p>

<pre><code>##### load #####
model = mx.mod.Module.load(prefix, 0, load_optimizer_states=True)
model.bind(...)
arg_params, aux_params=model.get_params()

model.fit(optimizer = opt, optimizer_params=('learning_rate', args.lr),
          arg_params=arg_params, aux_params=aux_params,
          batch_end_callback = batch_callback)
</code></pre>

<p>However, I find that the model is not correctly resumed. The results are quite bad. I am not sure but it seems that the parameters of model are random initialized rather than load from checkpoint.</p>

<p>So, what is the correct way to resume training with resuming optimizer status?</p>
","<mxnet>","2019-01-18 06:32:26","","0","10931864","2019-02-14 00:49:02","1","0","","","10931864","1","0","0"
"34851259","<p>My datasets is <a href=""http://yann.lecun.com/exdb/mnist/"" rel=""nofollow noreferrer"">MNIST</a>, and ML library is <a href=""https://github.com/dmlc/mxnet/"" rel=""nofollow noreferrer"">MXNet</a></p>

<p>I used the CNN algorithm to practice ML. Then I found the reference tutorial, <a href=""http://web.pdx.edu/~jduh/courses/Archive/geog481w07/Students/Ludwig_ImageConvolution.pdf"" rel=""nofollow noreferrer"">page 6 and 7</a>.</p>

<p><a href=""https://i.stack.imgur.com/wrxLE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wrxLE.png"" alt=""smoothly kernel""></a></p>

<p>I guess the default kernel is all '1' instances in a matrix (kernel in MXNet). How to make the smoothly kernel like above slide.</p>

<hr>

<p>This is the MXNet code with R.</p>

<pre><code>mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
</code></pre>
","<r><machine-learning><conv-neural-network><mxnet>","2016-01-18 09:29:05","","5","4469334","2018-03-01 02:36:51","1","2","3","","4469334","331","101","3"
"45853939","<p>I made a very simple network using mxnet(two fc layers with dim of 512).</p>

<p>By changing the ctx = mx.cpu() or ctx = mx.gpu(0), I run the same code on both CPU and GPU.</p>

<p>The memory cost of GPU is much bigger than CPU version.(I checked that using 'top' instead of 'nvidia-smi').</p>

<p>It seems strange, as the GPU version also has memory on GPU already, why GPU still need more space on memory?</p>

<p><a href=""https://i.stack.imgur.com/ynm6l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ynm6l.png"" alt=""CPU and GPU memory""></a></p>

<p>(line 1 is CPU program / line 2 is GPU program)</p>
","<deep-learning><gpu><mxnet>","2017-08-24 05:55:41","","0","1617034","2018-03-07 01:21:47","2","0","","","1617034","330","66","0"
"40423227","<p>I have created a Neural network model using mxnet package in R studio. I tested the model on local and it works as expected. I have deployed the same model as a webservice in AzureML using <code>publishwebservice()</code> function from R.</p>

<p>When I try to predict the test data with the webservice using <code>consume()</code> function: </p>

<pre><code>pred_cnn &lt;- consume(endpoint_cnn, testdf)
</code></pre>

<p>it always throws following error:</p>

<blockquote>
  <p>Error: AzureML returns error code: HTTP status code : 400 AzureML
  error code  : LibraryExecutionError</p>
  
  <p>Module execution encountered an internal library error.<br>
  The following
  error occurred during evaluation of R script: R_tryEval: return error: 
  Error in UseMethod(""predict"") :<br>
     no applicable method for 'predict'
  applied to an object of class ""MXFeedForwardModel""</p>
</blockquote>
","<r><azure-machine-learning-studio><mxnet>","2016-11-04 12:55:00","","2","870483","2018-03-21 16:56:45","1","2","1","","870483","13100","405","5"
"53512063","<p>I am training an object detector using mxnet/resnet50 
After the last training run the mAP was 78%, and the loss was 0.37
When I run the detector on my test set (independent of train/val data)
I am getting false positives result - with some rather high 30-60% confidence levels. I think I need to add some train/val images that do not have ANY of the objects i'm training the detector for.</p>

<p>I'm planning on adding about 20% more images that have a label of -1 -- which I read somewhere is how you designate an image having no label in mxnet.</p>

<p>Does this seem reasonable? is -1 the right way to designate it? any downside?
Thanks,
john</p>
","<mxnet><resnet>","2018-11-28 04:18:21","","1","10288357","2019-04-04 23:35:05","1","2","","","10288357","22","2","0"
"51163667","<p>I am try to write prediction part of script for the tutorial:  <a href=""https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html</a></p>

<pre><code>import mxnet as mx

from collections import Counter
import os
import re
import threading
import sys
import itertools
import numpy as np

from collections import namedtuple

SENTENCES_DIR = 'C:/code/mxnet/sentences'
CURRENT_DIR = 'C:/code/mxnet'

def clean_str(string):
    string = re.sub(r""[^A-Za-z0-9(),!?\'\`]"", "" "", string)
    string = re.sub(r""\'s"", "" \'s"", string)
    string = re.sub(r""\'ve"", "" \'ve"", string)
    string = re.sub(r""n\'t"", "" n\'t"", string)
    string = re.sub(r""\'re"", "" \'re"", string)
    string = re.sub(r""\'d"", "" \'d"", string)
    string = re.sub(r""\'ll"", "" \'ll"", string)
    string = re.sub(r"","", "" , "", string)
    string = re.sub(r""!"", "" ! "", string)
    string = re.sub(r""\("", "" \( "", string)
    string = re.sub(r""\)"", "" \) "", string)
    string = re.sub(r""\?"", "" \? "", string)
    string = re.sub(r""\s{2,}"", "" "", string)
    return string.strip().lower()

def load_data_sentences(filename):
    sentences_file = open( filename, ""r"")
    # Tokenize
    x_text = [line.decode('Latin1').strip() for line in sentences_file.readlines()] 
    x_text = [clean_str(sent).split("" "") for sent in x_text]
    return x_text


def pad_sentences(sentences, padding_word=""""):""
    sequence_length = max(len(x) for x in sentences)
    padded_sentences = []
    for i in range(len(sentences)):
        sentence = sentences[i]
        num_padding = sequence_length - len(sentence)
        new_sentence = sentence + [padding_word] * num_padding
        padded_sentences.append(new_sentence)
    return padded_sentences


def build_vocab(sentences):
    word_counts = Counter(itertools.chain(*sentences))
    vocabulary_inv = [x[0] for x in word_counts.most_common()]
    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}
    return vocabulary, vocabulary_inv

def build_input_data(sentences, vocabulary):
    x = np.array([
            [vocabulary[word] for word in sentence]
            for sentence in sentences])
    return x

def predict(mod, sen):
    mod.forward(Batch(data=[mx.nd.array(sen)]))
    prob = mod.get_outputs()[0].asnumpy()
    prob = np.squeeze(prob)
    a = np.argsort(prob)[::-1]    
    for i in a[0:5]:
        print('probability=%f' %(prob[i]))   


sentences = load_data_sentences( os.path.join( SENTENCES_DIR, 'test-pos-1.txt') )
sentences_padded = pad_sentences(sentences)
vocabulary, vocabulary_inv = build_vocab(sentences_padded)
x = build_input_data(sentences_padded, vocabulary)


Batch = namedtuple('Batch', ['data'])

sym, arg_params, aux_params = mx.model.load_checkpoint( os.path.join( CURRENT_DIR, 'cnn'), 19)
mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names = None)
mod.bind(for_training=False, data_shapes=[('data', (50,56))], label_shapes=mod._label_shapes)
mod.set_params(arg_params, aux_params, allow_missing=True)

predict(mod, x)
</code></pre>

<p>But I got the error:</p>

<blockquote>
  <p>infer_shape error. Arguments: data: (50, 26L)
  Traceback (most recent call last):
  File ""C:\code\mxnet\test2.py"", line 152, in  predict(mod, x)
  File ""C:\code\mxnet\test2.py"", line 123, in predict
  mod.forward(Batch(data=[mx.nd.array(sen)]))
  ...</p>
  
  <p>MXNetError: Error in operator reshape0: [16:20:21] c:\projects\mxnet-distro-win\mxnet-build\src\operator\tensor./matrix_op-inl.h:187: 
  Check failed: oshape.Size() == dshape.Size() (840000 vs. 390000) 
  Target shape size is different to source.
  Target: [50,1,56,300]
  Source: [50,26,300]</p>
</blockquote>

<p>Source is text file with 50 strings of sentences</p>

<p>Unfortunately I didn't found any help in Internet. Please take a look.
OS: Windows 10. Python 2.7 
Thank you.</p>
","<python><mxnet>","2018-07-03 22:41:26","","0","2048003","2018-07-17 19:26:35","1","0","","","2048003","20","1","0"
"41536586","<p>I'm trying to use the mx.nd.onehot_encode function, which should be straightforward, but I'm getting errors that are difficult to parse. Here is the example usage I'm trying.</p>

<pre><code>m0 = mx.nd.zeros(15)
mx.nd.onehot_encode(mx.nd.array([0]), m0)
</code></pre>

<p>I expect this to return a 15 dim vector (at same address as m0) with only the first element set to 1. Instead I get the error:</p>

<pre><code>src/ndarray/./ndarray_function.h:73: Check failed: index.ndim() == 1 &amp;&amp; proptype.ndim() == 2 OneHotEncode only support 1d index.
</code></pre>

<p>Neither ndarray is of dimension 2, so why am I getting this error? Is there some other input format I should be using?</p>
","<mxnet>","2017-01-08 19:00:14","","0","6106700","2017-01-09 18:31:50","1","0","","","6106700","25","1","0"
"47425711","<p>I have successfully installed MXNet-0.11 in my laptop, whose OS is Windows 10 and GPU is GTX1060. And now I want to install rcnn, I have run the Makefile in the folder example/rcnn in command line using MinGW64. But when I run demo.py, it tells me <strong>DLL load failed</strong>. How do I fix it? Thank you!</p>
","<python-import><mxnet>","2017-11-22 02:03:14","","0","8978649","2018-03-20 23:18:28","1","1","","","8978649","1","0","0"
"50241771","<p>I created training job in sagemaker with my own training and inference code using MXNet framework. I am able to train the model successfully and created endpoint as well. But while inferring the model, I am getting the following error:</p>

<p><strong><em>‘ClientError: An error occurred (413) when calling the InvokeEndpoint operation: HTTP content length exceeded 5246976 bytes.’</em></strong></p>

<p>What I understood from my research is the error is due to the size of the image. The image shape is (480, 512, 3). I trained the model with images of same shape (480, 512, 3).</p>

<p>When I resized the image to (240, 256), the error was gone. But producing another error 'shape inconsistent in convolution' as I the trained the model with images of size (480, 512).</p>

<p>I didn’t understand why I am getting this error while inferring.
Can't we use images of larger size to infer the model?
Any suggestions will be helpful</p>

<p>Thanks, Harathi</p>
","<python><mxnet><amazon-sagemaker>","2018-05-08 20:25:31","","0","9459389","2018-05-08 20:53:20","1","1","","","9459389","29","2","0"
"50030196","<p>I used to work with the <code>mxnet</code> package in R.
I have an old installation and I can use it in R 3.4x but now I want to switch to the newest R version (R 3.5 locally) and I would love to use it on rstudio.cloud.
The package was on CRAN (wasn't it?)
Now I try to follow the instructions from the packgage <a href=""https://mxnet.incubator.apache.org/install/windows_setup.html#install-mxnet-for-r"" rel=""nofollow noreferrer"">page</a>:</p>

<pre><code>  cran &lt;- getOption(""repos"")
  cran[""dmlc""] &lt;- ""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/""
  options(repos = cran)
  install.packages(""mxnet"")
</code></pre>

<p>and I get the following result:</p>

<blockquote>
  <p>installing the source package ‘mxnet’</p>
  
  <p>trying URL
  '<a href=""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz"" rel=""nofollow noreferrer"">https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz</a>'
  Warning in install.packages :   cannot open URL
  '<a href=""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz"" rel=""nofollow noreferrer"">https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz</a>':
  HTTP status was '404 Not Found' Error in download.file(url, destfile,
  method, mode = ""wb"", ...) :    cannot open URL
  '<a href=""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz"" rel=""nofollow noreferrer"">https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_0.10.1.tar.gz</a>'
  Warning in install.packages :   download of package ‘mxnet’ failed</p>
</blockquote>

<p>Is there a way to install mxnet for R from the R command line (so I can try it in the cloud as well)? or I have to switch to keras entirely ....:)</p>

<p>Any help is appreciated.</p>

<p>my sessioninfo is:</p>

<blockquote>
  <p>R version 3.5.0 (2018-04-23) Platform: x86_64-w64-mingw32/x64 (64-bit)
  Running under: Windows >= 8 x64 (build 9200)</p>
  
  <p>Matrix products: default</p>
  
  <p>locale: [1] LC_COLLATE=English_United States.1252 
  LC_CTYPE=English_United States.1252    [3] LC_MONETARY=English_United
  States.1252 LC_NUMERIC=C                           [5]
  LC_TIME=English_United States.1252    </p>
  
  <p>attached base packages: [1] stats     graphics  grDevices utils<br>
  datasets  methods   base     </p>
  
  <p>other attached packages: [1] xgboost_0.6.4.1</p>
  
  <p>loaded via a namespace (and not attached):  [1] drat_0.1.4<br>
  compiler_3.5.0      magrittr_1.5        Matrix_1.2-14<br>
  tools_3.5.0          [6] withr_2.1.2         yaml_2.1.18<br>
  memoise_1.1.0       stringi_1.1.7       grid_3.5.0          [11]
  data.table_1.10.4-3 digest_0.6.15       pacman_0.4.6<br>
  devtools_1.13.5     lattice_0.20-35</p>
</blockquote>
","<r><mxnet>","2018-04-25 19:44:00","","1","1863648","2018-04-25 20:09:57","1","3","","","1863648","1276","165","0"
"48541652","<p>I am trying to train a convolutional neural network with mxnet using the Gluon API on a set of images I want to classify. However, the same network and code sometimes outputs extremely different results for the same data, and on occasion simply crashes and refuses to run for some reason. Here is my code:</p>

<p>Additional information:</p>

<p>Images are all <em>131 x 131</em> px size, 176 images per class (2 classes) and 40 test per class. I'm confused as to why the same program for the same data should sometimes give output but otherwise crash.</p>

<p>Imports</p>

<pre><code>from __future__ import print_function
import mxnet as mx
import numpy as np
from mxnet import nd, autograd, gluon
import time
mx.random.seed(1)
</code></pre>

<p>Setting context</p>

<pre><code>ctx = mx.cpu()
</code></pre>

<p>Defining callback transform function</p>

<pre><code>def transform(data, label):
    return nd.transpose(data.astype(np.float32), (2, 0, 1))/255, label
</code></pre>

<p>Defining batch size and number of nodes in o/p layer</p>

<pre><code>batch_size = 5
num_outputs = 2
</code></pre>

<p>Load training and test data</p>

<pre><code>train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.ImageFolderDataset(""/somepath/train"", 0, transform), batch_size, shuffle=True)
test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.ImageFolderDataset(""/somepath/test"", 0, transform), batch_size, shuffle=False)
</code></pre>

<p>Define CNN using gluon.nn</p>

<pre><code>neural_net = gluon.nn.Sequential()
num_fc = 512

with neural_net.name_scope():
    neural_net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))
    neural_net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))
    neural_net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))
    neural_net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))
    neural_net.add(gluon.nn.Flatten())
    neural_net.add(gluon.nn.Dense(num_fc, activation=""relu""))
    neural_net.add(gluon.nn.Dense(num_outputs))
</code></pre>

<p>Initialize params, loss fn, and trainer object </p>

<pre><code>neural_net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)
cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()
trainer = gluon.Trainer(neural_net.collect_params(), 'adadelta')
</code></pre>

<p>Training Loop</p>

<pre><code>total_time = 0
for e in range(2):
    tick = time.time()
    for idx, (dpoint, label) in enumerate(train_data):
        data = dpoint.as_in_context(ctx)
        label = label.as_in_context(ctx)

        with autograd.record():
            output = neural_net(data)
            loss2 = cross_entropy(output, label)

        loss2.backward()    
        trainer.step(data.shape[0])
    tock = time.time()
    print(""Epoch %s. Took %s seconds to train"" %(e, tock-tick))
    total_time += tock-tick
print(""Total training time: %s"" %(total_time))
</code></pre>

<p>Measuring accuracy</p>

<pre><code>acc = mx.metric.Accuracy()
for idx, (data, label) in enumerate(test_data):
    something = data.as_in_context(ctx)
    something_label = label.as_in_context(ctx)

    output2 = neural_net(something)
    predictions = nd.argmax(output2, axis=1)

    acc.update(predictions, something_label)
print(acc.get()[-1])
</code></pre>
","<python><apache><deep-learning><mxnet>","2018-01-31 12:00:47","","1","8404593","2018-02-28 21:33:51","2","5","0","","8404593","18","8","0"
"42030229","<p>I am currently trying to set up a feed-forward NN using the MXNet R API. I would like to implement a custom loss function that uses pre-fixed weights defined by myself to be c(7,8,9). In Tensorflow, there is the option to define variables as non-trainable, which makes sure these variables are not modified during the training process. This is exactly what I would need for my weights! Unfortunately, I have not found any way of implementing this. Here is my code:</p>

<pre><code>data &lt;- mx.symbol.Variable('data')
label &lt;- mx.symbol.Variable('label')
weights &lt;- mx.symbol.Variable(name='weights')

... [some network layers]...

fc2 &lt;- mx.symbol.FullyConnected(data=tanh3, num_hidden=length(predictable_errors))
softmax &lt;- mx.symbol.SoftmaxActivation(data=fc2, name=""softmax_activation"")
weighted_l2 &lt;- mx.symbol.sum(mx.symbol.square(softmax - label)*weights)
loss &lt;- mx.symbol.MakeLoss(data=weighted_l2)

model &lt;- mx.model.FeedForward.create(loss, X=train.x, y=train.y, ctx=mx.cpu(), arg.params = list(weights=mx.nd.array( array(c(7,8,9), dim=c(3,1)), mx.cpu() )), num.round=1, learning.rate=0.05, momentum=0.9, array.batch.size = 1, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(1))
</code></pre>

<p>I know that the Python API offers the function set_lr_mult, with which I could set the learning rate to zero for ""weights"", but with R this does not seem to be an option. Would you have any suggestions?</p>

<p>Many thanks in adavance!</p>
","<r><mxnet>","2017-02-03 17:55:32","","0","7512500","2017-02-03 21:43:06","1","0","","","7512500","64","0","0"
"45607275","<p>I am changing an c++ example in mxnet. I do not understand how to allocate an NDArray object. There is no even basic documentation around, which is pretty frustrating.</p>

<p>I try to allocate an NDArray, but by declaring an instance it does not seem to allocate the data, only when I fill an array with data. Is that correct?</p>

<pre><code>// this code snippet does not work     
  NDArray a = NDArray(Shape(10, 20), Context::cpu());
  const float *dat = a.GetData();
  float result = *dat; // read memory violation
  result = *(dat + 10);

// this code snippet works
  NDArray b = NDArray(Shape(10, 20), Context::cpu());
  a.SampleUniform(1.0, 2.0, &amp;b);
  const float *dat2 = b.GetData();
  float result2 = *dat2; // works!!
  result2 = *(dat2 + 10); 
</code></pre>

<p>Has someone experience with the c++ API and changing networks?</p>
","<c++><mxnet>","2017-08-10 07:33:52","","0","2980583","2018-05-30 02:04:24","2","1","","","2980583","10","0","0"
"45592174","<p>I am working on a problem and were trying to solve using MXNet. I was trying to use a custom metric in the code. 
The code for the same is:</p>

<pre><code>def calculate_sales_from_bucket(bucketArray):
    return numpy.asarray(numpy.power(10, calculate_max_index_from_bucket(bucketArray)))

def calculate_max_index_from_bucket(bucketArray):
    answerArray = []
    for bucketValue in bucketArray:
        index, value = max(enumerate(bucketValue), key=operator.itemgetter(1))
        answerArray.append(index)
    return answerArray


def custom_metric(label, bucketArray):
    return numpy.mean(numpy.power(calculate_sales_from_bucket(label)-calculate_sales_from_bucket(bucketArray),2))

model.fit(
    train_iter,         # training data
    eval_data=val_iter, # validation data
    batch_end_callback = mx.callback.Speedometer(batch_size, 1000),    # output progress for each 1000 data batches
    num_epoch = 10,     # number of data passes for training 
    optimizer = 'adam',
    eval_metric = mx.metric.create(custom_metric),
    optimizer_params=(('learning_rate', 1),)
)
</code></pre>

<p>I am getting the output as:</p>

<pre><code>INFO:root:Epoch[0] Validation-custom_metric=38263835679935.953125
INFO:root:Epoch[1] Batch [1000]      Speed: 91353.72 samples/sec        Train-custom_metric=39460550891.057487
INFO:root:Epoch[1] Batch [2000]        Speed: 96233.05 samples/sec  Train-custom_metric=9483.127650
INFO:root:Epoch[1] Batch [3000] Speed: 90828.09 samples/sec   Train-custom_metric=57538.891485
INFO:root:Epoch[1] Batch [4000] Speed: 93025.54 samples/sec   Train-custom_metric=59861.927745
INFO:root:Epoch[1] Train-custom_metric=8351.460495
INFO:root:Epoch[1] Time cost=9.466
INFO:root:Epoch[1] Validation-custom_metric=38268.250469
INFO:root:Epoch[2] Batch [1000]     Speed: 94028.96 samples/sec       Train-custom_metric=58864.659051
INFO:root:Epoch[2] Batch [2000]     Speed: 94562.38 samples/sec       Train-custom_metric=9482.873310
INFO:root:Epoch[2] Batch [3000]      Speed: 93198.68 samples/sec        Train-custom_metric=57538.891485
INFO:root:Epoch[2] Batch [4000]      Speed: 93722.89 samples/sec        Train-custom_metric=59861.927745
INFO:root:Epoch[2] Train-custom_metric=8351.460495
INFO:root:Epoch[2] Time cost=9.341
INFO:root:Epoch[2] Validation-custom_metric=38268.250469
</code></pre>

<p>​In this case, irrespective of change in train-custom_metric for batches, the train-custom_metric is still the same. 
Like in case of batch 1000 for epoch 1 and epoch 2.</p>

<p>I believe that this is an issue as the Train-custom_metric​ and Validation-custom_metric​ is not changing irrespective of the value of epoch steps.
I am a beginner in MXNet and I might be wrong in this assumption. </p>

<p>Can you confirm if I am passing eval_metric in the correct way?</p>
","<machine-learning><neural-network><mxnet>","2017-08-09 13:31:20","","0","3962748","2017-12-14 01:27:15","1","0","","","3962748","490","34","1"
"44959694","<p>I'm a writing a C++ custom operator in MXNet and am having trouble finding documentation on when <code>kAddTo</code> is set in an operator invocation. As a minimal example, let's say that my new operator is called <code>foo()</code> and I want to perform the following calculation:</p>

<pre class=""lang-py prettyprint-override""><code>A = mx.sym.Variable('A')
B = mx.sym.Variable('B')
T = mx.sym.foo(A)
T += mx.sym.foo(B)
</code></pre>

<p>In general, how do I ensure that the fourth line above accumulates into T as opposed to creating a new temporary storage for the result of <code>mx.sym.foo(B)</code> and then performing the <code>T = T + temp</code> calculation?</p>

<p><em>(Using the Kernighan-Ritchie debugger, aka print statements, I found that <code>kWriteTo</code> is set on both lines three and four. The enum <code>kAddTo</code> is never set.)</em></p>

<p>A bit more detail concerning my specific problem: in my current implementation <code>foo()</code> <em>zeroes out</em> the output memory before performing a calculation which populates it with the appropriate values. I definitely only want to perform this zeroing out when creating a new output location, not when accumulating into an existing one.</p>

<p><strong>Update</strong></p>

<p>Offline, a colleague suggested using</p>

<pre class=""lang-py prettyprint-override""><code>mx.sym.elemwise_add(lhs=T, rhs=mx.sym.foo(B), out=T)
</code></pre>

<p>in place of line 4, above. However, I still saw that <code>kWriteTo</code> was being set in both lines of computation. I then received the following response:</p>

<blockquote>
  <p><strong>“Memory planning and inplace operations are automatic. It will be done automatically. Users don’t need to worry about it.”</strong>, which probably means that <code>req[0]</code> is not an accurate indicator in this case. If you want to verify whether it’s an inplace addTo, you can print out the value of <code>outputs[0].dptr_</code> and <code>lhs.dptr_</code> to see whether they are equal.</p>
</blockquote>

<p>I haven't checked this, yet.</p>
","<mxnet>","2017-07-06 22:13:47","","3","645494","2017-08-03 00:11:32","1","0","","","645494","331","21","1"
"45125919","<p>Trying to understand some Scala's code on network training in MXNet.</p>

<p>I believe you can access gradient on the executor in Scala by calling <code>networkExecutor.gradDict(""data"")</code>, what would be equivalent of it in Python MXNet?</p>

<p>Thanks! </p>
","<python><scala><mxnet>","2017-07-16 06:56:21","","0","2649999","2017-07-18 16:03:35","1","0","","","2649999","439","47","8"
"46340994","<p>Hi I'm a newbie to data science,
I followed this tutorial <a href=""https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/nlp/cnn.html</a> but I am confused over how to make a single prediction using the trained model generated by the above mentioned tutorial. Please guide me the right direction to fix this. Thanks.</p>
","<python><conv-neural-network><data-science><text-classification><mxnet>","2017-09-21 10:01:09","","4","7824627","2018-07-20 10:14:38","2","0","1","","7824627","36","16","0"
"42753386","<p>I follow the Character Level LSTM Tutorial on <a href=""http://mxnet.io/tutorials/python/char_lstm.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/python/char_lstm.html</a>.  After run this line
 `</p>

<p>import lstm`</p>

<p>I get the error:</p>

<blockquote>
  <p>ImportError: No module named lstm</p>
</blockquote>

<p>How to make this work? Thank you.</p>
","<mxnet>","2017-03-12 21:27:11","","0","6386280","2017-06-07 03:34:32","1","0","","","6386280","11","0","0"
"39346289","<p>I am new to image classification. I am trying to solve a problem on kaggle using mxnet in python. I was trying to run a script code which is one of the solutions for that problem. 
Code was like :</p>

<pre><code>prefix=""Inception/Inception-7""
num_round=1
network=model.FeedForward.load(prefix,num_round,ctx=mx.gpu(),numpy_batch_size=bx)
</code></pre>

<p>It is showing error :</p>

<blockquote>
  <p>MXNetError: [15:23:58] src/io/local_filesys.cc:149: Check failed:
  allow_null  LocalFileSystem: fail to open
  ""/Inception/Inception-7-symbol.json""</p>
</blockquote>

<p>I have even changed path in the ""prefix"" like :</p>

<pre><code>prefix=""/home/Inception""
</code></pre>

<p>But still I am not understanding why it is not opening the <code>.json</code> file and showing the error. I am using Ubuntu 16.04.</p>
","<python><ubuntu><kaggle><mxnet>","2016-09-06 10:07:03","","1","6648286","2017-03-02 17:58:46","1","2","","","6648286","24","0","0"
"42855864","<p>I have been trying to learn mxnet from the tutorial while doing data loading stuff I am getting 'int' doesn't have '<strong>getitem</strong>' but i am not able to find the location of error please help me thanks:</p>

<pre><code>import mxnet as mx
import numpy as np

class SimpleData :
    def __init__(self,data,label,pad = 0):
        self.data = data
        self.label = label
        self.pad = pad

class SimpleIter:
        def __init__(self,mean,std,data_shape,label_shape,num_of_classes,num_batch = 10):
        self._provide_data = zip(['data'],data_shape[0])
        self._provide_label = zip(['softmax_label'],label_shape[0])
        self.cur_batch = 0
        self.num_batch = 10
        self.mean = mean 
        self.std = std
        self.data_shape = data_shape[0]
        self.label_shape = label_shape[0]
        self.num_of_classes  = num_of_classes

    def __iter__(self):
        return self

    def __next__(self):
        return self.next()

    def reset(self):
        self.cur_batch = 0

    @property 
    def provide_data(self):
        return self._provide_data

    @property
    def provide_label(self):
        return self._provide_label

    def next(self):
        if(self.cur_batch &lt; self.num_batch):
            self.cur_batch += 1
            data = [mx.nd.array(np.random.normal(self.mean,self.std,    ((self.data_shape)[0][0]/self.num_batch,self.data_shape[0][1])))]
            label = [mx.nd.array(np.random.randint(0,10,    ((self.data_shape)[0][1]/self.num_batch)))]
            print data
            print label
            return SimpleBatch(data,label)
        else:
            raise StopIteration

class SyntheticData:
    def     __init__(self,mean,std,num_records,num_of_features,num_classes):
        self.mean = mean
        self.std = std
        self.data_shape = zip(num_records,num_of_features)
        self.label_shape = zip(num_records,)
        self.num_classes = num_classes

        def get_iter(self):
            return     SimpleIter(self.mean,self.std,self.data_shape,self.label_shape,self.num_classes)
net = mx.sym.Variable('data')
net = mx.sym.FullyConnected(data = net,name = 'fc1',num_hidden = 64)
net = mx.sym.Activation(data = net,name = 'relu_1',act_type = 'relu')
net = mx.sym.FullyConnected(data = net,name = 'fc2',num_hidden = 10)
net = mx.sym.SoftmaxOutput(data = net,name = 'softmax')
data = SyntheticData(10,128,[100],[100],10) 
mod.fit(data.get_iter(), 
    eval_data=data.get_iter(),
    optimizer='sgd',
    optimizer_params={'learning_rate':0.1},
    eval_metric='acc',
    num_epoch = 5)
</code></pre>

<p>the error is:</p>

<pre><code>    TypeError                                 Traceback (most recent call last)
 &lt;ipython-input-273-a7375f022406&gt; in &lt;module&gt;()
      4         optimizer_params={'learning_rate':0.1},
      5         eval_metric='acc',
----&gt; 6         num_epoch = 5)

/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/module/base_module.pyc in fit(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)
    440 
    441         self.bind(data_shapes=train_data.provide_data, label_shapes=train_data.provide_label,
--&gt; 442                   for_training=True, force_rebind=force_rebind)
    443         if monitor is not None:
    444             self.install_monitor(monitor)

/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/module/module.pyc in bind(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)
    386                                                      fixed_param_names=self._fixed_param_names,
    387                                                      grad_req=grad_req,
--&gt; 388                                                      state_names=self._state_names)
    389         self._total_exec_bytes = self._exec_group._total_exec_bytes
    390         if shared_module is not None:

/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/module/executor_group.pyc in __init__(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, logger, fixed_param_names, grad_req, state_names)
    203                                for name in self.symbol.list_outputs()]
    204 
--&gt; 205         self.bind_exec(data_shapes, label_shapes, shared_group)
    206 
    207     def decide_slices(self, data_shapes):

/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/module/executor_group.pyc in bind_exec(self, data_shapes, label_shapes, shared_group, reshape)
    282 
    283         # calculate workload and bind executors
--&gt; 284         self.data_layouts = self.decide_slices(data_shapes)
    285         if label_shapes is not None:
    286             # call it to make sure labels has the same batch size     as data

/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-    py2.7.egg/mxnet/module/executor_group.pyc in decide_slices(self,     data_shapes)
       220                 continue
       221 
--&gt;     222             batch_size = shape[axis]
       223             if self.batch_size is not None:
       224                 assert batch_size == self.batch_size, (""all data      must have the same batch size: ""

TypeError: 'int' object has no attribute '__getitem__'
</code></pre>
","<python-2.7><mxnet>","2017-03-17 11:05:30","","0","6710371","2017-04-10 14:43:13","1","3","","","6710371","15","1","0"
"42414595","<p>Learning rate is the key to the effect of my network.
When I define lr = 0.05, the train/validation-accuracy oscillate severely, however lr = 0.025 I cann't get any effect until Epoch[30].
So I remember the adapted learning rate in caffe, at first I choose a base lr = 0.1, as training going on, lr decays to 0.05, then 0.025 and smaller.
Does MxNet have this strategy, How can I use it?</p>
","<mxnet>","2017-02-23 11:32:15","","3","7610696","2017-02-26 00:13:50","1","0","","","7610696","18","0","0"
"51309178","<p>I want to create a recordio format dataset by using the custom images and use it for building a ml model. 
Is there any way to create the recordio format?</p>
","<machine-learning><build><model><dataset><mxnet>","2018-07-12 15:13:23","","0","9968859","2018-07-31 05:36:24","2","0","","","9968859","14","0","0"
"52381275","<p>After installing below packages on Windows 8.1 CPU 64-bit using conda command: ""conda install mxnet"", I am getting error (OSError: [WinError 126] The specified module could not be found) while importing mxnet library. </p>

<p><strong>Packages installed:</strong> </p>

<pre><code>_mutex_mxnet: 0.0.40-mkl
libmxnet:     1.2.1-mkl_h0aaf724_1
mxnet:        1.2.1-h8cc8929_0
py-mxnet:     1.2.1-py36hcd68555_0
</code></pre>

<p>Also, popup window <a href=""https://i.stack.imgur.com/SKSm6.png"" rel=""nofollow noreferrer"">OS error</a>
appears while executing the import command with OS error description: ""The program can't start because tiff.dll is missing from your computer.</p>

<p>Please note that tiff.dll file is already present in my folder ""C:\Users\XX\AppData\Local\Continuum\anaconda3\pkgs\libtiff-4.0.9-hb8ad9f9_1\Library\bin"" and have also tried re-installing the mxnet package but unfortunately problem is still not solved. 
Also, i already tried to searched similar issue on stackflow but couldn't find any relevant solution. Kindly help to resolve the issue.</p>

<p>PFB my code and error message.</p>

<pre><code>from __future__ import print_function
import numpy as np
import mxnet as mx
from mxnet import nd, autograd, gluon

---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
&lt;ipython-input-32-4901168cc2e7&gt; in &lt;module&gt;()
      1 from __future__ import print_function
      2 import numpy as np
----&gt; 3 import mxnet as mx
      4 from mxnet import nd, autograd, gluon

~\AppData\Local\Continuum\anaconda3\lib\site-packages\mxnet\__init__.py in &lt;module&gt;()
     23 
     24 from .context import Context, current_context, cpu, gpu
---&gt; 25 from . import engine
     26 from .base import MXNetError
     27 from . import base

~\AppData\Local\Continuum\anaconda3\lib\site-packages\mxnet\engine.py in &lt;module&gt;()
     21 
     22 import ctypes
---&gt; 23 from .base import _LIB, check_call
     24 
     25 

~\AppData\Local\Continuum\anaconda3\lib\site-packages\mxnet\base.py in &lt;module&gt;()
    111 __version__ = libinfo.__version__
    112 # library instance of mxnet
--&gt; 113 _LIB = _load_lib()
    114 
    115 # type definitions

~\AppData\Local\Continuum\anaconda3\lib\site-packages\mxnet\base.py in _load_lib()
    103     """"""Load library by searching possible path.""""""
    104     lib_path = libinfo.find_lib_path()
--&gt; 105     lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
    106     # DMatrix functions
    107     lib.MXGetLastError.restype = ctypes.c_char_p

~\AppData\Local\Continuum\anaconda3\lib\ctypes\__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error)
    346 
    347         if handle is None:
--&gt; 348             self._handle = _dlopen(self._name, mode)
    349         else:
    350             self._handle = handle

OSError: [WinError 126] The specified module could not be found
</code></pre>
","<neural-network><deep-learning><jupyter-notebook><python-3.6><mxnet>","2018-09-18 07:36:49","","0","10378802","2018-10-28 15:46:17","2","0","","","10378802","1","0","0"
"55981463","<p>this is the code:</p>

<pre><code>import mxnet
from mxnet import io, gluon, autograd
from mxnet.gluon import nn
from mxnet.gluon.data import ArrayDataset
ctx =  mxnet.gpu() if mxnet.test_utils.list_gpus() else mxnet.cpu()

iter = io.CSVIter(data_csv=""data/housing.csv"", batch_size=100, data_shape=(10, ))


loss = gluon.loss.L2Loss()
net = nn.Sequential()
net.add(nn.Dense(1))
net.initialize(mxnet.init.Normal(sigma=0.01), ctx=ctx)
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.001})

for (i, iter_data) in enumerate(iter):
    data = iter_data.data[0]
    label_data = data[:, 8]
    train_data = data[:, 3]
    with autograd.record():
        l = loss(net(train_data), label_data)
    l.backward()
    trainer.step(100)
    print(l.mean().asnumpy())
</code></pre>

<p>the data is USA's housing price, data is like these:</p>

<blockquote>
  <p>-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,452600.0,NEAR BAY
  -122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014,358500.0,NEAR BAY
  -122.24,37.85,52.0,1467.0,190.0,496.0,177.0,7.2574,352100.0,NEAR BAY
  -122.25,37.85,52.0,1274.0,235.0,558.0,219.0,5.6431,341300.0,NEAR BAY
  -122.25,37.85,52.0,1627.0,280.0,565.0,259.0,3.8462,342200.0,NEAR BAY
  -122.25,37.85,52.0,919.0,213.0,413.0,193.0,4.0368,269700.0,NEAR BAY
  -122.25,37.84,52.0,2535.0,489.0,1094.0,514.0,3.6591,299200.0,NEAR BAY
  -122.25,37.84,52.0,3104.0,687.0,1157.0,647.0,3.12,241400.0,NEAR BAY
  -122.26,37.84,42.0,2555.0,665.0,1206.0,595.0,2.0804,226700.0,NEAR BAY
  -122.25,37.84,52.0,3549.0,707.0,1551.0,714.0,3.6912,261100.0,NEAR BAY
  -122.26,37.85,52.0,2202.0,434.0,910.0,402.0,3.2031,281500.0,NEAR BAY
  -122.26,37.85,52.0,3503.0,752.0,1504.0,734.0,3.2705,241800.0,NEAR BAY</p>
</blockquote>

<p>the result is what confusing me:</p>

<blockquote>
  <p>[1.4657609e+10] 
  [2.184351e+17] 
  [7.357278e+24] 
  [1.0737887e+32] 
  [nan]
  [nan]
  ...</p>
</blockquote>

<p>So what's wrong with my code?</p>

<p>====================UPDATE==================================================
Using zscore to normalize the feature array, but didn't help(forgive my laziness to using numpy's function to calculate the zscore)</p>

<pre><code>import mxnet
import numpy as np
from mxnet import io, gluon, autograd, nd
from mxnet.gluon import nn
from mxnet.gluon.data import ArrayDataset
ctx =  mxnet.gpu() if mxnet.test_utils.list_gpus() else mxnet.cpu()

BATCH_SIZE = 100

iter = io.CSVIter(data_csv=""data/housing.csv"", batch_size=BATCH_SIZE, data_shape=(10, ))


loss = gluon.loss.L2Loss()
net = nn.Sequential()
net.add(nn.Dense(1))
net.initialize(mxnet.init.Normal(sigma=0.01), ctx=ctx)
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.001})

for (i, iter_data) in enumerate(iter):
    data = iter_data.data[0]
    label_data = data[:, 8]
    train_data = data[:, 3]
    train_data_np = train_data.asnumpy()
    stand = np.std(train_data_np)
    mean = np.mean(train_data_np)
    b = (train_data_np - mean) / stand
    train_data = nd.array(b)
    with autograd.record():
        l = loss(net(train_data), label_data)
    l.backward()
    trainer.step(BATCH_SIZE)
    print(l.mean().asnumpy())
</code></pre>
","<deep-learning><mxnet>","2019-05-04 10:07:42","","0","209403","2019-05-04 11:47:49","0","0","","","209403","341","6","0"
"46154642","<p>I tried the tutorial for image recognition in R using the MXNet package <a href=""https://www.r-bloggers.com/image-recognition-tutorial-in-r-using-deep-convolutional-neural-networks-mxnet-package"" rel=""nofollow noreferrer"">https://www.r-bloggers.com/image-recognition-tutorial-in-r-using-deep-convolutional-neural-networks-mxnet-package</a> . The aim of the tutorial is to recognize faces of 40 persons. The dataframe consists of 400 pictures (10 pictures per person). The CNN looks like this:</p>

<pre><code>data &lt;- mx.symbol.Variable('data')
# 1st convolutional layer
conv_1 &lt;- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 &lt;- mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 &lt;- mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel =    c(2, 2), stride = c(2, 2))

# 2nd convolutional layer
conv_2 &lt;- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 &lt;- mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 &lt;- mx.symbol.Pooling(data=tanh_2, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))

# 1st fully connected layer
flatten &lt;- mx.symbol.Flatten(data = pool_2)
fc_1 &lt;- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 &lt;- mx.symbol.Activation(data = fc_1, act_type = ""tanh"")

# 2nd fully connected layer
fc_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
# Output. Softmax output since we'd like to get some probabilities.
NN_model &lt;- mx.symbol.SoftmaxOutput(data = fc_2)
</code></pre>

<p>I used the same neuronal network for my own dataset, which consists of 1600 pictures of 5 persons. So I adjusted the number of nodes in the fully connected layer to 5.</p>

<pre><code>fc_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 5)
</code></pre>

<p>The results of the model are very bad, so I set ceteris paribus the number of nodes in the fully connected layer to 80 and got great results (accurancy: 100%).</p>

<pre><code>fc_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 80)
</code></pre>

<p>The model generates probabilities for 80 categories although I only got 5, but the accurancy is excellent. I don’t understand this event.
I tried to add a third fully connected layer to get the right number of catgories:</p>

<pre><code># 2nd fully connected layer
fc_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 80)
tanh_4 &lt;- mx.symbol.Activation(data = fc_2, act_type = ""tanh"")
# 3rd fully connected layer
fc_3 &lt;- mx.symbol.FullyConnected(data = tanh_4, num_hidden = 5)
# Output. Softmax output since we'd like to get some probabilities.
NN_model &lt;- mx.symbol.SoftmaxOutput(data = fc_3)
</code></pre>

<p>But the results are very bad. I thought the number of nodes in the fully connected layer represents the number of output categories which the model should try to distinguish.</p>

<ol>
<li>Is anyone possible to explain this event?</li>
<li>Does the number of hidden nodes in the fully connected layer has to be equal to the number of output categories?</li>
</ol>

<p>Thanks for your help.</p>
","<r><nodes><mxnet>","2017-09-11 11:28:45","","0","8591115","2017-09-18 09:17:20","2","0","","","8591115","11","0","0"
"55769986","<p>I am new to mxnet, I am trying to do this code:</p>

<pre><code>from mxnet import nd, sym
from mxnet.gluon import nn

class HybridNet(nn.HybridBlock):
    def __init__(self, **kwargs):
         super(HybridNet, self).__init__(**kwargs)
         self.hidden = nn.Dense(10)
         self.output = nn.Dense(2)

    def hybrid_forward(self, F, x):
         print('F: ', F)
         print('x: ', x.shape)

         x = F.relu(self.hidden(x))
         print('hidden: ', x.shape)

         x = F.relu(self.hidden(x))
         print('hidden: ', x.shape)

    return self.output(x)


    net = HybridNet()

    net.initialize()

    x = nd.random.normal(shape=(1, 4))
    net(x)
</code></pre>

<p>however, it got this error:
MXNetError: Shape inconsistent, Provided = [10,4], inferred shape=(10,10)</p>

<p>but if I change self.hidden = nn.Dense(10) to self.hidden = nn.Dense(4), the error would not exist any more.
but I cannot understand why, anyone could explain this to me?
thank you</p>
","<python><mxnet>","2019-04-20 03:28:00","","0","8764940","2019-04-20 03:28:00","0","0","","","8764940","21","4","0"
"55539565","<p>I tried to create some very basic mxnet code that should only initialize a variable and output the same.</p>

<p>The issue is, I can't get the initialization done.</p>

<p>I pass the initializer as parameter to Variable as indicated in the <a href=""https://mxnet.apache.org/api/python/symbol/symbol.html#mxnet.symbol.var"" rel=""nofollow noreferrer"">mxnet docs</a> </p>

<p>I already tried to use different initializers like Xavier, One, Uniform but all results are the same [0,0,0,0] output.</p>

<pre class=""lang-py prettyprint-override""><code>import mxnet as mx
cst = mx.init.Constant(value=2)
a = mx.sym.Variable('A', init=cst)
executor = a.simple_bind(ctx=mx.cpu(), A=(1,4))
executor.forward()
</code></pre>

<p>Output:</p>

<pre><code> [[ 0.  0.  0.  0.]]
 &lt;NDArray 1x4 @cpu(0)&gt;]
</code></pre>

<p>However I would expect the output to be [2, 2, 2, 2]</p>

<p>Any idea about what's going on here is most welcome.</p>
","<variables><binding><initialization><symbols><mxnet>","2019-04-05 16:14:29","","0","11318051","2019-04-11 21:34:24","1","0","","","11318051","1","0","0"
"55508457","<p>I am trying to build MXNET from this repo <a href=""https://github.com/mahyarnajibi/SNIPER/tree/cvpr3k"" rel=""nofollow noreferrer"">https://github.com/mahyarnajibi/SNIPER/tree/cvpr3k</a>. I have cuda, cudnn, and openblas installed. I build the code with the following command: <code>make  -j 8 USE_CUDA_PATH=/usr/local/cuda</code></p>

<p>The error message is as follows:</p>

<pre><code>/usr/local/lib/libopenblas.so: undefined reference to `_gfortran_concat_string'
/usr/local/liblibopenblas.so: undefined reference to `_gfortran_etime'
collect2: error: ld returned 1 exit status
Makefile:454: recipe for target 'bin/im2rec' failed
make: *** [bin/im2rec] Error 1
make: *** Waiting for unfinished jobs....
</code></pre>

<p>My config.mk file has these settings for some relevant (i think) variables:</p>

<pre><code>ADD_LDFLAGS=
ADD_CFLAGS=
USE_CUDA=1
USE_CUDNN=1
USE_OPENCV=1
USE_BLAS=openblas
USE_LAPACK=1
</code></pre>
","<fortran><gfortran><mxnet><openblas>","2019-04-04 05:27:06","","0","11201897","2019-04-11 21:09:19","1","3","","","11201897","3","0","0"
"47380174","<p>I'm trying to translate code from deepnet to mxnet, but I'm not sure what am I doing wrong. I'm getting an error message that says:</p>

<pre><code>""Error in nn$W[[i -1]] %*% t(post)"". 
requires numeric/complex matrix/vector arguments 
Calls: neural.predict -&gt; nn.predict -&gt; t
</code></pre>

<p>The code using deepnet (wrote by Johann C. Lotter) is:</p>

<pre><code>library('deepnet', quietly = T) 
library('caret', quietly = T)

neural.train = function(model,XY) 
{
  XY &lt;- as.matrix(XY)
  X &lt;- XY[,-ncol(XY)]
  Y &lt;- XY[,ncol(XY)]
  Y &lt;- ifelse(Y &gt; 0,1,0)
  Models[[model]] &lt;&lt;- sae.dnn.train(X,Y,
      hidden = c(30,30,30), 
      activationfun = ""tanh"", 
      learningrate = 0.5, 
      momentum = 0.5, 
      learningrate_scale = 1.0, 
      output = ""sigm"", 
      sae_output = ""linear"", 
      numepochs = 100, 
      batchsize = 100,
      hidden_dropout = 0, 
      visible_dropout = 0)
}

neural.predict = function(model,X) 
{
  if(is.vector(X)) X &lt;- t(X)
  return(nn.predict(Models[[model]],X))
}

neural.save = function(name)
{
  save(Models,file=name)  
}

neural.init = function()
{
  set.seed(365)
  Models &lt;&lt;- vector(""list"")
}
</code></pre>

<p>And for the mxnet translation I'm changing the neural train with:</p>

<pre><code>library('mxnet', quietly = T) 

neural.train = function(model,XY) 
{
  XY &lt;- as.matrix(XY)
  X &lt;- XY[,-ncol(XY)]
  Y &lt;- XY[,ncol(XY)]
  Y &lt;- ifelse(Y &gt; 0,1,0)
  Models[[model]] &lt;&lt;- mx.mlp(X,Y,
      hidden_node = c(30,30,30), 
      activation = ""relu"", 
      momentum = 0.9, 
      learning.rate = 0.07, 
      out_activation = ""softmax"",
      num_round = 100,
      out_node = 2,
      array.batch.size = 100)
}
</code></pre>

<p>I don't get what am I doing wrong..</p>
","<r><machine-learning><neural-network><mxnet>","2017-11-19 18:02:23","","0","8745371","2018-11-06 00:44:09","1","0","","","8745371","49","19","0"
"47963978","<pre><code> import graphlab as gl
 from graphlab import mxnet as mx

# Define the network symbol, equivalent to linear regression
 net = mx.symbol.Variable('data')
 net = mx.symbol.FullyConnected(data=net, name='fc1', num_hidden=1)
 net = mx.symbol.LinearRegressionOutput(data=net, name='lr')

# Load data into SFrame and normalize features
 sf = gl.SFrame.read_csv('https://static.turi.com/datasets/regression/houses.csv')
 features = ['tax', 'bedroom', 'bath', 'size', 'lot']
 for f in features:
    sf[f] = sf[f] - sf[f].mean()
    sf[f] = sf[f] / sf[f].std()

# Prepare the input iterator from SFrame
# `data_name` must match the first layer's name of the network.
# `label_name` must match the last layer's name plus ""_label"".
 dataiter = mx.io.SFrameIter(sf, data_field=features, label_field='price',
                        data_name='data', label_name='lr_label',
                        batch_size=1)

# Train the network
 model = mx.model.FeedForward.create(symbol=net, X=dataiter, num_epoch=20,
                                learning_rate=1e-2,
                                eval_metric='rmse')

# Make prediction
 model.predict(dataiter)
</code></pre>

<p><a href=""https://i.stack.imgur.com/i7tAG.jpg"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>I have written few lines of code to predict a parameter in my dataset, but it only gives RMSE for train data as shown in picture. What would be a way around that it shows RMSE for test data? <code>model.evaluate(dataiter)</code> does not work, help needed</p>
","<python><deep-learning><ipython><jupyter-notebook><mxnet>","2017-12-24 20:59:12","","0","9137182","2018-02-24 00:49:19","1","2","","","9137182","1","0","0"
"52687728","<p>When I import mxnet package in PyChram,</p>

<p>I met an OSError which I've never met before,</p>

<p>and I don't know how to solve it.</p>

<p>Here's the error information:</p>

<p>Traceback (most recent call last):</p>

<pre><code>File ""D:/PycharmProjects/LinearRegression/demo/pikachu_detection.py"", line 1, in &lt;module&gt;
    from mxnet import image
File ""D:\Anaconda3\lib\site-packages\mxnet\__init__.py"", line 25, in &lt;module&gt;
    from . import engine
File ""D:\Anaconda3\lib\site-packages\mxnet\engine.py"", line 23, in &lt;module&gt;
    from .base import _LIB, check_call
File ""D:\Anaconda3\lib\site-packages\mxnet\base.py"", line 113, in &lt;module&gt;
    _LIB = _load_lib()
File ""D:\Anaconda3\lib\site-packages\mxnet\base.py"", line 105, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
File ""D:\Anaconda3\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
</code></pre>

<p>Wait for your answers.</p>
","<pycharm><importerror><mxnet>","2018-10-07 10:45:44","","0","10468591","2018-10-08 19:58:33","1","0","","","10468591","1","0","0"
"41657841","<p>I'd like to reproduce a recurrent neural network where each time layer is followed by a dropout layer, and these dropout layers share their masks. This structure was described in, among others, <a href=""https://arxiv.org/abs/1512.05287"" rel=""nofollow noreferrer"">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>.</p>

<p>As far as I understand the code, the recurrent network models implemented in MXNet do not have any dropout layers applied between time layers; the <code>dropout</code> parameter of functions such as <code>lstm</code> (<a href=""https://github.com/dmlc/mxnet/blob/master/R-package/R/lstm.R#L4"" rel=""nofollow noreferrer"">R API</a>, <a href=""https://github.com/dmlc/mxnet/blob/master/example/rnn/lstm.py#L19"" rel=""nofollow noreferrer"">Python API</a>) actually defines dropout on the input. Therefore I'd need to reimplement these functions from scratch.</p>

<p>However, the Dropout layer does not seem to take a variable that defines mask as a parameter.</p>

<p>Is it possible to make multiple dropout layers in different places of the computation graph, yet sharing their masks?</p>
","<python><r><neural-network><recurrent-neural-network><mxnet>","2017-01-15 04:29:09","","0","42610","2018-01-08 07:42:08","1","0","","","42610","29001","897","29"
"47783181","<p>I am using BucketingModule for training multiple small models/bots together. Here, the bucket key is <code>bot_id</code>. However, each bot has separate set of target labels/classes (and hence, different size of softmax layer for each bot).</p>

<p>Is there any way to train such a model in mxnet, where I want to share the weights for all the layers but one (softmax) among all the bots?</p>

<p>How would I initialize such a model using <code>sym_gen</code> method?
If in the <code>sym_gen</code> method, for the Softmax layer I specify the <code>num_hidden=size_dict[bot]</code> i.e.,</p>

<pre><code>pred = mx.sym.FullyConnected(data=pred, num_hidden=len(size_dict[bot]), name='pred')
pred = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')
</code></pre>

<p>I get the error:</p>

<blockquote>
  <p>Inferred shape does not match shared_exec.arg_array's shape</p>
</blockquote>

<p>which makes sense as each bot has different number of target classes.</p>
","<mxnet><softmax>","2017-12-12 23:22:39","","1","9091302","2018-03-03 00:18:21","1","0","","","9091302","8","0","0"
"39004708","<p>Does anybody know where can I find an example of LSTM via MXNet (R package)? The basic task is prediction of x[t + 1] value by x[1 ... t] sequence.</p>
","<r><deep-learning><lstm><mxnet>","2016-08-17 19:23:41","","8","6561592","2019-04-07 00:42:27","1","0","1","","6561592","48","1","0"
"40738722","<p>I am trying to analyze a time series in R using convolutional neural network function provided in the mxnet package. Please let me know 
1) What should be the value of num.filter in mx.symbol.Convolution? 
2) What changes are to be done in the code <a href=""http://tjo-en.hatenablog.com/entry/2016/03/30/233848"" rel=""nofollow noreferrer"">here</a>, so that it becomes fit for 1D CNN (Time Series)? </p>

<p>Reference: <a href=""http://mxnet.io/api/r/mxnet-r-reference-manual.pdf"" rel=""nofollow noreferrer"">http://mxnet.io/api/r/mxnet-r-reference-manual.pdf</a></p>
","<r><time-series><mxnet>","2016-11-22 09:56:21","","0","7193655","2016-11-23 00:14:21","1","0","","","7193655","1","0","0"
"55948882","<p>I have trained an object detection model on AWS Sagemaker. I want to use this model locally in my machine. I downloaded this model which consist of 3 files hyperparams.json, model-symbol.json, and model-0000.params. I have seen plenty of tutorials to deploy object classification model locally but didn’t get any for object detection.</p>
","<amazon-web-services><object-detection><mxnet><amazon-sagemaker>","2019-05-02 08:57:18","","0","5717918","2019-05-04 00:43:54","2","0","","","5717918","4","0","0"
"42290860","<p>In installation guide...</p>

<p>3.Download the MXNet package as a .zip file from the MXNet Github repository and unpack it. You will be editing the ""/mxnet/R-package"" folder.  </p>

<p>-> OK, I downloaded 'mxnet-master.zip', and found 'R-Package' folder.</p>

<p>4.Download the most recent GPU-enabled MXNet package from the Releases tab. Unzip this file and navigate to the /nocudnn folder. Note: You will copy some of these extracted files into MXNet’s R-package folder. We are now working two folders, R-package/ and nocudnn/.</p>

<p>-> in my case, 
I downloaded 'mxnet-0.9.3.zip', 
The 'nocudnn' folder could not be found.  </p>

<p>What mistake did I make ? </p>
","<r><install><gpu><mxnet>","2017-02-17 06:28:09","","0","7578164","2017-06-13 23:17:51","1","0","","","7578164","1","0","0"
"55719096","<p>When we use mxnet's BatchNorm layer, input layer doesn't have gradient in backward.However,it has gradient while network is created without BatchNorm layer.</p>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=False</code> 
The input layer <em>has</em> gradient. </p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=True</code><br>
The input layer <em>has</em> gradient. </p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.sym.BatchNorm(data=x, fix_gamma=False, eps=2e-5, momentum=0.9, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=False</code>  </p>

<p>The input layer <em>doesn't</em> have gradient. </p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.sym.BatchNorm(data=x, fix_gamma=True, eps=2e-5, momentum=0.9, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=False</code> </p>

<p>The input layer <em>doesn't</em> have gradient.</p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.sym.BatchNorm(data=x, fix_gamma=True, eps=2e-5, momentum=0.9, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=True</code><br>
The input layer <em>doesn't</em> have gradient</p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.sym.BatchNorm(data=x, fix_gamma=False, eps=2e-5, momentum=0.9, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=True</code>  </p>

<p>The input layer <em>doesn't</em> have gradient</p>

<hr>

<p>There are gradients in these networks.</p>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=False</code><br>
The input layer <em>has</em> gradient. </p>

<hr>

<pre><code>x = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx')
y = mx.symbol.FullyConnected(data=x, num_hidden=256, name='gx0')
</code></pre>

<p>Forward parameter:<code>is_train=True</code> 
The input layer <em>has</em> gradient </p>

<hr>
","<python><gradient><backwards-compatibility><mxnet><batch-normalization>","2019-04-17 02:36:43","","-1","11371469","2019-04-17 03:08:52","0","1","","","11371469","1","0","0"
"49601077","<p>I'm using Mxnet to train a XOR neural network, but the losses don't go down, they are always above 0.5. </p>

<p>Below is my code in Mxnet 1.1.0; Python 3.6; OS X El Capitan 10.11.6</p>

<p>I tried 2 loss functions - squared loss and softmax loss, both didn't work.</p>

<pre><code>from mxnet import ndarray as nd
from mxnet import autograd
from mxnet import gluon
import matplotlib.pyplot as plt

X = nd.array([[0,0],[0,1],[1,0],[1,1]])
y = nd.array([0,1,1,0])
batch_size = 1
dataset = gluon.data.ArrayDataset(X, y)
data_iter = gluon.data.DataLoader(dataset, batch_size, shuffle=True)

plt.scatter(X[:, 1].asnumpy(),y.asnumpy())
plt.show()

net = gluon.nn.Sequential()
with net.name_scope():
    net.add(gluon.nn.Dense(2, activation=""tanh""))
    net.add(gluon.nn.Dense(1, activation=""tanh""))
net.initialize()

softmax_cross_entropy = gluon.loss.SigmoidBCELoss()#SigmoidBinaryCrossEntropyLoss()
square_loss = gluon.loss.L2Loss()
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.3})

train_losses = []

for epoch in range(100):
    train_loss = 0
    for data, label in data_iter:
        with autograd.record():
            output = net(data)
            loss = square_loss(output, label)
        loss.backward()
        trainer.step(batch_size)

        train_loss += nd.mean(loss).asscalar()
    train_losses.append(train_loss)

plt.plot(train_losses)
plt.show()
</code></pre>
","<python><machine-learning><neural-network><perceptron><mxnet>","2018-04-01 18:04:20","","3","2014948","2018-12-15 20:52:09","1","2","1","","2014948","161","41","1"
"41164370","<p>I'm trying to follow the <strong>Text Classification Tutorial</strong> on <a href=""http://mxnet.io/tutorials/nlp/cnn.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/nlp/cnn.html</a> </p>

<p>Until I call the function:</p>

<pre><code>conv_input = mx.sym.Reshape(data=embed_layer, target_shape=(batch_size, 1, sentence_size, num_embed))
</code></pre>

<p>everything goes well. But then I get the error:</p>

<blockquote>
  <p>conv_input = mx.sym.Reshape(data=embed_layer, target_shape=(batch_size, 1, sentence_size, num_embed))</p>
  
  <p>Traceback (most recent call last):
    File """", line 1, in 
    File ""C:\Users\my.name\Downloads\WinPython-64bit-2.7.10.3\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\symbol.py"", line 1062, in creator
      ctypes.byref(sym_handle)))
    File ""C:\Users\my.name\Downloads\WinPython-64bit-2.7.10.3\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\base.py"", line 77, in check_call
      raise MXNetError(py_str(_LIB.MXGetLastError()))
  mxnet.base.MXNetError: Invalid Parameter format for target_shape expect Shape(tuple) but value='(50, 1, 56L, 300)'</p>
</blockquote>

<p>Does anyone have an idea, How to make this work?</p>
","<python><convolution><text-classification><mxnet>","2016-12-15 12:37:56","","1","3452787","2016-12-19 17:38:27","1","1","","2016-12-19 18:53:02","3452787","64","4","0"
"41852885","<p>I have used R and MXNET and I see that the version of MXNET from the repo is 0.7</p>

<p>I've built 0.93 from Git and I succeded. (adding lots of dependencies and missing libraries.</p>

<p>But the thing is that it did not create ""mxnet.dll"" for R</p>

<p>The only output I get is ""libmxnet.dll"" and R is not loading it. I believe the old mxnet.dll is not going to work with the new libmxnet.dll</p>
","<r><build><mxnet>","2017-01-25 13:29:41","","2","7432103","2017-06-16 18:31:19","1","4","1","","7432103","25","0","0"
"55931620","<p>I am trying to use amazon sagemaker linear-learner algorithm, it support content type of ‘application/x-recordio-protobuf’. In preprocessing phase, i used scikit-learn preprocessing to one-hot-encode my features. Then i use linear learner estimator to with record-io converted input data.</p>

<p>I used package and the preprocess conversion was successful.</p>

<p><code>from sagemaker.amazon.common import write_spmatrix_to_sparse_tensor</code></p>

<pre class=""lang-py prettyprint-override""><code>def output_fn(prediction, accept):
    """"""Format prediction output

    The default accept/content-type between containers for serial inference is JSON.
    We also want to set the ContentType or mimetype as the same value as accept so the next
    container can read the response payload correctly.
    """"""
   if accept == 'text/csv':
        return worker.Response(encoders.encode(prediction.todense(), accept), mimetype=accept)
    elif accept == 'application/x-recordio-protobuf':
        buf = BytesIO()
        write_spmatrix_to_sparse_tensor(buf, prediction)
        buf.seek(0)
        return worker.Response(buf, accept, mimetype=accept)
    else:
        raise RuntimeError(""{} accept type is not supported by this script."".format(accept))
</code></pre>

<p>But when linear-learner takes the input record, it fails with the error below</p>

<p>Caused by: [15:53:30] /opt/brazil-pkg-cache/packages/AIAlgorithmsCppLibs/AIAlgorithmsCppLibs-2.0.774.0/AL2012/generic-flavor/src/src/aialgs/io/iterator_base.cpp:100:</p>

<p><code>(Input Error) The header of the MXNet RecordIO record at position 810 in the dataset does not start with a valid magic number.</code></p>
","<scikit-learn><protocol-buffers><linear-regression><mxnet><amazon-sagemaker>","2019-05-01 04:28:48","","1","2653683","2019-05-01 04:28:48","0","1","","","2653683","16","0","0"
"52374332","<p>I'm in the process of building a content recommendation model using MXNet. Despite being ~10K rows, out of memory issues are thrown with CPU and GPU contexts in MXNet. The current code is below.</p>

<p>```</p>

<pre><code>import mxnet as mx
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

df = pd.read_csv(""df_text.csv"")

tf = TfidfVectorizer(analyzer = ""word"",
        ngram_range = (1,3),
        min_df = 2,
        stop_words=""english"")

tfidf_matrix = tf.fit_transform(df[""text_column""])

mx_tfidf = mx.nd.array(tfidf_matrix, ctx=mx.gpu())

# Out of memory error occurs here.  
cosine_similarities = mx.ndarray.dot(mx_tfidf, mx_tfidf.T)
</code></pre>

<p>```</p>

<p>I'm aware that the dot product is a sparse matrix multiplied by a dense matrix, which may be part of the issue. This said, would the dot product have to be calculated across multiple GPU's, in order to prevent out of memory issues?</p>
","<python-3.x><numpy><recommendation-engine><tf-idf><mxnet>","2018-09-17 19:12:27","","0","4317871","2018-09-18 02:42:26","1","1","","","4317871","19","0","0"
"51985691","<p>I have used the resnet-binary model in BMXnet to train my own data, but get float weights not binary weights. Why?</p>

<p><strong>The parameter of the network</strong></p>

<p><a href=""https://i.stack.imgur.com/rugfL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rugfL.png"" alt=""enter image description here""></a></p>

<p><strong>Load the trained model and use <code>model.get_params()</code></strong></p>

<p><a href=""https://i.stack.imgur.com/x6J4l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/x6J4l.png"" alt=""enter image description here""></a></p>
","<python-3.x><mxnet><resnet>","2018-08-23 12:20:21","","0","10264667","2018-10-31 21:06:04","1","1","","","10264667","1","0","0"
"49430560","<p>I try to learn how to use customized loss function with mxnet.</p>

<p>Bellow is a minimal (not) working example of linear regression. 
When I set 'use_custom = False' everything work fine, rather than custom loss wan't work. What I'm doing wrong? </p>

<pre><code>import mxnet as mx
import logging
logging.basicConfig(level='DEBUG')

use_custom = False

mx.random.seed(1)

A =  mx.nd.random.uniform(-1, 1, (5, 1))
B =  mx.nd.random.uniform(-1, 1)

X = mx.nd.random.uniform(-1, 1, (100, 5))
y = mx.nd.dot(X, A) + B

iter = mx.io.NDArrayIter(data=X, label=y, data_name='data', label_name='label', batch_size=20, shuffle=True)

data  = mx.sym.Variable('data')
label = mx.sym.Variable('label')

net = mx.sym.FullyConnected(data, num_hidden=1)
if use_custom:
    net = mx.sym.MakeLoss(mx.sym.square(net - label))
else:
    net = mx.sym.LinearRegressionOutput(net, label=label)

mod = mx.mod.Module(net, label_names=('label',))
mod.fit(iter, num_epoch=50, eval_metric='mse', optimizer='adam')
</code></pre>
","<mxnet>","2018-03-22 13:57:34","","1","2900180","2018-03-22 18:51:54","1","0","","","2900180","578","26","6"
"49873467","<p>In numpy, one can append an element to an array by using np.append().</p>

<p>But though numpy and mxnet arrays are supposed to be sumilar, there is not append() function in NDArray class.</p>

<p>Update(18/04/24): 
Thanks Thom. In fact, what I tried to achieve is this in numpy :</p>

<pre><code>import numpy as np
np_a1 = np.empty((0,3), int)
np_a1 = np.append(np_a1, np.array([[1,2,3],[4,5,6]]), axis=0)
np_a1 = np.append(np_a1, np.array([[7,8,9]]), axis=0)
print(""\nnp_a1:\n"", np_a1)
print(np_a1.shape)
</code></pre>

<p>Thanks to you answer, I did that :</p>

<pre><code>import mxnet as mx
nd_a1 = mx.nd.array([[0, 0, 0]])
# nd_a1 = mx.nd.empty((0,3))
nd_a1 = mx.nd.concat(nd_a1, mx.nd.array([[1,2,3],[4,5,6]]), dim=0)
nd_a1 = mx.nd.concat(nd_a1, mx.nd.array([[7, 8, 9]]), dim=0)
print(""\nnd_a1"", nd_a1)
print(nd_a1.shape)
</code></pre>

<p>But I can't figure out how to start from an empty nd array.
Starting from :</p>

<pre><code>nd_a1 = mx.nd.empty((0,3))
</code></pre>

<p>does not work</p>
","<mxnet><numpy-ndarray>","2018-04-17 08:39:09","","1","3131604","2018-04-24 02:20:42","1","0","","","3131604","1678","45","1"
"40571097","<p>I'm following the documentation in <a href=""http://mxnet.io/how_to/new_op.html"" rel=""nofollow noreferrer"">http://mxnet.io/how_to/new_op.html</a> for how to define a new neural network layer in MXNet in python by subclassing the<code>mx.operator.CustomOp</code> class.  The example is of a loss layer that has no learned parameters.  So how do the learned parameters get into the <code>forward</code> and <code>backward</code> methods?  </p>
","<neural-network><deep-learning><mxnet>","2016-11-13 06:08:23","","1","303056","2016-11-21 18:07:52","1","0","1","","303056","26323","4114","191"
"52971674","<p>I am looking into using MXNet LSTM modelling for time-series analysis for a problem i am currently working on.</p>

<p>As a way of understanding how to implement this, I am following the example code given by xnNet from the link: <a href=""https://mxnet.incubator.apache.org/tutorials/r/MultidimLstm.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/tutorials/r/MultidimLstm.html</a> </p>

<p>When running this script after downloading the necessary data to my local source, i am able to execute the code fine until i get to the following section to train the model:</p>

<pre><code>## train the network
system.time(model &lt;- mx.model.buckets(symbol = symbol, 
                                  train.data = train.data, 
                                  eval.data = eval.data,
                                  num.round = 100, 
                                  ctx = ctx, 
                                  verbose = TRUE, 
                                  metric = mx.metric.mse.seq, 
                                  initializer = initializer,
                                  optimizer = optimizer, 
                                  batch.end.callback = NULL, 
                                  epoch.end.callback = epoch.end.callback))
</code></pre>

<p>When running this section, the following error occurs once gaining connection to the API.</p>

<pre><code> Error in mx.nd.internal.as.array(nd) : 
 [14:22:53] c:\jenkins\workspace\mxnet\mxnet\src\operator\./rnn-inl.h:359: 
 Check failed: param_.p == 0 (0.2 vs. 0) Dropout is not supported at the moment. 
</code></pre>

<p>Is there currently a problem internally within the XNNet R package which is unable to run this code? I can't imagine they would provide a tutorial example for the package that is not executable.</p>

<p>My other thought is that it is something to do with my local device execution and connection to the API. I haven't been able to find any information about this being a problem for other users though.</p>

<p>Any inputs or suggestions would be greatly appreciated thanks.</p>
","<r><deep-learning><time-series><lstm><mxnet>","2018-10-24 14:35:03","","1","7425051","2019-02-06 19:28:42","1","0","1","","7425051","28","2","0"
"50201065","<p>I am new to MXNet and have been experimenting with model parallelism. I found this nice post: <a href=""https://stackoverflow.com/questions/47029809/simple-example-of-mxnet-model-parallelism"">simple example of mxnet model parallelism</a></p>

<p>and modified the code to use HybridBlock as follows:</p>

<pre><code>import numpy as np
import mxnet as mx
from mxnet import nd, autograd, gluon
from mxnet.gluon import HybridBlock

num_inputs = 2
num_outputs = 1
num_examples = 10000


def real_fn(x):
    return 2 * x[:, 0] - 3.4 * x[:, 1] + 4.2


x = np.random.normal(0, 1, (num_examples, num_inputs))
noise = 0.001 * np.random.normal(0, 1, num_examples)
y = real_fn(x) + noise
y = y.reshape(-1, 1)

hidden_layers = 2
num_gpus = hidden_layers + 1
ctxList = [mx.gpu(i) for i in range(num_gpus)]


class MyDenseBlock(HybridBlock):
    def __init__(self, layer_number, size_input, size_output, **kwargs):
        super(MyDenseBlock, self).__init__(**kwargs)

        self.layer_number = layer_number
        self.size_input = size_input
        self.size_output = size_output

        with self.name_scope():
            # add parameters to the Block's ParameterDict.
            self.weight = self.params.get(
                'weight',
                init=mx.init.Xavier(magnitude=2.24),
                shape=(size_input, size_output),
                grad_req='write')

            self.bias = self.params.get(
                'bias',
                init=mx.init.Constant(0.5),
                shape=(size_output,),
                grad_req='write')

    def hybrid_forward(self, F, x, weight, bias):
        x = x.as_in_context(ctxList[self.layer_number])
        with x.context:
            linear = F.broadcast_add(F.dot(x, weight), bias)
            return linear


net = gluon.nn.HybridSequential()
with net.name_scope():
    net.add(MyDenseBlock(0, size_input=2, size_output=2))

    for i in range(hidden_layers - 1):
        net.add(MyDenseBlock(i + 1, size_input=2, size_output=2))

    net.add(MyDenseBlock(i + 2, size_input=2, size_output=1))


print(""\ninitializing:"")
params = net.collect_params()

for i, param in enumerate(params):
    if 'mydenseblock0' in param:
        params[param].initialize(ctx=ctxList[0])

    elif 'mydenseblock1' in param:
        params[param].initialize(ctx=ctxList[1])

    elif 'mydenseblock2' in param:
        params[param].initialize(ctx=ctxList[2])

    print(""  "", i, param, ""  "", params[param].list_data()[0].context)

#net.hybridize()


def square_loss(yhat, y):
    return nd.mean((yhat - y) ** 2)


def custom_trainer(updaters, params, ignore_stale_grad=False):
    for i, param in enumerate(params):
        if params[param].grad_req == 'null':
            continue
        if not ignore_stale_grad:
            for data in params[param].list_data():
                if not data._fresh_grad:
                    print(""`%s` on context %s has not been updated"" % (params[param].name, str(data.context)))
                    assert False

        for upd, arr, grad in zip(updaters, params[param].list_data(), params[param].list_grad()):
            if not ignore_stale_grad or arr._fresh_grad:
                upd(i, grad, arr)
                arr._fresh_grad = False


batch_size = 100
epochs = 100
iteration = -1

opt = mx.optimizer.create('adam', learning_rate=0.001, rescale_grad=1 / batch_size)
updaters = [mx.optimizer.get_updater(opt)]


results = []
for e in range(epochs):
    train_groups = np.array_split(np.arange(x.shape[0]), x.shape[0] / batch_size)
    for i, idx in enumerate(train_groups):
        iteration += 1
        xtrain, ytrain = x[idx, :], y[idx]

        xtrain = nd.array(xtrain)
        xtrain = xtrain.as_in_context(ctxList[0])

        ytrain = nd.array(ytrain).reshape((-1, 1))
        ytrain = ytrain.as_in_context(ctxList[0])

        with autograd.record():
            yhat = net(xtrain)
            loss = square_loss(yhat, ytrain.as_in_context(ctxList[-1]))

        loss.backward()
        custom_trainer(updaters, net.collect_params())

        if iteration % 10 == 0:
            results.append([iteration, loss.asnumpy().item()])
            print(""epoch= {:5,d}, iter= {:6,d},  error= {:6.3E}"".format(e, iteration, loss.asnumpy().item()))
</code></pre>

<p>However, I got the following error:</p>

<pre><code>RuntimeError: Parameter 'hybridsequential0_mydenseblock1_weight' was 
not initialized on context gpu(0). It was only initialized on [gpu(1)].
terminate called recursively
terminate called after throwing an instance of 'dmlc::Error'
</code></pre>

<p>I had no problem using Blocks (as already confirmed in the post), it is just HybridBlock that's not working. Could someone please help? It seems to me that model parallelism examples are pretty scant.</p>
","<deep-learning><mxnet>","2018-05-06 14:55:36","","0","7589181","2018-05-07 18:17:12","1","0","","","7589181","11","0","0"
"45845352","<p>After upgrading to MXNet 0.11.0 I get strange errors in my old code:</p>

<p>Working with the boston housing dataset from scikit-learn:</p>

<pre><code>data = mx.sym.Variable(""data"")
y = mx.sym.Variable(""output_label"")
fc = mx.sym.FullyConnected(data=data,num_hidden=20,name='FC1')
fc = mx.sym.Activation(data=fc, act_type='relu', name='act1')
regularization_cost = regularization_cost + mx.sym.sum(mx.sym.abs(fc.get_internals()['FC1_weight']))
fc = mx.sym.FullyConnected(data=fc,num_hidden=1,name='FC2')
regularization_cost = regularization_cost + mx.sym.sum(mx.sym.abs(fc.get_internals()['FC2_weight']))
ce = l1_reg * regularization_cost + 0.5 * mx.sym.mean(mx.symbol.square(fc - y))

train_iter = mx.io.NDArrayIter(data=x_train[:-44], label=y_train[:-44][:, np.newaxis], batch_size=20, shuffle=False,
                              label_name='output_label', last_batch_handle='pad')
mod = mx.mod.Module(symbol=loss,
                context=mx.cpu(),
                data_names=['data'],
                label_names=['output_label'])
mod.fit(train_iter, num_epoch=10, batch_end_callback=f, monitor=mon)
</code></pre>

<p>This raises the following error:</p>

<pre><code>---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
~/dev/mxnet/python/mxnet/symbol.py in simple_bind(self, ctx, grad_req, type_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)
   1472                                                  shared_exec_handle,
-&gt; 1473                                                  ctypes.byref(exe_handle)))
   1474         except MXNetError as e:

~/dev/mxnet/python/mxnet/base.py in check_call(ret)
    128     if ret != 0:
--&gt; 129         raise MXNetError(py_str(_LIB.MXGetLastError()))
    130 

MXNetError: [12:45:50] src/pass/infer_shape_type.cc:112: Check failed: rshape[eid] == rshape[idx.entry_id(fnode.inputs[i])] ((1,20) vs. ()) Backward shape inconsistent with the forward shape

Stack trace returned 10 entries:
RuntimeError: simple_bind error. Arguments:
output_label: (20, 1)
data: (20, 13)
[12:45:50] src/pass/infer_shape_type.cc:112: Check failed: rshape[eid] == rshape[idx.entry_id(fnode.inputs[i])] ((1,20) vs. ()) Backward shape inconsistent with the forward shape
</code></pre>
","<python><mxnet>","2017-08-23 16:50:48","","1","8345967","2017-09-24 21:50:10","1","0","","","8345967","16","0","0"
"49617270","<p>I want to be able to calculate the cosine distance between row vectors using MXNet. Additionally I am working with batches of samples, and would like to calculate the cosine distance for each pair of samples (i.e. cosine distance of 1st row vector of batch #1 with 1st row vector of batch #2).</p>

<p>Cosine distance between two vectors is defined as in <a href=""https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html"" rel=""nofollow noreferrer"">scipy.spatial.distance.cosine</a>:</p>

<p><a href=""https://i.stack.imgur.com/hPknw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hPknw.png"" alt=""enter image description here""></a></p>
","<mxnet>","2018-04-02 19:08:31","","0","5744361","2018-04-02 19:08:31","1","0","","","5744361","641","14","0"
"39995720","<p>When I read Mxnet source code, I was confused in following statements:</p>

<pre><code>object NDArray {
  private val logger = LoggerFactory.getLogger(classOf[NDArray])
  private[mxnet] val DTYPE_NATIVE_TO_MX: Map[Class[_ &gt;: Float with Int with Double], Int] = Map(
    classOf[Float] -&gt; 0,
    classOf[Double] -&gt; 1,
    classOf[Int] -&gt; 4
  )
</code></pre>

<p>What does it mean for ""Class[_ >: Float with Int with Double], Int]""?
I understand the scala keyword ""with"" could be used during class declaration, for example</p>

<pre><code>Class person with glass { 
</code></pre>

<p>means the class 'person' has the trait of objdect 'glass'. </p>

<p>How to interpret the usage of 'with' in above code?</p>
","<scala><syntax><keyword><mxnet>","2016-10-12 09:56:03","","3","6759432","2016-11-07 19:15:43","1","0","1","","6759432","16","0","0"
"49122455","<p>How can I set the number of CPUs to use in MXNET Gluon to a certain number, say 12?
I don't see the answer in the documentation anywhere and by default MXNET uses all the CPUs.</p>
","<python><gluon><mxnet>","2018-03-06 02:21:19","","0","2778224","2018-03-07 00:33:16","1","1","","","2778224","99","278","0"
"49002995","<p>I just got started with MXNet, and I have wrote and trained a CNN with MNIST based on some tutorials. Now I wish to actually send a picture to this CNN and get a result from it, how should I do it? </p>

<p>Here're my code:</p>

<pre><code>def get_lenet():
    data = mx.symbol.Variable('data')
    # first conv
    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)
    tanh1 = mx.symbol.Activation(data=conv1, act_type=""tanh"")
    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=""max"",
                          kernel=(2,2), stride=(2,2))
    # second conv
    conv2 = mx.symbol.Convolution(data=pool1, kernel=(4,4), num_filter=50)
    tanh2 = mx.symbol.Activation(data=conv2, act_type=""tanh"")
    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=""max"",
                          kernel=(2,2), stride=(2,2))

    # first fullc
    flatten = mx.symbol.Flatten(data=pool2)
    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)
    tanh4 = mx.symbol.Activation(data=fc1, act_type=""tanh"")

    # second fullc
    fc2 = mx.symbol.FullyConnected(data=tanh4, num_hidden=10)
    # loss
    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')
    return lenet

logging.getLogger().setLevel(logging.DEBUG)

model = mx.model.FeedForward(
    ctx=mx.cpu(),
    symbol=get_lenet(),
    num_epoch=5,
    learning_rate=0.1
)

model.fit(
    X=train_iter,
    eval_data=val_iter,
    batch_end_callback=mx.callback.Speedometer(batch_size, 200)
)
</code></pre>

<p>Thanks in advance for any help</p>
","<python><mxnet>","2018-02-27 07:06:36","","0","3505921","2018-02-28 19:28:16","1","0","","","3505921","27","1","0"
"47745218","<p>I'm trying to use MXNet/Gluon to train an Object Detection model (specifically multiple instances of one type of object within an image), and the im2rec tool does not appear to add bounding box information to the .rec file. </p>

<p><code>mxnet.recordio.pack_img()</code> appears to do the work of packing the image and the label together, but I can't find where/how to include bounding box information in pixel space.  From the documentation:</p>

<pre><code>label = 4 # label can also be a 1-D array, for example: label = [1,2,3]
id = 2574
header = mx.recordio.IRHeader(0, label, id, 0)
img = cv2.imread('test.jpg')
packed_s = mx.recordio.pack_img(header, img)
</code></pre>

<p>The header doesn't have a spot for bounding box info.  Any idea how to do this?</p>
","<computer-vision><object-detection><mxnet>","2017-12-11 01:11:28","","1","4036313","2017-12-13 08:25:37","1","0","","","4036313","35","6","0"
"42486293","<p>I want to ask whether I can set different workloads when I use distributed computing environment using mxnet. I read some tutorial for distributed GPUs. </p>

<p>But I want to use distributed nodes (CPUs) environment and I want to set different workload to them. Can I do that? If yes, then can I get some examples about it?</p>

<p>Thank you for your answer!</p>
","<mxnet>","2017-02-27 12:53:01","","0","7629903","2017-02-28 21:18:22","1","0","","","7629903","1","0","0"
"50946913","<p>Here trying to learn MXNET with “The Straight Dope”. On Linear Algebra - Tensors, I get ctypes error when running,</p>

<pre><code>X = nd.arange(24).reshape((2, 3, 4))
</code></pre>

<p>The error is,</p>

<pre><code>C:\Anaconda2\lib\site-packages\mxnet\ndarray\ndarray.pyc in reshape(self, *shape, **kwargs)
   1060                                            c_array(ctypes.c_int64, shape),
   1061                                            reverse,
-&gt; 1062                                            ctypes.byref(handle)))
   1063         return NDArray(handle=handle, writable=self.writable)
   1064

WindowsError: exception: access violation writing 0x00007FFB00000000
</code></pre>

<p>Why is this happening and how can I solve it?</p>
","<python><machine-learning><neural-network><ctypes><mxnet>","2018-06-20 11:14:52","","0","9730454","2018-09-27 10:00:32","1","0","","","9730454","22","0","0"
"49961351","<p>I am attempting to use <code>mxnet 1.10/mxnet-cu91</code> for image classification.  I am currently attempting to use <code>mxnet.image.ImageIter</code> to iterate through 
 and preprocess images.  I have been able to successfully use the <code>Augmenters</code> to preprocess the images, but have received the following error when using <code>Augmenters</code> (with the only exception being <code>ForceResizeAug</code>):</p>

<pre><code>Traceback (most recent call last):
  File ""image.py"", line 22, in &lt;module&gt;
    for batch in iterator:
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/image/image.py"", line 1181, in next
    data = self.augmentation_transform(data)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/image/image.py"", line 1239, in augmentation_transform
    data = aug(data)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/image/image.py"", line 659, in __call__
    src = t(src)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/image/image.py"", line 721, in __call__
    gray = src * self.coef
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/ndarray/ndarray.py"", line 235, in __mul__
    return multiply(self, other)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/ndarray/ndarray.py"", line 2566, in multiply
    None)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/ndarray/ndarray.py"", line 2379, in _ufunc_helper
    return fn_array(lhs, rhs)
  File ""&lt;string&gt;"", line 46, in broadcast_mul
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/_ctypes/ndarray.py"", line 92, in _imperative_invoke
    ctypes.byref(out_stypes)))
  File ""/usr/local/lib/python2.7/dist-packages/mxnet/base.py"", line 146, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [20:02:07] src/operator/contrib/../elemwise_op_common.h:123: Check failed: assign(&amp;dattr, (*vec)[i]) Incompatible attr in node  at 1-th input: expected uint8, got float32

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2ab9a8) [0x7f5c873f09a8]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2abdb8) [0x7f5c873f0db8]
[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2d2078) [0x7f5c87417078]
[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2d2b83) [0x7f5c87417b83]
[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x24c4c1e) [0x7f5c89609c1e]
[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x24c6e59) [0x7f5c8960be59]
[bt] (6) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x240539b) [0x7f5c8954a39b]
[bt] (7) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x63) [0x7f5c8954a903]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f5cc334ae40]
[bt] (9) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f5cc334a8ab]
</code></pre>

<p>The code needed to replicate the issue is below (shortened for brevity, closely resembles the code provided in the <a href=""https://mxnet.incubator.apache.org/api/python/image/image.html#image-iterators"" rel=""nofollow noreferrer"">documentation</a>):</p>

<pre><code>import mxnet as mx
import glob

type1_paths = glob.glob('type1/*.jpg')
type1_list = [[1.0, path] for path in type1_paths]

type2_paths = glob.glob('type2/*.JPG')
type2_list = [[2.0, path] for path in type2_paths]
all_paths = type1_list + type2_list
iterator = mx.image.ImageIter(1, (3, 1000, 1000),
                              imglist=all_paths,
                              aug_list=[
                              mx.image.ColorJitterAug(0.1, 0.1, 0.1),
                              ])
for batch in iterator:
    print batch.data
</code></pre>

<p>I am not sure why the error is occurring, as I am not using any custom augmenters that could effect the discrepancy in <code>dtype</code>.  I've also replicated this issue when using the following:</p>

<ul>
<li>RandomGrayAug</li>
<li>HueJitterAug</li>
<li>ContrastJitterAug</li>
<li>SaturationJitterAug</li>
</ul>

<p><strong>NOTE</strong>: In case this matters, the only differences I know between the loaded <code>jpg/JPG</code> is that some photos were taken using a phone, and others using a DSLR camera.</p>

<p>Please let me know if I am missing any information that would be helpful in learning.</p>
","<image><python-2.7><image-processing><mxnet>","2018-04-22 00:19:46","","0","2829487","2018-05-04 21:08:51","1","1","","","2829487","362","109","1"
"49237592","<pre><code>FC = mx.sym.FullyConnected(data=x_3,flatten=False, num_hidden=n_class)
x = mx.sym.softmax(data=FC)

sm_label = mx.sym.Reshape(data=label, shape=(-1,))
sm_label = mx.sym.Cast(data = sm_label, dtype = ‘int32’)
sm = mx.sym.WarpCTC(data=x, label=sm_label, label_length =n_len ,
input_length =rnn_length )
</code></pre>

<p>my x layer's shape[(32L, 35L, 27L)] （bacthsize，input_lenth，n_class)<br>
label的shape[(32L,21L)] (batchsize,label_lenth)<br>
warpctc<br>
simple_bind error.<br>
Arguments:<br>
data: (32, 1L, 32L, 286L)<br>
label: (32, 21L)<br>
Error in operator warpctc48: Shape inconsistent, Provided = [672], inferred shape=[0,1]</p>

<p>What can I do?</p>
","<mxnet>","2018-03-12 14:23:17","","0","7795423","2018-03-18 05:09:49","1","0","","","7795423","16","0","0"
"39832234","<p>I am trying to run the <a href=""https://github.com/dmlc/mxnet/blob/master/example/notebooks/predict-with-pretrained-model.ipynb"" rel=""nofollow"">this image classification example</a> that uses <a href=""https://github.com/dmlc/mxnet"" rel=""nofollow"">Mxnet library</a> in python and the pre-trained deep learning model Inception-BN. The execution throws and error on this line: <code>prob = model.predict(batch)[0]</code> with the error message:</p>

<pre><code>MXNetError: InferShape Error in ch_concat_3c_chconcat: [14:35:56] src/operator/./concat-inl.h:152: Check failed: (dshape[j]) == (tmp[j]) Incorrect shape[2]: (1,320,15,15). (first input shape: (1,576,14,14))
</code></pre>

<p>I tried downloading the Inception-BN model again to make sure it was up to date but it didn't make a difference. I do suspect the problem could be on line: <code>model = mx.model.FeedForward.load(prefix, num_round, ctx=mx.gpu(), numpy_batch_size=1)</code> where I had to change <strong>gpu</strong> for <strong>cpu</strong> since my server is not equiped with a gpu. Nevertheless the error doesn't seem to point on that direction.</p>

<p>Any idea how to fix it? Is using a cpu instead of a gpu a problem other than a lower performance?</p>

<p>Finally here is the complete error information:</p>

<pre><code>---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
&lt;ipython-input-7-98e51e4226e1&gt; in &lt;module&gt;()
      1 # Get prediction probability of 1000 classes from model
----&gt; 2 prob = model.predict(batch)[0]
      3 # Argsort, get prediction index from largest prob to lowest
      4 pred = np.argsort(prob)[::-1]
      5 # Get top1 label

/users/CREATE/olb/mxnet/python/mxnet/model.pyc in predict(self, X, num_batch, return_data, reset)
    589         data_shapes = X.provide_data
    590         data_names = [x[0] for x in data_shapes]
--&gt; 591         self._init_predictor(data_shapes)
    592         batch_size = X.batch_size
    593         data_arrays = [self._pred_exec.arg_dict[name] for name in data_names]

/users/CREATE/olb/mxnet/python/mxnet/model.pyc in _init_predictor(self, input_shapes)
    520         # for now only use the first device
    521         pred_exec = self.symbol.simple_bind(
--&gt; 522             self.ctx[0], grad_req='null', **dict(input_shapes))
    523         pred_exec.copy_params_from(self.arg_params, self.aux_params)
    524 

/users/CREATE/olb/mxnet/python/mxnet/symbol.pyc in simple_bind(self, ctx, grad_req, type_dict, **kwargs)
    623         if type_dict is None:
    624             type_dict = {k: mx_real_t for k in self.list_arguments()}
--&gt; 625         arg_shapes, _, aux_shapes = self.infer_shape(**kwargs)
    626         arg_types, _, aux_types = self.infer_type(**type_dict)
    627         if arg_shapes == None or arg_types == None:

/users/CREATE/olb/mxnet/python/mxnet/symbol.pyc in infer_shape(self, *args, **kwargs)
    410             The order is in the same order as list_auxiliary()
    411         """"""
--&gt; 412         return self._infer_shape_impl(False, *args, **kwargs)
    413 
    414     def infer_shape_partial(self, *args, **kwargs):

/users/CREATE/olb/mxnet/python/mxnet/symbol.pyc in _infer_shape_impl(self, partial, *args, **kwargs)
    470             ctypes.byref(aux_shape_ndim),
    471             ctypes.byref(aux_shape_data),
--&gt; 472             ctypes.byref(complete)))
    473         if complete.value != 0:
    474             arg_shapes = [

/users/CREATE/olb/mxnet/python/mxnet/base.pyc in check_call(ret)
     75     """"""
     76     if ret != 0:
---&gt; 77         raise MXNetError(py_str(_LIB.MXGetLastError()))
     78 
     79 def c_str(string):

MXNetError: InferShape Error in ch_concat_3c_chconcat: [14:35:56] src/operator/./concat-inl.h:152: Check failed: (dshape[j]) == (tmp[j]) Incorrect shape[2]: (1,320,15,15). (first input shape: (1,576,14,14))
</code></pre>
","<python-2.7><machine-learning><image-recognition><mxnet><imagenet>","2016-10-03 12:56:30","","1","2112239","2017-06-07 22:08:22","1","0","1","","2112239","599","189","4"
"47443201","<p>I am looking for the model file definition for a resnet implementation using the mxnet gluon api. The model zoo only provides pre-trained models:
<a href=""https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html</a></p>

<p>I am looking for the code implementing the resent model.</p>
","<mxnet><resnet>","2017-11-22 20:14:03","","0","6585583","2017-12-11 19:13:55","1","1","","","6585583","1","0","0"
"55915055","<p>I'm predicting the Dissolved Oxygen content (DO) from other nutrient variables and Month and Date. However, the accuracy of my model has been stuck at around 60% which is way lower than random forest (71%). I'm new to the field and was hoping if anyone can give me some suggestions to improve the model accuracy. I cannot install tensorflow in my laptop so mxnet is my best shot. </p>

<p>Also, I wonder if it's possible to use LSTM in mxnet for my data as it is not time series data.</p>

<p>In my data, I have 9 numerical variables and 47 binary variables due to hot encoding of Month and Date and Landuse.</p>

<p>Thanks!!!</p>

<p>I tried adjusting the num.round, number of hidden layer and hidden unit, batch.size and lr. But the highest accuracy I got ever was 65.5%.</p>

<pre><code> hcdata&lt;-read.csv(""hcdata.csv"", header = TRUE, sep = "","")
 set.seed(123)
 nobs &lt;- nrow(ndata)
 ntrain &lt;- sample(nobs, 0.8*nobs)
 ntest &lt;- setdiff(seq_len(nobs), ntrain)
 traindata &lt;- hcdata[ntrain, ]
 testdata &lt;- hcdata[ntest, ]
 data &lt;- mx.symbol.Variable(""data"")
 fc1 &lt;- mx.symbol.FullyConnected(data, name = ""fc1"", num_hidden = 20)
 act1 &lt;- mx.symbol.Activation(fc1, name = ""activ1"", act_type = ""relu"")

 drop1 &lt;- mx.symbol.Dropout(data = act1, p = 0.2)
 fc2 &lt;- mx.symbol.FullyConnected(drop1, name = ""fc2"", num_hidden = 10)
 act2 &lt;- mx.symbol.Activation(fc2, name = ""activ2"", act_type = ""relu"")

 drop2 &lt;- mx.symbol.Dropout(data = act2, p = 0.2)
 fc3 &lt;- mx.symbol.FullyConnected(drop2, name = ""fc3"", num_hidden = 3)

 softmax &lt;- mx.symbol.SoftmaxOutput(fc3, name = ""sm"")

 devices &lt;- mx.cpu()

 mx.set.seed(0)
 mxtraindata.x &lt;- t(traindata[,1:56])
 mxtestdata.x &lt;- t(testdata[,1:56])
 mxtraindata.x &lt;- data.matrix(mxtraindata.x)
 mxtestdata.x &lt;- data.matrix(mxtestdata.x)
 fm_dnn &lt;- mx.model.FeedForward.create(softmax, X = mxtraindata.x, 
 y = traindata$DO, ctx = devices,
 num.round = 100, array.batch.size = 50, learning.rate = 0.05, 
 momentum = 0.9, eval.metric = mx.metric.accuracy, 
 initializer = mx.init.uniform(0.01),
 epoch.end.callback = mx.callback.log.train.metric(1))

 prob_dnn &lt;- predict(fm_dnn, mxtestdata.x)
 pred_dnn &lt;- max.col(t(prob_dnn))-1
 pred_dnn &lt;- as.factor(pred_dnn)
 caret::confusionMatrix(testdata$DO, pred_dnn)
</code></pre>

<p>I was hoping to get a accuracy above 70%</p>
","<r><lstm><mxnet>","2019-04-30 06:26:09","","0","11430798","2019-04-30 06:26:09","0","0","","","11430798","1","0","0"
"55588177","<p>I'm trying to use Python to parse mxnet params into plain text. The code looks like the below. But the parsing result is not plain string, but some encoded text looks like this, ""... \xaa>\x0f\xed\x8e>\xaf!\x8f>g ..."" Could anybody give me some tips on it? Thanks a lot!</p>

<pre class=""lang-py prettyprint-override""><code>...

param_file = 'resnet-50-0000.params'
with open(param_file, 'rb') as f:
    net_params = f.read()

...

</code></pre>
","<mxnet>","2019-04-09 08:22:49","","0","10416362","2019-04-11 17:45:22","1","0","","","10416362","3","0","0"
"54870595","<p>I am trying to run <a href=""https://github.com/zhreshold/mxnet-ssd"" rel=""nofollow noreferrer"">MXNet port of SSD</a> in python but I am facing a strange error when I run the demo saying</p>

<pre><code>OSError: [WinError 126] The specified module could not be found
</code></pre>

<p>specifically when trying to open <code>libmxnet.dll</code> so I found when I tried to debug it.</p>

<p>the whole error message is like this:</p>

<pre><code>&gt;&gt;&gt;&gt; kernel32
&gt;&gt;&gt;&gt;  C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\site-packages\mxnet\libmxnet.dll
Traceback (most recent call last):
  File ""demo.py"", line 2, in &lt;module&gt;
    import tools.find_mxnet
  File ""C:\Users\wisdom\Desktop\mxnet-ssd-master\tools\find_mxnet.py"", line 6, in &lt;module&gt;
    import mxnet as mx
  File ""C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\site-packages\mxnet\__init__.py"", line 24, in &lt;module&gt;
    from .context import Context, current_context, cpu, gpu, cpu_pinned
  File ""C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\site-packages\mxnet\context.py"", line 24, in &lt;module&gt;
    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
  File ""C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\site-packages\mxnet\base.py"", line 213, in &lt;module&gt;
    _LIB = _load_lib()
  File ""C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\site-packages\mxnet\base.py"", line 204, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""C:\Users\wisdom\Anaconda3\envs\gpu-test\lib\ctypes\__init__.py"", line 353, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found
</code></pre>

<p>where first two lines with >>>> sign indicate to the lines I was trying to debug and check where/when the error is fired in <code>...\ctypes\__init__.py</code> file which look like this</p>

<pre><code>if handle is None:
    x = (self._name)
    print('&gt;&gt;&gt;&gt;',x)
    self._handle = _dlopen(self._name, mode)
</code></pre>

<p>I checked of course the existence of the requested file <code>libmxnet.dll</code> and it is there, but whenever it is called it throws this error!</p>
","<python><dll><ctypes><mxnet>","2019-02-25 16:24:36","","-1","1375406","2019-02-25 21:00:49","1","9","","","1375406","181","43","0"
"52641197","<p>I'm attempting to setup AWS Greengrass with mxnet for Machine Learning on a Raspberry Pi.</p>

<p>When running <code>./mxnet_installer.sh</code> from <a href=""https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-console.html#install-mxnet"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-console.html#install-mxnet</a> it takes ages and just disconnects my session with PuTTY.</p>

<p>It seems to be hanging on <code>Running setup.py bdist_wheel for scipy</code> - it sits there for about 2 hours before the PuTTY session is lost.</p>

<p>I'm executing the command on a clean PI, all all that has been done beforehand is modules 1 to 6 from <a href=""https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-gs.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-gs.html</a></p>

<pre><code>login as: pi
pi@192.168.0.49's password:
Linux raspberrypi 4.14.70-v7+ #1144 SMP Tue Sep 18 17:34:46 BST 2018 armv7l

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Tue Oct  2 14:53:14 2018 from 192.168.0.13

SSH is enabled and the default password for the 'pi' user has not been changed.
This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password.

pi@raspberrypi:~ $ ls
aws-greengrass-samples         ggc-mxnet-v1.2.1-python-raspi.tar.gz
ggc-mxnet-v1.2.1-python-raspi
pi@raspberrypi:~ $ cd ggc-mxnet-v1.2.1-python-raspi/
pi@raspberrypi:~/ggc-mxnet-v1.2.1-python-raspi $ ls
greengrass-ml-squeezenet-object-classification-raspi-python.tar.gz
mxnet-1.2.1-py2.py3-none-any.whl
mxnet_examples.tar.gz
mxnet_installer.sh
mxnet-python-unit-test.tar.gz
pi@raspberrypi:~/ggc-mxnet-v1.2.1-python-raspi $ ./mxnet_installer.sh
Starting MXNET installation on the system...
Unittests:  N
Swapfile location:  /var/swap
Swapfile size:  1 GB
Reading package lists... Done
Building dependency tree
Reading state information... Done
Suggested packages:
  python-numpy-dbg python-numpy-doc
The following NEW packages will be installed:
  python-numpy
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 0 B/1,694 kB of archives.
After this operation, 9,532 kB of additional disk space will be used.
Selecting previously unselected package python-numpy.
(Reading database ... 43734 files and directories currently installed.)
Preparing to unpack .../python-numpy_1%3a1.12.1-3_armhf.deb ...
Unpacking python-numpy (1:1.12.1-3) ...
Setting up python-numpy (1:1.12.1-3) ...
Processing triggers for man-db (2.7.6.1-2) ...
Reading package lists... Done
Building dependency tree
Reading state information... Done
liblapack3 is already the newest version (3.7.0-2).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Reading package lists... Done
Building dependency tree
Reading state information... Done
libopenblas-dev is already the newest version (0.2.19-3+rpi1).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Reading package lists... Done
Building dependency tree
Reading state information... Done
liblapack-dev is already the newest version (3.7.0-2).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Reading package lists... Done
Building dependency tree
Reading state information... Done
python-dev is already the newest version (2.7.13-2).
python-nose is already the newest version (1.3.7-2).
python-pip is already the newest version (9.0.1-2+rpt2).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Reading package lists... Done
Building dependency tree
Reading state information... Done
python-opencv is already the newest version (2.4.9.1+dfsg1-2).
zip is already the newest version (3.0-11).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
dpkg: python-numpy: dependency problems, but removing anyway as you requested:
 python-opencv depends on python-numpy-abi9; however:
  Package python-numpy-abi9 is not installed.
  Package python-numpy which provides python-numpy-abi9 is to be removed.
 python-opencv depends on python-numpy (&gt;= 1:1.6.1); however:
  Package python-numpy is to be removed.
 python-picamera depends on python-numpy.
 python-opencv depends on python-numpy-abi9; however:
  Package python-numpy-abi9 is not installed.
  Package python-numpy which provides python-numpy-abi9 is to be removed.
 python-opencv depends on python-numpy (&gt;= 1:1.6.1); however:
  Package python-numpy is to be removed.

(Reading database ... 44120 files and directories currently installed.)
Removing python-numpy (1:1.12.1-3) ...
Processing triggers for man-db (2.7.6.1-2) ...
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0)
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Requirement already satisfied: wheel in /usr/lib/python2.7/dist-packages (0.29.0)
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Requirement already up-to-date: picamera in /usr/lib/python2.7/dist-packages (1.13)
Checking numpy...
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Requirement already up-to-date: numpy in /usr/local/lib/python2.7/dist-packages (1.15.2)
'numpy' check complete!
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Collecting scipy
  Using cached https://files.pythonhosted.org/packages/07/76/7e844757b9f3bf5ab9f951ccd3e4a8eed91ab8720b0aac8c2adcc2fdae9f/scipy-1.1.0.tar.gz
Building wheels for collected packages: scipy
  Running setup.py bdist_wheel for scipy ... |
</code></pre>

<p>Any suggestions?</p>
","<scipy><raspberry-pi><aws-iot><mxnet><greengrass>","2018-10-04 07:23:52","","3","7925744","2018-10-15 04:59:14","1","2","","","7925744","125","33","0"
"41096590","<p>When I try to use mxnet to build a feedforward model it appeared the following error:</p>

<blockquote>
  <p>Error in mx.io.internal.arrayiter(as.array(data), as.array(label), unif.rnds,  : 
    basic_string::_M_replace_aux</p>
</blockquote>

<p>I follow the R regression example on mxnet website but I change the data into my own data which contains 109 examples and 1876 variables. The first several steps can run without error until ran the model building step. I just can't understand the error information mean. I wonder that it is because of my dataset or the way I deal with the data. </p>
","<mxnet>","2016-12-12 08:13:23","","0","7062661","2016-12-12 18:37:56","1","0","","","7062661","1","0","0"
"50563511","<pre><code>object LoadTest1 {
def main(args: Array[String]): Unit = {

var b = NDArray.array(Array(1, 2, 3),
    shape = Shape(1, 3))
//var c = b.copy()
val a = NDArray.one_hot(Map(""indices"" -&gt; NDArray.array(Array(1f, 2f, 3f), shape = Shape(1, 3)),
    ""on_value"" -&gt; 1,
    ""dtype"" -&gt; ""float16"",
    ""off_value"" -&gt; 0,
    ""depth"" -&gt; 4
    //                        ""out""-&gt;c
))(1)(1)
println(a)

println(""-----------------------"")
}
}
</code></pre>

<blockquote>
  <p>The code runs with an error like this :   </p>

<pre><code>    Exception in thread ""main"" ml.dmlc.mxnet.MXNetError: Cannot find argument 'indices', Possible Arguments:

    depth : int, required
        Depth of the one hot dimension.
    on_value : double, optional, default=1
        The value assigned to the locations represented by indices.
    off_value : double, optional, default=0
        The value assigned to the locations not represented by indices.
    dtype : {'float16', 'float32', 'float64', 'int32', 'uint8'},optional, default='float32'
    18/05/28 17:19:19 INFO util.NativeLibraryLoader: Deleting /var/folders/xh/cjnxxqwx05q4rmf3rz5zmt1r0000gn/T/mxnet4026866899089746779/mxnet-scala
        DType of the output
    18/05/28 17:19:19 INFO util.NativeLibraryLoader: Deleting /var/folders/xh/cjnxxqwx05q4rmf3rz5zmt1r0000gn/T/mxnet4026866899089746779
    , in operator one_hot(name="""", depth=""1"", on_value=""1"", off_value=""0"", indices=""ml.dmlc.mxnet.NDArray@c3b177e"",
</code></pre>
  
  <p>dtype=""float16"")
            at ml.dmlc.mxnet.Base$.checkCall(Base.scala:131)
            at ml.dmlc.mxnet.NDArray$.genericNDArrayFunctionInvoke(NDArray.scala:97)
            at ml.dmlc.mxnet.NDArray$.one_hot(NDArray.scala:33)
            at LoadTest$.main(LoadTest.scala:22)
            at LoadTest.main(LoadTest.scala)</p>

<pre><code>I think I add the ""indices"".

I am not very familiar with mxnet Scala, so what's wrong with this?
</code></pre>
</blockquote>
","<scala><mxnet><one-hot>","2018-05-28 09:48:46","","0","9857915","2018-05-29 03:45:23","1","0","0","","9857915","11","0","0"
"40743810","<p>In windows 10, I followed the step-by-step MXnet tutorial to use im2rec.py to create a dataset. I created a image list file like this:</p>

<pre><code>integer_image_index \t label_index \t path_to_image
</code></pre>

<blockquote>
  <p><img src=""https://i.stack.imgur.com/lPncW.jpg"" alt=""enter image description here""></p>
</blockquote>

<p>Next, I modified <code>.txt</code> to <code>.lst</code>.</p>

<blockquote>
  <p><img src=""https://i.stack.imgur.com/4Zjip.jpg"" alt=""enter image description here""></p>
</blockquote>

<p>Finally, I executed the command:    </p>

<pre><code>python im2rec.py --exts '.jpg' --train-ratio 0.41 --test-ratio 0.49 --recursive=True --pack-label=True D:\CUB_200_2011\data\image_label.lst D:\CUB_200_2011\CUB_200_2011\image
</code></pre>

<p>It is shown that ""read no error"", but the files created by the command like <code>.lst</code> and <code>.rec</code> are 0K, there is empty. I don't know why.</p>

<p>Please tell me what mistakes I made.</p>
","<windows><python-2.7><mxnet>","2016-11-22 13:58:31","","1","7194417","2016-11-23 00:58:48","1","1","","","7194417","13","0","0"
"50039719","<p>I wanted to install MXNET using commands <code>conda install -c anaconda mxnet</code> and <code>conda install mxnet</code>, but I am getting unsatisfiable error as show in images.</p>

<p><strong>'conda install -c anaconda mxnet'</strong>:
<img src=""https://i.stack.imgur.com/A3Yir.png"" alt=""FOR &#39;conda install -c anaconda mxnet&#39;"">
<strong>'conda install mxnet':</strong>
<img src=""https://i.stack.imgur.com/9AOQ1.png"" alt=""FOR &#39;conda install mxnet&#39;"">  </p>
","<windows><error-handling><install><anaconda><mxnet>","2018-04-26 09:40:29","","-1","9701719","2018-04-26 20:54:11","1","0","0","","9701719","10","0","0"
"49163334","<p>I am trying to install MXNet / MXNetR on Windows. 
To do so I did the following, which is recommended on their website (<a href=""https://mxnet.incubator.apache.org/install/windows_setup.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/install/windows_setup.html</a>)</p>

<pre><code>cran &lt;- getOption(""repos"")
cran[""dmlc""] &lt;- ""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/""
options(repos = cran)
install.packages(""mxnet"")
</code></pre>

<p>This worked just fine. Then I tried to load the library, which gives an error:</p>

<pre><code>library(mxnet)
Error: package or namespace load failed for ‘mxnet’:
 Object ‘set_global_graph_attrs’ is not exported by 'namespace:DiagrammeR'
</code></pre>

<p>I googled some more and the only help I could find was to try the following, which gave the same error:</p>

<pre><code>library(devtools)
install_version(""DiagrammeR"", version = ""0.9.1"", repos = ""http://cran.us.r-project.org"")
</code></pre>

<p>Trying an even earlier version of DiagrammeR also didn't work: </p>

<pre><code>library(devtools)
install_version(""DiagrammeR"", version = ""0.8.1"", repos = ""http://cran.us.r-project.org"")
</code></pre>

<p>I could not find any more help, how to deal with this error. 
I would be glad if someone has an idea. </p>
","<r><neural-network><deep-learning><data-science><mxnet>","2018-03-08 00:08:45","","2","1561441","2018-03-08 02:20:09","1","1","","","1561441","48","28","0"
"46103844","<p>In Nvidia website, they claimed MXNet uses NCCL (<a href=""https://developer.nvidia.com/nccl"" rel=""nofollow noreferrer"">https://developer.nvidia.com/nccl</a>). However, I haven't found any reference from MXNet's github repository that they actually use NCCL library. </p>

<p>In the chainer blog, they also claimed that chainer achieves better performance than MXNet on 4 GPUs because of the use of NCCL library in chainer.(<a href=""https://chainer.org/general/2017/02/08/Performance-of-Distributed-Deep-Learning-Using-ChainerMN.html"" rel=""nofollow noreferrer"">https://chainer.org/general/2017/02/08/Performance-of-Distributed-Deep-Learning-Using-ChainerMN.html</a>) </p>

<p>In some of the old posts in MXNet repository, I can see that they were talking about the difficulty in including the NCCL library in MXNet. </p>

<p><strong>My first question is, is there any version of MXNet with NCCL library?</strong>
<strong>Second, what might be the performance implications of using NCCL library (i.e. less memory usage, lesser communication overhead across multiple GPUs)?</strong></p>
","<machine-learning><nvidia><mxnet><multi-gpu>","2017-09-07 19:33:52","","2","8305275","2017-11-20 23:25:31","1","0","1","","8305275","16","1","0"
"48518155","<p>I installed mxnet using</p>

<pre><code>!pip install mxnet-cu80
</code></pre>

<p>However when I try to <code>import mxnet</code> I get error complaining that <code>libnvrtc.so.8.0</code> is missing. Searching for it by <code>!find / -name 'libnvrtc.*'</code> returns nothing. Searching by google reveals that <a href=""http://docs.nvidia.com/cuda/nvrtc/index.html"" rel=""nofollow noreferrer"">NVRTC</a> is part of cuda toolkit. I have tried with both python 2 and 3 runtimes. The GPU acceleration is enabled.</p>

<p>What can I do to make mxnet working?</p>
","<python><cuda><mxnet><google-colaboratory>","2018-01-30 09:36:49","","1","3185929","2018-01-30 16:57:28","1","0","","","3185929","412","33","0"
"44858318","<p>I am trying an MXNet tutorial mentioned at <a href=""http://mxnet.io/tutorials/embedded/wine_detector.html"" rel=""nofollow noreferrer"">http://mxnet.io/tutorials/embedded/wine_detector.html</a> (Section ""Running the Model"" on a raspberry pi3 using python3.4, specifically the script ""inception_predict.py"". I managed to fix a couple of issue but am getting stumped at this error:</p>

<blockquote>
  <p>>> import inception_predict<br>
  [23:43:37] src/nnvm/legacy_json_util.cc:190: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...<br>
  [23:43:37] src/nnvm/legacy_json_util.cc:198: Symbol successfully upgraded!  </p>
  
  <p>>> predict_from_url(""<a href=""https://imgur.com/HzafyBA"" rel=""nofollow noreferrer"">http://imgur.com/HzafyBA</a>"")<br>
  Traceback (most recent call last):<br>
   File """", line 1, in <br>
  NameError: name 'predict_from_url' is not defined</p>
</blockquote>

<p>Function predict_from_url is defined in the imported file inception_predict.py (as mentioned in the tutorial) so why is python telling me it is not defined?
 What am I doing wrong?</p>
","<python-3.4><raspberry-pi3><mxnet>","2017-07-01 07:06:59","","0","4739897","2017-07-04 15:11:34","1","0","","","4739897","23","1","0"
"51627685","<p>Using mxnet 1.1,
When I try to run net(data) on the following network:</p>

<pre><code>net = gluon.nn.HybridSequential()
    with net.name_scope():
        net.add(gluon.nn.Embedding(input_dim=MAX_EVENT_INDEX + 1, output_dim=EMBEDDING_VECTOR_LENGTH))
        net.add(gluon.nn.Conv1D(channels=conv1D_filters, kernel_size=conv1D_kernel_size, activation='relu'))
        net.add(gluon.nn.MaxPool1D(pool_size=max_pool_size, strides=2))
        net.add(gluon.rnn.LSTMCell(100))
        net.add(gluon.rnn.DropoutCell(dropout_rate))
        net.add(gluon.rnn.LSTMCell(100))
        net.add(gluon.rnn.DropoutCell(dropout_rate))
        net.add(gluon.rnn.LSTMCell(100))
        net.add(gluon.rnn.DropoutCell(dropout_rate))
        net.add(gluon.nn.Flatten())
        net.add(gluon.nn.Dense(1, activation=""sigmoid""))
    net.hybridize()
</code></pre>

<p>Error: forward() missing 1 required positional argument: 'states'</p>

<p>Everything works when I use  <code>gluon.nn.Sequential()</code> with <code>net.add(gluon.rnn.LSTM(100, dropout=dropout_rate))</code></p>

<p>Thanks</p>
","<deep-learning><lstm><mxnet>","2018-08-01 07:30:48","","-1","3644809","2018-08-07 20:37:23","1","0","","","3644809","11","0","0"
"55297514","<h1>Mxnet c++ inference with MXPredSetInput segmentation fault</h1>

<h3>1. background</h3>

<p>I have tried <a href=""https://github.com/apache/incubator-mxnet/tree/master/example/image-classification/predict-cpp"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/tree/master/example/image-classification/predict-cpp</a> successed.
But when I try to deploy mxnet in c++ with my own model, I met a segmentation fault error:</p>

<pre class=""lang-bsh prettyprint-override""><code>[17:33:07] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v1.2.1. Attempting to upgrade...
Signal: SIGSEGV (Segmentation fault)
</code></pre>

<h3>2. code with error:</h3>

<pre class=""lang-cpp prettyprint-override""><code>  MXPredSetInput(pred_hnd, ""data"", image_data.data(), static_cast&lt;mx_uint&gt;(image_size));
</code></pre>

<h3>3. tips</h3>

<p>First I thought it's because of input data shape not compatible with the model input layer.But I ask model designer, it's a resnet model with conv only, so, any kind input shape should be OK.</p>

<h3>4. Download model:</h3>

<p>Download them, and put them into model dir.
<a href=""https://drive.google.com/drive/folders/16MEKNOz_iwquVxHMk9c7igmBNuT6w7wz?usp=sharing"" rel=""nofollow noreferrer"">https://drive.google.com/drive/folders/16MEKNOz_iwquVxHMk9c7igmBNuT6w7wz?usp=sharing</a></p>

<h3>4. code: find: <a href=""https://github.com/jaysimon/mxnet_cpp_infere"" rel=""nofollow noreferrer"">https://github.com/jaysimon/mxnet_cpp_infere</a></h3>

<pre class=""lang-cpp prettyprint-override""><code>
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;vector&gt;
#include &lt;memory&gt;
#include &lt;thread&gt;
#include &lt;iomanip&gt;
#include &lt;opencv2/opencv.hpp&gt;
// Path for c_predict_api
#include &lt;mxnet/c_predict_api.h&gt;

const mx_float DEFAULT_MEAN = 117.0;

static std::string trim(const std::string&amp; input) {
  auto not_space = [](int ch) {
    return !std::isspace(ch);
  };
  auto output = input;
  output.erase(output.begin(), std::find_if(output.begin(), output.end(), not_space));
  output.erase(std::find_if(output.rbegin(), output.rend(), not_space).base(), output.end());
  return output;
}

// Read file to buffer
class BufferFile {
public :
  std::string file_path_;
  std::size_t length_ = 0;
  std::unique_ptr&lt;char[]&gt; buffer_;

  explicit BufferFile(const std::string&amp; file_path)
      : file_path_(file_path) {

    std::ifstream ifs(file_path.c_str(), std::ios::in | std::ios::binary);
    if (!ifs) {
      std::cerr &lt;&lt; ""Can't open the file. Please check "" &lt;&lt; file_path &lt;&lt; "". \n"";
      return;
    }

    ifs.seekg(0, std::ios::end);
    length_ = static_cast&lt;std::size_t&gt;(ifs.tellg());
    ifs.seekg(0, std::ios::beg);
    std::cout &lt;&lt; file_path.c_str() &lt;&lt; "" ... "" &lt;&lt; length_ &lt;&lt; "" bytes\n"";

    // Buffer as null terminated to be converted to string
    buffer_.reset(new char[length_ + 1]);
    buffer_[length_] = 0;
    ifs.read(buffer_.get(), length_);
    ifs.close();
  }

  std::size_t GetLength() {
    return length_;
  }

  char* GetBuffer() {
    return buffer_.get();
  }
};

void GetImageFile(const std::string&amp; image_file,
                  mx_float* image_data, int channels,
                  cv::Size resize_size, const mx_float* mean_data = nullptr) {
  // Read all kinds of file into a BGR color 3 channels image
  cv::Mat im_ori = cv::imread(image_file, cv::IMREAD_COLOR);

  if (im_ori.empty()) {
    std::cerr &lt;&lt; ""Can't open the image. Please check "" &lt;&lt; image_file &lt;&lt; "". \n"";
    assert(false);
  }

  cv::Mat im;

  resize(im_ori, im, resize_size);

  int size = im.rows * im.cols * channels;

  mx_float* ptr_image_r = image_data;
  mx_float* ptr_image_g = image_data + size / 3;
  mx_float* ptr_image_b = image_data + size / 3 * 2;

  float mean_b, mean_g, mean_r;
  mean_b = mean_g = mean_r = DEFAULT_MEAN;
  mean_b = 103.06;
  mean_g = 115.9;
  mean_r = 123.15;

  for (int i = 0; i &lt; im.rows; i++) {
    auto data = im.ptr&lt;uchar&gt;(i);

    for (int j = 0; j &lt; im.cols; j++) {
      if (channels &gt; 1) {
        *ptr_image_b++ = static_cast&lt;mx_float&gt;(*data++) - mean_b;
        *ptr_image_g++ = static_cast&lt;mx_float&gt;(*data++) - mean_g;
      }

      *ptr_image_r++ = static_cast&lt;mx_float&gt;(*data++) - mean_r;
    }
  }
}

// LoadSynsets
// Code from : https://github.com/pertusa/mxnet_predict_cc/blob/master/mxnet_predict.cc
std::vector&lt;std::string&gt; LoadSynset(const std::string&amp; synset_file) {
  std::ifstream fi(synset_file.c_str());

  if (!fi.is_open()) {
    std::cerr &lt;&lt; ""Error opening synset file "" &lt;&lt; synset_file &lt;&lt; std::endl;
    assert(false);
  }

  std::vector&lt;std::string&gt; output;

  std::string synset, lemma;
  while (fi &gt;&gt; synset) {
    getline(fi, lemma);
    output.push_back(lemma);
  }

  fi.close();

  return output;
}

void PrintOutputResult(const std::vector&lt;float&gt;&amp; data, const std::vector&lt;std::string&gt;&amp; synset) {
  if (data.size() != synset.size()) {
    std::cerr &lt;&lt; ""Result data and synset size do not match!"" &lt;&lt; std::endl;
  }

  float best_accuracy = 0.0;
  std::size_t best_idx = 0;

  for (std::size_t i = 0; i &lt; data.size(); ++i) {
    std::cout &lt;&lt; ""Accuracy["" &lt;&lt; i &lt;&lt; ""] = "" &lt;&lt; std::setprecision(8) &lt;&lt; data[i] &lt;&lt; std::endl;

    if (data[i] &gt; best_accuracy) {
      best_accuracy = data[i];
      best_idx = i;
    }
  }

  std::cout &lt;&lt; ""Best Result: "" &lt;&lt; trim(synset[best_idx]) &lt;&lt; "" (id="" &lt;&lt; best_idx &lt;&lt; "", "" &lt;&lt;
            ""accuracy="" &lt;&lt; std::setprecision(8) &lt;&lt; best_accuracy &lt;&lt; "")"" &lt;&lt; std::endl;
}

void predict(PredictorHandle pred_hnd, const std::vector&lt;mx_float&gt; &amp;image_data,
             NDListHandle nd_hnd, const std::string &amp;synset_file, int i) {
  auto image_size = image_data.size();
  // Set Input 
//&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Problem code &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
  MXPredSetInput(pred_hnd, ""data"", image_data.data(), static_cast&lt;mx_uint&gt;(image_size));
// &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; Problem code &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
  // Do Predict Forward
  MXPredForward(pred_hnd);

  mx_uint output_index = 0;

  mx_uint* shape = nullptr;
  mx_uint shape_len;

  // Get Output Result
  MXPredGetOutputShape(pred_hnd, output_index, &amp;shape, &amp;shape_len);

  std::size_t size = 1;
  for (mx_uint i = 0; i &lt; shape_len; ++i) { size *= shape[i]; }

  std::vector&lt;float&gt; data(size);

  MXPredGetOutput(pred_hnd, output_index, &amp;(data[0]), static_cast&lt;mx_uint&gt;(size));

  // Release NDList
  if (nd_hnd) {
    MXNDListFree(nd_hnd);
  }

  // Release Predictor
  MXPredFree(pred_hnd);

  // Synset path for your model, you have to modify it
  auto synset = LoadSynset(synset_file);

  // Print Output Data
  PrintOutputResult(data, synset);
}

int main(int argc, char* argv[]) {
  if (argc &lt; 2) {
    std::cout &lt;&lt; ""No test image here."" &lt;&lt; std::endl
              &lt;&lt; ""Usage: ./image-classification-predict apple.jpg [num_threads]"" &lt;&lt; std::endl;
    return EXIT_FAILURE;
  }

  std::string test_file(argv[1]);
  int num_threads = 1;
  if (argc == 3)
    num_threads = std::atoi(argv[2]);

  // Models path for your model, you have to modify it
  std::string json_file = ""../model/rfcn_dcn_chicken-0000.json"";
  std::string param_file = ""../model/rfcn_dcn_chicken-0000.params"";
  std::string synset_file = ""../model/synset.txt"";
  std::string nd_file = ""../model/mean_224.nd"";

  BufferFile json_data(json_file);
  BufferFile param_data(param_file);

  // Parameters
  int dev_type = 1;  // 1: cpu, 2: gpu
  int dev_id = 0;  // arbitrary.
  mx_uint num_input_nodes = 1;  // 1 for feedforward
  const char* input_key[1] = { ""data"" };
  const char** input_keys = input_key;

  // Image size and channels
  int width = 1000;
  int height = 562;
  int channels = 3;

  const mx_uint input_shape_indptr[2] = { 0, 4 };
  const mx_uint input_shape_data[4] = { 1,
                                        static_cast&lt;mx_uint&gt;(channels),
                                        static_cast&lt;mx_uint&gt;(height),
                                        static_cast&lt;mx_uint&gt;(width) };

  if (json_data.GetLength() == 0 || param_data.GetLength() == 0) {
    return EXIT_FAILURE;
  }

  auto image_size = static_cast&lt;std::size_t&gt;(width * height * channels);

  // Read Mean Data
  const mx_float* nd_data = nullptr;
  NDListHandle nd_hnd = nullptr;
  BufferFile nd_buf(nd_file);

  if (nd_buf.GetLength() &gt; 0) {
    mx_uint nd_index = 0;
    mx_uint nd_len;
    const mx_uint* nd_shape = nullptr;
    const char* nd_key = nullptr;
    mx_uint nd_ndim = 0;

    MXNDListCreate(static_cast&lt;const char*&gt;(nd_buf.GetBuffer()),
                   static_cast&lt;int&gt;(nd_buf.GetLength()),
                   &amp;nd_hnd, &amp;nd_len);

    MXNDListGet(nd_hnd, nd_index, &amp;nd_key, &amp;nd_data, &amp;nd_shape, &amp;nd_ndim);
  }

  // Read Image Data
  std::vector&lt;mx_float&gt; image_data(image_size);

  GetImageFile(test_file, image_data.data(), channels, cv::Size(width, height), nd_data);

  if (num_threads == 1) {
    // Create Predictor
    PredictorHandle pred_hnd;
    MXPredCreate(static_cast&lt;const char*&gt;(json_data.GetBuffer()),
                 static_cast&lt;const char*&gt;(param_data.GetBuffer()),
                 static_cast&lt;int&gt;(param_data.GetLength()),
                 dev_type,
                 dev_id,
                 num_input_nodes,
                 input_keys,
                 input_shape_indptr,
                 input_shape_data,
                 &amp;pred_hnd);
    assert(pred_hnd);

    predict(pred_hnd, image_data, nd_hnd, synset_file, 0);
  } else {
    // Create Predictor
    std::vector&lt;PredictorHandle&gt; pred_hnds(num_threads, nullptr);
    MXPredCreateMultiThread(static_cast&lt;const char*&gt;(json_data.GetBuffer()),
                            static_cast&lt;const char*&gt;(param_data.GetBuffer()),
                            static_cast&lt;int&gt;(param_data.GetLength()),
                            dev_type,
                            dev_id,
                            num_input_nodes,
                            input_keys,
                            input_shape_indptr,
                            input_shape_data,
                            pred_hnds.size(),
                            pred_hnds.data());
    for (auto hnd : pred_hnds)
      assert(hnd);

    std::vector&lt;std::thread&gt; threads;
    for (int i = 0; i &lt; num_threads; i++)
      threads.emplace_back(predict, pred_hnds[i], image_data, nd_hnd, synset_file, i);
    for (int i = 0; i &lt; num_threads; i++)
      threads[i].join();
  }
  printf(""run successfully\n"");

  return EXIT_SUCCESS;
}
</code></pre>
","<c++><segmentation-fault><mxnet>","2019-03-22 10:23:34","","1","7831403","2019-03-22 10:23:34","0","0","","","7831403","26","0","0"
"55572623","<p>I am running inference using Python 2.7, MXNet V1.3.0 ML framework on an image classification model of ONNX format (V1.2.1 with opset 7) where I feed an image to the inferrer at a time. What do I need to do to asynchronously run inference for multiple images but also await for all of them to finish?</p>

<p>I am extracting frames as .jpeg images from a video at 30 FPS. So for an example, when I run the process on a video of length 20s, it generates 600 .jpeg images. For now, I iterate through a list of those images and pass a relative path to each of them to the following function which then infers from the target image.</p>

<pre class=""lang-py prettyprint-override""><code>def infer(self, target_image_path):
        target_image_path = self.__output_directory + '/' + target_image_path

        image_data = self.__get_image_data(target_image_path)  # Get pixel data

        '''Define the model's input'''
        model_metadata = onnx_mxnet.get_model_metadata(self.__model)
        data_names = [inputs[0]
                      for inputs in model_metadata.get('input_tensor_data')]
        Batch = namedtuple('Batch', 'data')

        ctx = mx.eia()  # Set the context to elastic inference

        '''Load the model'''
        sym, arg, aux = onnx_mxnet.import_model(self.__model)
        mod = mx.mod.Module(symbol=sym, data_names=data_names,
                            context=ctx, label_names=None)
        mod.bind(data_shapes=[(data_names[0], image_data.shape)],
                 label_shapes=None, for_training=False)

        mod.set_params(arg_params=arg, aux_params=aux,
                       allow_missing=True, allow_extra=True)

        '''Run inference on the image'''
        mod.forward(Batch([mx.nd.array(image_data)]))
        predictions = mod.get_outputs()[0].asnumpy()
        predictions = predictions[0].tolist()

        '''Apply emotion labels'''
        zipb_object = zip(self.__emotion_labels, predictions)
        prediction_dictionary = dict(zipb_object)

        return prediction_dictionary
</code></pre>

<p>Expected behavior would be to run the inference for each image asynchronously but also to await the process to finish for the entire batch.</p>
","<python-2.7><mxnet>","2019-04-08 11:40:16","","0","2613614","2019-04-11 18:00:46","1","0","","","2613614","3","0","0"
"51733720","<p>In c++ mx:</p>

<pre><code>#include &lt;mxnet-cpp/MxNetCpp.h&gt;

namespace mx {
    using namespace mxnet::cpp;
}

int main(int argc, char *argv[])
{
    auto data = mx::Symbol::Variable(""input"");
    mx::Symbol conv_w(""conv1_w""), conv_b(""conv1_b"");
    auto a = mx::Convolution(""conv1"", data, conv_w, conv_b, mx::Shape(5, 5), 20);
    return 0;
}
</code></pre>

<p>It is linked against: libmxnet.a libnnvm.a libdmlc.a</p>

<p>On execution it fails at:</p>

<pre><code>inline Operator::Operator(const std::string &amp;operator_name) {
  handle_ = op_map()-&gt;GetSymbolCreator(operator_name);
  const char *name;
  const char *description;
  mx_uint num_args;
  const char **arg_names;
  const char **arg_type_infos;
  const char **arg_descriptions;
  const char *key_var_num_args;
  &gt;&gt;&gt;&gt;&gt; MXSymbolGetAtomicSymbolInfo(handle_,
      &amp;name,
      &amp;description,
      &amp;num_args,
      &amp;arg_names,
      &amp;arg_type_infos,
      &amp;arg_descriptions,
      &amp;key_var_num_args);
  for (mx_uint i = 0; i &lt; num_args; ++i) {
    arg_names_.push_back(arg_names[i]);
  }
}
</code></pre>

<p>Do I need to run an initializer somewhere first to register Operators?  I cannot find documentation.</p>
","<c++><mxnet>","2018-08-07 19:01:09","","0","2421075","2018-12-01 00:20:38","0","3","","","2421075","166","1","0"
"52045999","<p>I'm trying to implement the Inception model on a Raspberry Pi using mxnet, and getting an error that I haven't been able to unravel: ""unknown activation type"".</p>

<p>I successfully installed opencv, mxnet, and all dependencies. I'm running a short <a href=""https://github.com/djpetersen/pi-vision/blob/master/camera_test.py"" rel=""nofollow noreferrer"">python script</a> which on line 19 calls a function from <a href=""https://github.com/djpetersen/pi-vision/blob/master/inception_predict.py"" rel=""nofollow noreferrer"">inception_predict</a> which in turn calls (line 74) a prediction function (forward propagation) from mxnet. Mxnet then refers to a file called <a href=""https://github.com/djpetersen/pi-vision/blob/master/activation-inl.h"" rel=""nofollow noreferrer"">activation-in.h</a> which on line 149 has a last, fatal error if it can't find the activation type (e.g., Relu, Tanh, etc) you sent in.</p>

<p>I looked at the layers in the model (visualized <a href=""https://github.com/djpetersen/pi-vision/blob/master/inception_model_layers"" rel=""nofollow noreferrer"">here</a>) and all the activation functions appear to be Relu, which, I would have thought, would work fine. </p>

<p>Am I missing something easy? </p>

<pre><code>[16:49:22] /usr/bin/incubator-mxnet/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
[16:49:22] /usr/bin/incubator-mxnet/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
/usr/bin/incubator-mxnet/python/mxnet/module/base_module.py:67: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
  warnings.warn(msg)
Capturing
Predicting
pre-processed image in 0.22853398323059082
Traceback (most recent call last):
  File ""camera_test.py"", line 19, in &lt;module&gt;
    topn = inception_predict.predict_from_local_file(filename, N=5)
  File ""/home/pi/inception_predict.py"", line 74, in predict_from_local_file
    return predict(filename, mod, synsets, N)
  File ""/home/pi/inception_predict.py"", line 48, in predict
    prob = mod.get_outputs()[0].asnumpy()
  File ""/usr/bin/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1972, in asnumpy
    ctypes.c_size_t(data.size)))
  File ""/usr/bin/incubator-mxnet/python/mxnet/base.py"", line 252, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [16:49:24] /usr/bin/incubator-mxnet/src/operator/nn/./activation-inl.h:149: unknown activation type

Stack trace returned 9 entries:
[bt] (0) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x38) [0x6ed769e0]
[bt] (1) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x30) [0x6ed77134]
[bt] (2) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::op::ActivationCompute&lt;mshadow::cpu&gt;(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)+0x288) [0x6f19e0ac]
[bt] (3) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool)+0x68) [0x6ee3de84]
[bt] (4) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(+0x4bef54) [0x6ee44f54]
[bt] (5) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x3ec) [0x6ee2a800]
[bt] (6) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#1}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;)+0xd4) [0x6ee2b0a0]
[bt] (7) /usr/bin/incubator-mxnet/python/mxnet/../../build/libmxnet.so(std::thread::_State_impl&lt;std::_Bind_simple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; &gt;::_M_run()+0x38) [0x6ee2ad28]
[bt] (8) /usr/lib/arm-linux-gnueabihf/libstdc++.so.6(+0x9c9dc) [0x6e1fb9dc]
</code></pre>

<p>There is also the following warning up front about name matching, but it doesn't seem fatal or even necessarily pertinent to having an unrecognized activation function:</p>

<pre><code>  /usr/bin/incubator-mxnet/python/mxnet/module/base_module.py:67: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
</code></pre>
","<python><raspberry-pi><mxnet><activation-function>","2018-08-27 19:40:30","","0","10267175","2018-08-27 19:40:30","0","6","","","10267175","1","0","0"
"42521822","<p>This is my first ANN so I imagine that there might be a lot of things done wrong here. I don't follow </p>

<p>I'm trying to predict species of flowers from <code>iris</code> data set provided in <code>R</code> language but I get following error:</p>

<pre><code>Error in `dimnames&lt;-.data.frame`(`*tmp*`, value = list(n)) : 
invalid 'dimnames' given for data frame
</code></pre>

<p>My code:</p>

<pre><code>require(mxnet)

train &lt;- iris[1:130,]
test  &lt;- iris[131:150,]

train.data &lt;- as.data.frame(train[-5])
train.label &lt;- data.frame(model.matrix(data=train,object =~Species-1))


test.data &lt;- as.data.frame(test[-5])
test.label &lt;- data.frame(model.matrix(data=test,object =~Species-1))


var1 &lt;- mx.symbol.Variable(""data"")

layer0 &lt;- mx.symbol.FullyConnected(var1, num.hidden=3)
cat.out &lt;- mx.symbol.SoftmaxOutput(layer0)


net.model &lt;- mx.model.FeedForward.create(cat.out,
                                     array.layout = ""auto"",
                                     X=train.data, 
                                     y=train.label,
                                     eval.data = list(data=test.data,label=test.label),
                                     num.round = 20, 
                                     array.batch.size = 20,
                                     learning.rate=0.1,
                                     momentum=0.9,
                                     eval.metric = mx.metric.accuracy)
</code></pre>

<p>UPDATE:</p>

<p>I managed to get rid of this error by specifying column to use in labels(<code>traning.label[,1]</code>and <code>test.label[,1]</code>).</p>

<p>However now I'm training my net to predict just one of my binary variables while I have 3 (one for each species).</p>
","<r><mxnet>","2017-03-01 01:50:09","","0","3324507","2017-06-22 13:10:19","1","0","","","3324507","980","46","0"
"41716657","<p>I wish to convert one of the existing pre-trained mxnet models <a href=""http://data.dmlc.ml/"" rel=""nofollow noreferrer"">available here</a> to a fully convolutional one. </p>

<p>This means being able to input an image of any size, specifying the stride, and getting a full output.
For instance, assume the model was trained on 224x224x3 images. I want to input an image which is 226x226x3 and specify stride=1, in order to get a 3x3xnum-classes output.
I'm not asking ""theoretically"", but rather for an example code :-)</p>

<p>Thanks!</p>
","<mxnet>","2017-01-18 10:16:04","","1","828368","2017-01-19 00:59:43","1","0","","","828368","602","431","6"
"50545193","<p>when i <code>import mxnet</code> using <code>import mxnet as mx</code> in intellij (python) then compier generate error </p>

<blockquote>
  <p>OSError: [WinError 126] The specified module could not be found"" </p>
</blockquote>

<p>and shows trackcall shows </p>

<blockquote>
  <p>line 1 ""import mxnet as mx"" in test.python 
  mxnet already in env/lib</p>
</blockquote>
","<python><intellij-idea><mxnet>","2018-05-26 17:07:59","","0","4980294","2018-06-08 18:02:20","1","2","","","4980294","1","0","0"
"50898130","<p>I am trying to set up a neural network using Gluon and mxnet to implement the fizzbuzz program. However, it is giving me a weird result; the accuracy of the training data(35-42%) is significantly worse than the accuracy of the testing data(97-99%). I have used the numbers 101 through 1024 as the training dataset and the numbers 1 through 100 as the testing dataset. </p>

<p>So, why is the accuracy of the training data worse than that of the testing data? Isn't it supposed to be the other way round?</p>

<p>My code:</p>

<pre><code>import numpy as np
from mxnet import gluon, nd, autograd
import mxnet as mx

ctx = mx.cpu()
mx.random.seed(1)

def binary_encode(i, digits):
    return np.array([i&gt;&gt;d&amp;1 for d in range(digits)])
def fizzbuzz_encode(i):
    if i%15 == 0:
        return np.array([0, 0, 0, 1])
    elif i%5 == 0:
        return np.array([0, 0, 1, 0])
    elif i%3 == 0:
        return np.array([0, 1, 0, 0])
    else:
        return np.array([1, 0, 0, 0])

def fizzbuzz_decode(i, pred):
    if pred == 0:
        return i
    elif pred == 1:
        return 'fizz'
    elif pred == 2:
        return 'buzz'
    else:
        return 'fizzbuzz'

num_digits = 10         #number of digits in the input

trX = np.array([binary_encode(i, num_digits) for i in range(101, 2**num_digits)])
trY = np.array([fizzbuzz_encode(i) for i in range(101, 2**num_digits)])
tr_dataset = gluon.data.dataset.ArrayDataset(trX, trY)          #training dataset

testX = np.array([binary_encode(i, num_digits) for i in range(1, 101)])
testY = np.array([fizzbuzz_encode(i) for i in range(1, 101)])
test_dataset = gluon.data.dataset.ArrayDataset(testX, testY)    #testing dataset

hidden_layers = 1       #number of hidden layers
hidden_units = 100      #number of nodes in a hidden layer
batch_size = 32

train_data = gluon.data.DataLoader(tr_dataset, batch_size, shuffle=False)
test_data = gluon.data.DataLoader(test_dataset, batch_size, shuffle=False)

net = gluon.nn.Sequential()                                         #making the neural net
with net.name_scope():
    net.add(gluon.nn.Dense(hidden_units, activation='relu'))        #hidden layer
    net.add(gluon.nn.Dense(4))                                      #output layer

net.collect_params().initialize(mx.init.Normal(sigma=0.01), ctx=ctx)                #setting the initial weights and biases
softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)      #loss function (Softmax Cross Entropy)
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':0.05})        #setting up the optimizer (Stochastic Gradient Descent)

epochs = 1000

for e in range(epochs):                             #training procedure
    cumulative_loss = 0
    for i, (data, label) in enumerate(train_data):
        data = data.as_in_context(ctx)
        data = data.astype(np.float32)
        label = label.as_in_context(ctx)
        label = label.astype(np.float32)
        with autograd.record():
            output = net(data)
            loss = softmax_cross_entropy(output, label)
        loss.backward()
        trainer.step(data.shape[0])
        cumulative_loss += nd.sum(loss).asscalar()

prediction = []
correct = []

for i, (data, label) in enumerate(test_data):
    data = data.as_in_context(ctx)
    data = data.astype(np.float32)
    for j in net(data):
        prediction.append(fizzbuzz_decode(len(prediction)+1, nd.argmax(j, axis=0)))     #prediction array

for i in prediction:
    print(i)                                    #prints the final output

for i, val in enumerate(testY):
    correct.append(fizzbuzz_decode(i+1, np.argmax(val, axis=0)))

accuracy = 0

for i in range(100):
    if prediction[i]==correct[i]:
        accuracy+=1

print('\nThe acuuracy of the training data is ' + str(accuracy) + '%')
</code></pre>
","<machine-learning><deep-learning><mxnet>","2018-06-17 15:39:00","","-1","9953412","2018-06-18 20:53:17","1","2","","","9953412","1","0","0"
"47266456","<p>I am trying to reproduce an example from ND Lewis: Neural Networks for time series forecasting with R. If I include the device argument I get the error:</p>

<pre><code>Error in mx.opt.sgd(...) : 
  unused argument (device = list(device = ""cpu"", device_id = 0, device_typeid = 1))
In addition: Warning message:
In mx.model.select.layout.train(X, y) :
  Auto detect layout of input matrix, use rowmajor..
</code></pre>

<p>If I remove this parameter, I still get this warning:</p>

<pre><code>Warning message:
In mx.model.select.layout.train(X, y) :
  Auto detect layout of input matrix, use rowmajor..
</code></pre>

<p>The code is:</p>

<pre><code>library(zoo)
library(quantmod)
library(mxnet)

# data
data(""ecoli"", package = ""tscount"")
data &lt;- ecoli$cases
data &lt;- as.zoo(ts(data, start = c(2001, 1), end = c(2013, 20), frequency = 52))
xorig &lt;- do.call(cbind, lapply((1:4), function(x) as.zoo(Lag(data, k = x))))
xorig &lt;- cbind(xorig, data) 
xorig &lt;- xorig[-(1:4), ]

# normalization
range_data &lt;- function(x) {
  (x - min(x))/(max(x) - min(x))
}
xnorm &lt;- data.matrix(xorig)
xnorm &lt;- range_data(xnorm)

# test/train
y &lt;- xnorm[, 5]
x &lt;- xnorm[, -5]
n_train &lt;- 600
x_train &lt;- x[(1:n_train), ]
y_train &lt;- y[(1:n_train)]
x_test &lt;- x[-(1:n_train), ]
y_test &lt;- y[-(1:n_train)]

# mxnet:
mx.set.seed(2018) 
model1 &lt;- mx.mlp(x_train,
                 y_train,
                 hidden_node = c(10, 2),
                 out_node = 1,
                 activation = ""sigmoid"",
                 out_activation = ""rmse"",
                 num.round = 100,
                 array.batch.size = 20, 
                 learning.rate = 0.07,
                 momentum = 0.9
                 #, device = mx.cpu()
)
pred1_train &lt;- predict(model1, x_train, ctx = mx.cpu())
</code></pre>

<p>How can I fix this?</p>
","<r><mxnet>","2017-11-13 14:19:04","","0","6162011","2017-11-17 19:44:45","1","0","","","6162011","2329","1332","3"
"51197275","<p>When I run an R script to generate a model through machine learning frameworks like <code>mxnet</code> and <code>tensorflow</code>, I see in task manager that the cpu usage reaches 100%.
I have 2x 2.7 ghz and the pc becomes too slow until it blocks.</p>

<p>Is there a method to limit cpu usage in R with a slower model training time?</p>
","<r><cpu><mxnet>","2018-07-05 17:49:02","","0","9144796","2018-08-31 21:07:17","2","4","","","9144796","30","1","0"
"55874736","<p>I am trying to modify a model I found online (<a href=""https://github.com/apache/incubator-mxnet/tree/master/example/multivariate_time_series"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/tree/master/example/multivariate_time_series</a>) as I work to get to know <code>mxnet</code>. I am trying to build a model that takes both a CNN and RNN network in parallel and then uses the outputs of both to forecast a time series. However, I am running into this error</p>

<blockquote>
  <p>RuntimeError: simple_bind error. Arguments: data: (128, 96, 20)
  softmax_label: (128, 20) Error in operator concat1: [15:44:09]
  src/operator/nn/concat.cc:66: Check failed:
  shape_assign(&amp;(*in_shape)[i], dshape) Incompatible input shape:
  expected [128,0], got [128,96,300]</p>
</blockquote>

<p>This is the code, as I have tried to modify it:</p>

<pre><code>def rnn_cnn_model(iter_train, q, filter_list, num_filter, dropout, seasonal_period, time_interval):


# Choose cells for recurrent layers: each cell will take the output of the previous cell in the list
rcells = [mx.rnn.GRUCell(num_hidden=args.recurrent_state_size)]
skiprcells = [mx.rnn.LSTMCell(num_hidden=args.recurrent_state_size)]


input_feature_shape = iter_train.provide_data[0][1]
X = mx.symbol.Variable(iter_train.provide_data[0].name)
Y = mx.sym.Variable(iter_train.provide_label[0].name)

# reshape data before applying convolutional layer (takes 4D shape incase you ever work with images)
rnn_input = mx.sym.reshape(data=X, shape=(0, q, -1))

###############
# RNN Component
###############
stacked_rnn_cells = mx.rnn.SequentialRNNCell()
for i, recurrent_cell in enumerate(rcells):
    stacked_rnn_cells.add(recurrent_cell)
    stacked_rnn_cells.add(mx.rnn.DropoutCell(dropout))
outputs, states = stacked_rnn_cells.unroll(length=q, inputs=rnn_input, merge_outputs=False)
rnn_features = outputs[-1] #only take value from final unrolled cell for use later

input_feature_shape = iter_train.provide_data[0][1]
X = mx.symbol.Variable(iter_train.provide_data[0].name)
Y = mx.sym.Variable(iter_train.provide_label[0].name)

# reshape data before applying convolutional layer (takes 4D shape incase you ever work with images)
conv_input = mx.sym.reshape(data=X, shape=(0, 1, q, -1))

###############
# CNN Component
###############
outputs = []
for i, filter_size in enumerate(filter_list):
    # pad input array to ensure number output rows = number input rows after applying kernel
    padi = mx.sym.pad(data=conv_input, mode=""constant"", constant_value=0,
                      pad_width=(0, 0, 0, 0, filter_size - 1, 0, 0, 0))
    convi = mx.sym.Convolution(data=padi, kernel=(filter_size, input_feature_shape[2]), num_filter=num_filter)
    acti = mx.sym.Activation(data=convi, act_type='relu')
    trans = mx.sym.reshape(mx.sym.transpose(data=acti, axes=(0, 2, 1, 3)), shape=(0, 0, 0))
    outputs.append(trans)
cnn_features = mx.sym.Concat(*outputs, dim=2)
cnn_reg_features = mx.sym.Dropout(cnn_features, p=dropout)
c_features = mx.sym.reshape(data = cnn_reg_features, shape = (-1))
print(type(c_features))
######################
# Prediction Component
######################

print(rnn_features.infer_shape())   
neural_components = mx.sym.concat(*[rnn_features, c_features], dim=1)
neural_output = mx.sym.FullyConnected(data=neural_components, num_hidden=input_feature_shape[2])
model_output = neural_output
loss_grad = mx.sym.LinearRegressionOutput(data=model_output, label=Y)
return loss_grad, [v.name for v in iter_train.provide_data], [v.name for v in iter_train.provide_label]
</code></pre>

<p>and I believe the crash is happening on this line of code</p>

<pre><code>neural_components = mx.sym.concat(*[rnn_features, c_features], dim=1)
</code></pre>

<p>Here is what I have tried in an effort to get my dimensions to match up:</p>

<ul>
<li><code>c_features = mx.sym.reshape(data = cnn_reg_features, shape = (-1))</code></li>
<li><code>c_features = cnn_reg_features[-1]</code></li>
<li><code>c_features = cnn_reg_features[:, -1, :]</code></li>
</ul>

<p>I also tried to look at the git issues and Google around, but all I see is advice to use <code>infer_shape</code>. I tried applying this to <code>c_features</code>, but the output was not clear to me</p>

<pre><code>data: ()
gru_i2h_weight: ()
gru_i2h_bias: ()
</code></pre>

<p>Basically, I would like to know at each stage as this graph is built what the shape of the symbol is. I am used to this capability in Tensorflow, which makes it easier to build and debug graphs when one has gone astray in doing an incorrect reshape, or simply for getting the sense of how a model works by looking at its dimension. Is there no equivalent opportunity in <code>mxnet</code>? </p>

<p>Given that the <code>data_iter</code> is fed in when producing these <code>symbols</code> I would think the inferred shape should be available. Ultimately my questions are (1) how can I see that shape of a symbol when it uses the data in the iterator and should know all shapes? (2) general guidelines on debugging in this sort of situation?</p>

<p>Thank you.</p>
","<python><mxnet>","2019-04-26 20:46:53","","0","11417657","2019-04-26 21:10:15","0","0","","","11417657","1","0","0"
"42304820","<p>I am new to neural networks and the <code>mxnet</code> package in R. I want to do a logistic regression on my predictors since my observations are probabilities varying between 0 and 1. I'd like to weight my observations by a vector <code>obsWeights</code> I have, but I'm not sure where to implement the weights. There seems to be a <code>weight=</code> option in <code>mx.symbol.FullyConnected</code> but if I try <code>weight=obsWeights</code> I get the following error message </p>

<pre><code>Error in mx.varg.symbol.FullyConnected(list(...)) : 
  Cannot find argument 'weight', Possible Arguments:
----------------
num_hidden : int, required
  Number of hidden nodes of the output.
no_bias : boolean, optional, default=False
  Whether to disable bias parameter.
</code></pre>

<p>How should I proceed to weight my observations? Here is my code at the moment.</p>

<pre><code># Prepare data
train.mm = model.matrix(obs ~ . , data = train_data)
train_label = train_data$obs

# Normalize
train.mm = apply(train.mm, 2, function(x) (x-min(x))/(max(x)-min(x)))

# Create MXDataIter compatible iterator
batch_size = 128
train.iter = mx.io.arrayiter(data=t(train.mm), label=train_label, 
                               batch.size=batch_size, shuffle=T)

# Symbolic model definition
data = mx.symbol.Variable('data')
fc1 = mx.symbol.FullyConnected(data=data, num.hidden=128, name='fc1')
act1 = mx.symbol.Activation(data=fc1, act.type='relu', name='act1')
final = mx.symbol.FullyConnected(data=act1, num.hidden=1, name='final')
logistic = mx.symbol.LogisticRegressionOutput(data=final, name='logistic')

# Run model
mxnet_train = mx.model.FeedForward.create(
                symbol = logistic,
                X = train.iter,
                initializer = mx.init.Xavier(rnd_type = 'gaussian', factor_type = 'avg', magnitude = 2),
                num.round = 25)
</code></pre>
","<r><mxnet>","2017-02-17 18:14:53","","1","3072058","2017-02-19 03:33:17","1","0","3","","3072058","268","113","2"
"46460492","<p>I am using MXNet to finetune Resnet model on Caltech 256 dataset from the following example:</p>

<p><a href=""https://mxnet.incubator.apache.org/how_to/finetune.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/how_to/finetune.html</a></p>

<p>I am primarily doing it for a POC to test distributed training (which I'll later use in my actual project). </p>

<p>First I ran this example on a single machine with 2 GPUs for 8 epochs. I took around 20 minutes and the final validation accuracy was 0.809072.</p>

<p>Then I ran it on 2 machines (identical, each with 2 GPUs) with distributed setting and partitioned the training data in half for these two machines (using <code>num_parts</code> and <code>part_index</code>). </p>

<p>8 epochs took only 10 minutes, but the final validation accuracy was only 0.772847 (highest of the two). Even when I used 16 epochs, I was only able to achieve 0.797006.</p>

<p>So my question is that is it normal? I primarily want to use distributed training to reduce training time. But if it takes twice or more epochs to achieve the same accuracy, then what's the advantage? Maybe I am missing something.</p>

<p>I can post my code and run command if required.</p>

<p>Thanks  </p>

<p>EDIT</p>

<p>Some more info to help with the answer:</p>

<p><strong>MXNet version:</strong> 0.11.0</p>

<p><strong>Topology:</strong> 2 workers (each on a separate machine)</p>

<p><strong>Code:</strong> <a href=""https://gist.github.com/reactivefuture/2a1f9dcd3b27c0fe8215b4e3d25056ce"" rel=""nofollow noreferrer"">https://gist.github.com/reactivefuture/2a1f9dcd3b27c0fe8215b4e3d25056ce</a></p>

<p><strong>Command to start:</strong></p>

<p><code>python3 mxnet/tools/launch.py -n 2 -H hosts --sync-dst-dir /tmp/mxnet python3 training.py --kv-store dist_sync --gpus 0,1</code></p>

<p>I have used a hacky way to do partitioning (using IP addresses) since I couldn't get <code>kv.num_workers</code> and <code>kv.rank</code> to work. </p>
","<deep-learning><mxnet>","2017-09-28 03:26:55","","0","885119","2017-10-03 17:08:47","1","1","","","885119","3031","35","2"
"44473612","<p>I'm using mxnet's fine-tune example to fine-tune my own data with this code: </p>

<p><a href=""https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/blob/master/example/image-classification/fine-tune.py</a></p>

<p>By viewing common/fit.py, I got no idea of how to save temp model when I fine tuning.</p>

<p>For example, I wanna save .params files every 5000 iters, how can I do it?
THX!</p>
","<mxnet>","2017-06-10 13:03:16","","0","8141434","2017-06-13 06:16:14","1","0","","","8141434","13","0","0"
"39595084","<p>I would like to fit an LSTM model using MXNET in R for the purpose of predicting a continuous response (i.e., regression) given several continuous predictors. However, the mx.lstm() function seems to be geared toward NLP as it requires arguments which don't seem applicable to a regression problem (such as those related to embedding).</p>

<p>Is MXNET capable of this sort of modeling and, if not, what is an example of an appropriate tool (preferably in R)? Are there any tutorials relevant to the problem I've described?</p>
","<r><machine-learning><neural-network><regression><mxnet>","2016-09-20 13:11:54","","2","793362","2018-03-07 18:05:40","1","0","1","","793362","221","35","0"
"48772848","<p>i am wanted to experiment with the MxNet library and built a simple neural network which learns the XOR function. I am facing the problem, that the model is not learning.</p>

<p>Here is the complete script:</p>

<pre><code>library(mxnet)

train = matrix(c(0,0,0,
                 0,1,1,
                 1,0,1,
                 1,1,0),
               nrow=4,
               ncol=3,
               byrow=TRUE)

train.x = train[,-3]
train.y = train[,3]

data &lt;- mx.symbol.Variable(""data"")
fc1 &lt;- mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=2)
act1 &lt;- mx.symbol.Activation(fc1, name=""relu1"", act_type=""relu"")
fc2 &lt;- mx.symbol.FullyConnected(act1, name=""fc2"", num_hidden=3)
act2 &lt;- mx.symbol.Activation(fc2, name=""relu2"", act_type=""relu"")
fc3 &lt;- mx.symbol.FullyConnected(act2, name=""fc3"", num_hidden=1)
softmax &lt;- mx.symbol.SoftmaxOutput(fc3, name=""sm"")

mx.set.seed(0)
model &lt;- mx.model.FeedForward.create(
  softmax,
  X = t(train.x),
  y = train.y,
  num.round = 10,
  array.layout = ""columnmajor"",
  learning.rate = 0.01,
  momentum = 0.4,
  eval.metric = mx.metric.accuracy,
  epoch.end.callback = mx.callback.log.train.metric(100))

predict(model,train.x,array.layout=""rowmajor"")
</code></pre>

<p>An this output is produced:</p>

<pre><code>Start training with 1 devices
[1] Train-accuracy=NaN
[2] Train-accuracy=0.5
[3] Train-accuracy=0.5
[4] Train-accuracy=0.5
[5] Train-accuracy=0.5
[6] Train-accuracy=0.5
[7] Train-accuracy=0.5
[8] Train-accuracy=0.5
[9] Train-accuracy=0.5
[10] Train-accuracy=0.5

&gt; predict(model,train.x,array.layout=""rowmajor"")
[,1] [,2] [,3] [,4]
[1,]    1    1    1    1
</code></pre>

<p>How should I use mxnet to get this example working?</p>

<p>Regards,
vaka</p>
","<r><neural-network><mxnet>","2018-02-13 17:58:00","","0","7946228","2018-02-17 00:01:37","2","0","1","","7946228","18","2","0"
"46942883","<p>I am having trouble installing mxnet GPU for R on Amazon deep learning linux AMI. The environment variables are such a mess that it’s a nightmare for any non-expert sys-admin to figure out. </p>

<p>Step 1: install the ridiculous amount of missing/broken programs and R packages</p>

<pre><code>sudo yum install R
sudo yum install libxml2-devel   
sudo yum install cairo-devel
sudo yum install giflib-devel
sudo yum install libXt-devel
sudo R
install.packages(""devtools"")
library(devtools)
install_github(""igraph/rigraph"")
install.packages(‘DiagrammeR’) 
install.packages(‘roxygen2’)
install.packages(‘rgexf’)
install.packages(‘influenceR’)
install.packages(‘Cairo’)
install.packages(“imager”)
</code></pre>

<p>Step 2: edit the config.mk file</p>

<pre><code>cd /src/mxnet
cp make/config.mk .
echo ""USE_BLAS=openblas"" &gt;&gt;config.mk
echo ""ADD_CFLAGS += -I/usr/include/openblas"" &gt;&gt;config.mk
echo ""ADD_LDFLAGS += -lopencv_core -lopencv_imgproc -lopencv_imgcodecs"" &gt;&gt;config.mk
echo ""USE_CUDA=1"" &gt;&gt;config.mk
echo ""USE_CUDA_PATH=/usr/local/cuda"" &gt;&gt;config.mk
echo ""USE_CUDNN=1"" &gt;&gt;config.mk
</code></pre>

<p>*note even though the USE_CUDA_PATH is set, it STILL cannot find libcudart.so and needs to be linked in the make command (shown later)</p>

<p>Step 3: make new config file so make command can find libcudart.so</p>

<pre><code>/etc/ld.so.conf.d/cuda.conf
</code></pre>

<p>add /usr/local/cuda-8.0/lib64</p>

<pre><code>sudo ldconfig
</code></pre>

<ul>
<li>note this was posted by nvidia but does absolutely nothing to help the make rpkg</li>
</ul>

<p>Step 4: set up R directories </p>

<pre><code>Rscript -e ""install.packages('devtools', repo = 'https://cran.rstudio.com')""
cd R-package
Rscript -e ""library(devtools); library(methods); options(repos=c(CRAN='https://cran.rstudio.com'));
</code></pre>

<p>install_deps(dependencies = TRUE)""
    cd ..</p>

<p>step 5: make </p>

<pre><code>cd /src/mxnet
sudo make -j8
</code></pre>

<p>Result: </p>

<p>make CXX=g++ DEPS_PATH=/home/ec2-user/src/mxnet/deps -C /home/ec2-user/src/mxnet/ps-lite ps
cd /home/ec2-user/src/mxnet/dmlc-core; make libdmlc.a USE_SSE=1 config=/home/ec2-user/src/mxnet/config.mk; cd /home/ec2-user/src/mxnet
make[1]: Entering directory <code>/home/ec2-user/src/mxnet/dmlc-core'
make[1]:</code>libdmlc.a' is up to date.
make[1]: Leaving directory <code>/home/ec2-user/src/mxnet/dmlc-core'
make[1]: Entering directory</code>/home/ec2-user/src/mxnet/ps-lite'
make[1]: Nothing to be done for <code>ps'.
make[1]: Leaving directory</code>/home/ec2-user/src/mxnet/ps-lite'
ar crv lib/libmxnet.a</p>

<p>*note, even when changing the config.mk file, the make command always returns ‘nothing to update’</p>

<p>Step 6: attempt to make rpkg</p>

<pre><code>Cd /src/mxnet
Sudo make rpkg
</code></pre>

<p>Error: 
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/usr/lib64/R/library/mxnet/libs/libmxnet.so':
  libcudart.so.8.0: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted
ERROR: loading failed</p>

<p>So it’s looking in a location that doesn’t exist: /usr/lib64/R/library/mxnet/libs/
When the file actually lives: 
/home/ec2-user/src/mxnet/R-package/inst/libs/libmxnet.so
or
/home/ec2-user/src/mxnet/lib/libmxnet.so</p>

<p>What I’ve tried so far:</p>

<pre><code>sudo LD_LIBRARY_PATH=/usr/local/cuda/lib64 make rpkg
</code></pre>

<p>This will fix the missing libcudart.so.8.0 issue but it is simply replace with:
libmklml_intel.so: cannot open shared object file: No such file or directory as well as the original ‘cannot find libmxnet.so </p>

<p>Also tried:
1. actually creating directories (/usr/lib64/R/library/mxnet/libs/) and then copying libmxnet.so there
Result: same error</p>

<ol start=""2"">
<li><p>adding /home/ec2-user/src/mxnet/R-package/inst/libs/ to the make command
sudo LD_LIBRARY_PATH=/home/ec2-user/src/mxnet/R-package/inst/libs make rpkg
Result: same error</p></li>
<li><p>a ridiculous amount of environment labels all of which failed:</p>

<p>export MXNET_HOME=/usr/lib64/R/library/mxnet/libs/
export MXNET_HOME=/usr/lib64/R/library/mxnet/libs/libmxnet.so<br>
sudo ldconfig /usr/local/cuda/lib64
sudo ln -s /usr/lib64/R/library/mxnet/libs /usr/lib
sudo ln -s /usr/lib64/R/library/mxnet/libs/libmxnet.so /usr/lib
sudo ln -s /usr/local/lib/libmklml_intel.so /usr/lib
sudo ln -s /usr/local/lib/libiomp5.so /usr/lib
sudo ln -s /usr/local /usr/lib
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/libcudart.so.8.0
export LD_LIBRARY_PATH=/usr/lib64/R/library/mxnet/libs/libmxnet.so /usr/lib
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/libcudart.so.8.0</p></li>
</ol>

<p>In all ONE of these worked, because I briefly got mxnet R package working before it fell apart again. I’ve dropped 50+ hours into this installation, which, frankly is ridiculous. Tougher to install the software then it is to program an actual net....</p>

<p>I don’t have 5+ years of linux sys admin knowledge so if you’d like please be a bit more helpful then ‘fix environment variables.’ I can tell that’s obviously what’s wrong yet have no idea what ‘fix environment variables’ entails. </p>

<p>To top it off, even after successful install of the R package, it STILL won’t work until setting Rstudio server’s config file to: rsession-ld-library-path=/opt/local/lib:/usr/local/cuda/lib64</p>
","<r><linux><amazon-ec2><mxnet>","2017-10-25 22:14:36","","1","8268013","2017-10-25 23:58:27","1","0","","","8268013","142","18","5"
"47745819","<p>I think
Models listed on 
<a href=""https://mxnet.incubator.apache.org/model_zoo/"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/model_zoo/</a>
is free to use as basis of fine tuning. Am I right?
Is there any license problem or condition using these models (VGG16,ResidualNet152,etc)</p>
","<model><zoo><mxnet>","2017-12-11 02:53:42","","-1","8175589","2017-12-11 19:10:28","1","1","","","8175589","1","0","0"
"55414260","<p>I'm creating own SSD model using own pascal VOC dataset. How to fix the error in MultiBoxTarget.</p>

<p>checked this program with built-in dataset(pikachu) in my past while doing with own dataset it led to error</p>

<p>here I call the function (<strong>training_target</strong>)</p>

<pre><code> import time
 from mxnet import autograd as ag
 for epoch in range(start_epoch, epochs):
# reset iterator and tick

     cls_metric.reset()
     box_metric.reset()
     tic = time.time()
     # iterate through all batch
     for i, batch in enumerate(train_data):
         btic = time.time()
         # record gradients
         with ag.record():
             x = batch[0].as_in_context(ctx)
             y = batch[1].as_in_context(ctx)
             default_anchors, class_predictions, box_predictions = net(x)
             box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, y)
             # losses
             loss1 = cls_loss(class_predictions, cls_target)
             loss2 = box_loss(box_predictions, box_target, box_mask)
             # sum all losses
             loss = loss1 + loss2
             # backpropagate
             loss.backward()
         # apply
         trainer.step(batch_size)
         # update metrics
         cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])
         box_metric.update([box_target], [box_predictions * box_mask])
         if (i + 1) % log_interval == 0:
             name1, val1 = cls_metric.get()
             name2, val2 = box_metric.get()
             print('[Epoch %d Batch %d] speed: %f samples/s, training: %s=%f, %s=%f'
                   %(epoch ,i, batch_size/(time.time()-btic), name1, val1, name2, val2))

     # end of epoch logging
     name1, val1 = cls_metric.get()
     name2, val2 = box_metric.get()
     print('[Epoch %d] training: %s=%f, %s=%f'%(epoch, name1, val1, name2, val2))
     print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))
</code></pre>

<p>function training_targets defined where in <strong>MultiBoxTarget</strong> I got the error:</p>

<pre><code>from mxnet.contrib.ndarray import MultiBoxTarget
def training_targets(default_anchors, class_predicts, labels):
       class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))
       z = MultiBoxTarget(*[default_anchors, labels, class_predicts])
       box_target = z[0]  # box offset target for (x, y, width, height)
       box_mask = z[1]  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples
       cls_target = z[2]  # cls_target is an array of labels for all anchors boxes
       return box_target, box_mask, cls_target
</code></pre>

<p>expected output: training of model and saving the  net.save_parameters('ssd_%d.params' % epochs)</p>

<p>actual output:</p>

<pre><code> MXNetError                       Traceback (most recent call last)
 &lt;ipython-input-80-6e8fe42e4df5&gt; in &lt;module&gt;()
 16             default_anchors, class_predictions, box_predictions = net(x)
 17             print(y.shape)
 ---&gt; 18             box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, y)
 19             # losses
 20             loss1 = cls_loss(class_predictions, cls_target)

 &lt;ipython-input-68-866caabcf8c9&gt; in training_targets(default_anchors, class_predicts, labels)
  2 def training_targets(default_anchors, class_predicts, labels):
  3     class_predicts = nd.transpose(class_predicts, axes=(0, 2,                     
  1))
 ----&gt; 4     z = MultiBoxTarget(*[default_anchors, labels, class_predicts])
  5     box_target = z[0]  # box offset target for (x, y, width, height)
  6     box_mask = z[1]  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples

 /usr/local/lib/python3.6/dist-packages/mxnet/ndarray/register.py in MultiBoxTarget(anchor, label, cls_pred, overlap_threshold, ignore_label, negative_mining_ratio, negative_mining_thresh, minimum_negative_samples, variances, out, name, **kwargs)

 /usr/local/lib/python3.6/dist-packages/mxnet/_ctypes/ndarray.py in _imperative_invoke(handle, ndargs, keys, vals, out)
 90         c_str_array(keys),
 91         c_str_array([str(s) for s in vals]),
 ---&gt; 92         ctypes.byref(out_stypes)))
 93 
 94     if original_output is not None:

 /usr/local/lib/python3.6/dist-packages/mxnet/base.py in check_call(ret)
250     """"""
251     if ret != 0:
 --&gt; 252         raise MXNetError(py_str(_LIB.MXGetLastError()))
253 
254 

 **MXNetError: [08:50:36] include/mxnet/operator.h:228: Check failed: in_type-&gt;at(i) == mshadow::default_type_flag || in_type-&gt;at(i) == -1 Unsupported data type 1**

 Stack trace returned 10 entries:
 [bt] (0) /usr/local/lib/python3.6/dist-          
  packages/mxnet/libmxnet.so(+0x23d55a) [0x7f454cf5555a]
 [bt] (1) /usr/local/lib/python3.6/dist-          
   packages/mxnet/libmxnet.so(+0x23dbc1) [0x7f454cf55bc1]
 [bt] (2) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2fb9dd) [0x7f454d0139dd]
 [bt] (3) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2e0c0b5) [0x7f454fb240b5]
 [bt] (4) /usr/local/lib/python3.6/dist-     packages/mxnet/libmxnet.so(mxnet::imperative::SetShapeType(mxnet::Context const&amp;, nnvm::NodeAttrs const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, mxnet::DispatchMode*)+0x1274) [0x7f454f936814]
 [bt] (5) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&amp;, nnvm::NodeAttrs const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;)+0x309) [0x7f454f9400b9]
 [bt] (6) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x2b2d8b9) [0x7f454f8458b9]
 [bt] (7) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f454f845eaf]
 [bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f45761e6dae]
 [bt] (9) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f45761e671f]
</code></pre>
","<python><dataset><conv-neural-network><mxnet>","2019-03-29 09:29:33","","0","11191937","2019-03-29 09:29:33","0","0","","","11191937","6","0","0"
"53940367","<p>I started my mxnet package installation for R in ubuntu with the following command</p>

<pre><code>install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
</code></pre>

<p>while executing this command I got the following warning</p>

<pre><code>Warning in install.packages :
  package ‘mxnet’ is not available (for R version 3.4.4)
</code></pre>

<p>Then I went for the command </p>

<pre><code>cran &lt;- getOption(""repos"")
cran[""dmlc""] &lt;- ""https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/""
options(repos = cran)
install.packages(""mxnet"",dependencies = T)
</code></pre>

<p>At that time I got the warning </p>

<pre><code>Warning in install.packages :
  download of package ‘mxnet’ failed
</code></pre>

<p>For the first time I got installed the package ,but when I calling <code>library(mxnet)</code> I got the waring Error in <code>library(mxnet) : there is no package called ‘mxnet’</code>.After that I tried the same command above again ,at that time I got this error </p>

<pre><code>Warning in install.packages :
      download of package ‘mxnet’ failed
</code></pre>

<p>Please help me to solve this problem..</p>
","<r><classification><mxnet>","2018-12-27 05:56:37","","0","10323723","2018-12-27 07:00:46","2","0","","","10323723","19","4","0"
"41519677","<p>I try to reimplement the Gaussian simulator described in the GANs paper with mxnet. </p>

<p>But there are two problems in my <a href=""https://github.com/HuitingLiu/mxnet_demo/blob/master/gans.py"" rel=""nofollow noreferrer"">code</a>. </p>

<p>First, the model doesn't converge very well, even after I try to set a learning rate scheduler.</p>

<p><a href=""https://i.stack.imgur.com/ikAlh.png"" rel=""nofollow noreferrer"">This is how it looks like after about 500 epochs and the accuracy is bouncing around 0.5 ~ 0.6.</a></p>

<p>Second, I don't know how to draw the output of the discriminative model. The current curve doesn't look like the one described in the paper. </p>

<p>Could anyone please offer any suggestion? </p>
","<mxnet>","2017-01-07 09:00:46","","0","7386279","2017-01-08 12:10:26","1","0","","","7386279","11","0","0"
"41365542","<p>After using the mx.io.ImageRecordIter() to load my training examples, is there a way to retrieve the total number of examples from the returned DataIter object ? </p>

<p>Many thanks, </p>
","<mxnet>","2016-12-28 15:57:49","","0","7350566","2016-12-29 00:14:45","1","1","","","7350566","24","2","0"
"47362383","<p>I want to develop own chatbot for my retail store project. I have checked different frameworks like API.AI (DialogFlow), LUIS, WIT.AI and Whatsan virtual agent. But I also come across <a href=""https://mxnet.incubator.apache.org/"" rel=""nofollow noreferrer"">MXNet</a>. So if I develop my own chatbot using MxNet then what will be advantageous over other above discussed inbuilt API</p>
","<luis><wit.ai><mxnet><dialogflow>","2017-11-18 04:06:14","","-3","996787","2017-11-23 04:08:27","2","1","","2017-11-28 00:38:23","996787","2220","155","15"
"47988436","<p>When using mxnet, after building and training a module <code>mod</code>, I called the method <code>mod.get_params()</code> to inspect the weights and bias of the model.</p>

<p>However, I found that even if I set the context to <code>mx.gpu(0)</code> when creating the module, the outputs of the <code>get_params</code> method always show that the parameters (weights and bias) are on <code>cpu(0)</code>. See below:</p>

<p><a href=""https://i.stack.imgur.com/483LE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/483LE.png"" alt=""results of get_params""></a></p>

<p>I wonder whether the weights were really on cpu, so I timed the program and found that, it was in fact much faster if I set the context to <code>gpu(0)</code> than to <code>cpu(0)</code>. Therefore, I think the weights were in fact on gpu, otherwise the training wouldn't be so fast. But, why did the <code>get_params</code> method show that my weights were on cpu?</p>
","<deep-learning><mxnet>","2017-12-27 07:57:57","","0","9144124","2018-02-24 00:25:32","1","0","","","9144124","1","0","0"
"47897924","<p>When I use the function <code>UpSampling</code> (python, mxnet version:  1.0.0) with nearest interpolation, everything goes normal (prints upscaled output shape): </p>

<pre class=""lang-py prettyprint-override""><code>nfilters = 16
xx = nd.random_normal(shape=[2,nfilters,64,64],ctx=mx.cpu())
print xx.asnumpy().shape
temp = nd.UpSampling(xx,scale=2,sample_type='nearest')
print temp.asnumpy().shape
</code></pre>

<p>when I try to perform the same action with sample_type = 'bilinear' I get errors: 
</p>

<pre><code>nfilters = 16
xx = nd.random_normal(shape=[2,nfilters,64,64],ctx=mx.cpu())
print xx.asnumpy().shape
temp = nd.UpSampling(xx,scale=2,sample_type='bilinear')
print temp.asnumpy().shape
</code></pre>

<p>any pointers/ideas on what I am doing wrong? I need it to work correctly for both ndarray and mx.sym (but I assume should be the same for both). </p>

<h2>Error Message:</h2>

<pre><code>---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
&lt;ipython-input-57-7b8d60ea54bb&gt; in &lt;module&gt;()
      3 xx = nd.random_normal(shape=[2,nfilters,64,64],ctx=mx.cpu())
      4 print xx.asnumpy().shape
----&gt; 5 temp = mx.nd.UpSampling(xx,scale=2,sample_type='bilinear')
      6 print temp.asnumpy().shape

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/ndarray/register.pyc in UpSampling(*data, **kwargs)

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/_ctypes/ndarray.pyc in _imperative_invoke(handle, ndargs, keys, vals, out)
     90         c_str_array(keys),
     91         c_str_array([str(s) for s in vals]),
---&gt; 92         ctypes.byref(out_stypes)))
     93 
     94     if original_output is not None:

/home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/base.pyc in check_call(ret)
    144     """"""
    145     if ret != 0:
--&gt; 146         raise MXNetError(py_str(_LIB.MXGetLastError()))
    147 
    148 

MXNetError: [17:20:11] src/c_api/../imperative/imperative_utils.h:303: Check failed: num_inputs == infered_num_inputs (1 vs. 2) Operator UpSampling expects 2 inputs, but got 1 instead.

Stack trace returned 10 entries:
[bt] (0) /home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x289a1c) [0x7fe0ed9d6a1c]
[bt] (1) /home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x240538f) [0x7fe0efb5238f]
[bt] (2) /home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x24029a2) [0x7fe0efb4f9a2]
[bt] (3) /home/dia021/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x63) [0x7fe0efb4ffb3]
[bt] (4) /home/dia021/anaconda2/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7fe12e6dd57c]
[bt] (5) /home/dia021/anaconda2/lib/python2.7/lib-dynload/_ctypes.so(ffi_call+0x1f5) [0x7fe12e6dccd5]
[bt] (6) /home/dia021/anaconda2/lib/python2.7/lib-dynload/_ctypes.so(_ctypes_callproc+0x3e6) [0x7fe12e6d4376]
[bt] (7) /home/dia021/anaconda2/lib/python2.7/lib-dynload/_ctypes.so(+0x9db3) [0x7fe12e6cbdb3]
[bt] (8) /home/dia021/anaconda2/bin/../lib/libpython2.7.so.1.0(PyObject_Call+0x53) [0x7fe13375de93]
[bt] (9) /home/dia021/anaconda2/bin/../lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x715d) [0x7fe13381080d]
</code></pre>
","<python><mxnet>","2017-12-20 02:24:19","","0","3830606","2017-12-28 20:21:34","1","0","","","3830606","360","183","0"
"47193488","<p>1.When defining custom operator in MXNet with C++, how does the custom operator defined in C++ generate its python API automatically? 
2.How can I finde the corresponding codes?
3. What's the difference between defining custom operator with C++ and with python?  </p>
","<python><deep-learning><mxnet><custom-operator>","2017-11-09 03:35:56","","1","2854015","2017-11-20 21:49:40","1","0","","","2854015","6","0","0"
"47190614","<p>I have trained a network using MXnet, but am not sure how I can save and load the parameters for later use. First I define and train the network:</p>

<pre class=""lang-python prettyprint-override""><code>    dataIn = mx.sym.var('data')
    fc1 = mx.symbol.FullyConnected(data=dataIn, num_hidden=100)
    act1 = mx.sym.Activation(data=fc1, act_type=""relu"")
    fc2 = mx.symbol.FullyConnected(data=act1, num_hidden=50)
    act2 = mx.sym.Activation(data=fc2, act_type=""relu"")
    fc3 = mx.symbol.FullyConnected(data=act2, num_hidden=25)
    act3 = mx.sym.Activation(data=fc3, act_type=""relu"")
    fc4 = mx.symbol.FullyConnected(data=act3, num_hidden=10)
    act4 = mx.sym.Activation(data=fc4, act_type=""relu"")
    fc5 = mx.symbol.FullyConnected(data=act4, num_hidden=2)
    lenet = mx.sym.SoftmaxOutput(data=fc5, name='softmax',normalization = 'batch')


# create iterator around training and validation data
train_iter = mx.io.NDArrayIter(data=data[:ntrain], label = phen[:ntrain],batch_size=batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(data=data[ntrain:], label=phen[ntrain:], batch_size=batch_size)

# create a trainable module on GPU 0
lenet_model = mx.mod.Module(symbol=lenet, context=mx.gpu())
# train with the same
lenet_model.fit(train_iter,
                eval_data=val_iter,
                optimizer='adam',
                optimizer_params={'learning_rate':0.00001},
                eval_metric='f1',
                batch_end_callback = mx.callback.Speedometer(batch_size, 10),
                num_epoch=1000)
</code></pre>

<p>This model performs well on the test set, so I want to keep it. Next, I save the network layout and the parameterization:</p>

<pre class=""lang-python prettyprint-override""><code>lenet.save('./testNet_symbol.mxnet')
lenet_model.save_params('./testNet_module.mxnet')
</code></pre>

<p>All the documentation I can find on loading the network seem to have implemented the save function within the training routine, to save the network parameters at the end of each epoch. I haven't set these checkpoints during the training process Other methods use the mx.model.FeedForward class, which doesn't seem appropriate. Still other methods load the network from a .json file, which I don't have as a result of my save functions. How can I save/load a network after it's already finished training?</p>
","<deep-learning><mxnet>","2017-11-08 22:14:17","","3","4790950","2017-11-14 08:03:08","1","0","1","","4790950","128","1","0"
"49164123","<p>Is there a way to take MxNet model adn deploy it to embedded device directly? As ""embedded"", objective is to have super lightweight, optionally optimized for ARM/neon.</p>
","<mxnet>","2018-03-08 01:51:27","","0","2561862","2018-03-08 18:42:04","1","0","","","2561862","108","15","0"
"47569144","<p>I am using faster rcnn(mxnet) for object detection on my own dataset, which has 9 classes(including background). However, i found that in the end it only prints out the average accuracy over all 9 classes during trainning process. Furthermore, during test process, it also only prints out the average precision and recall over all 9 classes. I am wondering how can i print out each class's accuracy during the training process, and each class's recall and precision during the test process?
Or can someone tell me where should i look at to approach my goal?
An ideal example will be shown in the image. <a href=""https://i.stack.imgur.com/m6Tsr.jpg"" rel=""nofollow noreferrer"">enter image description here</a></p>
","<computer-vision><deep-learning><object-detection><mxnet>","2017-11-30 08:43:35","","1","7879764","2018-01-23 01:15:16","1","0","","","7879764","6","0","0"
"49171322","<p>I wanted to install <code>Mxnet library</code> and found on this forum the topic where was described how do it .</p>

<pre><code>  cran &lt;- getOption(""repos"")
    cran[""dmlc""] &lt;- ""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/""
    options(repos = cran)
    install.packages(""mxnet"")
    library(""mxnet"")
</code></pre>

<p>and then i got the error </p>

<pre><code>Error: package or namespace load failed for ‘mxnet’:
 object ‘set_global_graph_attrs’ is not exported from 'namespace:DiagrammeR'
</code></pre>

<p>what's wrong?
<code>DiagrammeR library</code> is installed.</p>
","<r><package><mxnet>","2018-03-08 10:51:10","","1","6357714","2018-03-08 22:49:29","2","0","","","6357714","633","316","2"
"39530875","<p>I wish to see exactly which cpu or gpu my mxnet program is running, so I add a <code>print self._ctx</code> at the source code of <a href=""https://github.com/dmlc/mxnet/blob/master/python/mxnet/executor.py"" rel=""nofollow"">executor.py</a>. 
Then I bind the executor with gup(10), but no error was thrown since I only have one gpu in my computer. Can someone explain this?</p>
","<python><machine-learning><neural-network><mxnet>","2016-09-16 11:54:56","","1","6839261","2016-11-07 19:37:10","1","0","","","6839261","6","0","0"
"41345033","<p>I rewrote an example available here (link to data in document) <a href=""https://github.com/dmlc/mxnet/blob/master/example/recommenders/demo1-MF.ipynb"" rel=""nofollow noreferrer"">https://github.com/dmlc/mxnet/blob/master/example/recommenders/demo1-MF.ipynb</a></p>

<pre><code>library(mxnet)


DF &lt;- read.delim(""./data/ml-100k/u.data"", header=F)
names(DF) &lt;- c(""user"", ""item"", ""score"", ""time"")

max_user&lt;- max(DF$user)
max_item &lt;- max(DF$item)

DF_mat_x &lt;- data.matrix(t(sapply(DF[,1:2], as.numeric)))
DF_y &lt;- DF[,3]

mx.io.arrayiter(DF_mat_x, t(data.matrix(data.frame(score=DF_y))))


k &lt;- 64


## model
user &lt;- mx.symbol.Variable(""user"")
item &lt;- mx.symbol.Variable(""item"")
score &lt;- mx.symbol.Variable(""label"")
## user feature lookup
user1 &lt;- mx.symbol.Embedding(data=user, input_dim = max_user, output_dim = k, name=""user1"") 
## item feature lookup
item1 &lt;- mx.symbol.Embedding(data=item, input_dim = max_item, output_dim = k, name=""item1"")
## predict by the inner product, which is elementwise product and then sum
pred &lt;- user1 * item1
pred1 &lt;- mx.symbol.sum_axis(pred, axis = 1, name=""pred1"")
pred2 &lt;- mx.symbol.Flatten(pred1, name=""pred2"")
## loss layer
pred3 &lt;- mx.symbol.LinearRegressionOutput(data=pred2, label=score, name=""pred3"")


devices &lt;- mx.cpu()
mx.set.seed(123)


mx.model.FeedForward.create(pred3, X =  mx.io.arrayiter(data=DF_mat_x,   label=t(data.matrix(data.frame(score=DF_y)))),
                            ctx=devices, num.round=10, array.batch.size=10,
                            verbose=T, #array.layout=""rowmajor"",
                            initializer=mx.init.uniform(0.07),  learning.rate=0.07,
                            eval.metric=mx.metric.rmse, momentum = 0.9,
                            epoch.end.callback=mx.callback.log.train.metric(1))
</code></pre>

<p>Get error</p>

<pre><code>[19:28:45] /root/mxnet/dmlc-core/include/dmlc/logging.h:235: [19:28:45]  src/symbol/symbol.cc:155: Symbol.InferShapeKeyword argument name data not  found.
Candidate arguments:
    [0]user
    [1]user1_weight
    [2]item
    [3]item1_weight
    [4]label

Error in symbol$infer.shape(list(...)) : basic_string::resize
&gt; traceback()
6: stop(list(message = ""basic_string::resize"", call =   symbol$infer.shape(list(...)), 
       cppstack = NULL))
5: .External(list(name = ""CppMethod__invoke_notvoid"", address = &lt;pointer: 0x11caef0&gt;, 
       dll = list(name = ""Rcpp"", path = ""/usr/local/lib/R/site-library/Rcpp/libs/Rcpp.so"", 
           dynamicLookup = TRUE, handle = &lt;pointer: 0x1404520&gt;, 
           info = &lt;pointer: 0x7f348a598d80&gt;), numParameters = -1L), 
       &lt;pointer: 0x3835820&gt;, &lt;pointer: 0x3836540&gt;, .pointer, ...)
4: symbol$infer.shape(list(...))
3: mx.symbol.infer.shape(symbol, data = input.shape)
2: mx.model.init.params(symbol, input.shape, initializer, mx.cpu())
1: mx.model.FeedForward.create(pred3, X = mx.io.arrayiter(data = DF_mat_x, 
        label = t(data.matrix(data.frame(score = DF_y)))), ctx = devices, 
        num.round = 10, array.batch.size = 10, verbose = T, initializer = mx.init.uniform(0.07), 
       learning.rate = 0.07, eval.metric = mx.metric.rmse, momentum = 0.9, 
       epoch.end.callback = mx.callback.log.train.metric(1))
</code></pre>

<p>Manually I get data one labels</p>

<pre><code>&gt; X &lt;- mx.io.arrayiter(data=DF_mat_x, label=t(data.matrix(data.frame(score=DF_y))))
&gt; Z &lt;- mxnet:::mx.model.init.iter(X, NULL, batch.size = 120, is.train = TRUE)
&gt; Z$iter.next()
[1] TRUE
&gt; Z$value()
$data
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
[1,]  196  186   22  244  166  298  115  253  305     6    62   286   200   210
[2,]  242  302  377   51  346  474  265  465  451    86   257  1014   222    40
     [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]
[1,]   224   303   122   194   291   234   119   167   299   291   308    95
[2,]    29   785   387   274  1042  1184   392   486   144   118     1   546
     [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]
[1,]    38   102    63   160    50   301   225   290    97   157   181   278
[2,]    95   768   277   234   246    98   193    88   194   274  1081   603
     [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]
[1,]   276     7    10   284   201   276   287   246   242   249    99   178
[2,]   796    32    16   304   979   564   327   201  1137   241     4   332
     [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]
[1,]   251    81   260    25    59    72    87   290    42   292   115    20
[2,]   100   432   322   181   196   679   384   143   423   515    20   288
     [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]
[1,]   201    13   246   138   167    60    57   223   189   243    92   246
[2,]   219   526   919    26   232   427   304   274   512    15  1049   416
     [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86]
[1,]   194   241   178   254   293   127   225   299   225   276   291   222
[2,]   165   690   248  1444     5   229   237   229   480    54   144   366
     [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98]
[1,]   267    42    11    95     8   162    87   279   145   119    62    62
[2,]   518   403   111   625   338    25  1016   154   275  1153   498   382
     [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108]
[1,]    28    135     32     90    286    293    216    166    250    271
[2,]   209     23    294    382    208    685    144    328    496    132
     [,109] [,110] [,111] [,112] [,113] [,114] [,115] [,116] [,117] [,118]
[1,]    160    265    198     42    168    110     58     90    271     62
[2,]    174    118    498     96    151    307    144    648    346     21
     [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] [,128]
[1,]    279    237     94    128    298     44    264    194     72    222
[2,]    832    514    789    485    317    195    200    385    195    750

$label
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]     [,14]
  [1,]    3    3    1    2    1    4    2    5    3     3     2     5       5     3
    [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]
[1,]     3     3     5     2     4     2     4     4     4     2     4     2
    [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]
[1,]     5     2     4     5     3     4     4     4     3     4     1     5
     [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]
[1,]     1     4     4     4     2     3     5     5     5     5     5     3
    [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]
[1,]     4     2     4     5     5     2     4     5     5     4     3     1
     [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]
[1,]     4     3     4     5     1     5     5     4     4     3     1     3
     [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86]
[1,]     4     2     4     3     3     5     5     3     5     3     5     4
     [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98]
[1,]     5     3     4     4     4     4     4     5     2     5     4     3
     [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108]
[1,]     4      4      3      5      4      3      4      5      4      5
     [,109] [,110] [,111] [,112] [,113] [,114] [,115] [,116] [,117] [,118]
[1,]      5      4      3      5      5      4      4      4      4      3
     [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] [,128]
[1,]      3      4      4      3      4      5      5      2      5      5
</code></pre>

<p>And the model does not see the data</p>

<p>Original example uses </p>

<pre><code>    user = mx.nd.array(user)
    item = mx.nd.array(item)
    score = mx.nd.array(score)
    return mx.io.NDArrayIter(data={'user':user,'item':item},label={'score':score}, 
                             batch_size=batch_size, shuffle=True)
</code></pre>

<p><strong>How do it properly in R?</strong></p>

<p>UPDATE</p>

<p>New network</p>

<pre><code>data &lt;- mx.symbol.Variable(""data"")
user &lt;- mx.symbol.transpose(mx.symbol.slice_axis(data=data, axis=0,    begin=1, end=2, name=""user""))
item &lt;- mx.symbol.transpose(mx.symbol.slice_axis(data=data, axis=0, begin=0, end=1, name=""item""))
score &lt;- mx.symbol.Variable(""label"")
## user feature lookup
user1 &lt;- mx.symbol.Embedding(data=user, input_dim = max_user, output_dim = k, name=""user1"")
## item feature lookup
item1 &lt;- mx.symbol.Embedding(data=item, input_dim = max_item, output_dim = k, name=""item1"")
## predict by the inner product, which is elementwise product and then sum
pred &lt;- user1 * item1
pred1 &lt;- mx.symbol.sum_axis(pred, axis = 1, name=""pred1"")
pred2 &lt;- mx.symbol.Flatten(pred1, name=""pred2"")
## loss layer
pred3 &lt;- mx.symbol.LinearRegressionOutput(data=pred2, label=score, name=""pred3"")


X.train.iter &lt;- mx.io.arrayiter(data=DF_mat_x,   label=t(data.matrix(data.frame(score=DF_y))))

mx.model.FeedForward.create(pred3, X = X.train.iter ,
                            ctx=devices, num.round=10, array.batch.size=10,
                            verbose=T, #array.layout=""colmajor"",
                            initializer=mx.init.uniform(0.07), learning.rate=0.07,
                            eval.metric=mx.metric.rmse, momentum = 0.9,
                          epoch.end.callback=mx.callback.log.train.metric(1))
</code></pre>

<p>Error</p>

<pre><code> Start training with 1 devices
[22:43:54] /root/mxnet/dmlc-core/include/dmlc/logging.h:235: [22:43:54]  src/ndarray/ndarray.cc:231: Check failed: from.shape() == to-&gt;shape() operands shape mismatch
Error in exec$update.arg.arrays(arg.arrays, match.name, skip.null) : 
  basic_string::resize
 traceback()
6: stop(list(message = ""basic_string::resize"", call =  exec$update.arg.arrays(arg.arrays, 
       match.name, skip.null), cppstack = NULL))
5: .External(list(name = ""CppMethod__invoke_void"", address = &lt;pointer: 0x18be2c0&gt;, 
       dll = list(name = ""Rcpp"", path = ""/usr/local/lib/R/site-library/Rcpp/libs/Rcpp.so"", 
           dynamicLookup = TRUE, handle = &lt;pointer: 0x2a27840&gt;, 
           info = &lt;pointer: 0x7f021bba2d80&gt;), numParameters = -1L), 
   &lt;pointer: 0x3c71d10&gt;, &lt;pointer: 0x3c61310&gt;, .pointer, ...)
4: exec$update.arg.arrays(arg.arrays, match.name, skip.null)
3: mx.exec.update.arg.arrays(train.execs[[i]], s, match.name = TRUE)
2: mx.model.train(symbol, ctx, input.shape, params$arg.params, params$aux.params, 
       begin.round, num.round, optimizer = optimizer, train.data = X, 
       eval.data = eval.data, metric = eval.metric, epoch.end.callback = epoch.end.callback, 
       batch.end.callback = batch.end.callback, kvstore = kvstore, 
   verbose = verbose)
1: mx.model.FeedForward.create(pred3, X = X.train.iter, ctx = devices, 
       num.round = 10, array.batch.size = 10, verbose = T, initializer = mx.init.uniform(0.07), 
       learning.rate = 0.07, eval.metric = mx.metric.rmse, momentum = 0.9, 
       epoch.end.callback = mx.callback.log.train.metric(1))
</code></pre>

<p>Model is created, but does not work.</p>
","<r><mxnet>","2016-12-27 12:15:58","","1","1887913","2016-12-30 22:47:58","1","0","","","1887913","60","10","0"
"51142720","<p>I'm using DEC from mxnet (<a href=""https://github.com/apache/incubator-mxnet/tree/master/example/deep-embedded-clustering"" rel=""nofollow noreferrer"">https://github.com/apache/incubator-mxnet/tree/master/example/deep-embedded-clustering</a>)</p>

<p>While it defaults to run on the MNIST, I have changed the datasource to several hundreds of documents (which should be perfectly fine, given that mxnet can work with the Reuters dataset)</p>

<p>The question; after training MXNET, how can I use it on new, unseen data? It shows me a new prediction each time!</p>

<p>Here is the code for collecting the dataset:</p>

<pre><code>vectorizer = TfidfVectorizer(dtype=np.float64, stop_words='english', max_features=2000, norm='l2', sublinear_tf=True).fit(training)

X = vectorizer.transform(training)
X = np.asarray(X.todense()) # * np.sqrt(X.shape[1])

Y = np.asarray(labels)
</code></pre>

<p>Here is the code for prediction:</p>

<pre><code>def predict(self, TrainX, X, update_interval=None):
    N = TrainX.shape[0]
    if not update_interval:
        update_interval = N
    batch_size = 256
    test_iter = mx.io.NDArrayIter({'data': TrainX}, batch_size=batch_size, shuffle=False,
                                  last_batch_handle='pad')
    args = {k: mx.nd.array(v.asnumpy(), ctx=self.xpu) for k, v in self.args.items()}
    z = list(model.extract_feature(self.feature, args, None, test_iter, N, self.xpu).values())[0]
    kmeans = KMeans(self.num_centers, n_init=20)
    kmeans.fit(z)

    args['dec_mu'][:] = kmeans.cluster_centers_
    print(args)

    sample_iter = mx.io.NDArrayIter({'data': X})
    z = list(model.extract_feature(self.feature, args, None, sample_iter, N, self.xpu).values())[0]
    p = np.zeros((z.shape[0], self.num_centers))
    self.dec_op.forward([z, args['dec_mu'].asnumpy()], [p])
    print(p)
    y_pred = p.argmax(axis=1)

    self.y_pred = y_pred
    return y_pred
</code></pre>

<p>Explanation: I thought I also need to pass a sample of the data I trained the system with. That is why you see both TrainX and X there.</p>

<p>Any help is greatly appreciated.</p>
","<machine-learning><deep-learning><mxnet>","2018-07-02 19:37:26","","0","7012349","2018-07-09 22:36:30","1","0","","","7012349","597","13","0"
"37293992","<p>Due to no step-by-step guidebook to learn how to use mxnet to train a  image-classification model or raise a model's accuracy which alreadly exist , for example, I have 5 classes iamges and I wanna to train a model which can classify these 5 classes things very well. plus, the mxnet guidebook failed to find the detail. How can I do?is there any github projects? </p>
","<python><neural-network><mxnet>","2016-05-18 08:21:14","","2","6349705","2016-08-02 01:54:58","1","0","","","6349705","11","0","0"
"48909615","<p>In my problem I have a vector containing <code>n</code> elements. Given a window size <code>k</code> I want to efficiently create a matrix size <code>n x 2k+1</code> which contains the banded diagonal. For example:</p>

<pre><code>a = [a_1, a_2, a_3, a_4]
k = 1
b = [[0, a_1, a_2],
    [a_1, a_2, a_3],
    [a_2, a_3, a_4],
    [a_3, a_4, a_5],
    [a_4, a_5, 0]]
</code></pre>

<p>The naive way to implement this would be using for loops</p>

<pre class=""lang-python prettyprint-override""><code>out_data = mx.ndarray.zeros((n, 2k+1))
for i in range(0, n):
    for j in range(0, 2k+1):
        index = i - k + j
        if not (index &lt; 0 or index &gt;= seq_len):
            out_data[i][j] = in_data[index]
</code></pre>

<p>This is very slow.</p>

<p>Creating the full matrix would be easy by just using <code>tile</code> and <code>reshape</code>, however the masking part is not clear. </p>

<p><strong>Update</strong>
I found a faster, yet still very slow, implementation:</p>

<pre><code>window = 2*self.windowSize + 1
in_data_reshaped = in_data.reshape((batch_size, seq_len))
out_data = mx.ndarray.zeros((seq_len * window))
for i in range(0, seq_len):
    copy_from_start = max(i - self.windowSize, 0)
    copy_from_end = min(seq_len -1, i+1+self.windowSize)
    copy_length = copy_from_end - copy_from_start
    copy_to_start = i*window + (2*self.windowSize + 1 - copy_length)
    copy_to_end = copy_to_start + copy_length
    out_data[copy_to_start:copy_to_end] = in_data_reshaped[copy_from_start:copy_from_end]
out_data = out_data.reshape((seq_len, window))
</code></pre>
","<python><mxnet>","2018-02-21 15:28:00","","1","3256397","2018-03-02 00:38:56","1","0","","","3256397","10","0","0"
"47630770","<p>When training a Deep Convolutional Neural Network using MxNet, what is the simplest way to turn on some amount of dropout in order to reduce overfitting? Is there a way to add a dropout rate without manually implementing dropout in the network architecture?</p>
","<deep-learning><mxnet>","2017-12-04 10:01:53","","0","1162647","2017-12-04 22:40:07","1","0","","","1162647","5649","160","1"
"47074388","<p>I want to install r studio on virtual machine to work with mxnet package.</p>

<p>Here is how to configure Rstudio on microsoft azzure linux virtual machine:
<a href=""http://moresi.de/posts/2016-04-02-setting-up-r-studio-server-on-microsoft-azure.html"" rel=""nofollow noreferrer"">http://moresi.de/posts/2016-04-02-setting-up-r-studio-server-on-microsoft-azure.html</a></p>

<p>And there is how to install mxnet packages for linux:
<a href=""https://mxnet.incubator.apache.org/get_started/install.html"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/get_started/install.html</a></p>

<p>My question is: If I will install R-studio and Mxnet package following the step in this 2 tutorial will I be able to use mxnet package from R Studio workspace?</p>

<p>Another question is: It is possible to install all availible r packages in this configuration from R studio workspace?</p>

<p>I know that maybe this is a trivial question, but i am completly new to microsoft azzure, and spend a lot of time looking for an answer on web. Its seems that there wasn't any exemple of using mxnet packages with R on cloud.I would be very grateful even for some tips : )</p>
","<r><linux><azure><cloud><mxnet>","2017-11-02 11:39:28","","0","8874034","2018-06-09 11:05:12","1","1","1","","8874034","1","0","0"
"47240559","<p>I'm running the mnist example of mxnet in Spyder IDE. The training does not progress, just as if the learning rate were <code>0</code> (see output below).</p>

<p>If I run the same file on the console using either <code>python</code> or <code>ipython</code>, it works as expected (seeing improvements in the second epoch).</p>

<p>If I run the file using the normal Python console of Spyder, it also works.
But if I run the file using the <code>ipython</code> console, I get the output shown below.</p>

<p>I'm new to Python. Any ideas?</p>

<h2>Source code</h2>

<pre><code>#!/usr/bin/env python2
# -*- coding: utf-8 -*-

#%%
import mxnet as mx

#%% load mnist

mnist = mx.test_utils.get_mnist()

#%% define data iterators

batch_size = 100
train_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)

#%% create input variable

data = mx.sym.var('data')
# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)
data = mx.sym.flatten(data=data)

#%% Multilayer Perceptron with softmax

# The first fully-connected layer and the corresponding activation function
fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)
act1 = mx.sym.Activation(data=fc1, act_type=""relu"")

# The second fully-connected layer and the corresponding activation function
fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)
act2 = mx.sym.Activation(data=fc2, act_type=""relu"")

# MNIST has 10 classes
fc3  = mx.sym.FullyConnected(data=act2, num_hidden=10)
# Softmax with cross entropy loss
mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')

#%% Training
import logging
logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout
# create a trainable module on CPU
mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())
mlp_model.fit(train_iter,  # train data
              eval_data=val_iter,  # validation data
              optimizer='sgd',  # use SGD to train
              optimizer_params={'learning_rate':0.1},  # use fixed learning rate
              eval_metric='acc',  # report accuracy during training
              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches
              num_epoch=10)  # train for at most 10 dataset passes
</code></pre>

<h2>Output of <code>ipython</code> console in Spyder</h2>

<pre><code>runfile('/home/thomas/workspace/clover-python/mnist.py', wdir='/home/thomas/workspace/clover-python')
INFO:root:train-labels-idx1-ubyte.gz exists, skipping download
INFO:root:train-images-idx3-ubyte.gz exists, skipping download
INFO:root:t10k-labels-idx1-ubyte.gz exists, skipping download
INFO:root:t10k-images-idx3-ubyte.gz exists, skipping download
INFO:root:Epoch[0] Batch [100]  Speed: 1304.05 samples/sec      accuracy=0.097921
INFO:root:Epoch[0] Batch [200]  Speed: 1059.19 samples/sec      accuracy=0.098200
INFO:root:Epoch[0] Batch [300]  Speed: 1178.64 samples/sec      accuracy=0.099600
INFO:root:Epoch[0] Batch [400]  Speed: 1292.71 samples/sec      accuracy=0.098900
INFO:root:Epoch[0] Batch [500]  Speed: 1394.21 samples/sec      accuracy=0.096500
INFO:root:Epoch[0] Train-accuracy=0.101212
INFO:root:Epoch[0] Time cost=47.798
INFO:root:Epoch[0] Validation-accuracy=0.098000
INFO:root:Epoch[1] Batch [100]  Speed: 1247.47 samples/sec      accuracy=0.097921
INFO:root:Epoch[1] Batch [200]  Speed: 1673.79 samples/sec      accuracy=0.098200
INFO:root:Epoch[1] Batch [300]  Speed: 1283.91 samples/sec      accuracy=0.099600
INFO:root:Epoch[1] Batch [400]  Speed: 1247.79 samples/sec      accuracy=0.098900
INFO:root:Epoch[1] Batch [500]  Speed: 1371.93 samples/sec      accuracy=0.096500
INFO:root:Epoch[1] Train-accuracy=0.101212
INFO:root:Epoch[1] Time cost=44.201
INFO:root:Epoch[1] Validation-accuracy=0.098000
INFO:root:Epoch[2] Batch [100]  Speed: 1387.72 samples/sec      accuracy=0.097921
INFO:root:Epoch[2] Batch [200]  Speed: 1196.37 samples/sec      accuracy=0.098200
INFO:root:Epoch[2] Batch [300]  Speed: 1220.44 samples/sec      accuracy=0.099600
INFO:root:Epoch[2] Batch [400]  Speed: 1387.75 samples/sec      accuracy=0.098900
INFO:root:Epoch[2] Batch [500]  Speed: 1279.58 samples/sec      accuracy=0.096500
INFO:root:Epoch[2] Train-accuracy=0.101212
INFO:root:Epoch[2] Time cost=46.929
INFO:root:Epoch[2] Validation-accuracy=0.098000
INFO:root:Epoch[3] Batch [100]  Speed: 1266.24 samples/sec      accuracy=0.097921

and so on…
</code></pre>
","<ipython><spyder><mxnet>","2017-11-11 17:05:28","","0","108915","2017-12-08 22:39:37","2","0","","","108915","19965","2046","370"
"46965919","<p>Recently, I learned mxnet, by following the tutorials in <code>mxnet.io</code>. In Handwritten Digit Recognition, I run the following code:</p>

<pre><code>import mxnet as mx
mnist = mx.test_utils.get_mnist()
</code></pre>

<p>It shows:</p>

<pre><code>---------------------------------------------------------------------------
error                                     Traceback (most recent call last)
&lt;ipython-input-1-9ce98614649e&gt; in &lt;module&gt;()
      1 import mxnet as mx
----&gt; 2 mnist=mx.test_utils.get_mnist()

/home/lthpc/mxnet/python/mxnet/test_utils.pyc in get_mnist()
   1014     path = 'http://data.mxnet.io/data/mnist/'
   1015     (train_lbl, train_img) = read_data(
-&gt; 1016         path+'train-labels-idx1-ubyte.gz', path+'train-images-idx3-ubyte.gz')
   1017     (test_lbl, test_img) = read_data(
   1018         path+'t10k-labels-idx1-ubyte.gz', path+'t10k-images-idx3-ubyte.gz')

/home/lthpc/mxnet/python/mxnet/test_utils.pyc in read_data(label_url, image_url)
   1002     def read_data(label_url, image_url):
   1003         with gzip.open(mx.test_utils.download(label_url)) as flbl:
-&gt; 1004             struct.unpack(""&gt;II"", flbl.read(8))
   1005             label = np.fromstring(flbl.read(), dtype=np.int8)
   1006         with gzip.open(mx.test_utils.download(image_url), 'rb') as fimg:

error: unpack requires a string argument of length 8
</code></pre>

<p>How can I fix this?</p>
","<python><ipython-notebook><mxnet>","2017-10-27 00:52:16","","0","8089410","2017-10-27 18:01:04","1","0","","","8089410","8","0","0"
"55516323","<p>we're training a network for a recommender system, on  triplets. The core code for the fit method is as follows:</p>

<pre><code>for e in range(epochs):
    start = time.time()

    cumulative_loss = 0

    for i, batch in enumerate(train_iterator):
        # Forward + backward.
        with autograd.record():
            output = self.model(batch.data[0])
            loss = loss_fn(output, batch.label[0])

        # Calculate gradients
        loss.backward()
        # Update parameters of the network.
        trainer_fn.step(batch_size)
        # Calculate training metrics. Sum losses of every batch.
        cumulative_loss += nd.mean(loss).asscalar()
    train_iterator.reset()
</code></pre>

<p>where the <code>train_iterator</code> is a custom iterator class that inherits from <code>mx.io.DataIter</code>, and is returning the data ( triples) already in the appropriate context, as:</p>

<pre><code>        data = [mx.nd.array(data[:, :-1], self.ctx, dtype=np.int)]
        labels = [mx.nd.array(data[:, -1], self.ctx)]
        return mx.io.DataBatch(data, labels)
</code></pre>

<p><code>self.model.initialize(ctx=mx.gpu(0))</code> was also called before running the <code>fit</code> method. <code>loss_fn = gluon.loss.L1Loss()</code>.</p>

<p>The trouble is that <code>nvidia-smi</code> reports that the process is correctly allocated into GPU. However, running <code>fit</code> in GPU is not much faster than running it in CPU. In addition, increasing <code>batch_size</code> from 50000 to 500000 increases time per batch by a factor of 10 (which I was not expecting, given GPU parallelization). </p>

<p>Specifically, for a 50k batch:
* <code>output = self.model(batch.data[0])</code> takes 0.03 seconds on GPU, and 0.08 on CPU.
* <code>loss.backward()</code> takes 0.11 seconds, and 0.39 on CPU.</p>

<p>both assessed with <code>nd.waitall()</code> to avoid asynchronous calls leading to incorrect measurements.</p>

<p>In addition, a very similar code that was running on plain MXNet took less than 0.03 seconds for the corresponding part, which leads to a full epoch taking from slightly above one minute with MXNet, up to 15 minutes with Gluon.</p>

<p>Any ideas on what might be happening here? </p>

<p>Thanks in advance!</p>
","<mxnet>","2019-04-04 12:44:14","","0","10109789","2019-04-23 15:59:15","1","0","","","10109789","171","5","0"
"46963622","<p>I am getting this error message </p>

<blockquote>
  <p>Error in mx.model.select.layout.train(X, y) :  Cannot auto select
  array.layout, please specify this parameter</p>
</blockquote>

<p>I am trying to create simple model to understand how things work</p>

<h1>create data</h1>

<pre><code>train.x &lt;- data.matrix(sample(1:100,1000,replace=T) )
colnames(train.x) &lt;- ""X""
train.y &lt;- data.matrix(train.x^2)
colnames(train.y) &lt;- ""Y""

test.x = data.matrix(sample(1:100,50,replace=T) )
colnames(test.x) &lt;- ""X""
test.y &lt;-data.matrix(test.x^2)
colnames(test.y) &lt;- ""Y""
</code></pre>

<h1>test data</h1>

<pre><code>mx.set.seed(0)
model &lt;- mx.mlp(train.x, train.y, hidden_node=10, out_node=2, 
out_activation=""softmax"",
num.round=20, array.batch.size=15, learning.rate=0.07, momentum=0.9,
eval.metric=mx.metric.accuracy)
</code></pre>
","<mxnet>","2017-10-26 20:53:42","","0","8840214","2017-12-11 19:45:31","1","0","","","8840214","1","0","0"
"47634190","<p>I am using the <strong>Passenger Screening Challenge</strong> from the <strong>Kaggle</strong> website for a class project.  </p>

<p>I've implemented an out-of-the-box <strong>Convolutional Neural Network</strong> from this tutorial: <a href=""https://www.r-bloggers.com/image-recognition-tutorial-in-r-using-deep-convolutional-neural-networks-mxnet-package/"" rel=""nofollow noreferrer"">https://www.r-bloggers.com/image-recognition-tutorial-in-r-using-deep-convolutional-neural-networks-mxnet-package/</a>.  </p>

<p>Here is the code from the tutorial for the architecture:</p>

<pre><code># 1st convolutional layer
conv_1 &lt;- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)
tanh_1 &lt;- mx.symbol.Activation(data = conv_1, act_type = ""tanh"")
pool_1 &lt;- mx.symbol.Pooling(data = tanh_1, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))
# 2nd convolutional layer
conv_2 &lt;- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)
tanh_2 &lt;- mx.symbol.Activation(data = conv_2, act_type = ""tanh"")
pool_2 &lt;- mx.symbol.Pooling(data=tanh_2, pool_type = ""max"", kernel = c(2, 2), stride = c(2, 2))
# 1st fully connected layer
flatten &lt;- mx.symbol.Flatten(data = pool_2)
fc_1 &lt;- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)
tanh_3 &lt;- mx.symbol.Activation(data = fc_1, act_type = ""tanh"")
# 2nd fully connected layer
fc_2 &lt;- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)
# Output. Softmax output since we'd like to get some probabilities.
NN_model &lt;- mx.symbol.SoftmaxOutput(data = fc_2)
</code></pre>

<p>However, I have a question about the <code>num_hidden</code> on the <code>fc_2</code>. In the tutorial, this number was 40 because there were 40 classes.  </p>

<p>In my example, I'm determining if there is a threat present on an image or not.  Would my <code>num_hidden</code> in the last fully connected layer be 2 (threat present or no threat) or 1 (probability that there is a threat present?  Am I overthinking?  </p>

<p>Thanks so much for any help.</p>
","<neural-network><conv-neural-network><convolution><mxnet><softmax>","2017-12-04 13:11:14","","1","9050965","2017-12-04 22:43:11","1","1","","","9050965","6","0","0"
"39197658","<p>I've found RNN symbol is added in mxnet v0.7 python lib.
Now, I'm trying to use it to impl lstm in example/rnn with python.
But I have no idea because there's no document or any information of the input and output.
Can anyone give me any advice?
thanks</p>
","<deep-learning><mxnet>","2016-08-29 02:14:23","","2","6768307","2016-09-19 02:56:27","1","0","1","","6768307","18","0","0"
"53987045","<p>I referred to <a href=""https://github.com/omoindrot/tensorflow-triplet-loss"" rel=""nofollow noreferrer"">this</a> implementation in tensorflow. Itrequires the shape of the output batch embeddings but I can't get the actual shape of an mxnet symbol. Any ideas how?</p>
","<mxnet>","2018-12-31 11:39:49","","0","10851740","2019-01-04 16:44:17","1","0","","","10851740","1","0","0"
"47297354","<p>After I have trained a model, how do I use it with C++? </p>

<p>I have tried MXNet <code>incubator-mxnet/example/image-classification/predict-cpp/</code>
 and <code>incubator-mxnet/cpp-package/example/</code>.</p>
","<c++><mxnet>","2017-11-15 00:08:47","","0","8941985","2018-05-04 21:24:48","1","9","","","8941985","4","0","0"
"47002369","<p>I want to plot or visualize  the result of each layers out from a trained CNN with mxnet in R. Like w´those abstract art from what a nn's each layer can see.</p>

<p>But I don't know how. Please somebody help me. One way I can think out is to put the weights and bias back to every step and plot the step out. But when I try to put <code>model$arg.params$convolution0_weight</code> back to <code>mx.symbol.Convolution()</code>, I get </p>

<pre><code>Error in mx.varg.symbol.Convolution(list(...)) : 
  ./base.h:291: Unsupported parameter type object type for argument weight, expect integer, logical, or string.
</code></pre>

<p>Can anyone help me?</p>
","<r><layer><convolution><mxnet><visualize>","2017-10-29 16:12:11","","1","8852268","2018-02-14 01:38:58","2","0","","","8852268","6","0","0"
"41918693","<p>I am struggling to understand the symbolic API nuances of MXNet in Julia. I saw an example in MXNet documentation which has the following line:</p>

<pre><code>act1 = mx.Activation(data = fc1, name=:relu1, act_type=:relu)
</code></pre>

<p>Why is <code>act_type</code> assigned the symbol <code>:relu</code>.?</p>

<p>Is <code>:relu</code> a function pointer? If not, then where do we assign the value to <code>:relu</code> symbol? Why is data not assigned a symbol?  Why is name assigned a symbol rather than a string?</p>
","<julia><mxnet>","2017-01-29 07:43:19","","0","7463041","2017-01-31 04:34:39","1","0","","","7463041","81","8","0"
"44736543","<p>I am following <a href=""http://mxnet.io/get_started/windows_setup.html"" rel=""nofollow noreferrer"">http://mxnet.io/get_started/windows_setup.html</a> to generate libmxnet.dll using the prebuild package for windows.</p>

<p>I have downloaded the nightly prebuild release from windows here <a href=""https://github.com/yajiedesign/mxnet/releases"" rel=""nofollow noreferrer"">https://github.com/yajiedesign/mxnet/releases</a> packe 20170624_mxnet_x64_vc14_gpu.</p>

<p>Step 4 in the procedure request that I should build the windows studio solution to generate the libmxnet.dll. This step does not mention the name or location of the solution file, so I have searched for *.sln and *.suo but it is nowhere.</p>

<p>Does anybody know if I have picked the wrong package for download or what else can be wrong? </p>
","<visual-studio-2015><mxnet>","2017-06-24 12:47:14","","0","8209058","2017-06-25 05:01:12","1","0","","","8209058","1","0","0"